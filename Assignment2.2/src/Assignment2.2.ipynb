{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.1.post3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.is_available(),torch.cuda.current_device(),torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78200, 1, 32, 32), (78200,), (4600, 1, 32, 32), (4600,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train=pd.read_csv('devanagri_data/train_data_shuffled.csv',header=None)\n",
    "# X_test=pd.read_csv('devanagri_data/public_test.csv',header=None)\n",
    "# X_train,y_train=X_train.iloc[:,:-1].to_numpy().astype(np.float32),X_train.iloc[:,-1].to_numpy().astype(np.float32)\n",
    "# X_test,y_test=X_test.iloc[:,:-1].to_numpy().astype(np.float32),X_test.iloc[:,-1].to_numpy().astype(np.float32)\n",
    "# X_train,X_test=X_train.reshape((-1,1,32,32)),X_test.reshape((-1,1,32,32))\n",
    "# X_train.shape,y_train.shape,X_test.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class dev_dataset(Dataset):\n",
    "#     X=y=l=0\n",
    "#     def __init__(self,X,y):\n",
    "#         self.l=X.shape[0]\n",
    "#         self.X=torch.from_numpy(X).cuda()\n",
    "#         self.y=torch.LongTensor(y).cuda()\n",
    "#     def __len__(self):\n",
    "#         return self.l\n",
    "#     def __getitem__(self,i):\n",
    "#         return self.X[i],self.y[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN_A(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN_A,self).__init__()\n",
    "#         self.c1=nn.Conv2d(1,32,3)\n",
    "#         self.bn1=nn.BatchNorm2d(32)\n",
    "#         self.c2=nn.Conv2d(32,64,3)\n",
    "#         self.bn2=nn.BatchNorm2d(64)\n",
    "#         self.c3=nn.Conv2d(64,256,3)\n",
    "#         self.bn3=nn.BatchNorm2d(256)\n",
    "#         self.c4=nn.Conv2d(256,512,3)\n",
    "#         self.fc1=nn.Linear(512,256)\n",
    "#         self.fc2=nn.Linear(256,46)\n",
    "#         self.dropout=nn.Dropout(.2)\n",
    "#         self.p1=nn.MaxPool2d(2,1)\n",
    "#         self.p2=nn.MaxPool2d(2,2)\n",
    "#     def forward(self,X):\n",
    "#         X=self.p2(F.relu(self.bn1(self.c1(X))))\n",
    "#         X=self.p2(F.relu(self.bn2(self.c2(X)))) \n",
    "#         X=self.p1(F.relu(self.bn3(self.c3(X))))        \n",
    "#         X=F.relu(self.c4(X))\n",
    "#         X=X.view(-1,512)\n",
    "#         X=self.fc2(self.dropout(F.relu(self.fc1(X))))\n",
    "#         return X\n",
    "# def acc(y_true,y_preds):\n",
    "#     y_preds=torch.argmax(y_preds,dim=1).squeeze()\n",
    "#     return (y_true==y_preds).sum().item()/len(y_true)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=CNN_A().cuda()\n",
    "# b=dev_dataset(X_train,y_train)\n",
    "# d=a.forward(b.__getitem__(0)[0].reshape(1,1,32,32))\n",
    "# d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs=400\n",
    "# train_data=DataLoader(dev_dataset(X_train,y_train),batch_size=bs,shuffle=False)\n",
    "# # X_train,y_train=torch.from_numpy(X_train).cuda(),torch.LongTensor(y_train).cuda()\n",
    "# X_test,y_test=torch.from_numpy(X_test).cuda(),torch.LongTensor(y_test).cuda()\n",
    "# cnn=CNN_A()\n",
    "# cnn=cnn.cuda()\n",
    "# opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "# loss=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(cnn,train_data,epochs,opt,loss,X_test,y_test):\n",
    "#     losses=[]\n",
    "#     accuracies=[]\n",
    "#     for i in range(epochs):\n",
    "#         l=0\n",
    "#         for j,(X,y) in enumerate(train_data):\n",
    "#             #print(X.shape,y.shape,type(X),type(y))\n",
    "#             yh=cnn(X)\n",
    "#             train_loss=loss(yh,y)\n",
    "#             opt.zero_grad()\n",
    "#             l+=train_loss.item()\n",
    "#             train_loss.backward()\n",
    "#             opt.step()\n",
    "#         l/=len(train_data) \n",
    "#         with torch.no_grad():\n",
    "#             losses.append(l)\n",
    "#             y_preds=cnn(X_test)\n",
    "#             accuracies.append(acc(y_test,y_preds))\n",
    "#             print(\"Epoch: \"+str(i+1)+\" Train loss: \"+str(losses[-1])+\" test accuracy: \" +str(accuracies[-1]))        \n",
    "#     return losses,accuracies      \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 2.141618229600848 test accuracy: 0.7615217391304347\n",
      "Epoch: 2 Train loss: 0.625746605803772 test accuracy: 0.8797826086956522\n",
      "Epoch: 3 Train loss: 0.3616248066632115 test accuracy: 0.9202173913043479\n",
      "Epoch: 4 Train loss: 0.2501646329705812 test accuracy: 0.9382608695652174\n",
      "Epoch: 5 Train loss: 0.18843132512149763 test accuracy: 0.9482608695652174\n",
      "Epoch: 6 Train loss: 0.15078934339084188 test accuracy: 0.9558695652173913\n",
      "Epoch: 7 Train loss: 0.12248340952305162 test accuracy: 0.9602173913043478\n",
      "Epoch: 8 Train loss: 0.1014196918517047 test accuracy: 0.9634782608695652\n"
     ]
    }
   ],
   "source": [
    "# epochs=8\n",
    "# losses,accuracies=train(cnn,train_data,epochs,opt,loss,X_test,y_test)\n",
    "\n",
    "# f=open('loss.txt','w')\n",
    "# for l in losses:\n",
    "#     f.write(str(l))\n",
    "#     f.write('\\n')\n",
    "# f.close()    \n",
    "# f=open('accuracy.txt','w')\n",
    "# for l in accuracies:\n",
    "#     f.write(str(l))\n",
    "#     f.write('\\n')\n",
    "# f.close()\n",
    "# torch.save(cnn.state_dict(),'./model.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "38\n",
      "11\n",
      "30\n",
      "17\n",
      "9\n",
      "6\n",
      "41\n",
      "31\n",
      "16\n",
      "5\n",
      "14\n",
      "9\n",
      "21\n",
      "6\n",
      "7\n",
      "14\n",
      "19\n",
      "10\n",
      "45\n",
      "25\n",
      "20\n",
      "23\n",
      "18\n",
      "2\n",
      "26\n",
      "6\n",
      "30\n",
      "30\n",
      "11\n",
      "19\n",
      "25\n",
      "43\n",
      "1\n",
      "27\n",
      "30\n",
      "8\n",
      "33\n",
      "45\n",
      "27\n",
      "23\n",
      "28\n",
      "18\n",
      "44\n",
      "29\n",
      "45\n",
      "10\n",
      "3\n",
      "44\n",
      "39\n",
      "27\n",
      "33\n",
      "15\n",
      "1\n",
      "29\n",
      "10\n",
      "11\n",
      "17\n",
      "6\n",
      "42\n",
      "4\n",
      "25\n",
      "14\n",
      "13\n",
      "2\n",
      "15\n",
      "7\n",
      "14\n",
      "17\n",
      "38\n",
      "45\n",
      "24\n",
      "13\n",
      "25\n",
      "35\n",
      "24\n",
      "44\n",
      "38\n",
      "3\n",
      "28\n",
      "39\n",
      "25\n",
      "21\n",
      "35\n",
      "31\n",
      "28\n",
      "37\n",
      "35\n",
      "35\n",
      "15\n",
      "42\n",
      "44\n",
      "20\n",
      "39\n",
      "5\n",
      "31\n",
      "32\n",
      "15\n",
      "1\n",
      "9\n",
      "1\n",
      "12\n",
      "23\n",
      "40\n",
      "23\n",
      "40\n",
      "16\n",
      "20\n",
      "24\n",
      "40\n",
      "41\n",
      "19\n",
      "28\n",
      "3\n",
      "44\n",
      "15\n",
      "35\n",
      "33\n",
      "17\n",
      "27\n",
      "20\n",
      "31\n",
      "34\n",
      "12\n",
      "14\n",
      "39\n",
      "23\n",
      "15\n",
      "43\n",
      "41\n",
      "23\n",
      "0\n",
      "26\n",
      "32\n",
      "32\n",
      "45\n",
      "40\n",
      "17\n",
      "22\n",
      "21\n",
      "1\n",
      "36\n",
      "27\n",
      "22\n",
      "41\n",
      "19\n",
      "6\n",
      "10\n",
      "2\n",
      "6\n",
      "8\n",
      "34\n",
      "9\n",
      "25\n",
      "16\n",
      "28\n",
      "12\n",
      "20\n",
      "22\n",
      "40\n",
      "19\n",
      "45\n",
      "42\n",
      "2\n",
      "15\n",
      "4\n",
      "44\n",
      "28\n",
      "39\n",
      "13\n",
      "33\n",
      "28\n",
      "33\n",
      "5\n",
      "45\n",
      "1\n",
      "36\n",
      "27\n",
      "38\n",
      "15\n",
      "42\n",
      "13\n",
      "39\n",
      "23\n",
      "5\n",
      "12\n",
      "18\n",
      "7\n",
      "33\n",
      "10\n",
      "36\n",
      "34\n",
      "36\n",
      "41\n",
      "13\n",
      "37\n",
      "25\n",
      "8\n",
      "45\n",
      "29\n",
      "2\n",
      "8\n",
      "1\n",
      "15\n",
      "14\n",
      "25\n",
      "19\n",
      "13\n",
      "7\n",
      "7\n",
      "14\n",
      "41\n",
      "2\n",
      "19\n",
      "1\n",
      "13\n",
      "43\n",
      "33\n",
      "43\n",
      "11\n",
      "20\n",
      "4\n",
      "0\n",
      "43\n",
      "33\n",
      "14\n",
      "27\n",
      "31\n",
      "4\n",
      "27\n",
      "20\n",
      "29\n",
      "7\n",
      "36\n",
      "35\n",
      "31\n",
      "9\n",
      "21\n",
      "42\n",
      "33\n",
      "30\n",
      "43\n",
      "25\n",
      "30\n",
      "45\n",
      "10\n",
      "20\n",
      "28\n",
      "6\n",
      "27\n",
      "42\n",
      "25\n",
      "27\n",
      "28\n",
      "4\n",
      "16\n",
      "19\n",
      "9\n",
      "5\n",
      "20\n",
      "2\n",
      "29\n",
      "28\n",
      "32\n",
      "38\n",
      "17\n",
      "8\n",
      "38\n",
      "25\n",
      "15\n",
      "14\n",
      "31\n",
      "40\n",
      "3\n",
      "19\n",
      "24\n",
      "1\n",
      "18\n",
      "43\n",
      "29\n",
      "21\n",
      "41\n",
      "15\n",
      "16\n",
      "44\n",
      "28\n",
      "39\n",
      "12\n",
      "1\n",
      "32\n",
      "10\n",
      "6\n",
      "19\n",
      "11\n",
      "3\n",
      "26\n",
      "19\n",
      "14\n",
      "37\n",
      "30\n",
      "20\n",
      "34\n",
      "23\n",
      "36\n",
      "21\n",
      "0\n",
      "36\n",
      "30\n",
      "27\n",
      "15\n",
      "40\n",
      "45\n",
      "36\n",
      "39\n",
      "13\n",
      "16\n",
      "35\n",
      "25\n",
      "40\n",
      "34\n",
      "31\n",
      "16\n",
      "31\n",
      "27\n",
      "20\n",
      "9\n",
      "41\n",
      "31\n",
      "41\n",
      "3\n",
      "16\n",
      "19\n",
      "11\n",
      "45\n",
      "8\n",
      "29\n",
      "15\n",
      "36\n",
      "45\n",
      "45\n",
      "40\n",
      "0\n",
      "32\n",
      "22\n",
      "19\n",
      "13\n",
      "40\n",
      "23\n",
      "31\n",
      "7\n",
      "17\n",
      "17\n",
      "39\n",
      "24\n",
      "22\n",
      "31\n",
      "5\n",
      "39\n",
      "0\n",
      "34\n",
      "2\n",
      "27\n",
      "33\n",
      "11\n",
      "34\n",
      "3\n",
      "24\n",
      "44\n",
      "40\n",
      "29\n",
      "23\n",
      "12\n",
      "23\n",
      "1\n",
      "17\n",
      "12\n",
      "25\n",
      "12\n",
      "42\n",
      "8\n",
      "19\n",
      "3\n",
      "13\n",
      "39\n",
      "31\n",
      "37\n",
      "16\n",
      "35\n",
      "42\n",
      "20\n",
      "35\n",
      "39\n",
      "4\n",
      "23\n",
      "32\n",
      "5\n",
      "33\n",
      "12\n",
      "16\n",
      "19\n",
      "22\n",
      "1\n",
      "10\n",
      "43\n",
      "28\n",
      "24\n",
      "27\n",
      "17\n",
      "37\n",
      "20\n",
      "18\n",
      "29\n",
      "39\n",
      "15\n",
      "21\n",
      "16\n",
      "6\n",
      "12\n",
      "36\n",
      "27\n",
      "5\n",
      "45\n",
      "4\n",
      "25\n",
      "19\n",
      "7\n",
      "37\n",
      "20\n",
      "31\n",
      "22\n",
      "23\n",
      "33\n",
      "45\n",
      "16\n",
      "21\n",
      "23\n",
      "17\n",
      "44\n",
      "38\n",
      "43\n",
      "16\n",
      "30\n",
      "2\n",
      "9\n",
      "11\n",
      "16\n",
      "23\n",
      "8\n",
      "4\n",
      "43\n",
      "30\n",
      "28\n",
      "44\n",
      "0\n",
      "33\n",
      "26\n",
      "12\n",
      "26\n",
      "33\n",
      "31\n",
      "42\n",
      "18\n",
      "25\n",
      "7\n",
      "43\n",
      "25\n",
      "5\n",
      "12\n",
      "39\n",
      "10\n",
      "10\n",
      "43\n",
      "21\n",
      "14\n",
      "1\n",
      "3\n",
      "25\n",
      "13\n",
      "40\n",
      "5\n",
      "28\n",
      "34\n",
      "40\n",
      "43\n",
      "22\n",
      "28\n",
      "10\n",
      "20\n",
      "45\n",
      "33\n",
      "10\n",
      "3\n",
      "22\n",
      "7\n",
      "42\n",
      "4\n",
      "15\n",
      "22\n",
      "25\n",
      "29\n",
      "38\n",
      "38\n",
      "35\n",
      "10\n",
      "5\n",
      "17\n",
      "37\n",
      "38\n",
      "4\n",
      "33\n",
      "34\n",
      "9\n",
      "14\n",
      "40\n",
      "16\n",
      "21\n",
      "41\n",
      "10\n",
      "12\n",
      "4\n",
      "17\n",
      "12\n",
      "32\n",
      "23\n",
      "21\n",
      "15\n",
      "14\n",
      "10\n",
      "18\n",
      "5\n",
      "34\n",
      "45\n",
      "17\n",
      "25\n",
      "41\n",
      "33\n",
      "5\n",
      "43\n",
      "6\n",
      "43\n",
      "9\n",
      "37\n",
      "43\n",
      "27\n",
      "12\n",
      "36\n",
      "42\n",
      "31\n",
      "28\n",
      "31\n",
      "14\n",
      "35\n",
      "22\n",
      "30\n",
      "16\n",
      "9\n",
      "4\n",
      "29\n",
      "28\n",
      "19\n",
      "14\n",
      "8\n",
      "1\n",
      "38\n",
      "35\n",
      "38\n",
      "3\n",
      "8\n",
      "40\n",
      "15\n",
      "1\n",
      "21\n",
      "17\n",
      "42\n",
      "1\n",
      "26\n",
      "39\n",
      "39\n",
      "13\n",
      "3\n",
      "33\n",
      "10\n",
      "17\n",
      "32\n",
      "7\n",
      "33\n",
      "3\n",
      "1\n",
      "6\n",
      "34\n",
      "32\n",
      "3\n",
      "18\n",
      "44\n",
      "28\n",
      "13\n",
      "35\n",
      "2\n",
      "36\n",
      "45\n",
      "2\n",
      "6\n",
      "36\n",
      "24\n",
      "20\n",
      "45\n",
      "44\n",
      "40\n",
      "34\n",
      "21\n",
      "33\n",
      "38\n",
      "16\n",
      "40\n",
      "24\n",
      "18\n",
      "27\n",
      "4\n",
      "10\n",
      "25\n",
      "38\n",
      "38\n",
      "43\n",
      "43\n",
      "36\n",
      "41\n",
      "31\n",
      "38\n",
      "28\n",
      "37\n",
      "11\n",
      "40\n",
      "37\n",
      "11\n",
      "19\n",
      "17\n",
      "43\n",
      "23\n",
      "35\n",
      "1\n",
      "30\n",
      "5\n",
      "10\n",
      "32\n",
      "45\n",
      "39\n",
      "11\n",
      "9\n",
      "19\n",
      "19\n",
      "17\n",
      "15\n",
      "1\n",
      "32\n",
      "35\n",
      "40\n",
      "28\n",
      "26\n",
      "7\n",
      "1\n",
      "36\n",
      "1\n",
      "41\n",
      "34\n",
      "39\n",
      "43\n",
      "5\n",
      "41\n",
      "10\n",
      "26\n",
      "18\n",
      "20\n",
      "12\n",
      "1\n",
      "26\n",
      "26\n",
      "17\n",
      "0\n",
      "6\n",
      "5\n",
      "18\n",
      "37\n",
      "11\n",
      "34\n",
      "29\n",
      "29\n",
      "39\n",
      "42\n",
      "21\n",
      "9\n",
      "27\n",
      "35\n",
      "3\n",
      "34\n",
      "7\n",
      "17\n",
      "41\n",
      "30\n",
      "19\n",
      "4\n",
      "9\n",
      "40\n",
      "39\n",
      "11\n",
      "43\n",
      "39\n",
      "16\n",
      "3\n",
      "31\n",
      "34\n",
      "16\n",
      "18\n",
      "39\n",
      "44\n",
      "14\n",
      "32\n",
      "29\n",
      "32\n",
      "3\n",
      "15\n",
      "24\n",
      "7\n",
      "3\n",
      "25\n",
      "33\n",
      "34\n",
      "43\n",
      "1\n",
      "43\n",
      "14\n",
      "1\n",
      "14\n",
      "45\n",
      "6\n",
      "13\n",
      "20\n",
      "45\n",
      "10\n",
      "36\n",
      "19\n",
      "35\n",
      "33\n",
      "1\n",
      "0\n",
      "13\n",
      "11\n",
      "26\n",
      "45\n",
      "3\n",
      "8\n",
      "12\n",
      "37\n",
      "16\n",
      "11\n",
      "23\n",
      "45\n",
      "29\n",
      "6\n",
      "38\n",
      "34\n",
      "38\n",
      "39\n",
      "24\n",
      "32\n",
      "39\n",
      "30\n",
      "27\n",
      "42\n",
      "23\n",
      "30\n",
      "14\n",
      "30\n",
      "2\n",
      "17\n",
      "10\n",
      "44\n",
      "27\n",
      "43\n",
      "43\n",
      "12\n",
      "20\n",
      "7\n",
      "34\n",
      "3\n",
      "2\n",
      "42\n",
      "17\n",
      "18\n",
      "36\n",
      "17\n",
      "7\n",
      "30\n",
      "26\n",
      "24\n",
      "30\n",
      "32\n",
      "23\n",
      "13\n",
      "11\n",
      "30\n",
      "39\n",
      "45\n",
      "38\n",
      "18\n",
      "15\n",
      "36\n",
      "28\n",
      "6\n",
      "38\n",
      "31\n",
      "9\n",
      "23\n",
      "8\n",
      "35\n",
      "25\n",
      "30\n",
      "20\n",
      "23\n",
      "29\n",
      "10\n",
      "40\n",
      "27\n",
      "3\n",
      "22\n",
      "8\n",
      "38\n",
      "3\n",
      "4\n",
      "26\n",
      "8\n",
      "6\n",
      "24\n",
      "1\n",
      "19\n",
      "1\n",
      "27\n",
      "15\n",
      "44\n",
      "25\n",
      "17\n",
      "45\n",
      "3\n",
      "29\n",
      "39\n",
      "10\n",
      "45\n",
      "18\n",
      "6\n",
      "16\n",
      "23\n",
      "29\n",
      "35\n",
      "38\n",
      "34\n",
      "42\n",
      "17\n",
      "29\n",
      "33\n",
      "28\n",
      "10\n",
      "6\n",
      "40\n",
      "36\n",
      "39\n",
      "39\n",
      "33\n",
      "45\n",
      "44\n",
      "12\n",
      "10\n",
      "27\n",
      "41\n",
      "25\n",
      "4\n",
      "14\n",
      "43\n",
      "12\n",
      "29\n",
      "40\n",
      "45\n",
      "6\n",
      "34\n",
      "30\n",
      "35\n",
      "43\n",
      "8\n",
      "11\n",
      "4\n",
      "28\n",
      "7\n",
      "40\n",
      "30\n",
      "41\n",
      "0\n",
      "21\n",
      "43\n",
      "45\n",
      "31\n",
      "32\n",
      "8\n",
      "8\n",
      "29\n",
      "1\n",
      "39\n",
      "41\n",
      "38\n",
      "38\n",
      "37\n",
      "0\n",
      "41\n",
      "28\n",
      "14\n",
      "0\n",
      "5\n",
      "36\n",
      "37\n",
      "42\n",
      "5\n",
      "41\n",
      "24\n",
      "19\n",
      "24\n",
      "19\n",
      "18\n",
      "11\n",
      "3\n",
      "43\n",
      "15\n",
      "26\n",
      "23\n",
      "30\n",
      "20\n",
      "8\n",
      "2\n",
      "4\n",
      "3\n",
      "33\n",
      "9\n",
      "9\n",
      "30\n",
      "44\n",
      "37\n",
      "26\n",
      "42\n",
      "40\n",
      "23\n",
      "37\n",
      "28\n",
      "18\n",
      "0\n",
      "44\n",
      "40\n",
      "27\n",
      "28\n",
      "11\n",
      "42\n",
      "31\n",
      "6\n",
      "21\n",
      "10\n",
      "12\n",
      "38\n",
      "31\n",
      "17\n",
      "40\n",
      "26\n",
      "37\n",
      "45\n",
      "12\n",
      "27\n",
      "34\n",
      "45\n",
      "35\n",
      "37\n",
      "42\n",
      "21\n",
      "12\n",
      "34\n",
      "32\n",
      "28\n",
      "1\n",
      "8\n",
      "20\n",
      "30\n",
      "0\n",
      "19\n",
      "13\n",
      "11\n",
      "35\n",
      "9\n",
      "39\n",
      "44\n",
      "19\n",
      "12\n",
      "23\n",
      "26\n",
      "18\n",
      "40\n",
      "27\n",
      "20\n",
      "19\n",
      "10\n",
      "23\n",
      "12\n",
      "2\n",
      "18\n",
      "13\n",
      "0\n",
      "36\n",
      "11\n",
      "11\n",
      "21\n",
      "45\n",
      "22\n",
      "12\n",
      "39\n",
      "7\n",
      "5\n",
      "29\n",
      "11\n",
      "16\n",
      "8\n",
      "17\n",
      "7\n",
      "32\n",
      "30\n",
      "27\n",
      "5\n",
      "24\n",
      "2\n",
      "44\n",
      "19\n",
      "8\n",
      "30\n",
      "1\n",
      "7\n",
      "6\n",
      "15\n",
      "34\n",
      "24\n",
      "2\n",
      "45\n",
      "3\n",
      "42\n",
      "8\n",
      "10\n",
      "17\n",
      "38\n",
      "17\n",
      "41\n",
      "11\n",
      "34\n",
      "6\n",
      "3\n",
      "43\n",
      "32\n",
      "37\n",
      "22\n",
      "10\n",
      "25\n",
      "3\n",
      "6\n",
      "26\n",
      "14\n",
      "2\n",
      "37\n",
      "30\n",
      "37\n",
      "19\n",
      "6\n",
      "5\n",
      "1\n",
      "41\n",
      "37\n",
      "16\n",
      "14\n",
      "31\n",
      "24\n",
      "23\n",
      "0\n",
      "33\n",
      "41\n",
      "12\n",
      "31\n",
      "4\n",
      "7\n",
      "19\n",
      "29\n",
      "31\n",
      "34\n",
      "22\n",
      "2\n",
      "5\n",
      "15\n",
      "22\n",
      "38\n",
      "35\n",
      "4\n",
      "8\n",
      "28\n",
      "42\n",
      "41\n",
      "36\n",
      "12\n",
      "18\n",
      "32\n",
      "15\n",
      "8\n",
      "42\n",
      "29\n",
      "41\n",
      "0\n",
      "3\n",
      "16\n",
      "33\n",
      "24\n",
      "33\n",
      "42\n",
      "11\n",
      "27\n",
      "23\n",
      "26\n",
      "11\n",
      "6\n",
      "1\n",
      "14\n",
      "23\n",
      "13\n",
      "28\n",
      "2\n",
      "6\n",
      "6\n",
      "23\n",
      "41\n",
      "23\n",
      "30\n",
      "4\n",
      "39\n",
      "18\n",
      "44\n",
      "0\n",
      "1\n",
      "22\n",
      "8\n",
      "28\n",
      "12\n",
      "41\n",
      "32\n",
      "23\n",
      "40\n",
      "1\n",
      "7\n",
      "36\n",
      "19\n",
      "24\n",
      "33\n",
      "41\n",
      "32\n",
      "39\n",
      "31\n",
      "28\n",
      "25\n",
      "33\n",
      "19\n",
      "37\n",
      "14\n",
      "2\n",
      "13\n",
      "22\n",
      "15\n",
      "15\n",
      "26\n",
      "34\n",
      "16\n",
      "15\n",
      "43\n",
      "37\n",
      "39\n",
      "42\n",
      "5\n",
      "0\n",
      "19\n",
      "15\n",
      "29\n",
      "22\n",
      "39\n",
      "21\n",
      "34\n",
      "26\n",
      "20\n",
      "24\n",
      "41\n",
      "14\n",
      "41\n",
      "42\n",
      "17\n",
      "1\n",
      "31\n",
      "37\n",
      "34\n",
      "25\n",
      "27\n",
      "7\n",
      "22\n",
      "7\n",
      "24\n",
      "38\n",
      "23\n",
      "39\n",
      "35\n",
      "3\n",
      "6\n",
      "31\n",
      "8\n",
      "4\n",
      "4\n",
      "40\n",
      "4\n",
      "5\n",
      "12\n",
      "17\n",
      "26\n",
      "9\n",
      "2\n",
      "23\n",
      "21\n",
      "32\n",
      "41\n",
      "27\n",
      "22\n",
      "24\n",
      "28\n",
      "2\n",
      "9\n",
      "26\n",
      "21\n",
      "15\n",
      "40\n",
      "42\n",
      "26\n",
      "30\n",
      "36\n",
      "8\n",
      "40\n",
      "42\n",
      "36\n",
      "5\n",
      "1\n",
      "38\n",
      "36\n",
      "44\n",
      "4\n",
      "26\n",
      "3\n",
      "14\n",
      "8\n",
      "35\n",
      "0\n",
      "14\n",
      "21\n",
      "43\n",
      "37\n",
      "10\n",
      "30\n",
      "1\n",
      "2\n",
      "29\n",
      "43\n",
      "12\n",
      "8\n",
      "36\n",
      "38\n",
      "21\n",
      "20\n",
      "30\n",
      "45\n",
      "40\n",
      "13\n",
      "16\n",
      "32\n",
      "1\n",
      "43\n",
      "19\n",
      "1\n",
      "34\n",
      "34\n",
      "29\n",
      "43\n",
      "20\n",
      "22\n",
      "27\n",
      "12\n",
      "20\n",
      "22\n",
      "11\n",
      "22\n",
      "44\n",
      "42\n",
      "26\n",
      "28\n",
      "29\n",
      "23\n",
      "2\n",
      "24\n",
      "16\n",
      "34\n",
      "11\n",
      "33\n",
      "13\n",
      "32\n",
      "33\n",
      "16\n",
      "2\n",
      "13\n",
      "30\n",
      "2\n",
      "37\n",
      "32\n",
      "25\n",
      "23\n",
      "22\n",
      "42\n",
      "13\n",
      "31\n",
      "13\n",
      "31\n",
      "0\n",
      "37\n",
      "19\n",
      "38\n",
      "43\n",
      "8\n",
      "23\n",
      "31\n",
      "3\n",
      "14\n",
      "26\n",
      "37\n",
      "7\n",
      "30\n",
      "27\n",
      "12\n",
      "22\n",
      "33\n",
      "31\n",
      "3\n",
      "25\n",
      "11\n",
      "37\n",
      "37\n",
      "25\n",
      "19\n",
      "40\n",
      "6\n",
      "24\n",
      "20\n",
      "44\n",
      "22\n",
      "8\n",
      "0\n",
      "37\n",
      "6\n",
      "22\n",
      "40\n",
      "16\n",
      "32\n",
      "44\n",
      "21\n",
      "36\n",
      "39\n",
      "5\n",
      "31\n",
      "22\n",
      "11\n",
      "18\n",
      "9\n",
      "6\n",
      "28\n",
      "28\n",
      "41\n",
      "37\n",
      "40\n",
      "31\n",
      "2\n",
      "10\n",
      "33\n",
      "15\n",
      "7\n",
      "39\n",
      "7\n",
      "41\n",
      "10\n",
      "23\n",
      "45\n",
      "19\n",
      "37\n",
      "8\n",
      "3\n",
      "45\n",
      "21\n",
      "9\n",
      "40\n",
      "25\n",
      "33\n",
      "13\n",
      "31\n",
      "20\n",
      "34\n",
      "3\n",
      "41\n",
      "31\n",
      "28\n",
      "34\n",
      "13\n",
      "43\n",
      "1\n",
      "18\n",
      "12\n",
      "7\n",
      "37\n",
      "1\n",
      "33\n",
      "16\n",
      "23\n",
      "0\n",
      "11\n",
      "26\n",
      "41\n",
      "25\n",
      "22\n",
      "10\n",
      "2\n",
      "4\n",
      "45\n",
      "10\n",
      "13\n",
      "24\n",
      "20\n",
      "3\n",
      "39\n",
      "30\n",
      "1\n",
      "19\n",
      "9\n",
      "24\n",
      "16\n",
      "39\n",
      "17\n",
      "35\n",
      "38\n",
      "40\n",
      "44\n",
      "44\n",
      "40\n",
      "13\n",
      "27\n",
      "26\n",
      "21\n",
      "8\n",
      "3\n",
      "12\n",
      "14\n",
      "14\n",
      "13\n",
      "7\n",
      "38\n",
      "5\n",
      "37\n",
      "2\n",
      "44\n",
      "35\n",
      "7\n",
      "2\n",
      "2\n",
      "33\n",
      "12\n",
      "12\n",
      "18\n",
      "18\n",
      "23\n",
      "20\n",
      "29\n",
      "23\n",
      "2\n",
      "28\n",
      "9\n",
      "18\n",
      "26\n",
      "24\n",
      "34\n",
      "22\n",
      "10\n",
      "17\n",
      "6\n",
      "5\n",
      "5\n",
      "13\n",
      "26\n",
      "32\n",
      "34\n",
      "38\n",
      "11\n",
      "18\n",
      "30\n",
      "35\n",
      "13\n",
      "29\n",
      "39\n",
      "23\n",
      "43\n",
      "26\n",
      "23\n",
      "43\n",
      "26\n",
      "15\n",
      "8\n",
      "15\n",
      "31\n",
      "34\n",
      "3\n",
      "25\n",
      "21\n",
      "43\n",
      "33\n",
      "44\n",
      "4\n",
      "15\n",
      "43\n",
      "43\n",
      "22\n",
      "27\n",
      "40\n",
      "5\n",
      "15\n",
      "22\n",
      "30\n",
      "43\n",
      "6\n",
      "15\n",
      "1\n",
      "10\n",
      "45\n",
      "14\n",
      "38\n",
      "16\n",
      "16\n",
      "3\n",
      "34\n",
      "0\n",
      "15\n",
      "36\n",
      "26\n",
      "38\n",
      "37\n",
      "0\n",
      "21\n",
      "2\n",
      "40\n",
      "44\n",
      "8\n",
      "32\n",
      "10\n",
      "22\n",
      "1\n",
      "9\n",
      "2\n",
      "27\n",
      "0\n",
      "25\n",
      "41\n",
      "40\n",
      "5\n",
      "27\n",
      "13\n",
      "29\n",
      "11\n",
      "26\n",
      "5\n",
      "27\n",
      "31\n",
      "8\n",
      "20\n",
      "44\n",
      "29\n",
      "8\n",
      "2\n",
      "1\n",
      "24\n",
      "30\n",
      "41\n",
      "17\n",
      "5\n",
      "34\n",
      "45\n",
      "43\n",
      "13\n",
      "40\n",
      "35\n",
      "26\n",
      "11\n",
      "33\n",
      "16\n",
      "9\n",
      "33\n",
      "6\n",
      "25\n",
      "29\n",
      "11\n",
      "38\n",
      "37\n",
      "25\n",
      "24\n",
      "17\n",
      "30\n",
      "4\n",
      "5\n",
      "33\n",
      "26\n",
      "31\n",
      "11\n",
      "19\n",
      "36\n",
      "42\n",
      "14\n",
      "13\n",
      "2\n",
      "9\n",
      "7\n",
      "38\n",
      "40\n",
      "3\n",
      "26\n",
      "10\n",
      "22\n",
      "20\n",
      "23\n",
      "6\n",
      "7\n",
      "33\n",
      "12\n",
      "41\n",
      "43\n",
      "18\n",
      "16\n",
      "44\n",
      "17\n",
      "0\n",
      "7\n",
      "11\n",
      "25\n",
      "29\n",
      "9\n",
      "12\n",
      "41\n",
      "20\n",
      "6\n",
      "28\n",
      "17\n",
      "44\n",
      "2\n",
      "39\n",
      "31\n",
      "23\n",
      "26\n",
      "19\n",
      "21\n",
      "17\n",
      "26\n",
      "23\n",
      "2\n",
      "9\n",
      "26\n",
      "44\n",
      "5\n",
      "42\n",
      "44\n",
      "0\n",
      "23\n",
      "9\n",
      "25\n",
      "12\n",
      "9\n",
      "7\n",
      "34\n",
      "40\n",
      "5\n",
      "28\n",
      "36\n",
      "9\n",
      "16\n",
      "31\n",
      "44\n",
      "20\n",
      "45\n",
      "28\n",
      "25\n",
      "26\n",
      "1\n",
      "42\n",
      "1\n",
      "8\n",
      "18\n",
      "45\n",
      "24\n",
      "12\n",
      "39\n",
      "23\n",
      "21\n",
      "43\n",
      "12\n",
      "7\n",
      "18\n",
      "26\n",
      "30\n",
      "0\n",
      "40\n",
      "7\n",
      "27\n",
      "29\n",
      "0\n",
      "16\n",
      "43\n",
      "22\n",
      "24\n",
      "26\n",
      "8\n",
      "33\n",
      "27\n",
      "43\n",
      "3\n",
      "34\n",
      "6\n",
      "16\n",
      "23\n",
      "2\n",
      "30\n",
      "36\n",
      "16\n",
      "33\n",
      "20\n",
      "6\n",
      "29\n",
      "30\n",
      "8\n",
      "1\n",
      "13\n",
      "32\n",
      "3\n",
      "21\n",
      "35\n",
      "27\n",
      "9\n",
      "6\n",
      "16\n",
      "35\n",
      "6\n",
      "4\n",
      "6\n",
      "40\n",
      "35\n",
      "8\n",
      "41\n",
      "0\n",
      "17\n",
      "13\n",
      "17\n",
      "13\n",
      "18\n",
      "12\n",
      "26\n",
      "43\n",
      "2\n",
      "14\n",
      "24\n",
      "5\n",
      "28\n",
      "40\n",
      "15\n",
      "31\n",
      "5\n",
      "36\n",
      "39\n",
      "9\n",
      "7\n",
      "14\n",
      "11\n",
      "11\n",
      "32\n",
      "14\n",
      "17\n",
      "13\n",
      "7\n",
      "43\n",
      "0\n",
      "41\n",
      "8\n",
      "23\n",
      "14\n",
      "34\n",
      "13\n",
      "35\n",
      "36\n",
      "28\n",
      "12\n",
      "11\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "43\n",
      "42\n",
      "30\n",
      "21\n",
      "7\n",
      "23\n",
      "5\n",
      "19\n",
      "12\n",
      "38\n",
      "15\n",
      "4\n",
      "34\n",
      "35\n",
      "34\n",
      "37\n",
      "37\n",
      "43\n",
      "14\n",
      "35\n",
      "11\n",
      "21\n",
      "23\n",
      "6\n",
      "16\n",
      "22\n",
      "26\n",
      "30\n",
      "9\n",
      "42\n",
      "7\n",
      "36\n",
      "22\n",
      "18\n",
      "14\n",
      "6\n",
      "37\n",
      "36\n",
      "39\n",
      "45\n",
      "17\n",
      "4\n",
      "28\n",
      "39\n",
      "25\n",
      "16\n",
      "11\n",
      "17\n",
      "11\n",
      "19\n",
      "27\n",
      "17\n",
      "14\n",
      "33\n",
      "22\n",
      "19\n",
      "45\n",
      "19\n",
      "13\n",
      "15\n",
      "6\n",
      "43\n",
      "9\n",
      "21\n",
      "31\n",
      "1\n",
      "32\n",
      "24\n",
      "34\n",
      "4\n",
      "25\n",
      "24\n",
      "36\n",
      "28\n",
      "32\n",
      "40\n",
      "28\n",
      "45\n",
      "45\n",
      "24\n",
      "32\n",
      "15\n",
      "30\n",
      "25\n",
      "1\n",
      "9\n",
      "28\n",
      "35\n",
      "24\n",
      "22\n",
      "32\n",
      "34\n",
      "13\n",
      "5\n",
      "2\n",
      "42\n",
      "27\n",
      "4\n",
      "21\n",
      "30\n",
      "27\n",
      "5\n",
      "22\n",
      "1\n",
      "41\n",
      "45\n",
      "24\n",
      "13\n",
      "25\n",
      "36\n",
      "2\n",
      "42\n",
      "29\n",
      "25\n",
      "39\n",
      "36\n",
      "42\n",
      "11\n",
      "19\n",
      "41\n",
      "45\n",
      "31\n",
      "0\n",
      "12\n",
      "43\n",
      "32\n",
      "42\n",
      "22\n",
      "19\n",
      "40\n",
      "17\n",
      "29\n",
      "36\n",
      "17\n",
      "39\n",
      "9\n",
      "36\n",
      "0\n",
      "39\n",
      "9\n",
      "7\n",
      "45\n",
      "22\n",
      "4\n",
      "2\n",
      "38\n",
      "6\n",
      "16\n",
      "31\n",
      "28\n",
      "44\n",
      "23\n",
      "16\n",
      "32\n",
      "20\n",
      "23\n",
      "6\n",
      "35\n",
      "5\n",
      "36\n",
      "27\n",
      "42\n",
      "6\n",
      "13\n",
      "39\n",
      "15\n",
      "6\n",
      "39\n",
      "8\n",
      "18\n",
      "4\n",
      "41\n",
      "12\n",
      "2\n",
      "32\n",
      "35\n",
      "33\n",
      "2\n",
      "5\n",
      "3\n",
      "18\n",
      "32\n",
      "7\n",
      "20\n",
      "43\n",
      "14\n",
      "17\n",
      "2\n",
      "13\n",
      "28\n",
      "8\n",
      "19\n",
      "3\n",
      "13\n",
      "39\n",
      "26\n",
      "6\n",
      "4\n",
      "34\n",
      "13\n",
      "42\n",
      "33\n",
      "22\n",
      "6\n",
      "3\n",
      "45\n",
      "16\n",
      "42\n",
      "12\n",
      "0\n",
      "43\n",
      "11\n",
      "2\n",
      "12\n",
      "34\n",
      "44\n",
      "44\n",
      "33\n",
      "24\n",
      "18\n",
      "44\n",
      "39\n",
      "14\n",
      "4\n",
      "0\n",
      "43\n",
      "34\n",
      "32\n",
      "30\n",
      "21\n",
      "2\n",
      "41\n",
      "31\n",
      "6\n",
      "19\n",
      "29\n",
      "40\n",
      "1\n",
      "11\n",
      "16\n",
      "24\n",
      "1\n",
      "40\n",
      "45\n",
      "15\n",
      "39\n",
      "27\n",
      "21\n",
      "41\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "33\n",
      "43\n",
      "38\n",
      "13\n",
      "35\n",
      "32\n",
      "2\n",
      "29\n",
      "40\n",
      "25\n",
      "25\n",
      "35\n",
      "35\n",
      "45\n",
      "23\n",
      "33\n",
      "22\n",
      "28\n",
      "8\n",
      "10\n",
      "38\n",
      "35\n",
      "11\n",
      "35\n",
      "11\n",
      "27\n",
      "19\n",
      "35\n",
      "37\n",
      "44\n",
      "22\n",
      "35\n",
      "3\n",
      "19\n",
      "18\n",
      "33\n",
      "6\n",
      "12\n",
      "38\n",
      "9\n",
      "14\n",
      "44\n",
      "38\n",
      "13\n",
      "30\n",
      "44\n",
      "34\n",
      "42\n",
      "20\n",
      "44\n",
      "6\n",
      "39\n",
      "14\n",
      "0\n",
      "37\n",
      "20\n",
      "3\n",
      "10\n",
      "24\n",
      "24\n",
      "34\n",
      "6\n",
      "28\n",
      "10\n",
      "9\n",
      "25\n",
      "42\n",
      "35\n",
      "21\n",
      "20\n",
      "15\n",
      "17\n",
      "15\n",
      "35\n",
      "11\n",
      "40\n",
      "7\n",
      "36\n",
      "15\n",
      "21\n",
      "17\n",
      "7\n",
      "5\n",
      "11\n",
      "12\n",
      "39\n",
      "19\n",
      "41\n",
      "15\n",
      "39\n",
      "24\n",
      "11\n",
      "22\n",
      "7\n",
      "9\n",
      "36\n",
      "40\n",
      "13\n",
      "37\n",
      "37\n",
      "13\n",
      "29\n",
      "26\n",
      "41\n",
      "25\n",
      "32\n",
      "19\n",
      "17\n",
      "34\n",
      "10\n",
      "17\n",
      "24\n",
      "29\n",
      "7\n",
      "38\n",
      "8\n",
      "20\n",
      "43\n",
      "27\n",
      "34\n",
      "40\n",
      "35\n",
      "21\n",
      "10\n",
      "40\n",
      "16\n",
      "5\n",
      "7\n",
      "34\n",
      "23\n",
      "27\n",
      "21\n",
      "26\n",
      "18\n",
      "4\n",
      "31\n",
      "44\n",
      "5\n",
      "44\n",
      "27\n",
      "30\n",
      "16\n",
      "15\n",
      "26\n",
      "37\n",
      "36\n",
      "26\n",
      "23\n",
      "13\n",
      "13\n",
      "24\n",
      "12\n",
      "16\n",
      "22\n",
      "14\n",
      "7\n",
      "24\n",
      "37\n",
      "12\n",
      "21\n",
      "44\n",
      "20\n",
      "38\n",
      "15\n",
      "13\n",
      "17\n",
      "25\n",
      "35\n",
      "3\n",
      "5\n",
      "20\n",
      "18\n",
      "5\n",
      "24\n",
      "26\n",
      "25\n",
      "12\n",
      "23\n",
      "25\n",
      "35\n",
      "25\n",
      "39\n",
      "11\n",
      "15\n",
      "23\n",
      "44\n",
      "10\n",
      "2\n",
      "36\n",
      "7\n",
      "23\n",
      "18\n",
      "42\n",
      "6\n",
      "7\n",
      "4\n",
      "22\n",
      "33\n",
      "20\n",
      "15\n",
      "12\n",
      "42\n",
      "7\n",
      "0\n",
      "4\n",
      "28\n",
      "37\n",
      "39\n",
      "13\n",
      "3\n",
      "39\n",
      "1\n",
      "45\n",
      "35\n",
      "29\n",
      "32\n",
      "12\n",
      "18\n",
      "18\n",
      "17\n",
      "4\n",
      "39\n",
      "17\n",
      "12\n",
      "18\n",
      "0\n",
      "41\n",
      "30\n",
      "33\n",
      "35\n",
      "13\n",
      "45\n",
      "27\n",
      "11\n",
      "29\n",
      "11\n",
      "0\n",
      "26\n",
      "29\n",
      "0\n",
      "0\n",
      "22\n",
      "2\n",
      "21\n",
      "36\n",
      "23\n",
      "30\n",
      "1\n",
      "35\n",
      "39\n",
      "1\n",
      "4\n",
      "25\n",
      "4\n",
      "10\n",
      "4\n",
      "27\n",
      "32\n",
      "17\n",
      "9\n",
      "16\n",
      "31\n",
      "29\n",
      "7\n",
      "23\n",
      "29\n",
      "7\n",
      "33\n",
      "15\n",
      "13\n",
      "2\n",
      "21\n",
      "1\n",
      "38\n",
      "37\n",
      "41\n",
      "10\n",
      "31\n",
      "27\n",
      "7\n",
      "33\n",
      "2\n",
      "0\n",
      "2\n",
      "27\n",
      "13\n",
      "34\n",
      "5\n",
      "21\n",
      "45\n",
      "5\n",
      "23\n",
      "36\n",
      "32\n",
      "8\n",
      "29\n",
      "18\n",
      "42\n",
      "29\n",
      "18\n",
      "42\n",
      "4\n",
      "9\n",
      "35\n",
      "42\n",
      "4\n",
      "41\n",
      "36\n",
      "7\n",
      "6\n",
      "32\n",
      "37\n",
      "24\n",
      "40\n",
      "13\n",
      "16\n",
      "43\n",
      "15\n",
      "32\n",
      "31\n",
      "25\n",
      "42\n",
      "39\n",
      "41\n",
      "33\n",
      "21\n",
      "41\n",
      "39\n",
      "12\n",
      "29\n",
      "0\n",
      "26\n",
      "6\n",
      "16\n",
      "36\n",
      "30\n",
      "18\n",
      "37\n",
      "34\n",
      "15\n",
      "0\n",
      "45\n",
      "45\n",
      "12\n",
      "4\n",
      "22\n",
      "5\n",
      "25\n",
      "12\n",
      "28\n",
      "3\n",
      "32\n",
      "14\n",
      "6\n",
      "44\n",
      "26\n",
      "9\n",
      "41\n",
      "28\n",
      "41\n",
      "27\n",
      "5\n",
      "25\n",
      "15\n",
      "25\n",
      "11\n",
      "39\n",
      "30\n",
      "30\n",
      "36\n",
      "2\n",
      "2\n",
      "8\n",
      "0\n",
      "44\n",
      "31\n",
      "12\n",
      "1\n",
      "15\n",
      "39\n",
      "14\n",
      "40\n",
      "42\n",
      "22\n",
      "35\n",
      "27\n",
      "31\n",
      "8\n",
      "3\n",
      "28\n",
      "27\n",
      "45\n",
      "26\n",
      "13\n",
      "19\n",
      "2\n",
      "16\n",
      "6\n",
      "36\n",
      "5\n",
      "38\n",
      "16\n",
      "19\n",
      "29\n",
      "12\n",
      "21\n",
      "43\n",
      "17\n",
      "17\n",
      "8\n",
      "45\n",
      "21\n",
      "12\n",
      "44\n",
      "19\n",
      "41\n",
      "31\n",
      "40\n",
      "16\n",
      "12\n",
      "6\n",
      "24\n",
      "29\n",
      "31\n",
      "26\n",
      "25\n",
      "14\n",
      "42\n",
      "36\n",
      "29\n",
      "41\n",
      "18\n",
      "26\n",
      "12\n",
      "31\n",
      "22\n",
      "9\n",
      "20\n",
      "5\n",
      "23\n",
      "45\n",
      "37\n",
      "45\n",
      "7\n",
      "37\n",
      "23\n",
      "36\n",
      "40\n",
      "14\n",
      "27\n",
      "15\n",
      "9\n",
      "31\n",
      "3\n",
      "10\n",
      "28\n",
      "40\n",
      "27\n",
      "35\n",
      "38\n",
      "20\n",
      "9\n",
      "45\n",
      "3\n",
      "34\n",
      "40\n",
      "25\n",
      "43\n",
      "30\n",
      "8\n",
      "14\n",
      "29\n",
      "42\n",
      "0\n",
      "24\n",
      "42\n",
      "27\n",
      "14\n",
      "23\n",
      "15\n",
      "19\n",
      "11\n",
      "8\n",
      "20\n",
      "21\n",
      "32\n",
      "21\n",
      "31\n",
      "44\n",
      "20\n",
      "15\n",
      "13\n",
      "17\n",
      "29\n",
      "45\n",
      "36\n",
      "34\n",
      "35\n",
      "34\n",
      "19\n",
      "16\n",
      "42\n",
      "43\n",
      "3\n",
      "26\n",
      "41\n",
      "36\n",
      "44\n",
      "36\n",
      "16\n",
      "23\n",
      "30\n",
      "10\n",
      "29\n",
      "6\n",
      "26\n",
      "7\n",
      "32\n",
      "1\n",
      "10\n",
      "45\n",
      "8\n",
      "43\n",
      "22\n",
      "17\n",
      "6\n",
      "32\n",
      "41\n",
      "30\n",
      "4\n",
      "13\n",
      "37\n",
      "1\n",
      "20\n",
      "34\n",
      "41\n",
      "9\n",
      "21\n",
      "28\n",
      "11\n",
      "27\n",
      "7\n",
      "40\n",
      "29\n",
      "30\n",
      "12\n",
      "36\n",
      "36\n",
      "32\n",
      "18\n",
      "10\n",
      "13\n",
      "2\n",
      "45\n",
      "30\n",
      "32\n",
      "35\n",
      "29\n",
      "45\n",
      "29\n",
      "0\n",
      "27\n",
      "29\n",
      "9\n",
      "21\n",
      "33\n",
      "14\n",
      "14\n",
      "14\n",
      "8\n",
      "30\n",
      "43\n",
      "24\n",
      "15\n",
      "8\n",
      "13\n",
      "1\n",
      "31\n",
      "30\n",
      "18\n",
      "16\n",
      "40\n",
      "37\n",
      "32\n",
      "23\n",
      "11\n",
      "30\n",
      "34\n",
      "23\n",
      "15\n",
      "25\n",
      "6\n",
      "21\n",
      "3\n",
      "34\n",
      "8\n",
      "38\n",
      "6\n",
      "35\n",
      "9\n",
      "41\n",
      "36\n",
      "7\n",
      "31\n",
      "7\n",
      "7\n",
      "9\n",
      "32\n",
      "4\n",
      "22\n",
      "29\n",
      "45\n",
      "13\n",
      "12\n",
      "41\n",
      "44\n",
      "26\n",
      "19\n",
      "9\n",
      "10\n",
      "31\n",
      "41\n",
      "28\n",
      "16\n",
      "20\n",
      "15\n",
      "25\n",
      "31\n",
      "39\n",
      "16\n",
      "13\n",
      "8\n",
      "9\n",
      "20\n",
      "31\n",
      "12\n",
      "0\n",
      "2\n",
      "24\n",
      "16\n",
      "15\n",
      "40\n",
      "34\n",
      "33\n",
      "24\n",
      "32\n",
      "11\n",
      "27\n",
      "9\n",
      "43\n",
      "21\n",
      "8\n",
      "17\n",
      "37\n",
      "0\n",
      "34\n",
      "29\n",
      "38\n",
      "36\n",
      "30\n",
      "36\n",
      "29\n",
      "6\n",
      "5\n",
      "25\n",
      "26\n",
      "42\n",
      "28\n",
      "18\n",
      "18\n",
      "28\n",
      "40\n",
      "1\n",
      "18\n",
      "24\n",
      "36\n",
      "17\n",
      "25\n",
      "1\n",
      "26\n",
      "24\n",
      "26\n",
      "9\n",
      "39\n",
      "9\n",
      "3\n",
      "24\n",
      "26\n",
      "32\n",
      "32\n",
      "5\n",
      "38\n",
      "36\n",
      "20\n",
      "10\n",
      "17\n",
      "6\n",
      "21\n",
      "6\n",
      "33\n",
      "16\n",
      "12\n",
      "28\n",
      "20\n",
      "35\n",
      "22\n",
      "12\n",
      "36\n",
      "45\n",
      "17\n",
      "9\n",
      "13\n",
      "1\n",
      "1\n",
      "18\n",
      "33\n",
      "2\n",
      "40\n",
      "14\n",
      "5\n",
      "16\n",
      "13\n",
      "33\n",
      "35\n",
      "37\n",
      "35\n",
      "39\n",
      "42\n",
      "10\n",
      "28\n",
      "28\n",
      "24\n",
      "37\n",
      "19\n",
      "30\n",
      "8\n",
      "45\n",
      "28\n",
      "15\n",
      "33\n",
      "17\n",
      "27\n",
      "24\n",
      "30\n",
      "5\n",
      "2\n",
      "1\n",
      "18\n",
      "38\n",
      "3\n",
      "13\n",
      "31\n",
      "6\n",
      "32\n",
      "2\n",
      "0\n",
      "39\n",
      "22\n",
      "16\n",
      "15\n",
      "43\n",
      "41\n",
      "36\n",
      "37\n",
      "41\n",
      "45\n",
      "6\n",
      "9\n",
      "14\n",
      "9\n",
      "45\n",
      "11\n",
      "45\n",
      "30\n",
      "31\n",
      "26\n",
      "22\n",
      "12\n",
      "35\n",
      "8\n",
      "7\n",
      "13\n",
      "8\n",
      "15\n",
      "18\n",
      "35\n",
      "41\n",
      "16\n",
      "7\n",
      "40\n",
      "34\n",
      "12\n",
      "17\n",
      "21\n",
      "21\n",
      "6\n",
      "21\n",
      "13\n",
      "3\n",
      "0\n",
      "32\n",
      "25\n",
      "24\n",
      "26\n",
      "42\n",
      "30\n",
      "43\n",
      "2\n",
      "40\n",
      "5\n",
      "14\n",
      "35\n",
      "36\n",
      "34\n",
      "0\n",
      "9\n",
      "16\n",
      "9\n",
      "10\n",
      "21\n",
      "42\n",
      "9\n",
      "42\n",
      "25\n",
      "23\n",
      "10\n",
      "7\n",
      "16\n",
      "35\n",
      "3\n",
      "41\n",
      "5\n",
      "17\n",
      "2\n",
      "44\n",
      "13\n",
      "30\n",
      "34\n",
      "38\n",
      "45\n",
      "39\n",
      "14\n",
      "25\n",
      "13\n",
      "23\n",
      "0\n",
      "43\n",
      "18\n",
      "45\n",
      "0\n",
      "24\n",
      "30\n",
      "40\n",
      "10\n",
      "39\n",
      "3\n",
      "32\n",
      "9\n",
      "38\n",
      "25\n",
      "21\n",
      "30\n",
      "9\n",
      "25\n",
      "3\n",
      "31\n",
      "10\n",
      "10\n",
      "2\n",
      "15\n",
      "40\n",
      "28\n",
      "40\n",
      "36\n",
      "32\n",
      "17\n",
      "4\n",
      "25\n",
      "20\n",
      "31\n",
      "43\n",
      "31\n",
      "23\n",
      "28\n",
      "22\n",
      "33\n",
      "25\n",
      "4\n",
      "35\n",
      "38\n",
      "5\n",
      "44\n",
      "8\n",
      "33\n",
      "7\n",
      "34\n",
      "39\n",
      "15\n",
      "42\n",
      "31\n",
      "32\n",
      "26\n",
      "27\n",
      "15\n",
      "36\n",
      "2\n",
      "14\n",
      "44\n",
      "18\n",
      "5\n",
      "24\n",
      "19\n",
      "29\n",
      "21\n",
      "22\n",
      "35\n",
      "9\n",
      "5\n",
      "22\n",
      "1\n",
      "26\n",
      "17\n",
      "3\n",
      "27\n",
      "31\n",
      "41\n",
      "1\n",
      "1\n",
      "2\n",
      "20\n",
      "5\n",
      "9\n",
      "36\n",
      "16\n",
      "27\n",
      "1\n",
      "26\n",
      "23\n",
      "1\n",
      "10\n",
      "44\n",
      "29\n",
      "25\n",
      "31\n",
      "44\n",
      "35\n",
      "40\n",
      "3\n",
      "12\n",
      "34\n",
      "18\n",
      "32\n",
      "41\n",
      "31\n",
      "38\n",
      "18\n",
      "37\n",
      "37\n",
      "45\n",
      "10\n",
      "32\n",
      "6\n",
      "38\n",
      "36\n",
      "9\n",
      "34\n",
      "9\n",
      "9\n",
      "22\n",
      "44\n",
      "4\n",
      "32\n",
      "21\n",
      "29\n",
      "10\n",
      "40\n",
      "3\n",
      "35\n",
      "44\n",
      "24\n",
      "9\n",
      "6\n",
      "32\n",
      "24\n",
      "1\n",
      "3\n",
      "33\n",
      "7\n",
      "44\n",
      "31\n",
      "37\n",
      "20\n",
      "40\n",
      "18\n",
      "18\n",
      "15\n",
      "16\n",
      "38\n",
      "36\n",
      "13\n",
      "3\n",
      "13\n",
      "26\n",
      "13\n",
      "38\n",
      "23\n",
      "19\n",
      "16\n",
      "22\n",
      "21\n",
      "14\n",
      "24\n",
      "22\n",
      "15\n",
      "31\n",
      "4\n",
      "22\n",
      "10\n",
      "8\n",
      "15\n",
      "17\n",
      "33\n",
      "16\n",
      "16\n",
      "25\n",
      "37\n",
      "2\n",
      "41\n",
      "0\n",
      "0\n",
      "33\n",
      "19\n",
      "2\n",
      "10\n",
      "7\n",
      "32\n",
      "43\n",
      "27\n",
      "37\n",
      "0\n",
      "43\n",
      "29\n",
      "14\n",
      "24\n",
      "40\n",
      "40\n",
      "18\n",
      "10\n",
      "33\n",
      "34\n",
      "26\n",
      "35\n",
      "0\n",
      "34\n",
      "3\n",
      "1\n",
      "7\n",
      "18\n",
      "20\n",
      "41\n",
      "15\n",
      "14\n",
      "37\n",
      "32\n",
      "45\n",
      "33\n",
      "12\n",
      "2\n",
      "11\n",
      "11\n",
      "43\n",
      "19\n",
      "23\n",
      "8\n",
      "9\n",
      "20\n",
      "14\n",
      "5\n",
      "21\n",
      "36\n",
      "23\n",
      "45\n",
      "36\n",
      "23\n",
      "28\n",
      "3\n",
      "38\n",
      "25\n",
      "35\n",
      "21\n",
      "16\n",
      "26\n",
      "30\n",
      "22\n",
      "25\n",
      "10\n",
      "16\n",
      "10\n",
      "4\n",
      "13\n",
      "20\n",
      "21\n",
      "27\n",
      "24\n",
      "27\n",
      "28\n",
      "6\n",
      "38\n",
      "40\n",
      "40\n",
      "25\n",
      "33\n",
      "6\n",
      "32\n",
      "24\n",
      "22\n",
      "6\n",
      "27\n",
      "4\n",
      "12\n",
      "4\n",
      "11\n",
      "20\n",
      "31\n",
      "24\n",
      "10\n",
      "6\n",
      "40\n",
      "14\n",
      "24\n",
      "17\n",
      "20\n",
      "31\n",
      "32\n",
      "15\n",
      "36\n",
      "37\n",
      "31\n",
      "29\n",
      "45\n",
      "6\n",
      "35\n",
      "32\n",
      "42\n",
      "12\n",
      "11\n",
      "3\n",
      "42\n",
      "24\n",
      "11\n",
      "23\n",
      "14\n",
      "14\n",
      "0\n",
      "19\n",
      "11\n",
      "38\n",
      "20\n",
      "14\n",
      "30\n",
      "15\n",
      "20\n",
      "7\n",
      "18\n",
      "36\n",
      "23\n",
      "8\n",
      "18\n",
      "33\n",
      "1\n",
      "8\n",
      "11\n",
      "38\n",
      "25\n",
      "20\n",
      "14\n",
      "42\n",
      "4\n",
      "14\n",
      "32\n",
      "30\n",
      "21\n",
      "39\n",
      "31\n",
      "31\n",
      "29\n",
      "8\n",
      "34\n",
      "24\n",
      "42\n",
      "38\n",
      "38\n",
      "10\n",
      "21\n",
      "18\n",
      "1\n",
      "0\n",
      "35\n",
      "30\n",
      "7\n",
      "16\n",
      "2\n",
      "18\n",
      "41\n",
      "44\n",
      "38\n",
      "7\n",
      "23\n",
      "16\n",
      "25\n",
      "22\n",
      "5\n",
      "3\n",
      "41\n",
      "5\n",
      "27\n",
      "37\n",
      "6\n",
      "28\n",
      "33\n",
      "36\n",
      "30\n",
      "1\n",
      "40\n",
      "14\n",
      "9\n",
      "9\n",
      "24\n",
      "18\n",
      "27\n",
      "33\n",
      "41\n",
      "39\n",
      "18\n",
      "2\n",
      "34\n",
      "23\n",
      "2\n",
      "7\n",
      "41\n",
      "25\n",
      "0\n",
      "9\n",
      "0\n",
      "3\n",
      "38\n",
      "8\n",
      "2\n",
      "29\n",
      "42\n",
      "29\n",
      "20\n",
      "7\n",
      "38\n",
      "24\n",
      "15\n",
      "10\n",
      "13\n",
      "17\n",
      "1\n",
      "45\n",
      "13\n",
      "6\n",
      "13\n",
      "1\n",
      "8\n",
      "6\n",
      "44\n",
      "14\n",
      "38\n",
      "0\n",
      "22\n",
      "8\n",
      "41\n",
      "30\n",
      "17\n",
      "18\n",
      "10\n",
      "20\n",
      "37\n",
      "0\n",
      "2\n",
      "33\n",
      "6\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "27\n",
      "18\n",
      "22\n",
      "23\n",
      "16\n",
      "19\n",
      "10\n",
      "3\n",
      "4\n",
      "12\n",
      "3\n",
      "27\n",
      "40\n",
      "19\n",
      "37\n",
      "17\n",
      "18\n",
      "24\n",
      "26\n",
      "17\n",
      "27\n",
      "27\n",
      "34\n",
      "23\n",
      "39\n",
      "17\n",
      "44\n",
      "25\n",
      "10\n",
      "9\n",
      "44\n",
      "11\n",
      "7\n",
      "40\n",
      "26\n",
      "30\n",
      "15\n",
      "45\n",
      "10\n",
      "19\n",
      "41\n",
      "32\n",
      "1\n",
      "13\n",
      "6\n",
      "38\n",
      "31\n",
      "33\n",
      "0\n",
      "33\n",
      "25\n",
      "27\n",
      "17\n",
      "31\n",
      "27\n",
      "19\n",
      "26\n",
      "34\n",
      "28\n",
      "32\n",
      "45\n",
      "11\n",
      "25\n",
      "13\n",
      "39\n",
      "6\n",
      "19\n",
      "8\n",
      "33\n",
      "42\n",
      "30\n",
      "4\n",
      "29\n",
      "29\n",
      "3\n",
      "13\n",
      "21\n",
      "25\n",
      "16\n",
      "16\n",
      "0\n",
      "32\n",
      "20\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "43\n",
      "25\n",
      "10\n",
      "0\n",
      "5\n",
      "18\n",
      "15\n",
      "32\n",
      "41\n",
      "12\n",
      "31\n",
      "0\n",
      "44\n",
      "18\n",
      "21\n",
      "3\n",
      "7\n",
      "29\n",
      "35\n",
      "14\n",
      "15\n",
      "34\n",
      "28\n",
      "2\n",
      "41\n",
      "33\n",
      "10\n",
      "18\n",
      "39\n",
      "38\n",
      "7\n",
      "10\n",
      "22\n",
      "45\n",
      "35\n",
      "22\n",
      "30\n",
      "19\n",
      "8\n",
      "35\n",
      "29\n",
      "24\n",
      "30\n",
      "14\n",
      "26\n",
      "9\n",
      "42\n",
      "28\n",
      "2\n",
      "5\n",
      "8\n",
      "45\n",
      "9\n",
      "44\n",
      "10\n",
      "8\n",
      "32\n",
      "37\n",
      "40\n",
      "9\n",
      "27\n",
      "9\n",
      "42\n",
      "14\n",
      "13\n",
      "2\n",
      "34\n",
      "45\n",
      "15\n",
      "20\n",
      "35\n",
      "41\n",
      "1\n",
      "2\n",
      "30\n",
      "39\n",
      "34\n",
      "20\n",
      "45\n",
      "38\n",
      "32\n",
      "44\n",
      "37\n",
      "42\n",
      "16\n",
      "30\n",
      "12\n",
      "13\n",
      "8\n",
      "8\n",
      "45\n",
      "18\n",
      "13\n",
      "22\n",
      "2\n",
      "5\n",
      "28\n",
      "30\n",
      "37\n",
      "25\n",
      "31\n",
      "19\n",
      "3\n",
      "35\n",
      "25\n",
      "28\n",
      "14\n",
      "5\n",
      "38\n",
      "37\n",
      "22\n",
      "11\n",
      "11\n",
      "22\n",
      "28\n",
      "44\n",
      "10\n",
      "1\n",
      "8\n",
      "8\n",
      "6\n",
      "37\n",
      "28\n",
      "23\n",
      "6\n",
      "27\n",
      "11\n",
      "37\n",
      "45\n",
      "15\n",
      "9\n",
      "37\n",
      "34\n",
      "14\n",
      "12\n",
      "5\n",
      "22\n",
      "25\n",
      "3\n",
      "31\n",
      "4\n",
      "17\n",
      "19\n",
      "8\n",
      "31\n",
      "16\n",
      "20\n",
      "18\n",
      "1\n",
      "26\n",
      "25\n",
      "34\n",
      "36\n",
      "26\n",
      "10\n",
      "12\n",
      "39\n",
      "8\n",
      "11\n",
      "3\n",
      "30\n",
      "31\n",
      "5\n",
      "4\n",
      "38\n",
      "25\n",
      "11\n",
      "17\n",
      "31\n",
      "11\n",
      "14\n",
      "38\n",
      "43\n",
      "30\n",
      "30\n",
      "9\n",
      "34\n",
      "25\n",
      "5\n",
      "21\n",
      "14\n",
      "29\n",
      "6\n",
      "17\n",
      "4\n",
      "33\n",
      "20\n",
      "23\n",
      "5\n",
      "42\n",
      "28\n",
      "21\n",
      "17\n",
      "1\n",
      "42\n",
      "17\n",
      "15\n",
      "0\n",
      "4\n",
      "22\n",
      "22\n",
      "0\n",
      "8\n",
      "33\n",
      "4\n",
      "22\n",
      "38\n",
      "5\n",
      "43\n",
      "37\n",
      "7\n",
      "19\n",
      "15\n",
      "23\n",
      "40\n",
      "4\n",
      "44\n",
      "1\n",
      "20\n",
      "27\n",
      "7\n",
      "7\n",
      "37\n",
      "1\n",
      "14\n",
      "4\n",
      "35\n",
      "37\n",
      "37\n",
      "5\n",
      "0\n",
      "32\n",
      "45\n",
      "2\n",
      "11\n",
      "38\n",
      "10\n",
      "1\n",
      "15\n",
      "21\n",
      "7\n",
      "3\n",
      "24\n",
      "20\n",
      "41\n",
      "20\n",
      "15\n",
      "27\n",
      "28\n",
      "21\n",
      "17\n",
      "0\n",
      "37\n",
      "28\n",
      "5\n",
      "36\n",
      "15\n",
      "27\n",
      "32\n",
      "27\n",
      "37\n",
      "40\n",
      "40\n",
      "34\n",
      "37\n",
      "1\n",
      "27\n",
      "13\n",
      "14\n",
      "24\n",
      "24\n",
      "40\n",
      "43\n",
      "26\n",
      "35\n",
      "36\n",
      "13\n",
      "4\n",
      "38\n",
      "43\n",
      "23\n",
      "42\n",
      "33\n",
      "11\n",
      "32\n",
      "39\n",
      "8\n",
      "19\n",
      "34\n",
      "22\n",
      "9\n",
      "11\n",
      "20\n",
      "0\n",
      "4\n",
      "42\n",
      "33\n",
      "32\n",
      "37\n",
      "4\n",
      "22\n",
      "17\n",
      "17\n",
      "24\n",
      "9\n",
      "21\n",
      "43\n",
      "23\n",
      "36\n",
      "18\n",
      "39\n",
      "41\n",
      "26\n",
      "1\n",
      "38\n",
      "18\n",
      "43\n",
      "44\n",
      "32\n",
      "38\n",
      "8\n",
      "18\n",
      "45\n",
      "2\n",
      "14\n",
      "3\n",
      "22\n",
      "13\n",
      "1\n",
      "7\n",
      "21\n",
      "8\n",
      "29\n",
      "26\n",
      "11\n",
      "34\n",
      "24\n",
      "43\n",
      "35\n",
      "29\n",
      "29\n",
      "14\n",
      "4\n",
      "36\n",
      "35\n",
      "10\n",
      "12\n",
      "11\n",
      "21\n",
      "15\n",
      "3\n",
      "24\n",
      "35\n",
      "3\n",
      "11\n",
      "20\n",
      "26\n",
      "16\n",
      "18\n",
      "18\n",
      "20\n",
      "10\n",
      "39\n",
      "43\n",
      "12\n",
      "5\n",
      "0\n",
      "33\n",
      "30\n",
      "20\n",
      "35\n",
      "4\n",
      "34\n",
      "26\n",
      "32\n",
      "18\n",
      "34\n",
      "21\n",
      "36\n",
      "7\n",
      "14\n",
      "13\n",
      "42\n",
      "43\n",
      "4\n",
      "19\n",
      "11\n",
      "33\n",
      "44\n",
      "20\n",
      "25\n",
      "9\n",
      "19\n",
      "31\n",
      "34\n",
      "41\n",
      "0\n",
      "44\n",
      "2\n",
      "39\n",
      "41\n",
      "17\n",
      "22\n",
      "42\n",
      "34\n",
      "32\n",
      "35\n",
      "34\n",
      "32\n",
      "39\n",
      "11\n",
      "24\n",
      "37\n",
      "16\n",
      "39\n",
      "0\n",
      "3\n",
      "21\n",
      "34\n",
      "5\n",
      "35\n",
      "0\n",
      "4\n",
      "18\n",
      "41\n",
      "11\n",
      "40\n",
      "44\n",
      "18\n",
      "35\n",
      "23\n",
      "41\n",
      "14\n",
      "5\n",
      "18\n",
      "0\n",
      "30\n",
      "7\n",
      "40\n",
      "42\n",
      "24\n",
      "4\n",
      "23\n",
      "0\n",
      "1\n",
      "29\n",
      "24\n",
      "25\n",
      "40\n",
      "27\n",
      "17\n",
      "21\n",
      "9\n",
      "34\n",
      "23\n",
      "28\n",
      "14\n",
      "26\n",
      "9\n",
      "20\n",
      "39\n",
      "28\n",
      "44\n",
      "38\n",
      "5\n",
      "5\n",
      "39\n",
      "12\n",
      "3\n",
      "29\n",
      "17\n",
      "25\n",
      "6\n",
      "42\n",
      "9\n",
      "16\n",
      "25\n",
      "8\n",
      "25\n",
      "40\n",
      "13\n",
      "13\n",
      "31\n",
      "40\n",
      "21\n",
      "4\n",
      "7\n",
      "40\n",
      "32\n",
      "39\n",
      "22\n",
      "30\n",
      "45\n",
      "7\n",
      "11\n",
      "36\n",
      "10\n",
      "45\n",
      "35\n",
      "35\n",
      "2\n",
      "25\n",
      "28\n",
      "19\n",
      "13\n",
      "6\n",
      "7\n",
      "7\n",
      "43\n",
      "10\n",
      "4\n",
      "41\n",
      "42\n",
      "3\n",
      "2\n",
      "11\n",
      "13\n",
      "36\n",
      "7\n",
      "5\n",
      "15\n",
      "24\n",
      "7\n",
      "22\n",
      "5\n",
      "1\n",
      "32\n",
      "35\n",
      "21\n",
      "43\n",
      "21\n",
      "15\n",
      "29\n",
      "25\n",
      "22\n",
      "18\n",
      "11\n",
      "21\n",
      "23\n",
      "4\n",
      "41\n",
      "8\n",
      "44\n",
      "34\n",
      "37\n",
      "7\n",
      "2\n",
      "20\n",
      "8\n",
      "45\n",
      "19\n",
      "25\n",
      "34\n",
      "18\n",
      "13\n",
      "12\n",
      "8\n",
      "23\n",
      "30\n",
      "35\n",
      "22\n",
      "29\n",
      "21\n",
      "44\n",
      "0\n",
      "22\n",
      "17\n",
      "2\n",
      "29\n",
      "30\n",
      "23\n",
      "35\n",
      "35\n",
      "42\n",
      "14\n",
      "3\n",
      "31\n",
      "40\n",
      "22\n",
      "19\n",
      "9\n",
      "13\n",
      "22\n",
      "6\n",
      "30\n",
      "25\n",
      "43\n",
      "41\n",
      "32\n",
      "14\n",
      "18\n",
      "43\n",
      "22\n",
      "17\n",
      "6\n",
      "12\n",
      "27\n",
      "39\n",
      "21\n",
      "4\n",
      "37\n",
      "38\n",
      "16\n",
      "12\n",
      "12\n",
      "18\n",
      "30\n",
      "35\n",
      "2\n",
      "17\n",
      "14\n",
      "6\n",
      "41\n",
      "30\n",
      "0\n",
      "29\n",
      "35\n",
      "45\n",
      "22\n",
      "10\n",
      "5\n",
      "16\n",
      "12\n",
      "22\n",
      "13\n",
      "42\n",
      "20\n",
      "7\n",
      "14\n",
      "22\n",
      "8\n",
      "40\n",
      "17\n",
      "5\n",
      "5\n",
      "8\n",
      "2\n",
      "38\n",
      "26\n",
      "6\n",
      "15\n",
      "37\n",
      "9\n",
      "10\n",
      "33\n",
      "42\n",
      "21\n",
      "7\n",
      "14\n",
      "38\n",
      "44\n",
      "18\n",
      "19\n",
      "2\n",
      "8\n",
      "43\n",
      "20\n",
      "4\n",
      "4\n",
      "23\n",
      "39\n",
      "22\n",
      "41\n",
      "3\n",
      "35\n",
      "4\n",
      "22\n",
      "43\n",
      "29\n",
      "21\n",
      "17\n",
      "10\n",
      "44\n",
      "43\n",
      "1\n",
      "36\n",
      "33\n",
      "26\n",
      "20\n",
      "23\n",
      "0\n",
      "24\n",
      "25\n",
      "33\n",
      "19\n",
      "4\n",
      "44\n",
      "4\n",
      "0\n",
      "11\n",
      "14\n",
      "44\n",
      "40\n",
      "44\n",
      "8\n",
      "39\n",
      "1\n",
      "41\n",
      "12\n",
      "44\n",
      "24\n",
      "24\n",
      "1\n",
      "42\n",
      "28\n",
      "16\n",
      "20\n",
      "13\n",
      "41\n",
      "33\n",
      "4\n",
      "30\n",
      "0\n",
      "27\n",
      "33\n",
      "43\n",
      "37\n",
      "18\n",
      "37\n",
      "22\n",
      "18\n",
      "2\n",
      "20\n",
      "26\n",
      "4\n",
      "2\n",
      "18\n",
      "29\n",
      "5\n",
      "36\n",
      "18\n",
      "14\n",
      "31\n",
      "4\n",
      "20\n",
      "41\n",
      "20\n",
      "42\n",
      "41\n",
      "36\n",
      "8\n",
      "45\n",
      "8\n",
      "11\n",
      "9\n",
      "11\n",
      "44\n",
      "44\n",
      "29\n",
      "0\n",
      "4\n",
      "24\n",
      "34\n",
      "19\n",
      "22\n",
      "24\n",
      "39\n",
      "19\n",
      "13\n",
      "9\n",
      "20\n",
      "6\n",
      "4\n",
      "1\n",
      "10\n",
      "16\n",
      "27\n",
      "42\n",
      "19\n",
      "17\n",
      "14\n",
      "32\n",
      "44\n",
      "21\n",
      "15\n",
      "40\n",
      "15\n",
      "0\n",
      "6\n",
      "9\n",
      "29\n",
      "4\n",
      "29\n",
      "18\n",
      "22\n",
      "26\n",
      "19\n",
      "14\n",
      "5\n",
      "27\n",
      "25\n",
      "5\n",
      "2\n",
      "32\n",
      "43\n",
      "12\n",
      "20\n",
      "38\n",
      "44\n",
      "16\n",
      "8\n",
      "45\n",
      "37\n",
      "21\n",
      "29\n",
      "4\n",
      "33\n",
      "7\n",
      "42\n",
      "0\n",
      "5\n",
      "21\n",
      "36\n",
      "1\n",
      "0\n",
      "19\n",
      "7\n",
      "24\n",
      "19\n",
      "29\n",
      "26\n",
      "19\n",
      "18\n",
      "18\n",
      "12\n",
      "5\n",
      "1\n",
      "11\n",
      "8\n",
      "34\n",
      "28\n",
      "12\n",
      "10\n",
      "26\n",
      "0\n",
      "41\n",
      "38\n",
      "42\n",
      "31\n",
      "16\n",
      "9\n",
      "45\n",
      "43\n",
      "29\n",
      "15\n",
      "39\n",
      "17\n",
      "45\n",
      "36\n",
      "5\n",
      "38\n",
      "7\n",
      "35\n",
      "16\n",
      "39\n",
      "14\n",
      "43\n",
      "0\n",
      "26\n",
      "43\n",
      "35\n",
      "4\n",
      "38\n",
      "30\n",
      "20\n",
      "25\n",
      "36\n",
      "12\n",
      "5\n",
      "11\n",
      "23\n",
      "11\n",
      "14\n",
      "43\n",
      "4\n",
      "5\n",
      "0\n",
      "4\n",
      "12\n",
      "10\n",
      "23\n",
      "27\n",
      "6\n",
      "8\n",
      "13\n",
      "22\n",
      "5\n",
      "11\n",
      "42\n",
      "29\n",
      "2\n",
      "30\n",
      "36\n",
      "7\n",
      "9\n",
      "6\n",
      "1\n",
      "34\n",
      "39\n",
      "44\n",
      "13\n",
      "17\n",
      "19\n",
      "23\n",
      "20\n",
      "38\n",
      "36\n",
      "15\n",
      "10\n",
      "30\n",
      "26\n",
      "17\n",
      "3\n",
      "24\n",
      "24\n",
      "40\n",
      "44\n",
      "5\n",
      "34\n",
      "32\n",
      "28\n",
      "25\n",
      "20\n",
      "10\n",
      "9\n",
      "5\n",
      "29\n",
      "28\n",
      "23\n",
      "4\n",
      "33\n",
      "15\n",
      "27\n",
      "10\n",
      "35\n",
      "23\n",
      "13\n",
      "28\n",
      "33\n",
      "21\n",
      "38\n",
      "7\n",
      "25\n",
      "27\n",
      "2\n",
      "43\n",
      "17\n",
      "15\n",
      "15\n",
      "28\n",
      "16\n",
      "30\n",
      "29\n",
      "12\n",
      "42\n",
      "26\n",
      "11\n",
      "1\n",
      "31\n",
      "43\n",
      "11\n",
      "40\n",
      "45\n",
      "34\n",
      "45\n",
      "9\n",
      "38\n",
      "7\n",
      "43\n",
      "0\n",
      "28\n",
      "7\n",
      "11\n",
      "16\n",
      "23\n",
      "19\n",
      "21\n",
      "8\n",
      "36\n",
      "4\n",
      "36\n",
      "42\n",
      "21\n",
      "39\n",
      "39\n",
      "31\n",
      "28\n",
      "27\n",
      "18\n",
      "42\n",
      "24\n",
      "26\n",
      "34\n",
      "28\n",
      "31\n",
      "28\n",
      "11\n",
      "25\n",
      "1\n",
      "13\n",
      "9\n",
      "8\n",
      "44\n",
      "21\n",
      "44\n",
      "3\n",
      "14\n",
      "44\n",
      "33\n",
      "31\n",
      "15\n",
      "24\n",
      "28\n",
      "12\n",
      "31\n",
      "11\n",
      "24\n",
      "8\n",
      "28\n",
      "42\n",
      "42\n",
      "35\n",
      "0\n",
      "9\n",
      "3\n",
      "7\n",
      "20\n",
      "31\n",
      "10\n",
      "44\n",
      "21\n",
      "4\n",
      "18\n",
      "0\n",
      "37\n",
      "44\n",
      "2\n",
      "10\n",
      "24\n",
      "29\n",
      "25\n",
      "22\n",
      "17\n",
      "41\n",
      "26\n",
      "14\n",
      "28\n",
      "42\n",
      "41\n",
      "16\n",
      "19\n",
      "41\n",
      "36\n",
      "43\n",
      "21\n",
      "14\n",
      "22\n",
      "0\n",
      "28\n",
      "7\n",
      "5\n",
      "42\n",
      "10\n",
      "12\n",
      "10\n",
      "44\n",
      "21\n",
      "31\n",
      "29\n",
      "23\n",
      "1\n",
      "36\n",
      "38\n",
      "33\n",
      "3\n",
      "19\n",
      "7\n",
      "26\n",
      "19\n",
      "37\n",
      "27\n",
      "29\n",
      "18\n",
      "6\n",
      "12\n",
      "26\n",
      "25\n",
      "21\n",
      "32\n",
      "8\n",
      "23\n",
      "40\n",
      "36\n",
      "28\n",
      "35\n",
      "10\n",
      "2\n",
      "42\n",
      "4\n",
      "40\n",
      "17\n",
      "40\n",
      "39\n",
      "17\n",
      "21\n",
      "24\n",
      "13\n",
      "32\n",
      "40\n",
      "32\n",
      "28\n",
      "16\n",
      "10\n",
      "19\n",
      "6\n",
      "13\n",
      "30\n",
      "35\n",
      "27\n",
      "42\n",
      "19\n",
      "5\n",
      "2\n",
      "19\n",
      "4\n",
      "39\n",
      "3\n",
      "4\n",
      "42\n",
      "36\n",
      "22\n",
      "20\n",
      "4\n",
      "8\n",
      "29\n",
      "0\n",
      "41\n",
      "29\n",
      "45\n",
      "8\n",
      "16\n",
      "36\n",
      "18\n",
      "20\n",
      "33\n",
      "45\n",
      "20\n",
      "27\n",
      "20\n",
      "37\n",
      "30\n",
      "23\n",
      "4\n",
      "2\n",
      "37\n",
      "13\n",
      "45\n",
      "13\n",
      "26\n",
      "19\n",
      "24\n",
      "41\n",
      "3\n",
      "32\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# y_preds=torch.argmax(cnn(X_test),dim=1).squeeze().cpu().numpy()\n",
    "# for l in y_preds:\n",
    "#     print(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader Class\n",
    "# if BATCH_SIZE = N, dataloader returns images tensor of size [N, C, H, W] and labels [N]\n",
    "class DevanagariDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_csv, train = True , img_transform = None):\n",
    "        \"\"\"\n",
    "        Dataset init function\n",
    "        \n",
    "        INPUT:\n",
    "        data_csv: Path to csv file containing [data, labels]\n",
    "        train: \n",
    "            True: if the csv file has [data, labels] (Train data and Public Test Data) \n",
    "            False: if the csv file has only [data] and labels are not present.\n",
    "        img_transform: List of preprocessing operations need to performed on image. \n",
    "        \"\"\"\n",
    "        self.data_csv = data_csv\n",
    "        self.img_transform = img_transform\n",
    "        self.is_train = train\n",
    "        \n",
    "        data = pd.read_csv(data_csv, header=None)\n",
    "        if self.is_train:\n",
    "            images = data.iloc[:,:-1].to_numpy()\n",
    "            labels = data.iloc[:,-1].astype(int)\n",
    "        else:\n",
    "            images = data.iloc[:,:]\n",
    "            labels = None\n",
    "        \n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        print(\"Total Images: {}, Data Shape = {}\".format(len(self.images), images.shape))\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns total number of samples in the dataset\"\"\"\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Loads image of the given index and performs preprocessing.\n",
    "        \n",
    "        INPUT: \n",
    "        idx: index of the image to be loaded.\n",
    "        \n",
    "        OUTPUT:\n",
    "        sample: dictionary with keys images (Tensor of shape [1,C,H,W]) and labels (Tensor of labels [1]).\n",
    "        \"\"\"\n",
    "        image = self.images[idx]\n",
    "        image = np.array(image).astype(np.uint8).reshape(32, 32, 1)\n",
    "        \n",
    "        if self.is_train:\n",
    "            label = self.labels[idx]\n",
    "        else:\n",
    "            label = -1\n",
    "        \n",
    "        image = self.img_transform(image)\n",
    "#         print(image.shape, label, type(image))\n",
    "        #sample = {\"images\": image, \"labels\": label}\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images: 78200, Data Shape = (78200, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images: 4600, Data Shape = (4600, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Data Loader Usage\n",
    "\n",
    "BATCH_SIZE = 200 # Batch Size. Adjust accordingly\n",
    "NUM_WORKERS = 0 # Number of threads to be used for image loading. Adjust accordingly.\n",
    "\n",
    "img_transforms = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])\n",
    "\n",
    "# Train DataLoader\n",
    "train_data = 'devanagri_data/train_data_shuffled.csv' # Path to train csv file\n",
    "train_dataset = DevanagariDataset(data_csv = train_data, train=True, img_transform=img_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)\n",
    "\n",
    "# Test DataLoader\n",
    "test_data = 'devanagri_data/public_test.csv' # Path to test csv file\n",
    "test_dataset = DevanagariDataset(data_csv = test_data, train=True, img_transform=img_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)\n",
    "n=test_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.1.post3'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_A(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_A,self).__init__()\n",
    "        self.c1=nn.Conv2d(1,32,3)\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,64,3)\n",
    "        self.bn2=nn.BatchNorm2d(64)\n",
    "        self.c3=nn.Conv2d(64,256,3)\n",
    "        self.bn3=nn.BatchNorm2d(256)\n",
    "        self.c4=nn.Conv2d(256,512,3)\n",
    "        self.fc1=nn.Linear(512,256)\n",
    "        self.fc2=nn.Linear(256,46)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn1(self.c1(X))))\n",
    "        X=self.p2(F.relu(self.bn2(self.c2(X)))) \n",
    "        X=self.p1(F.relu(self.bn3(self.c3(X))))        \n",
    "        X=F.relu(self.c4(X))\n",
    "        X=X.view(-1,512)\n",
    "        X=self.fc2(self.dropout(F.relu(self.fc1(X))))\n",
    "        return X\n",
    "def acc(y_true,y_preds):\n",
    "    y_preds=torch.argmax(y_preds,dim=1).squeeze()\n",
    "    return (y_true==y_preds).sum().item()/len(y_true)\n",
    "bs=200\n",
    "#train_data=DataLoader(dev_dataset(X_train,y_train),batch_size=bs,shuffle=False)\n",
    "# X_train,y_train=torch.from_numpy(X_train).cuda(),torch.LongTensor(y_train).cuda()\n",
    "#X_test,y_test=torch.from_numpy(X_test).cuda(),torch.LongTensor(y_test).cuda()\n",
    "torch.manual_seed(51)\n",
    "cnn=CNN_A()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "def train(cnn,train_data,epochs,opt,loss,test_data):\n",
    "    losses=[]\n",
    "    accuracies=[]\n",
    "    for i in range(epochs):\n",
    "        l=0\n",
    "        for j,(X,y) in enumerate(train_data):\n",
    "            #print(X.shape,y.shape,type(X),type(y))\n",
    "            yh=cnn(X.cuda())\n",
    "            train_loss=loss(yh,y.type(torch.LongTensor).cuda())\n",
    "            \n",
    "            \n",
    "            train_loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                l+=train_loss.item()\n",
    "        with torch.no_grad():\n",
    "            l/=len(train_data) \n",
    "        \n",
    "            c=0\n",
    "            for j,(X,y) in enumerate(test_data):\n",
    "            \n",
    "                losses.append(l)\n",
    "                y_preds=cnn(X.cuda())\n",
    "                y_preds=torch.argmax(y_preds,dim=1).squeeze()\n",
    "                c+=(y.cuda()==y_preds).sum().item()\n",
    "        \n",
    "            c/=n    \n",
    "        accuracies.append(c)\n",
    "        print(\"Epoch: \"+str(i+1)+\" Train loss: \"+str(losses[-1])+\" test accuracy: \" +str(accuracies[-1]))        \n",
    "    return losses,accuracies      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.359662632884272 test accuracy: 0.8752173913043478\n",
      "Epoch: 2 Train loss: 0.32990321768519215 test accuracy: 0.9328260869565217\n",
      "Epoch: 3 Train loss: 0.19394106791376153 test accuracy: 0.9467391304347826\n",
      "Epoch: 4 Train loss: 0.13565470591721024 test accuracy: 0.9576086956521739\n",
      "Epoch: 5 Train loss: 0.10027738248029024 test accuracy: 0.9658695652173913\n",
      "Epoch: 6 Train loss: 0.07670301097490446 test accuracy: 0.9680434782608696\n",
      "Epoch: 7 Train loss: 0.059538032359365 test accuracy: 0.967391304347826\n",
      "Epoch: 8 Train loss: 0.04807524788705513 test accuracy: 0.9743478260869565\n"
     ]
    }
   ],
   "source": [
    "epochs=8\n",
    "l,a=train(cnn,train_loader,epochs,opt,loss,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1490542"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in CNN_A().parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_A(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_A,self).__init__()\n",
    "        self.c1=nn.Conv2d(1,32,3)\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,64,3)\n",
    "        self.bn2=nn.BatchNorm2d(64)\n",
    "        self.c3=nn.Conv2d(64,256,3)\n",
    "        self.bn3=nn.BatchNorm2d(256)\n",
    "        self.c4=nn.Conv2d(256,512,3)\n",
    "        self.fc1=nn.Linear(512,256)\n",
    "        self.fc2=nn.Linear(256,46)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn1(self.c1(X))))\n",
    "        X=self.p2(F.relu(self.bn2(self.c2(X)))) \n",
    "        X=self.p1(F.relu(self.bn3(self.c3(X))))        \n",
    "        X=F.relu(self.c4(X))\n",
    "        X=X.view(-1,512)\n",
    "        X=self.fc2(self.dropout(F.relu(self.fc1(X))))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=CNN_A().cuda()\n",
    "cnn.load_state_dict(torch.load('./model.pth'))\n",
    "cnn.eval()\n",
    "X_test=pd.read_csv('devanagri_data/public_test.csv',header=None).iloc[:,:-1].to_numpy().astype(np.float32).reshape((-1,1,32,32))\n",
    "X_test=torch.from_numpy(X_test).cuda()\n",
    "sps\n",
    "f=open('pred.txt','w')\n",
    "for l in y_preds:\n",
    "    f.write(str(l))\n",
    "    f.write('\\n')\n",
    "f.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "38\n",
      "11\n",
      "30\n",
      "17\n",
      "9\n",
      "6\n",
      "41\n",
      "31\n",
      "16\n",
      "5\n",
      "16\n",
      "9\n",
      "21\n",
      "6\n",
      "7\n",
      "14\n",
      "19\n",
      "10\n",
      "45\n",
      "25\n",
      "20\n",
      "23\n",
      "18\n",
      "2\n",
      "26\n",
      "6\n",
      "30\n",
      "30\n",
      "11\n",
      "19\n",
      "25\n",
      "43\n",
      "1\n",
      "27\n",
      "30\n",
      "8\n",
      "33\n",
      "45\n",
      "27\n",
      "23\n",
      "28\n",
      "18\n",
      "44\n",
      "29\n",
      "45\n",
      "10\n",
      "3\n",
      "44\n",
      "39\n",
      "27\n",
      "33\n",
      "15\n",
      "1\n",
      "29\n",
      "10\n",
      "11\n",
      "17\n",
      "6\n",
      "42\n",
      "4\n",
      "25\n",
      "22\n",
      "13\n",
      "2\n",
      "15\n",
      "7\n",
      "14\n",
      "17\n",
      "38\n",
      "45\n",
      "24\n",
      "13\n",
      "25\n",
      "35\n",
      "24\n",
      "44\n",
      "38\n",
      "3\n",
      "28\n",
      "39\n",
      "25\n",
      "21\n",
      "35\n",
      "31\n",
      "28\n",
      "37\n",
      "35\n",
      "35\n",
      "15\n",
      "42\n",
      "44\n",
      "20\n",
      "39\n",
      "5\n",
      "31\n",
      "32\n",
      "15\n",
      "1\n",
      "9\n",
      "1\n",
      "12\n",
      "23\n",
      "40\n",
      "23\n",
      "40\n",
      "16\n",
      "20\n",
      "24\n",
      "32\n",
      "41\n",
      "19\n",
      "28\n",
      "3\n",
      "44\n",
      "15\n",
      "35\n",
      "33\n",
      "17\n",
      "27\n",
      "20\n",
      "31\n",
      "34\n",
      "12\n",
      "14\n",
      "39\n",
      "23\n",
      "15\n",
      "43\n",
      "41\n",
      "23\n",
      "0\n",
      "26\n",
      "32\n",
      "32\n",
      "45\n",
      "40\n",
      "17\n",
      "22\n",
      "21\n",
      "1\n",
      "36\n",
      "27\n",
      "22\n",
      "41\n",
      "19\n",
      "6\n",
      "10\n",
      "2\n",
      "6\n",
      "8\n",
      "34\n",
      "9\n",
      "25\n",
      "16\n",
      "28\n",
      "12\n",
      "20\n",
      "22\n",
      "40\n",
      "19\n",
      "45\n",
      "42\n",
      "2\n",
      "15\n",
      "4\n",
      "44\n",
      "28\n",
      "39\n",
      "13\n",
      "33\n",
      "28\n",
      "33\n",
      "5\n",
      "45\n",
      "1\n",
      "36\n",
      "27\n",
      "38\n",
      "15\n",
      "42\n",
      "13\n",
      "39\n",
      "23\n",
      "5\n",
      "12\n",
      "18\n",
      "7\n",
      "33\n",
      "10\n",
      "36\n",
      "34\n",
      "36\n",
      "41\n",
      "13\n",
      "37\n",
      "25\n",
      "8\n",
      "45\n",
      "29\n",
      "2\n",
      "8\n",
      "1\n",
      "15\n",
      "14\n",
      "25\n",
      "19\n",
      "13\n",
      "7\n",
      "0\n",
      "14\n",
      "41\n",
      "2\n",
      "19\n",
      "1\n",
      "13\n",
      "43\n",
      "33\n",
      "43\n",
      "11\n",
      "20\n",
      "4\n",
      "0\n",
      "43\n",
      "33\n",
      "14\n",
      "27\n",
      "31\n",
      "4\n",
      "27\n",
      "20\n",
      "29\n",
      "7\n",
      "36\n",
      "35\n",
      "31\n",
      "9\n",
      "21\n",
      "42\n",
      "33\n",
      "30\n",
      "43\n",
      "25\n",
      "30\n",
      "45\n",
      "10\n",
      "20\n",
      "28\n",
      "6\n",
      "27\n",
      "14\n",
      "25\n",
      "27\n",
      "28\n",
      "4\n",
      "16\n",
      "19\n",
      "9\n",
      "5\n",
      "20\n",
      "2\n",
      "29\n",
      "28\n",
      "32\n",
      "38\n",
      "17\n",
      "8\n",
      "38\n",
      "20\n",
      "15\n",
      "14\n",
      "31\n",
      "40\n",
      "3\n",
      "19\n",
      "24\n",
      "1\n",
      "18\n",
      "43\n",
      "29\n",
      "21\n",
      "41\n",
      "15\n",
      "16\n",
      "44\n",
      "28\n",
      "39\n",
      "12\n",
      "1\n",
      "32\n",
      "10\n",
      "6\n",
      "19\n",
      "11\n",
      "3\n",
      "26\n",
      "19\n",
      "14\n",
      "37\n",
      "30\n",
      "20\n",
      "34\n",
      "23\n",
      "36\n",
      "21\n",
      "0\n",
      "36\n",
      "30\n",
      "27\n",
      "15\n",
      "43\n",
      "45\n",
      "36\n",
      "39\n",
      "13\n",
      "16\n",
      "35\n",
      "25\n",
      "40\n",
      "34\n",
      "31\n",
      "16\n",
      "31\n",
      "27\n",
      "20\n",
      "9\n",
      "41\n",
      "31\n",
      "41\n",
      "3\n",
      "16\n",
      "19\n",
      "11\n",
      "45\n",
      "8\n",
      "29\n",
      "15\n",
      "36\n",
      "45\n",
      "45\n",
      "40\n",
      "0\n",
      "32\n",
      "22\n",
      "19\n",
      "13\n",
      "40\n",
      "23\n",
      "31\n",
      "7\n",
      "17\n",
      "17\n",
      "39\n",
      "24\n",
      "22\n",
      "31\n",
      "5\n",
      "39\n",
      "0\n",
      "34\n",
      "2\n",
      "27\n",
      "33\n",
      "11\n",
      "34\n",
      "3\n",
      "24\n",
      "44\n",
      "40\n",
      "29\n",
      "23\n",
      "12\n",
      "23\n",
      "1\n",
      "17\n",
      "12\n",
      "25\n",
      "12\n",
      "42\n",
      "8\n",
      "19\n",
      "3\n",
      "13\n",
      "39\n",
      "31\n",
      "37\n",
      "16\n",
      "35\n",
      "42\n",
      "20\n",
      "35\n",
      "39\n",
      "4\n",
      "23\n",
      "32\n",
      "5\n",
      "33\n",
      "12\n",
      "16\n",
      "19\n",
      "22\n",
      "1\n",
      "10\n",
      "43\n",
      "28\n",
      "24\n",
      "27\n",
      "17\n",
      "37\n",
      "20\n",
      "18\n",
      "45\n",
      "39\n",
      "15\n",
      "21\n",
      "16\n",
      "6\n",
      "12\n",
      "36\n",
      "27\n",
      "5\n",
      "45\n",
      "4\n",
      "25\n",
      "19\n",
      "7\n",
      "37\n",
      "20\n",
      "31\n",
      "22\n",
      "23\n",
      "33\n",
      "45\n",
      "16\n",
      "21\n",
      "23\n",
      "17\n",
      "44\n",
      "38\n",
      "43\n",
      "16\n",
      "30\n",
      "2\n",
      "9\n",
      "11\n",
      "16\n",
      "23\n",
      "8\n",
      "4\n",
      "43\n",
      "30\n",
      "28\n",
      "44\n",
      "0\n",
      "33\n",
      "6\n",
      "12\n",
      "26\n",
      "33\n",
      "31\n",
      "42\n",
      "18\n",
      "25\n",
      "7\n",
      "43\n",
      "25\n",
      "5\n",
      "12\n",
      "39\n",
      "10\n",
      "10\n",
      "43\n",
      "21\n",
      "14\n",
      "1\n",
      "3\n",
      "25\n",
      "13\n",
      "40\n",
      "5\n",
      "28\n",
      "34\n",
      "40\n",
      "43\n",
      "22\n",
      "28\n",
      "10\n",
      "20\n",
      "45\n",
      "33\n",
      "10\n",
      "3\n",
      "22\n",
      "7\n",
      "42\n",
      "2\n",
      "15\n",
      "22\n",
      "25\n",
      "29\n",
      "38\n",
      "38\n",
      "35\n",
      "10\n",
      "5\n",
      "17\n",
      "37\n",
      "38\n",
      "4\n",
      "33\n",
      "34\n",
      "9\n",
      "14\n",
      "40\n",
      "16\n",
      "21\n",
      "41\n",
      "10\n",
      "39\n",
      "4\n",
      "17\n",
      "12\n",
      "32\n",
      "23\n",
      "21\n",
      "15\n",
      "14\n",
      "10\n",
      "18\n",
      "5\n",
      "34\n",
      "45\n",
      "17\n",
      "25\n",
      "41\n",
      "33\n",
      "5\n",
      "43\n",
      "6\n",
      "43\n",
      "9\n",
      "37\n",
      "43\n",
      "27\n",
      "12\n",
      "36\n",
      "42\n",
      "31\n",
      "28\n",
      "31\n",
      "14\n",
      "35\n",
      "22\n",
      "30\n",
      "16\n",
      "9\n",
      "4\n",
      "29\n",
      "28\n",
      "19\n",
      "14\n",
      "8\n",
      "1\n",
      "38\n",
      "35\n",
      "38\n",
      "3\n",
      "8\n",
      "40\n",
      "15\n",
      "1\n",
      "21\n",
      "17\n",
      "42\n",
      "1\n",
      "26\n",
      "39\n",
      "39\n",
      "13\n",
      "3\n",
      "33\n",
      "10\n",
      "17\n",
      "32\n",
      "7\n",
      "33\n",
      "3\n",
      "1\n",
      "6\n",
      "34\n",
      "32\n",
      "3\n",
      "18\n",
      "44\n",
      "28\n",
      "13\n",
      "26\n",
      "2\n",
      "36\n",
      "45\n",
      "2\n",
      "16\n",
      "36\n",
      "24\n",
      "20\n",
      "45\n",
      "44\n",
      "40\n",
      "33\n",
      "21\n",
      "33\n",
      "38\n",
      "16\n",
      "40\n",
      "24\n",
      "18\n",
      "27\n",
      "4\n",
      "10\n",
      "25\n",
      "38\n",
      "38\n",
      "43\n",
      "43\n",
      "36\n",
      "41\n",
      "31\n",
      "38\n",
      "28\n",
      "37\n",
      "11\n",
      "40\n",
      "37\n",
      "11\n",
      "19\n",
      "17\n",
      "43\n",
      "23\n",
      "35\n",
      "1\n",
      "30\n",
      "5\n",
      "10\n",
      "32\n",
      "45\n",
      "39\n",
      "11\n",
      "9\n",
      "19\n",
      "19\n",
      "17\n",
      "15\n",
      "1\n",
      "32\n",
      "35\n",
      "40\n",
      "28\n",
      "26\n",
      "7\n",
      "1\n",
      "36\n",
      "44\n",
      "41\n",
      "34\n",
      "39\n",
      "43\n",
      "5\n",
      "41\n",
      "10\n",
      "26\n",
      "18\n",
      "20\n",
      "12\n",
      "1\n",
      "26\n",
      "26\n",
      "17\n",
      "0\n",
      "6\n",
      "5\n",
      "18\n",
      "37\n",
      "11\n",
      "34\n",
      "29\n",
      "29\n",
      "39\n",
      "42\n",
      "21\n",
      "9\n",
      "27\n",
      "35\n",
      "3\n",
      "34\n",
      "7\n",
      "17\n",
      "41\n",
      "30\n",
      "19\n",
      "4\n",
      "9\n",
      "40\n",
      "39\n",
      "11\n",
      "43\n",
      "39\n",
      "16\n",
      "3\n",
      "31\n",
      "34\n",
      "16\n",
      "18\n",
      "39\n",
      "44\n",
      "14\n",
      "32\n",
      "29\n",
      "32\n",
      "3\n",
      "15\n",
      "24\n",
      "7\n",
      "3\n",
      "25\n",
      "33\n",
      "34\n",
      "43\n",
      "1\n",
      "43\n",
      "14\n",
      "1\n",
      "14\n",
      "45\n",
      "6\n",
      "13\n",
      "20\n",
      "45\n",
      "10\n",
      "36\n",
      "19\n",
      "35\n",
      "33\n",
      "1\n",
      "0\n",
      "13\n",
      "11\n",
      "26\n",
      "45\n",
      "3\n",
      "8\n",
      "12\n",
      "37\n",
      "16\n",
      "11\n",
      "23\n",
      "45\n",
      "29\n",
      "6\n",
      "38\n",
      "34\n",
      "38\n",
      "39\n",
      "24\n",
      "32\n",
      "39\n",
      "30\n",
      "27\n",
      "42\n",
      "27\n",
      "30\n",
      "14\n",
      "30\n",
      "2\n",
      "17\n",
      "10\n",
      "44\n",
      "27\n",
      "43\n",
      "43\n",
      "12\n",
      "20\n",
      "7\n",
      "34\n",
      "3\n",
      "2\n",
      "42\n",
      "17\n",
      "18\n",
      "36\n",
      "17\n",
      "7\n",
      "30\n",
      "26\n",
      "24\n",
      "30\n",
      "32\n",
      "23\n",
      "13\n",
      "11\n",
      "30\n",
      "39\n",
      "45\n",
      "38\n",
      "18\n",
      "15\n",
      "36\n",
      "28\n",
      "6\n",
      "38\n",
      "31\n",
      "9\n",
      "23\n",
      "8\n",
      "35\n",
      "25\n",
      "30\n",
      "20\n",
      "23\n",
      "29\n",
      "10\n",
      "40\n",
      "27\n",
      "3\n",
      "22\n",
      "8\n",
      "38\n",
      "3\n",
      "4\n",
      "26\n",
      "8\n",
      "6\n",
      "24\n",
      "30\n",
      "19\n",
      "1\n",
      "27\n",
      "15\n",
      "44\n",
      "25\n",
      "17\n",
      "45\n",
      "3\n",
      "29\n",
      "39\n",
      "10\n",
      "45\n",
      "18\n",
      "6\n",
      "16\n",
      "23\n",
      "29\n",
      "35\n",
      "38\n",
      "34\n",
      "42\n",
      "17\n",
      "29\n",
      "33\n",
      "28\n",
      "10\n",
      "16\n",
      "40\n",
      "36\n",
      "39\n",
      "39\n",
      "33\n",
      "45\n",
      "44\n",
      "12\n",
      "10\n",
      "27\n",
      "41\n",
      "29\n",
      "4\n",
      "14\n",
      "43\n",
      "12\n",
      "29\n",
      "40\n",
      "45\n",
      "6\n",
      "34\n",
      "30\n",
      "35\n",
      "43\n",
      "8\n",
      "11\n",
      "4\n",
      "28\n",
      "7\n",
      "40\n",
      "30\n",
      "41\n",
      "0\n",
      "21\n",
      "32\n",
      "45\n",
      "31\n",
      "32\n",
      "8\n",
      "8\n",
      "29\n",
      "1\n",
      "39\n",
      "41\n",
      "38\n",
      "38\n",
      "37\n",
      "0\n",
      "41\n",
      "28\n",
      "14\n",
      "0\n",
      "5\n",
      "36\n",
      "37\n",
      "42\n",
      "5\n",
      "41\n",
      "24\n",
      "19\n",
      "24\n",
      "19\n",
      "33\n",
      "11\n",
      "3\n",
      "43\n",
      "15\n",
      "26\n",
      "23\n",
      "30\n",
      "20\n",
      "8\n",
      "2\n",
      "4\n",
      "3\n",
      "33\n",
      "9\n",
      "9\n",
      "30\n",
      "44\n",
      "37\n",
      "26\n",
      "42\n",
      "40\n",
      "23\n",
      "37\n",
      "28\n",
      "18\n",
      "0\n",
      "44\n",
      "40\n",
      "27\n",
      "28\n",
      "11\n",
      "42\n",
      "31\n",
      "6\n",
      "21\n",
      "10\n",
      "12\n",
      "38\n",
      "31\n",
      "17\n",
      "40\n",
      "26\n",
      "37\n",
      "45\n",
      "12\n",
      "27\n",
      "34\n",
      "45\n",
      "35\n",
      "37\n",
      "42\n",
      "21\n",
      "12\n",
      "34\n",
      "32\n",
      "28\n",
      "1\n",
      "8\n",
      "20\n",
      "30\n",
      "0\n",
      "19\n",
      "13\n",
      "11\n",
      "35\n",
      "9\n",
      "39\n",
      "44\n",
      "19\n",
      "12\n",
      "23\n",
      "26\n",
      "18\n",
      "40\n",
      "27\n",
      "20\n",
      "19\n",
      "10\n",
      "23\n",
      "12\n",
      "2\n",
      "18\n",
      "13\n",
      "0\n",
      "36\n",
      "11\n",
      "11\n",
      "21\n",
      "45\n",
      "22\n",
      "12\n",
      "39\n",
      "7\n",
      "5\n",
      "29\n",
      "11\n",
      "16\n",
      "8\n",
      "17\n",
      "7\n",
      "32\n",
      "30\n",
      "27\n",
      "5\n",
      "24\n",
      "2\n",
      "44\n",
      "19\n",
      "8\n",
      "30\n",
      "1\n",
      "7\n",
      "6\n",
      "15\n",
      "34\n",
      "24\n",
      "36\n",
      "45\n",
      "3\n",
      "42\n",
      "8\n",
      "10\n",
      "17\n",
      "38\n",
      "17\n",
      "41\n",
      "11\n",
      "34\n",
      "6\n",
      "3\n",
      "43\n",
      "32\n",
      "37\n",
      "22\n",
      "10\n",
      "25\n",
      "3\n",
      "6\n",
      "26\n",
      "14\n",
      "2\n",
      "37\n",
      "30\n",
      "37\n",
      "19\n",
      "6\n",
      "5\n",
      "1\n",
      "41\n",
      "37\n",
      "13\n",
      "14\n",
      "31\n",
      "24\n",
      "23\n",
      "0\n",
      "33\n",
      "41\n",
      "12\n",
      "31\n",
      "4\n",
      "7\n",
      "19\n",
      "29\n",
      "31\n",
      "34\n",
      "22\n",
      "2\n",
      "5\n",
      "15\n",
      "22\n",
      "38\n",
      "35\n",
      "4\n",
      "8\n",
      "28\n",
      "42\n",
      "41\n",
      "36\n",
      "12\n",
      "18\n",
      "32\n",
      "15\n",
      "8\n",
      "42\n",
      "29\n",
      "41\n",
      "0\n",
      "3\n",
      "16\n",
      "33\n",
      "24\n",
      "33\n",
      "42\n",
      "11\n",
      "27\n",
      "23\n",
      "26\n",
      "11\n",
      "6\n",
      "1\n",
      "14\n",
      "23\n",
      "28\n",
      "28\n",
      "2\n",
      "6\n",
      "6\n",
      "23\n",
      "41\n",
      "23\n",
      "30\n",
      "4\n",
      "39\n",
      "18\n",
      "44\n",
      "0\n",
      "1\n",
      "22\n",
      "8\n",
      "28\n",
      "12\n",
      "41\n",
      "32\n",
      "23\n",
      "40\n",
      "1\n",
      "7\n",
      "36\n",
      "19\n",
      "24\n",
      "33\n",
      "41\n",
      "32\n",
      "39\n",
      "31\n",
      "28\n",
      "25\n",
      "33\n",
      "19\n",
      "37\n",
      "14\n",
      "2\n",
      "13\n",
      "22\n",
      "15\n",
      "15\n",
      "26\n",
      "34\n",
      "16\n",
      "15\n",
      "43\n",
      "37\n",
      "39\n",
      "42\n",
      "5\n",
      "0\n",
      "19\n",
      "15\n",
      "29\n",
      "22\n",
      "39\n",
      "21\n",
      "34\n",
      "26\n",
      "20\n",
      "24\n",
      "41\n",
      "14\n",
      "41\n",
      "42\n",
      "17\n",
      "1\n",
      "31\n",
      "37\n",
      "34\n",
      "25\n",
      "23\n",
      "7\n",
      "22\n",
      "7\n",
      "24\n",
      "38\n",
      "23\n",
      "39\n",
      "39\n",
      "3\n",
      "6\n",
      "31\n",
      "8\n",
      "4\n",
      "4\n",
      "40\n",
      "4\n",
      "5\n",
      "12\n",
      "17\n",
      "26\n",
      "9\n",
      "2\n",
      "23\n",
      "21\n",
      "32\n",
      "41\n",
      "27\n",
      "22\n",
      "24\n",
      "28\n",
      "2\n",
      "9\n",
      "26\n",
      "21\n",
      "15\n",
      "40\n",
      "42\n",
      "26\n",
      "30\n",
      "36\n",
      "8\n",
      "40\n",
      "42\n",
      "36\n",
      "5\n",
      "1\n",
      "38\n",
      "36\n",
      "44\n",
      "4\n",
      "26\n",
      "3\n",
      "14\n",
      "8\n",
      "35\n",
      "0\n",
      "14\n",
      "21\n",
      "43\n",
      "37\n",
      "10\n",
      "30\n",
      "1\n",
      "2\n",
      "29\n",
      "43\n",
      "12\n",
      "8\n",
      "36\n",
      "38\n",
      "21\n",
      "20\n",
      "30\n",
      "45\n",
      "40\n",
      "13\n",
      "16\n",
      "32\n",
      "1\n",
      "43\n",
      "19\n",
      "1\n",
      "34\n",
      "29\n",
      "29\n",
      "43\n",
      "20\n",
      "22\n",
      "27\n",
      "12\n",
      "23\n",
      "22\n",
      "11\n",
      "22\n",
      "44\n",
      "42\n",
      "26\n",
      "28\n",
      "29\n",
      "23\n",
      "2\n",
      "24\n",
      "16\n",
      "34\n",
      "11\n",
      "33\n",
      "13\n",
      "32\n",
      "33\n",
      "16\n",
      "2\n",
      "13\n",
      "30\n",
      "2\n",
      "37\n",
      "32\n",
      "25\n",
      "23\n",
      "22\n",
      "42\n",
      "13\n",
      "31\n",
      "13\n",
      "31\n",
      "0\n",
      "37\n",
      "19\n",
      "38\n",
      "45\n",
      "8\n",
      "23\n",
      "31\n",
      "3\n",
      "14\n",
      "26\n",
      "37\n",
      "7\n",
      "30\n",
      "27\n",
      "12\n",
      "22\n",
      "18\n",
      "31\n",
      "3\n",
      "25\n",
      "11\n",
      "37\n",
      "37\n",
      "25\n",
      "19\n",
      "40\n",
      "6\n",
      "24\n",
      "20\n",
      "44\n",
      "22\n",
      "8\n",
      "0\n",
      "37\n",
      "6\n",
      "22\n",
      "40\n",
      "16\n",
      "32\n",
      "44\n",
      "21\n",
      "36\n",
      "39\n",
      "5\n",
      "31\n",
      "22\n",
      "11\n",
      "18\n",
      "9\n",
      "6\n",
      "28\n",
      "28\n",
      "41\n",
      "37\n",
      "40\n",
      "31\n",
      "2\n",
      "10\n",
      "33\n",
      "15\n",
      "7\n",
      "39\n",
      "7\n",
      "41\n",
      "10\n",
      "27\n",
      "45\n",
      "19\n",
      "37\n",
      "8\n",
      "3\n",
      "45\n",
      "21\n",
      "9\n",
      "40\n",
      "25\n",
      "33\n",
      "13\n",
      "31\n",
      "20\n",
      "34\n",
      "3\n",
      "41\n",
      "31\n",
      "28\n",
      "34\n",
      "13\n",
      "43\n",
      "1\n",
      "18\n",
      "12\n",
      "7\n",
      "37\n",
      "1\n",
      "33\n",
      "16\n",
      "23\n",
      "0\n",
      "11\n",
      "26\n",
      "41\n",
      "25\n",
      "22\n",
      "10\n",
      "2\n",
      "4\n",
      "45\n",
      "10\n",
      "13\n",
      "24\n",
      "22\n",
      "3\n",
      "39\n",
      "30\n",
      "1\n",
      "19\n",
      "9\n",
      "24\n",
      "16\n",
      "39\n",
      "17\n",
      "35\n",
      "38\n",
      "40\n",
      "44\n",
      "44\n",
      "40\n",
      "13\n",
      "27\n",
      "26\n",
      "21\n",
      "8\n",
      "3\n",
      "12\n",
      "14\n",
      "14\n",
      "13\n",
      "7\n",
      "38\n",
      "5\n",
      "37\n",
      "2\n",
      "44\n",
      "35\n",
      "7\n",
      "2\n",
      "2\n",
      "33\n",
      "12\n",
      "12\n",
      "18\n",
      "18\n",
      "23\n",
      "20\n",
      "29\n",
      "23\n",
      "2\n",
      "28\n",
      "9\n",
      "18\n",
      "26\n",
      "24\n",
      "34\n",
      "22\n",
      "10\n",
      "17\n",
      "6\n",
      "5\n",
      "5\n",
      "13\n",
      "26\n",
      "32\n",
      "34\n",
      "38\n",
      "11\n",
      "18\n",
      "30\n",
      "35\n",
      "13\n",
      "29\n",
      "39\n",
      "23\n",
      "43\n",
      "26\n",
      "23\n",
      "43\n",
      "26\n",
      "15\n",
      "8\n",
      "15\n",
      "31\n",
      "34\n",
      "3\n",
      "25\n",
      "21\n",
      "43\n",
      "33\n",
      "44\n",
      "4\n",
      "15\n",
      "43\n",
      "43\n",
      "22\n",
      "27\n",
      "40\n",
      "5\n",
      "15\n",
      "22\n",
      "30\n",
      "43\n",
      "6\n",
      "15\n",
      "1\n",
      "10\n",
      "45\n",
      "14\n",
      "38\n",
      "16\n",
      "16\n",
      "3\n",
      "34\n",
      "0\n",
      "15\n",
      "36\n",
      "26\n",
      "38\n",
      "37\n",
      "0\n",
      "21\n",
      "2\n",
      "40\n",
      "44\n",
      "8\n",
      "32\n",
      "10\n",
      "22\n",
      "1\n",
      "9\n",
      "2\n",
      "27\n",
      "0\n",
      "25\n",
      "32\n",
      "40\n",
      "5\n",
      "27\n",
      "13\n",
      "29\n",
      "11\n",
      "26\n",
      "5\n",
      "27\n",
      "31\n",
      "8\n",
      "20\n",
      "44\n",
      "29\n",
      "8\n",
      "2\n",
      "1\n",
      "24\n",
      "30\n",
      "41\n",
      "17\n",
      "5\n",
      "41\n",
      "45\n",
      "43\n",
      "13\n",
      "40\n",
      "35\n",
      "26\n",
      "11\n",
      "33\n",
      "16\n",
      "9\n",
      "33\n",
      "6\n",
      "25\n",
      "41\n",
      "11\n",
      "32\n",
      "37\n",
      "25\n",
      "24\n",
      "17\n",
      "30\n",
      "4\n",
      "5\n",
      "33\n",
      "26\n",
      "31\n",
      "11\n",
      "19\n",
      "36\n",
      "42\n",
      "14\n",
      "13\n",
      "2\n",
      "9\n",
      "7\n",
      "38\n",
      "40\n",
      "3\n",
      "28\n",
      "10\n",
      "22\n",
      "20\n",
      "23\n",
      "6\n",
      "7\n",
      "33\n",
      "12\n",
      "41\n",
      "43\n",
      "18\n",
      "16\n",
      "44\n",
      "17\n",
      "0\n",
      "7\n",
      "11\n",
      "25\n",
      "29\n",
      "9\n",
      "12\n",
      "41\n",
      "20\n",
      "6\n",
      "28\n",
      "17\n",
      "44\n",
      "2\n",
      "39\n",
      "31\n",
      "23\n",
      "26\n",
      "19\n",
      "21\n",
      "17\n",
      "26\n",
      "23\n",
      "2\n",
      "9\n",
      "26\n",
      "44\n",
      "5\n",
      "42\n",
      "44\n",
      "0\n",
      "23\n",
      "9\n",
      "25\n",
      "12\n",
      "9\n",
      "7\n",
      "34\n",
      "40\n",
      "5\n",
      "28\n",
      "36\n",
      "9\n",
      "16\n",
      "31\n",
      "44\n",
      "20\n",
      "45\n",
      "28\n",
      "25\n",
      "26\n",
      "1\n",
      "42\n",
      "1\n",
      "8\n",
      "18\n",
      "45\n",
      "24\n",
      "12\n",
      "39\n",
      "23\n",
      "21\n",
      "43\n",
      "12\n",
      "7\n",
      "18\n",
      "26\n",
      "30\n",
      "0\n",
      "40\n",
      "7\n",
      "27\n",
      "29\n",
      "0\n",
      "16\n",
      "43\n",
      "22\n",
      "24\n",
      "26\n",
      "8\n",
      "33\n",
      "27\n",
      "43\n",
      "3\n",
      "34\n",
      "6\n",
      "16\n",
      "23\n",
      "2\n",
      "30\n",
      "36\n",
      "16\n",
      "33\n",
      "20\n",
      "6\n",
      "29\n",
      "30\n",
      "8\n",
      "1\n",
      "13\n",
      "32\n",
      "3\n",
      "21\n",
      "35\n",
      "27\n",
      "9\n",
      "6\n",
      "16\n",
      "35\n",
      "6\n",
      "4\n",
      "6\n",
      "40\n",
      "35\n",
      "8\n",
      "41\n",
      "0\n",
      "17\n",
      "13\n",
      "17\n",
      "13\n",
      "18\n",
      "12\n",
      "26\n",
      "43\n",
      "2\n",
      "14\n",
      "24\n",
      "5\n",
      "28\n",
      "40\n",
      "15\n",
      "31\n",
      "5\n",
      "36\n",
      "39\n",
      "9\n",
      "7\n",
      "14\n",
      "11\n",
      "11\n",
      "32\n",
      "14\n",
      "17\n",
      "13\n",
      "7\n",
      "43\n",
      "0\n",
      "41\n",
      "8\n",
      "23\n",
      "14\n",
      "34\n",
      "32\n",
      "35\n",
      "36\n",
      "28\n",
      "37\n",
      "11\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "43\n",
      "42\n",
      "30\n",
      "21\n",
      "7\n",
      "23\n",
      "5\n",
      "19\n",
      "12\n",
      "38\n",
      "15\n",
      "4\n",
      "12\n",
      "35\n",
      "37\n",
      "37\n",
      "37\n",
      "43\n",
      "14\n",
      "35\n",
      "11\n",
      "21\n",
      "23\n",
      "6\n",
      "16\n",
      "22\n",
      "26\n",
      "30\n",
      "9\n",
      "42\n",
      "7\n",
      "36\n",
      "22\n",
      "18\n",
      "14\n",
      "6\n",
      "37\n",
      "36\n",
      "39\n",
      "45\n",
      "17\n",
      "4\n",
      "28\n",
      "39\n",
      "25\n",
      "16\n",
      "11\n",
      "17\n",
      "11\n",
      "19\n",
      "27\n",
      "17\n",
      "14\n",
      "33\n",
      "22\n",
      "19\n",
      "45\n",
      "19\n",
      "13\n",
      "15\n",
      "6\n",
      "43\n",
      "9\n",
      "21\n",
      "31\n",
      "1\n",
      "32\n",
      "24\n",
      "34\n",
      "4\n",
      "25\n",
      "24\n",
      "36\n",
      "28\n",
      "32\n",
      "40\n",
      "28\n",
      "45\n",
      "45\n",
      "24\n",
      "32\n",
      "15\n",
      "30\n",
      "25\n",
      "1\n",
      "9\n",
      "28\n",
      "35\n",
      "24\n",
      "22\n",
      "32\n",
      "34\n",
      "13\n",
      "5\n",
      "2\n",
      "42\n",
      "27\n",
      "4\n",
      "21\n",
      "30\n",
      "27\n",
      "5\n",
      "22\n",
      "1\n",
      "41\n",
      "45\n",
      "24\n",
      "13\n",
      "25\n",
      "36\n",
      "2\n",
      "42\n",
      "29\n",
      "25\n",
      "39\n",
      "36\n",
      "42\n",
      "11\n",
      "19\n",
      "41\n",
      "45\n",
      "31\n",
      "0\n",
      "12\n",
      "43\n",
      "32\n",
      "42\n",
      "22\n",
      "19\n",
      "40\n",
      "17\n",
      "29\n",
      "36\n",
      "17\n",
      "39\n",
      "9\n",
      "36\n",
      "0\n",
      "39\n",
      "9\n",
      "7\n",
      "45\n",
      "22\n",
      "4\n",
      "2\n",
      "38\n",
      "6\n",
      "16\n",
      "31\n",
      "28\n",
      "44\n",
      "23\n",
      "16\n",
      "32\n",
      "20\n",
      "42\n",
      "6\n",
      "35\n",
      "3\n",
      "36\n",
      "27\n",
      "42\n",
      "6\n",
      "13\n",
      "39\n",
      "15\n",
      "6\n",
      "39\n",
      "8\n",
      "18\n",
      "4\n",
      "41\n",
      "12\n",
      "2\n",
      "32\n",
      "35\n",
      "33\n",
      "2\n",
      "5\n",
      "3\n",
      "18\n",
      "32\n",
      "7\n",
      "20\n",
      "43\n",
      "14\n",
      "17\n",
      "2\n",
      "13\n",
      "28\n",
      "8\n",
      "19\n",
      "3\n",
      "28\n",
      "39\n",
      "26\n",
      "6\n",
      "4\n",
      "34\n",
      "13\n",
      "42\n",
      "33\n",
      "22\n",
      "6\n",
      "3\n",
      "45\n",
      "16\n",
      "42\n",
      "12\n",
      "0\n",
      "43\n",
      "11\n",
      "3\n",
      "12\n",
      "34\n",
      "44\n",
      "44\n",
      "33\n",
      "39\n",
      "18\n",
      "44\n",
      "39\n",
      "14\n",
      "4\n",
      "0\n",
      "43\n",
      "34\n",
      "32\n",
      "30\n",
      "21\n",
      "3\n",
      "41\n",
      "31\n",
      "6\n",
      "19\n",
      "29\n",
      "40\n",
      "1\n",
      "11\n",
      "16\n",
      "24\n",
      "1\n",
      "40\n",
      "45\n",
      "15\n",
      "39\n",
      "27\n",
      "21\n",
      "41\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "33\n",
      "43\n",
      "38\n",
      "13\n",
      "35\n",
      "32\n",
      "2\n",
      "29\n",
      "40\n",
      "25\n",
      "25\n",
      "35\n",
      "35\n",
      "45\n",
      "23\n",
      "33\n",
      "22\n",
      "28\n",
      "8\n",
      "10\n",
      "38\n",
      "35\n",
      "11\n",
      "35\n",
      "11\n",
      "27\n",
      "19\n",
      "26\n",
      "37\n",
      "44\n",
      "22\n",
      "35\n",
      "3\n",
      "19\n",
      "18\n",
      "33\n",
      "6\n",
      "12\n",
      "38\n",
      "9\n",
      "14\n",
      "44\n",
      "38\n",
      "13\n",
      "30\n",
      "44\n",
      "34\n",
      "42\n",
      "20\n",
      "44\n",
      "6\n",
      "39\n",
      "14\n",
      "0\n",
      "37\n",
      "20\n",
      "3\n",
      "10\n",
      "24\n",
      "24\n",
      "34\n",
      "6\n",
      "28\n",
      "10\n",
      "9\n",
      "25\n",
      "42\n",
      "26\n",
      "21\n",
      "20\n",
      "15\n",
      "17\n",
      "15\n",
      "35\n",
      "11\n",
      "40\n",
      "7\n",
      "36\n",
      "15\n",
      "21\n",
      "17\n",
      "7\n",
      "5\n",
      "5\n",
      "12\n",
      "39\n",
      "19\n",
      "41\n",
      "15\n",
      "39\n",
      "24\n",
      "11\n",
      "22\n",
      "7\n",
      "9\n",
      "36\n",
      "40\n",
      "13\n",
      "37\n",
      "37\n",
      "6\n",
      "29\n",
      "26\n",
      "41\n",
      "25\n",
      "32\n",
      "19\n",
      "31\n",
      "34\n",
      "10\n",
      "17\n",
      "24\n",
      "29\n",
      "7\n",
      "38\n",
      "8\n",
      "20\n",
      "43\n",
      "27\n",
      "34\n",
      "40\n",
      "35\n",
      "21\n",
      "10\n",
      "40\n",
      "16\n",
      "5\n",
      "7\n",
      "34\n",
      "23\n",
      "27\n",
      "21\n",
      "26\n",
      "18\n",
      "4\n",
      "31\n",
      "44\n",
      "5\n",
      "44\n",
      "27\n",
      "30\n",
      "16\n",
      "15\n",
      "26\n",
      "37\n",
      "36\n",
      "26\n",
      "23\n",
      "13\n",
      "13\n",
      "24\n",
      "12\n",
      "16\n",
      "22\n",
      "14\n",
      "7\n",
      "24\n",
      "37\n",
      "12\n",
      "21\n",
      "44\n",
      "20\n",
      "38\n",
      "15\n",
      "13\n",
      "17\n",
      "25\n",
      "35\n",
      "3\n",
      "5\n",
      "20\n",
      "18\n",
      "5\n",
      "24\n",
      "26\n",
      "25\n",
      "12\n",
      "23\n",
      "25\n",
      "35\n",
      "25\n",
      "39\n",
      "11\n",
      "15\n",
      "23\n",
      "44\n",
      "10\n",
      "2\n",
      "36\n",
      "7\n",
      "23\n",
      "18\n",
      "42\n",
      "6\n",
      "7\n",
      "4\n",
      "22\n",
      "33\n",
      "20\n",
      "15\n",
      "12\n",
      "42\n",
      "7\n",
      "0\n",
      "4\n",
      "28\n",
      "37\n",
      "39\n",
      "13\n",
      "3\n",
      "39\n",
      "1\n",
      "45\n",
      "35\n",
      "29\n",
      "32\n",
      "12\n",
      "18\n",
      "18\n",
      "17\n",
      "4\n",
      "39\n",
      "17\n",
      "12\n",
      "18\n",
      "0\n",
      "41\n",
      "30\n",
      "33\n",
      "35\n",
      "13\n",
      "45\n",
      "27\n",
      "11\n",
      "29\n",
      "11\n",
      "0\n",
      "26\n",
      "29\n",
      "0\n",
      "0\n",
      "22\n",
      "2\n",
      "21\n",
      "36\n",
      "23\n",
      "30\n",
      "1\n",
      "35\n",
      "39\n",
      "1\n",
      "4\n",
      "25\n",
      "4\n",
      "10\n",
      "4\n",
      "27\n",
      "38\n",
      "17\n",
      "9\n",
      "16\n",
      "31\n",
      "29\n",
      "7\n",
      "23\n",
      "29\n",
      "7\n",
      "33\n",
      "15\n",
      "13\n",
      "2\n",
      "21\n",
      "1\n",
      "38\n",
      "37\n",
      "41\n",
      "10\n",
      "31\n",
      "27\n",
      "7\n",
      "33\n",
      "2\n",
      "0\n",
      "2\n",
      "27\n",
      "13\n",
      "34\n",
      "5\n",
      "21\n",
      "45\n",
      "5\n",
      "23\n",
      "36\n",
      "32\n",
      "8\n",
      "29\n",
      "18\n",
      "42\n",
      "29\n",
      "18\n",
      "42\n",
      "4\n",
      "9\n",
      "35\n",
      "42\n",
      "4\n",
      "41\n",
      "36\n",
      "7\n",
      "6\n",
      "32\n",
      "37\n",
      "24\n",
      "40\n",
      "13\n",
      "16\n",
      "43\n",
      "15\n",
      "32\n",
      "31\n",
      "25\n",
      "42\n",
      "39\n",
      "41\n",
      "33\n",
      "21\n",
      "41\n",
      "39\n",
      "12\n",
      "29\n",
      "0\n",
      "26\n",
      "6\n",
      "16\n",
      "36\n",
      "30\n",
      "18\n",
      "37\n",
      "34\n",
      "15\n",
      "0\n",
      "45\n",
      "45\n",
      "12\n",
      "4\n",
      "22\n",
      "5\n",
      "25\n",
      "12\n",
      "28\n",
      "3\n",
      "32\n",
      "14\n",
      "6\n",
      "44\n",
      "26\n",
      "9\n",
      "41\n",
      "28\n",
      "41\n",
      "27\n",
      "5\n",
      "25\n",
      "15\n",
      "25\n",
      "11\n",
      "39\n",
      "30\n",
      "30\n",
      "36\n",
      "2\n",
      "2\n",
      "8\n",
      "0\n",
      "44\n",
      "31\n",
      "12\n",
      "1\n",
      "15\n",
      "39\n",
      "14\n",
      "40\n",
      "42\n",
      "22\n",
      "26\n",
      "27\n",
      "31\n",
      "8\n",
      "3\n",
      "28\n",
      "27\n",
      "45\n",
      "26\n",
      "13\n",
      "19\n",
      "2\n",
      "16\n",
      "6\n",
      "36\n",
      "5\n",
      "38\n",
      "16\n",
      "19\n",
      "29\n",
      "12\n",
      "21\n",
      "43\n",
      "17\n",
      "17\n",
      "8\n",
      "45\n",
      "21\n",
      "12\n",
      "44\n",
      "19\n",
      "41\n",
      "31\n",
      "40\n",
      "16\n",
      "12\n",
      "6\n",
      "24\n",
      "29\n",
      "31\n",
      "26\n",
      "25\n",
      "14\n",
      "42\n",
      "36\n",
      "29\n",
      "41\n",
      "18\n",
      "26\n",
      "12\n",
      "31\n",
      "22\n",
      "9\n",
      "20\n",
      "5\n",
      "23\n",
      "45\n",
      "37\n",
      "45\n",
      "7\n",
      "37\n",
      "23\n",
      "36\n",
      "40\n",
      "14\n",
      "27\n",
      "15\n",
      "9\n",
      "31\n",
      "3\n",
      "10\n",
      "28\n",
      "40\n",
      "27\n",
      "35\n",
      "38\n",
      "20\n",
      "9\n",
      "45\n",
      "3\n",
      "34\n",
      "40\n",
      "25\n",
      "43\n",
      "30\n",
      "8\n",
      "14\n",
      "29\n",
      "42\n",
      "0\n",
      "24\n",
      "42\n",
      "27\n",
      "14\n",
      "23\n",
      "15\n",
      "19\n",
      "11\n",
      "8\n",
      "20\n",
      "21\n",
      "32\n",
      "21\n",
      "31\n",
      "44\n",
      "20\n",
      "15\n",
      "13\n",
      "17\n",
      "29\n",
      "45\n",
      "36\n",
      "34\n",
      "35\n",
      "34\n",
      "19\n",
      "16\n",
      "42\n",
      "43\n",
      "3\n",
      "15\n",
      "41\n",
      "36\n",
      "44\n",
      "36\n",
      "16\n",
      "23\n",
      "30\n",
      "10\n",
      "29\n",
      "6\n",
      "26\n",
      "7\n",
      "32\n",
      "1\n",
      "10\n",
      "45\n",
      "8\n",
      "43\n",
      "22\n",
      "17\n",
      "6\n",
      "32\n",
      "41\n",
      "30\n",
      "4\n",
      "13\n",
      "37\n",
      "1\n",
      "20\n",
      "34\n",
      "41\n",
      "9\n",
      "21\n",
      "28\n",
      "11\n",
      "27\n",
      "7\n",
      "40\n",
      "29\n",
      "30\n",
      "12\n",
      "36\n",
      "36\n",
      "32\n",
      "18\n",
      "10\n",
      "13\n",
      "2\n",
      "45\n",
      "30\n",
      "32\n",
      "35\n",
      "29\n",
      "11\n",
      "29\n",
      "0\n",
      "27\n",
      "29\n",
      "9\n",
      "21\n",
      "33\n",
      "14\n",
      "14\n",
      "27\n",
      "8\n",
      "30\n",
      "43\n",
      "24\n",
      "15\n",
      "8\n",
      "13\n",
      "1\n",
      "31\n",
      "30\n",
      "18\n",
      "16\n",
      "40\n",
      "37\n",
      "32\n",
      "23\n",
      "11\n",
      "34\n",
      "34\n",
      "23\n",
      "15\n",
      "25\n",
      "6\n",
      "21\n",
      "3\n",
      "34\n",
      "8\n",
      "38\n",
      "6\n",
      "35\n",
      "9\n",
      "39\n",
      "36\n",
      "7\n",
      "31\n",
      "7\n",
      "7\n",
      "9\n",
      "32\n",
      "4\n",
      "22\n",
      "29\n",
      "17\n",
      "13\n",
      "12\n",
      "41\n",
      "44\n",
      "26\n",
      "19\n",
      "9\n",
      "10\n",
      "31\n",
      "27\n",
      "28\n",
      "16\n",
      "20\n",
      "15\n",
      "25\n",
      "31\n",
      "39\n",
      "16\n",
      "13\n",
      "8\n",
      "9\n",
      "20\n",
      "31\n",
      "12\n",
      "0\n",
      "2\n",
      "24\n",
      "16\n",
      "15\n",
      "40\n",
      "34\n",
      "33\n",
      "24\n",
      "32\n",
      "11\n",
      "27\n",
      "9\n",
      "43\n",
      "21\n",
      "8\n",
      "17\n",
      "37\n",
      "0\n",
      "34\n",
      "29\n",
      "38\n",
      "36\n",
      "30\n",
      "36\n",
      "29\n",
      "6\n",
      "5\n",
      "25\n",
      "26\n",
      "42\n",
      "28\n",
      "18\n",
      "18\n",
      "28\n",
      "40\n",
      "1\n",
      "18\n",
      "24\n",
      "36\n",
      "17\n",
      "25\n",
      "1\n",
      "26\n",
      "24\n",
      "26\n",
      "9\n",
      "39\n",
      "9\n",
      "3\n",
      "24\n",
      "26\n",
      "32\n",
      "32\n",
      "5\n",
      "38\n",
      "36\n",
      "20\n",
      "10\n",
      "17\n",
      "6\n",
      "21\n",
      "6\n",
      "33\n",
      "16\n",
      "12\n",
      "28\n",
      "20\n",
      "35\n",
      "22\n",
      "12\n",
      "36\n",
      "45\n",
      "17\n",
      "9\n",
      "13\n",
      "1\n",
      "1\n",
      "18\n",
      "33\n",
      "2\n",
      "40\n",
      "14\n",
      "5\n",
      "16\n",
      "13\n",
      "33\n",
      "35\n",
      "37\n",
      "35\n",
      "39\n",
      "42\n",
      "10\n",
      "28\n",
      "28\n",
      "24\n",
      "37\n",
      "19\n",
      "30\n",
      "8\n",
      "45\n",
      "28\n",
      "15\n",
      "33\n",
      "17\n",
      "27\n",
      "24\n",
      "30\n",
      "5\n",
      "2\n",
      "1\n",
      "18\n",
      "38\n",
      "3\n",
      "13\n",
      "31\n",
      "6\n",
      "45\n",
      "2\n",
      "0\n",
      "39\n",
      "22\n",
      "16\n",
      "15\n",
      "43\n",
      "41\n",
      "36\n",
      "37\n",
      "41\n",
      "45\n",
      "6\n",
      "4\n",
      "14\n",
      "9\n",
      "45\n",
      "11\n",
      "45\n",
      "30\n",
      "24\n",
      "26\n",
      "22\n",
      "12\n",
      "35\n",
      "8\n",
      "7\n",
      "13\n",
      "8\n",
      "15\n",
      "18\n",
      "35\n",
      "41\n",
      "16\n",
      "7\n",
      "40\n",
      "34\n",
      "12\n",
      "17\n",
      "21\n",
      "21\n",
      "6\n",
      "21\n",
      "13\n",
      "3\n",
      "0\n",
      "32\n",
      "25\n",
      "24\n",
      "26\n",
      "42\n",
      "30\n",
      "43\n",
      "2\n",
      "40\n",
      "5\n",
      "14\n",
      "35\n",
      "36\n",
      "34\n",
      "0\n",
      "9\n",
      "16\n",
      "9\n",
      "10\n",
      "21\n",
      "42\n",
      "9\n",
      "42\n",
      "25\n",
      "23\n",
      "10\n",
      "7\n",
      "16\n",
      "35\n",
      "3\n",
      "41\n",
      "5\n",
      "17\n",
      "2\n",
      "44\n",
      "13\n",
      "30\n",
      "34\n",
      "38\n",
      "45\n",
      "39\n",
      "14\n",
      "25\n",
      "13\n",
      "23\n",
      "0\n",
      "43\n",
      "18\n",
      "45\n",
      "0\n",
      "24\n",
      "30\n",
      "40\n",
      "10\n",
      "39\n",
      "3\n",
      "32\n",
      "9\n",
      "38\n",
      "25\n",
      "21\n",
      "30\n",
      "9\n",
      "25\n",
      "3\n",
      "31\n",
      "10\n",
      "10\n",
      "2\n",
      "15\n",
      "40\n",
      "28\n",
      "40\n",
      "36\n",
      "32\n",
      "17\n",
      "4\n",
      "25\n",
      "20\n",
      "31\n",
      "43\n",
      "31\n",
      "23\n",
      "28\n",
      "22\n",
      "33\n",
      "25\n",
      "4\n",
      "35\n",
      "38\n",
      "5\n",
      "44\n",
      "8\n",
      "33\n",
      "7\n",
      "34\n",
      "39\n",
      "15\n",
      "42\n",
      "31\n",
      "32\n",
      "26\n",
      "27\n",
      "15\n",
      "36\n",
      "2\n",
      "14\n",
      "44\n",
      "18\n",
      "5\n",
      "24\n",
      "19\n",
      "29\n",
      "21\n",
      "22\n",
      "35\n",
      "9\n",
      "5\n",
      "22\n",
      "1\n",
      "26\n",
      "17\n",
      "3\n",
      "27\n",
      "31\n",
      "41\n",
      "1\n",
      "1\n",
      "2\n",
      "20\n",
      "5\n",
      "9\n",
      "36\n",
      "16\n",
      "27\n",
      "1\n",
      "26\n",
      "23\n",
      "1\n",
      "10\n",
      "44\n",
      "29\n",
      "25\n",
      "31\n",
      "44\n",
      "35\n",
      "30\n",
      "3\n",
      "12\n",
      "34\n",
      "18\n",
      "32\n",
      "41\n",
      "31\n",
      "38\n",
      "18\n",
      "37\n",
      "37\n",
      "45\n",
      "10\n",
      "32\n",
      "6\n",
      "38\n",
      "36\n",
      "9\n",
      "34\n",
      "9\n",
      "9\n",
      "22\n",
      "44\n",
      "4\n",
      "32\n",
      "21\n",
      "29\n",
      "10\n",
      "40\n",
      "3\n",
      "35\n",
      "44\n",
      "24\n",
      "9\n",
      "6\n",
      "32\n",
      "24\n",
      "1\n",
      "3\n",
      "33\n",
      "7\n",
      "44\n",
      "31\n",
      "37\n",
      "20\n",
      "40\n",
      "18\n",
      "18\n",
      "15\n",
      "16\n",
      "38\n",
      "36\n",
      "13\n",
      "3\n",
      "13\n",
      "26\n",
      "13\n",
      "38\n",
      "23\n",
      "19\n",
      "16\n",
      "22\n",
      "21\n",
      "14\n",
      "24\n",
      "22\n",
      "15\n",
      "31\n",
      "4\n",
      "22\n",
      "10\n",
      "8\n",
      "15\n",
      "17\n",
      "33\n",
      "16\n",
      "16\n",
      "25\n",
      "37\n",
      "2\n",
      "41\n",
      "0\n",
      "0\n",
      "33\n",
      "19\n",
      "2\n",
      "10\n",
      "7\n",
      "32\n",
      "43\n",
      "27\n",
      "37\n",
      "0\n",
      "43\n",
      "29\n",
      "14\n",
      "24\n",
      "40\n",
      "40\n",
      "18\n",
      "10\n",
      "33\n",
      "34\n",
      "28\n",
      "35\n",
      "0\n",
      "34\n",
      "3\n",
      "1\n",
      "7\n",
      "18\n",
      "20\n",
      "41\n",
      "15\n",
      "14\n",
      "37\n",
      "32\n",
      "45\n",
      "33\n",
      "12\n",
      "2\n",
      "11\n",
      "11\n",
      "43\n",
      "19\n",
      "23\n",
      "8\n",
      "9\n",
      "20\n",
      "14\n",
      "5\n",
      "21\n",
      "36\n",
      "23\n",
      "45\n",
      "36\n",
      "23\n",
      "28\n",
      "3\n",
      "38\n",
      "25\n",
      "35\n",
      "21\n",
      "16\n",
      "26\n",
      "30\n",
      "22\n",
      "25\n",
      "10\n",
      "16\n",
      "10\n",
      "4\n",
      "13\n",
      "20\n",
      "21\n",
      "27\n",
      "24\n",
      "27\n",
      "28\n",
      "6\n",
      "38\n",
      "40\n",
      "40\n",
      "25\n",
      "33\n",
      "6\n",
      "32\n",
      "24\n",
      "22\n",
      "6\n",
      "27\n",
      "4\n",
      "12\n",
      "4\n",
      "11\n",
      "20\n",
      "31\n",
      "24\n",
      "10\n",
      "6\n",
      "40\n",
      "14\n",
      "24\n",
      "17\n",
      "20\n",
      "31\n",
      "32\n",
      "15\n",
      "36\n",
      "37\n",
      "31\n",
      "29\n",
      "45\n",
      "6\n",
      "35\n",
      "32\n",
      "42\n",
      "12\n",
      "11\n",
      "3\n",
      "42\n",
      "24\n",
      "11\n",
      "23\n",
      "14\n",
      "14\n",
      "0\n",
      "19\n",
      "11\n",
      "38\n",
      "20\n",
      "14\n",
      "30\n",
      "15\n",
      "20\n",
      "7\n",
      "18\n",
      "36\n",
      "23\n",
      "8\n",
      "18\n",
      "33\n",
      "1\n",
      "8\n",
      "11\n",
      "38\n",
      "25\n",
      "20\n",
      "14\n",
      "42\n",
      "4\n",
      "14\n",
      "32\n",
      "30\n",
      "21\n",
      "39\n",
      "31\n",
      "31\n",
      "29\n",
      "8\n",
      "33\n",
      "24\n",
      "42\n",
      "38\n",
      "38\n",
      "10\n",
      "21\n",
      "18\n",
      "1\n",
      "0\n",
      "35\n",
      "30\n",
      "7\n",
      "16\n",
      "2\n",
      "18\n",
      "41\n",
      "44\n",
      "38\n",
      "7\n",
      "23\n",
      "16\n",
      "25\n",
      "22\n",
      "5\n",
      "3\n",
      "41\n",
      "5\n",
      "27\n",
      "37\n",
      "6\n",
      "28\n",
      "33\n",
      "36\n",
      "30\n",
      "1\n",
      "40\n",
      "14\n",
      "9\n",
      "9\n",
      "24\n",
      "18\n",
      "27\n",
      "33\n",
      "41\n",
      "39\n",
      "18\n",
      "2\n",
      "34\n",
      "23\n",
      "2\n",
      "7\n",
      "41\n",
      "25\n",
      "0\n",
      "9\n",
      "0\n",
      "3\n",
      "1\n",
      "8\n",
      "2\n",
      "29\n",
      "42\n",
      "29\n",
      "20\n",
      "7\n",
      "38\n",
      "24\n",
      "15\n",
      "10\n",
      "28\n",
      "17\n",
      "1\n",
      "45\n",
      "13\n",
      "6\n",
      "13\n",
      "1\n",
      "8\n",
      "6\n",
      "44\n",
      "14\n",
      "38\n",
      "0\n",
      "22\n",
      "8\n",
      "41\n",
      "30\n",
      "17\n",
      "18\n",
      "10\n",
      "20\n",
      "37\n",
      "21\n",
      "2\n",
      "33\n",
      "6\n",
      "9\n",
      "8\n",
      "27\n",
      "18\n",
      "22\n",
      "23\n",
      "16\n",
      "19\n",
      "10\n",
      "3\n",
      "4\n",
      "12\n",
      "3\n",
      "27\n",
      "40\n",
      "19\n",
      "37\n",
      "17\n",
      "18\n",
      "24\n",
      "26\n",
      "17\n",
      "27\n",
      "27\n",
      "34\n",
      "42\n",
      "39\n",
      "17\n",
      "44\n",
      "12\n",
      "10\n",
      "9\n",
      "44\n",
      "11\n",
      "7\n",
      "40\n",
      "26\n",
      "30\n",
      "15\n",
      "45\n",
      "10\n",
      "19\n",
      "41\n",
      "32\n",
      "1\n",
      "13\n",
      "6\n",
      "38\n",
      "31\n",
      "33\n",
      "0\n",
      "33\n",
      "25\n",
      "27\n",
      "17\n",
      "10\n",
      "27\n",
      "19\n",
      "26\n",
      "34\n",
      "28\n",
      "32\n",
      "45\n",
      "11\n",
      "25\n",
      "13\n",
      "39\n",
      "6\n",
      "19\n",
      "8\n",
      "33\n",
      "42\n",
      "30\n",
      "4\n",
      "29\n",
      "29\n",
      "3\n",
      "13\n",
      "21\n",
      "25\n",
      "16\n",
      "16\n",
      "0\n",
      "32\n",
      "20\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "43\n",
      "25\n",
      "10\n",
      "0\n",
      "5\n",
      "18\n",
      "15\n",
      "32\n",
      "41\n",
      "12\n",
      "31\n",
      "0\n",
      "44\n",
      "18\n",
      "21\n",
      "3\n",
      "7\n",
      "29\n",
      "35\n",
      "14\n",
      "15\n",
      "34\n",
      "28\n",
      "2\n",
      "41\n",
      "33\n",
      "10\n",
      "18\n",
      "39\n",
      "38\n",
      "7\n",
      "10\n",
      "22\n",
      "45\n",
      "35\n",
      "22\n",
      "30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "8\n",
      "35\n",
      "29\n",
      "24\n",
      "30\n",
      "14\n",
      "26\n",
      "9\n",
      "42\n",
      "28\n",
      "2\n",
      "5\n",
      "8\n",
      "45\n",
      "9\n",
      "44\n",
      "10\n",
      "8\n",
      "32\n",
      "37\n",
      "40\n",
      "9\n",
      "27\n",
      "9\n",
      "42\n",
      "14\n",
      "13\n",
      "2\n",
      "34\n",
      "45\n",
      "15\n",
      "20\n",
      "26\n",
      "41\n",
      "1\n",
      "2\n",
      "30\n",
      "39\n",
      "34\n",
      "20\n",
      "45\n",
      "38\n",
      "32\n",
      "44\n",
      "37\n",
      "42\n",
      "16\n",
      "30\n",
      "12\n",
      "13\n",
      "8\n",
      "8\n",
      "45\n",
      "18\n",
      "13\n",
      "22\n",
      "2\n",
      "5\n",
      "28\n",
      "30\n",
      "37\n",
      "25\n",
      "31\n",
      "19\n",
      "3\n",
      "35\n",
      "25\n",
      "28\n",
      "14\n",
      "5\n",
      "38\n",
      "37\n",
      "22\n",
      "11\n",
      "11\n",
      "36\n",
      "28\n",
      "44\n",
      "10\n",
      "1\n",
      "8\n",
      "8\n",
      "6\n",
      "37\n",
      "28\n",
      "23\n",
      "6\n",
      "38\n",
      "11\n",
      "37\n",
      "45\n",
      "15\n",
      "9\n",
      "37\n",
      "34\n",
      "14\n",
      "12\n",
      "5\n",
      "22\n",
      "25\n",
      "3\n",
      "16\n",
      "4\n",
      "17\n",
      "19\n",
      "8\n",
      "31\n",
      "16\n",
      "20\n",
      "18\n",
      "1\n",
      "26\n",
      "25\n",
      "34\n",
      "36\n",
      "26\n",
      "10\n",
      "12\n",
      "39\n",
      "8\n",
      "11\n",
      "3\n",
      "30\n",
      "31\n",
      "5\n",
      "27\n",
      "38\n",
      "25\n",
      "11\n",
      "17\n",
      "31\n",
      "11\n",
      "14\n",
      "38\n",
      "43\n",
      "30\n",
      "30\n",
      "9\n",
      "34\n",
      "25\n",
      "5\n",
      "21\n",
      "14\n",
      "29\n",
      "6\n",
      "17\n",
      "4\n",
      "33\n",
      "20\n",
      "23\n",
      "5\n",
      "42\n",
      "28\n",
      "21\n",
      "17\n",
      "1\n",
      "42\n",
      "17\n",
      "15\n",
      "0\n",
      "4\n",
      "22\n",
      "22\n",
      "0\n",
      "8\n",
      "33\n",
      "4\n",
      "22\n",
      "38\n",
      "5\n",
      "43\n",
      "37\n",
      "7\n",
      "19\n",
      "15\n",
      "38\n",
      "40\n",
      "4\n",
      "44\n",
      "1\n",
      "20\n",
      "27\n",
      "7\n",
      "7\n",
      "37\n",
      "1\n",
      "14\n",
      "4\n",
      "35\n",
      "37\n",
      "37\n",
      "5\n",
      "0\n",
      "32\n",
      "45\n",
      "2\n",
      "11\n",
      "38\n",
      "10\n",
      "1\n",
      "15\n",
      "21\n",
      "7\n",
      "3\n",
      "24\n",
      "20\n",
      "41\n",
      "20\n",
      "15\n",
      "27\n",
      "28\n",
      "21\n",
      "17\n",
      "0\n",
      "37\n",
      "28\n",
      "5\n",
      "36\n",
      "15\n",
      "27\n",
      "32\n",
      "27\n",
      "37\n",
      "40\n",
      "40\n",
      "34\n",
      "37\n",
      "1\n",
      "27\n",
      "13\n",
      "14\n",
      "24\n",
      "24\n",
      "40\n",
      "43\n",
      "26\n",
      "35\n",
      "36\n",
      "13\n",
      "4\n",
      "38\n",
      "43\n",
      "23\n",
      "42\n",
      "33\n",
      "11\n",
      "32\n",
      "39\n",
      "36\n",
      "19\n",
      "34\n",
      "22\n",
      "9\n",
      "11\n",
      "20\n",
      "0\n",
      "4\n",
      "42\n",
      "33\n",
      "32\n",
      "10\n",
      "4\n",
      "22\n",
      "17\n",
      "17\n",
      "24\n",
      "9\n",
      "21\n",
      "43\n",
      "23\n",
      "36\n",
      "18\n",
      "39\n",
      "41\n",
      "26\n",
      "1\n",
      "38\n",
      "18\n",
      "43\n",
      "44\n",
      "32\n",
      "38\n",
      "8\n",
      "18\n",
      "45\n",
      "2\n",
      "14\n",
      "3\n",
      "22\n",
      "13\n",
      "1\n",
      "7\n",
      "21\n",
      "8\n",
      "29\n",
      "26\n",
      "11\n",
      "34\n",
      "24\n",
      "43\n",
      "35\n",
      "29\n",
      "29\n",
      "14\n",
      "4\n",
      "36\n",
      "35\n",
      "10\n",
      "12\n",
      "11\n",
      "21\n",
      "15\n",
      "3\n",
      "24\n",
      "35\n",
      "3\n",
      "11\n",
      "20\n",
      "26\n",
      "16\n",
      "18\n",
      "18\n",
      "20\n",
      "10\n",
      "39\n",
      "43\n",
      "12\n",
      "5\n",
      "0\n",
      "33\n",
      "30\n",
      "20\n",
      "35\n",
      "4\n",
      "34\n",
      "26\n",
      "32\n",
      "18\n",
      "34\n",
      "21\n",
      "36\n",
      "7\n",
      "14\n",
      "13\n",
      "42\n",
      "43\n",
      "4\n",
      "19\n",
      "11\n",
      "33\n",
      "44\n",
      "20\n",
      "25\n",
      "9\n",
      "19\n",
      "31\n",
      "34\n",
      "41\n",
      "0\n",
      "44\n",
      "2\n",
      "39\n",
      "41\n",
      "17\n",
      "22\n",
      "42\n",
      "34\n",
      "32\n",
      "35\n",
      "34\n",
      "32\n",
      "39\n",
      "11\n",
      "24\n",
      "37\n",
      "16\n",
      "39\n",
      "0\n",
      "3\n",
      "21\n",
      "34\n",
      "5\n",
      "35\n",
      "0\n",
      "4\n",
      "18\n",
      "41\n",
      "11\n",
      "40\n",
      "44\n",
      "18\n",
      "35\n",
      "23\n",
      "41\n",
      "14\n",
      "5\n",
      "18\n",
      "0\n",
      "30\n",
      "7\n",
      "40\n",
      "42\n",
      "24\n",
      "4\n",
      "23\n",
      "0\n",
      "1\n",
      "29\n",
      "24\n",
      "25\n",
      "40\n",
      "27\n",
      "17\n",
      "21\n",
      "9\n",
      "34\n",
      "23\n",
      "28\n",
      "14\n",
      "26\n",
      "9\n",
      "20\n",
      "39\n",
      "28\n",
      "44\n",
      "38\n",
      "5\n",
      "5\n",
      "39\n",
      "30\n",
      "3\n",
      "29\n",
      "17\n",
      "25\n",
      "6\n",
      "42\n",
      "9\n",
      "16\n",
      "25\n",
      "8\n",
      "25\n",
      "40\n",
      "13\n",
      "13\n",
      "31\n",
      "40\n",
      "21\n",
      "4\n",
      "7\n",
      "40\n",
      "32\n",
      "39\n",
      "22\n",
      "24\n",
      "45\n",
      "7\n",
      "11\n",
      "36\n",
      "10\n",
      "45\n",
      "35\n",
      "35\n",
      "2\n",
      "25\n",
      "28\n",
      "19\n",
      "13\n",
      "6\n",
      "7\n",
      "7\n",
      "43\n",
      "10\n",
      "4\n",
      "41\n",
      "42\n",
      "3\n",
      "2\n",
      "11\n",
      "13\n",
      "36\n",
      "7\n",
      "5\n",
      "15\n",
      "24\n",
      "7\n",
      "22\n",
      "5\n",
      "1\n",
      "32\n",
      "35\n",
      "21\n",
      "43\n",
      "21\n",
      "15\n",
      "29\n",
      "25\n",
      "22\n",
      "18\n",
      "11\n",
      "21\n",
      "23\n",
      "4\n",
      "41\n",
      "8\n",
      "44\n",
      "34\n",
      "37\n",
      "7\n",
      "2\n",
      "20\n",
      "8\n",
      "45\n",
      "19\n",
      "25\n",
      "34\n",
      "18\n",
      "13\n",
      "12\n",
      "8\n",
      "23\n",
      "30\n",
      "35\n",
      "22\n",
      "29\n",
      "21\n",
      "44\n",
      "0\n",
      "22\n",
      "17\n",
      "2\n",
      "29\n",
      "30\n",
      "23\n",
      "35\n",
      "35\n",
      "42\n",
      "14\n",
      "3\n",
      "31\n",
      "40\n",
      "22\n",
      "19\n",
      "9\n",
      "43\n",
      "22\n",
      "6\n",
      "30\n",
      "25\n",
      "43\n",
      "41\n",
      "32\n",
      "14\n",
      "18\n",
      "43\n",
      "22\n",
      "17\n",
      "6\n",
      "12\n",
      "27\n",
      "39\n",
      "21\n",
      "4\n",
      "37\n",
      "38\n",
      "16\n",
      "12\n",
      "12\n",
      "18\n",
      "30\n",
      "35\n",
      "2\n",
      "17\n",
      "14\n",
      "6\n",
      "41\n",
      "30\n",
      "0\n",
      "29\n",
      "35\n",
      "45\n",
      "22\n",
      "10\n",
      "5\n",
      "16\n",
      "12\n",
      "22\n",
      "13\n",
      "42\n",
      "20\n",
      "7\n",
      "14\n",
      "22\n",
      "8\n",
      "40\n",
      "17\n",
      "5\n",
      "5\n",
      "8\n",
      "2\n",
      "38\n",
      "26\n",
      "6\n",
      "15\n",
      "37\n",
      "9\n",
      "10\n",
      "33\n",
      "42\n",
      "21\n",
      "7\n",
      "14\n",
      "38\n",
      "44\n",
      "18\n",
      "19\n",
      "2\n",
      "8\n",
      "43\n",
      "20\n",
      "4\n",
      "4\n",
      "23\n",
      "39\n",
      "22\n",
      "41\n",
      "3\n",
      "35\n",
      "4\n",
      "22\n",
      "43\n",
      "29\n",
      "21\n",
      "17\n",
      "10\n",
      "44\n",
      "43\n",
      "1\n",
      "36\n",
      "33\n",
      "26\n",
      "20\n",
      "23\n",
      "0\n",
      "24\n",
      "25\n",
      "33\n",
      "19\n",
      "4\n",
      "44\n",
      "4\n",
      "0\n",
      "11\n",
      "14\n",
      "44\n",
      "40\n",
      "44\n",
      "8\n",
      "39\n",
      "1\n",
      "41\n",
      "12\n",
      "44\n",
      "24\n",
      "24\n",
      "1\n",
      "42\n",
      "28\n",
      "16\n",
      "20\n",
      "13\n",
      "41\n",
      "33\n",
      "4\n",
      "30\n",
      "0\n",
      "27\n",
      "33\n",
      "43\n",
      "37\n",
      "18\n",
      "37\n",
      "22\n",
      "18\n",
      "2\n",
      "20\n",
      "26\n",
      "4\n",
      "2\n",
      "18\n",
      "29\n",
      "5\n",
      "36\n",
      "18\n",
      "14\n",
      "31\n",
      "4\n",
      "20\n",
      "41\n",
      "20\n",
      "42\n",
      "41\n",
      "36\n",
      "8\n",
      "45\n",
      "8\n",
      "11\n",
      "9\n",
      "11\n",
      "44\n",
      "44\n",
      "29\n",
      "0\n",
      "4\n",
      "31\n",
      "34\n",
      "19\n",
      "22\n",
      "24\n",
      "39\n",
      "19\n",
      "13\n",
      "9\n",
      "20\n",
      "6\n",
      "4\n",
      "1\n",
      "10\n",
      "16\n",
      "27\n",
      "13\n",
      "19\n",
      "17\n",
      "14\n",
      "32\n",
      "44\n",
      "21\n",
      "15\n",
      "40\n",
      "15\n",
      "0\n",
      "6\n",
      "9\n",
      "29\n",
      "4\n",
      "29\n",
      "18\n",
      "22\n",
      "26\n",
      "19\n",
      "14\n",
      "5\n",
      "27\n",
      "25\n",
      "5\n",
      "2\n",
      "32\n",
      "43\n",
      "12\n",
      "20\n",
      "38\n",
      "44\n",
      "16\n",
      "8\n",
      "45\n",
      "37\n",
      "21\n",
      "29\n",
      "4\n",
      "33\n",
      "7\n",
      "42\n",
      "0\n",
      "5\n",
      "21\n",
      "36\n",
      "1\n",
      "0\n",
      "19\n",
      "7\n",
      "24\n",
      "19\n",
      "29\n",
      "26\n",
      "19\n",
      "18\n",
      "18\n",
      "12\n",
      "5\n",
      "1\n",
      "11\n",
      "8\n",
      "34\n",
      "28\n",
      "12\n",
      "10\n",
      "26\n",
      "0\n",
      "41\n",
      "38\n",
      "42\n",
      "31\n",
      "16\n",
      "9\n",
      "45\n",
      "43\n",
      "29\n",
      "15\n",
      "39\n",
      "17\n",
      "45\n",
      "36\n",
      "5\n",
      "38\n",
      "31\n",
      "35\n",
      "16\n",
      "39\n",
      "14\n",
      "43\n",
      "0\n",
      "26\n",
      "43\n",
      "35\n",
      "4\n",
      "38\n",
      "30\n",
      "20\n",
      "38\n",
      "36\n",
      "12\n",
      "5\n",
      "11\n",
      "23\n",
      "11\n",
      "14\n",
      "43\n",
      "4\n",
      "5\n",
      "0\n",
      "4\n",
      "12\n",
      "10\n",
      "27\n",
      "27\n",
      "6\n",
      "8\n",
      "13\n",
      "22\n",
      "5\n",
      "11\n",
      "42\n",
      "37\n",
      "2\n",
      "30\n",
      "36\n",
      "7\n",
      "9\n",
      "6\n",
      "1\n",
      "34\n",
      "39\n",
      "44\n",
      "13\n",
      "17\n",
      "19\n",
      "23\n",
      "22\n",
      "38\n",
      "36\n",
      "15\n",
      "10\n",
      "30\n",
      "26\n",
      "17\n",
      "3\n",
      "24\n",
      "24\n",
      "40\n",
      "44\n",
      "2\n",
      "34\n",
      "32\n",
      "28\n",
      "25\n",
      "20\n",
      "10\n",
      "9\n",
      "5\n",
      "29\n",
      "28\n",
      "23\n",
      "4\n",
      "33\n",
      "15\n",
      "27\n",
      "10\n",
      "26\n",
      "23\n",
      "13\n",
      "28\n",
      "33\n",
      "21\n",
      "38\n",
      "7\n",
      "25\n",
      "27\n",
      "2\n",
      "43\n",
      "17\n",
      "15\n",
      "15\n",
      "28\n",
      "16\n",
      "30\n",
      "29\n",
      "12\n",
      "42\n",
      "28\n",
      "11\n",
      "1\n",
      "31\n",
      "43\n",
      "11\n",
      "40\n",
      "45\n",
      "34\n",
      "45\n",
      "9\n",
      "38\n",
      "7\n",
      "43\n",
      "0\n",
      "28\n",
      "7\n",
      "11\n",
      "16\n",
      "23\n",
      "19\n",
      "21\n",
      "8\n",
      "36\n",
      "4\n",
      "36\n",
      "42\n",
      "21\n",
      "39\n",
      "39\n",
      "31\n",
      "28\n",
      "27\n",
      "18\n",
      "42\n",
      "24\n",
      "26\n",
      "34\n",
      "28\n",
      "31\n",
      "28\n",
      "11\n",
      "25\n",
      "1\n",
      "13\n",
      "9\n",
      "8\n",
      "44\n",
      "36\n",
      "44\n",
      "3\n",
      "14\n",
      "44\n",
      "33\n",
      "31\n",
      "15\n",
      "24\n",
      "28\n",
      "12\n",
      "31\n",
      "11\n",
      "24\n",
      "8\n",
      "43\n",
      "42\n",
      "42\n",
      "35\n",
      "0\n",
      "9\n",
      "3\n",
      "7\n",
      "20\n",
      "31\n",
      "10\n",
      "44\n",
      "21\n",
      "4\n",
      "18\n",
      "0\n",
      "37\n",
      "44\n",
      "2\n",
      "10\n",
      "24\n",
      "29\n",
      "25\n",
      "22\n",
      "17\n",
      "41\n",
      "26\n",
      "14\n",
      "28\n",
      "42\n",
      "41\n",
      "16\n",
      "19\n",
      "41\n",
      "36\n",
      "43\n",
      "21\n",
      "14\n",
      "22\n",
      "0\n",
      "28\n",
      "7\n",
      "5\n",
      "42\n",
      "10\n",
      "12\n",
      "10\n",
      "44\n",
      "21\n",
      "31\n",
      "29\n",
      "23\n",
      "1\n",
      "36\n",
      "38\n",
      "32\n",
      "3\n",
      "19\n",
      "7\n",
      "26\n",
      "19\n",
      "37\n",
      "27\n",
      "29\n",
      "18\n",
      "6\n",
      "12\n",
      "26\n",
      "25\n",
      "21\n",
      "32\n",
      "8\n",
      "23\n",
      "42\n",
      "36\n",
      "28\n",
      "35\n",
      "10\n",
      "2\n",
      "42\n",
      "4\n",
      "40\n",
      "17\n",
      "40\n",
      "39\n",
      "17\n",
      "21\n",
      "24\n",
      "13\n",
      "32\n",
      "40\n",
      "15\n",
      "28\n",
      "16\n",
      "10\n",
      "19\n",
      "6\n",
      "13\n",
      "30\n",
      "35\n",
      "27\n",
      "42\n",
      "19\n",
      "5\n",
      "2\n",
      "19\n",
      "4\n",
      "39\n",
      "3\n",
      "4\n",
      "42\n",
      "36\n",
      "22\n",
      "20\n",
      "4\n",
      "8\n",
      "29\n",
      "0\n",
      "41\n",
      "29\n",
      "45\n",
      "8\n",
      "16\n",
      "36\n",
      "18\n",
      "20\n",
      "33\n",
      "45\n",
      "20\n",
      "27\n",
      "20\n",
      "37\n",
      "30\n",
      "23\n",
      "4\n",
      "2\n",
      "37\n",
      "13\n",
      "45\n",
      "13\n",
      "26\n",
      "19\n",
      "24\n",
      "41\n",
      "3\n",
      "32\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for l in y_preds:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train=pd.read_csv('cifar10_data/train_data.csv',header=None)\n",
    "# X_test=pd.read_csv('cifar10_data/public_test.csv',header=None)\n",
    "# X_train,y_train=X_train.iloc[:,1:].to_numpy().astype(np.float32),X_train.iloc[:,0].to_numpy().astype(np.float32)\n",
    "# X_test,y_test=X_test.iloc[:,1:].to_numpy().astype(np.float32),X_test.iloc[:,0].to_numpy().astype(np.float32)\n",
    "# X_train,X_test=X_train.reshape((-1,3,32,32)),X_test.reshape((-1,3,32,32))\n",
    "# X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class cifar10_dataset(Dataset):\n",
    "#     X=y=l=0\n",
    "#     def __init__(self,X,y):\n",
    "#         self.l=X.shape[0]\n",
    "#         self.X=torch.from_numpy(X).cuda()\n",
    "#         self.y=torch.LongTensor(y).cuda()\n",
    "#     def __len__(self):\n",
    "#         return self.l\n",
    "#     def __getitem__(self,i):\n",
    "#         return self.X[i],self.y[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN_B(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN_B,self).__init__()\n",
    "#         self.c1=nn.Conv2d(3,32,3)\n",
    "#         self.bn1=nn.BatchNorm2d(32)\n",
    "#         self.c2=nn.Conv2d(32,64,3)\n",
    "#         self.bn2=nn.BatchNorm2d(64)\n",
    "#         self.c3=nn.Conv2d(64,512,3)\n",
    "#         self.bn3=nn.BatchNorm2d(512)\n",
    "#         self.c4=nn.Conv2d(512,1024,2)\n",
    "#         self.fc1=nn.Linear(1024,256)\n",
    "#         self.fc2=nn.Linear(256,10)\n",
    "#         self.dropout=nn.Dropout(.2)\n",
    "#         #self.p1=nn.MaxPool2d(2,1)\n",
    "#         self.p2=nn.MaxPool2d(2,2)\n",
    "#     def forward(self,X):\n",
    "#         X=self.p2(F.relu(self.bn1(self.c1(X))))\n",
    "#         X=self.p2(F.relu(self.bn2(self.c2(X)))) \n",
    "#         X=self.p2(F.relu(self.bn3(self.c3(X))))        \n",
    "#         X=F.relu(self.c4(X))\n",
    "#         X=X.view(-1,1024)\n",
    "#         X=self.fc2(self.dropout(F.relu(self.fc1(X))))\n",
    "#         return X\n",
    "# def acc(y_true,y_preds):\n",
    "#     y_preds=torch.argmax(y_preds,dim=1).squeeze()\n",
    "#     return (y_true==y_preds).sum().item()/len(y_true)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a=CNN_B().cuda()\n",
    "# b=cifar10_dataset(X_train,y_train)\n",
    "# d=a.forward(b.__getitem__(0)[0].reshape(1,3,32,32))\n",
    "# d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs=500\n",
    "# train_data=DataLoader(cifar10_dataset(X_train,y_train),batch_size=bs,shuffle=False)\n",
    "# # X_train,y_train=torch.from_numpy(X_train).cuda(),torch.LongTensor(y_train).cuda()\n",
    "# X_test,y_test=torch.from_numpy(X_test).cuda(),torch.LongTensor(y_test).cuda()\n",
    "# cnn=CNN_B()\n",
    "# cnn=cnn.cuda()\n",
    "# opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "# loss=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(cnn,train_data,epochs,opt,loss,X_test,y_test):\n",
    "#     losses=[]\n",
    "#     accuracies=[]\n",
    "#     for i in range(epochs):\n",
    "#         l=0\n",
    "#         for j,(X,y) in enumerate(train_data):\n",
    "#             #print(X.shape,y.shape,type(X),type(y))\n",
    "#             yh=cnn(X)\n",
    "#             train_loss=loss(yh,y)\n",
    "#             opt.zero_grad()\n",
    "#             l+=train_loss.item()\n",
    "#             train_loss.backward()\n",
    "#             opt.step()\n",
    "#         l/=len(train_data) \n",
    "#         with torch.no_grad():\n",
    "#             losses.append(l)\n",
    "#             y_preds=cnn(X_test)\n",
    "#             accuracies.append(acc(y_test,y_preds))\n",
    "#             print(\"Epoch: \"+str(i+1)+\" Train loss: \"+str(losses[-1])+\" test accuracy: \" +str(accuracies[-1]))        \n",
    "#     return losses,accuracies                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.6639203707377115 test accuracy: 0.50875\n",
      "Epoch: 2 Train loss: 1.2587094912926355 test accuracy: 0.57425\n",
      "Epoch: 3 Train loss: 1.0991837456822395 test accuracy: 0.615\n",
      "Epoch: 4 Train loss: 0.9890262434879938 test accuracy: 0.64\n",
      "Epoch: 5 Train loss: 0.9008586332201958 test accuracy: 0.65225\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "losses,accuracies=train(cnn,train_data,epochs,opt,loss,X_test,y_test)\n",
    "f=open('loss.txt','w')\n",
    "for l in losses:\n",
    "    f.write(str(l))\n",
    "    f.write('\\n')\n",
    "f.close()    \n",
    "f=open('accuracy.txt','w')\n",
    "for l in accuracies:\n",
    "    f.write(str(l))\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "torch.save(cnn.state_dict(),'./model.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n",
      "2\n",
      "7\n",
      "2\n",
      "9\n",
      "9\n",
      "5\n",
      "8\n",
      "1\n",
      "5\n",
      "0\n",
      "6\n",
      "1\n",
      "0\n",
      "6\n",
      "7\n",
      "5\n",
      "8\n",
      "6\n",
      "7\n",
      "9\n",
      "2\n",
      "4\n",
      "6\n",
      "2\n",
      "5\n",
      "0\n",
      "8\n",
      "1\n",
      "0\n",
      "2\n",
      "6\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "9\n",
      "3\n",
      "9\n",
      "6\n",
      "2\n",
      "7\n",
      "9\n",
      "0\n",
      "7\n",
      "2\n",
      "9\n",
      "8\n",
      "4\n",
      "0\n",
      "3\n",
      "7\n",
      "0\n",
      "0\n",
      "5\n",
      "9\n",
      "5\n",
      "4\n",
      "5\n",
      "0\n",
      "5\n",
      "0\n",
      "3\n",
      "2\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "9\n",
      "9\n",
      "1\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "6\n",
      "8\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "3\n",
      "4\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "8\n",
      "3\n",
      "7\n",
      "8\n",
      "6\n",
      "5\n",
      "8\n",
      "8\n",
      "6\n",
      "5\n",
      "0\n",
      "7\n",
      "8\n",
      "2\n",
      "8\n",
      "7\n",
      "4\n",
      "6\n",
      "7\n",
      "1\n",
      "3\n",
      "6\n",
      "9\n",
      "3\n",
      "2\n",
      "9\n",
      "6\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "1\n",
      "1\n",
      "8\n",
      "9\n",
      "1\n",
      "5\n",
      "9\n",
      "1\n",
      "2\n",
      "8\n",
      "8\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "0\n",
      "6\n",
      "9\n",
      "5\n",
      "7\n",
      "0\n",
      "8\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "0\n",
      "2\n",
      "1\n",
      "9\n",
      "8\n",
      "1\n",
      "0\n",
      "9\n",
      "6\n",
      "8\n",
      "1\n",
      "2\n",
      "9\n",
      "7\n",
      "8\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "6\n",
      "7\n",
      "2\n",
      "5\n",
      "4\n",
      "9\n",
      "5\n",
      "0\n",
      "9\n",
      "7\n",
      "1\n",
      "7\n",
      "7\n",
      "5\n",
      "9\n",
      "8\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "7\n",
      "4\n",
      "6\n",
      "9\n",
      "2\n",
      "4\n",
      "9\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "9\n",
      "5\n",
      "3\n",
      "6\n",
      "1\n",
      "4\n",
      "5\n",
      "0\n",
      "3\n",
      "7\n",
      "9\n",
      "5\n",
      "3\n",
      "8\n",
      "7\n",
      "7\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "0\n",
      "3\n",
      "0\n",
      "7\n",
      "0\n",
      "9\n",
      "9\n",
      "2\n",
      "9\n",
      "3\n",
      "5\n",
      "2\n",
      "1\n",
      "3\n",
      "7\n",
      "0\n",
      "9\n",
      "8\n",
      "9\n",
      "7\n",
      "3\n",
      "3\n",
      "2\n",
      "9\n",
      "1\n",
      "9\n",
      "7\n",
      "9\n",
      "7\n",
      "0\n",
      "5\n",
      "9\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "6\n",
      "7\n",
      "8\n",
      "5\n",
      "8\n",
      "8\n",
      "7\n",
      "3\n",
      "0\n",
      "2\n",
      "1\n",
      "6\n",
      "7\n",
      "5\n",
      "1\n",
      "6\n",
      "1\n",
      "9\n",
      "8\n",
      "6\n",
      "4\n",
      "1\n",
      "6\n",
      "1\n",
      "6\n",
      "6\n",
      "1\n",
      "5\n",
      "1\n",
      "6\n",
      "8\n",
      "9\n",
      "2\n",
      "3\n",
      "3\n",
      "9\n",
      "1\n",
      "0\n",
      "5\n",
      "2\n",
      "8\n",
      "2\n",
      "1\n",
      "8\n",
      "4\n",
      "1\n",
      "9\n",
      "2\n",
      "8\n",
      "1\n",
      "4\n",
      "4\n",
      "9\n",
      "1\n",
      "8\n",
      "5\n",
      "7\n",
      "2\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "0\n",
      "6\n",
      "5\n",
      "5\n",
      "8\n",
      "2\n",
      "4\n",
      "4\n",
      "9\n",
      "9\n",
      "2\n",
      "1\n",
      "8\n",
      "8\n",
      "0\n",
      "6\n",
      "5\n",
      "7\n",
      "1\n",
      "8\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "8\n",
      "2\n",
      "7\n",
      "3\n",
      "5\n",
      "6\n",
      "3\n",
      "8\n",
      "6\n",
      "8\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "5\n",
      "2\n",
      "7\n",
      "9\n",
      "7\n",
      "6\n",
      "2\n",
      "2\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "6\n",
      "8\n",
      "9\n",
      "2\n",
      "1\n",
      "7\n",
      "2\n",
      "8\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "6\n",
      "9\n",
      "5\n",
      "9\n",
      "9\n",
      "3\n",
      "5\n",
      "7\n",
      "0\n",
      "9\n",
      "2\n",
      "1\n",
      "5\n",
      "6\n",
      "1\n",
      "5\n",
      "2\n",
      "3\n",
      "9\n",
      "0\n",
      "4\n",
      "9\n",
      "7\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "8\n",
      "9\n",
      "8\n",
      "0\n",
      "9\n",
      "3\n",
      "4\n",
      "1\n",
      "5\n",
      "8\n",
      "3\n",
      "8\n",
      "9\n",
      "7\n",
      "1\n",
      "3\n",
      "8\n",
      "6\n",
      "2\n",
      "7\n",
      "1\n",
      "8\n",
      "2\n",
      "8\n",
      "0\n",
      "4\n",
      "2\n",
      "9\n",
      "7\n",
      "4\n",
      "3\n",
      "4\n",
      "6\n",
      "3\n",
      "2\n",
      "9\n",
      "2\n",
      "1\n",
      "9\n",
      "8\n",
      "2\n",
      "6\n",
      "3\n",
      "1\n",
      "9\n",
      "9\n",
      "5\n",
      "2\n",
      "2\n",
      "7\n",
      "2\n",
      "1\n",
      "6\n",
      "2\n",
      "8\n",
      "8\n",
      "5\n",
      "4\n",
      "7\n",
      "8\n",
      "6\n",
      "9\n",
      "2\n",
      "9\n",
      "4\n",
      "5\n",
      "7\n",
      "5\n",
      "9\n",
      "9\n",
      "8\n",
      "1\n",
      "5\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "9\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "6\n",
      "7\n",
      "3\n",
      "3\n",
      "0\n",
      "7\n",
      "8\n",
      "8\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "7\n",
      "0\n",
      "7\n",
      "1\n",
      "7\n",
      "8\n",
      "6\n",
      "9\n",
      "3\n",
      "9\n",
      "1\n",
      "2\n",
      "2\n",
      "4\n",
      "8\n",
      "8\n",
      "0\n",
      "9\n",
      "5\n",
      "8\n",
      "3\n",
      "4\n",
      "7\n",
      "8\n",
      "2\n",
      "2\n",
      "9\n",
      "0\n",
      "8\n",
      "2\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "0\n",
      "6\n",
      "6\n",
      "2\n",
      "0\n",
      "3\n",
      "6\n",
      "5\n",
      "4\n",
      "9\n",
      "4\n",
      "1\n",
      "5\n",
      "6\n",
      "4\n",
      "1\n",
      "8\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "1\n",
      "7\n",
      "1\n",
      "0\n",
      "2\n",
      "9\n",
      "0\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "0\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "1\n",
      "2\n",
      "7\n",
      "3\n",
      "6\n",
      "9\n",
      "5\n",
      "4\n",
      "4\n",
      "8\n",
      "1\n",
      "3\n",
      "4\n",
      "0\n",
      "8\n",
      "5\n",
      "7\n",
      "5\n",
      "0\n",
      "2\n",
      "7\n",
      "6\n",
      "0\n",
      "9\n",
      "5\n",
      "9\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "0\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "8\n",
      "4\n",
      "1\n",
      "5\n",
      "9\n",
      "2\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "7\n",
      "0\n",
      "6\n",
      "5\n",
      "9\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "9\n",
      "4\n",
      "9\n",
      "2\n",
      "7\n",
      "5\n",
      "0\n",
      "5\n",
      "3\n",
      "9\n",
      "5\n",
      "3\n",
      "6\n",
      "6\n",
      "1\n",
      "0\n",
      "3\n",
      "7\n",
      "4\n",
      "0\n",
      "9\n",
      "7\n",
      "7\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "7\n",
      "0\n",
      "6\n",
      "4\n",
      "9\n",
      "0\n",
      "0\n",
      "5\n",
      "2\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "2\n",
      "5\n",
      "7\n",
      "9\n",
      "2\n",
      "8\n",
      "6\n",
      "8\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "1\n",
      "0\n",
      "3\n",
      "7\n",
      "7\n",
      "2\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "1\n",
      "3\n",
      "8\n",
      "3\n",
      "7\n",
      "2\n",
      "5\n",
      "8\n",
      "6\n",
      "0\n",
      "3\n",
      "5\n",
      "7\n",
      "8\n",
      "5\n",
      "3\n",
      "9\n",
      "1\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "8\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "8\n",
      "6\n",
      "2\n",
      "8\n",
      "3\n",
      "8\n",
      "2\n",
      "7\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "7\n",
      "5\n",
      "8\n",
      "5\n",
      "7\n",
      "1\n",
      "8\n",
      "5\n",
      "9\n",
      "3\n",
      "2\n",
      "7\n",
      "9\n",
      "8\n",
      "8\n",
      "1\n",
      "3\n",
      "9\n",
      "6\n",
      "1\n",
      "8\n",
      "0\n",
      "3\n",
      "4\n",
      "4\n",
      "7\n",
      "3\n",
      "3\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "1\n",
      "9\n",
      "8\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "6\n",
      "7\n",
      "4\n",
      "9\n",
      "8\n",
      "8\n",
      "6\n",
      "5\n",
      "9\n",
      "9\n",
      "3\n",
      "4\n",
      "9\n",
      "7\n",
      "1\n",
      "7\n",
      "8\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "8\n",
      "8\n",
      "3\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "5\n",
      "8\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "9\n",
      "2\n",
      "9\n",
      "6\n",
      "5\n",
      "2\n",
      "7\n",
      "0\n",
      "3\n",
      "7\n",
      "6\n",
      "2\n",
      "5\n",
      "3\n",
      "6\n",
      "1\n",
      "6\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "9\n",
      "2\n",
      "5\n",
      "6\n",
      "6\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "8\n",
      "0\n",
      "7\n",
      "5\n",
      "8\n",
      "4\n",
      "8\n",
      "7\n",
      "4\n",
      "5\n",
      "3\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "0\n",
      "5\n",
      "1\n",
      "7\n",
      "1\n",
      "7\n",
      "4\n",
      "4\n",
      "6\n",
      "1\n",
      "3\n",
      "2\n",
      "8\n",
      "5\n",
      "5\n",
      "9\n",
      "5\n",
      "7\n",
      "2\n",
      "6\n",
      "7\n",
      "6\n",
      "8\n",
      "5\n",
      "7\n",
      "4\n",
      "9\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "9\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "2\n",
      "1\n",
      "0\n",
      "4\n",
      "6\n",
      "9\n",
      "9\n",
      "0\n",
      "3\n",
      "5\n",
      "2\n",
      "0\n",
      "7\n",
      "2\n",
      "7\n",
      "0\n",
      "7\n",
      "5\n",
      "7\n",
      "5\n",
      "1\n",
      "6\n",
      "2\n",
      "3\n",
      "2\n",
      "7\n",
      "7\n",
      "0\n",
      "5\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "1\n",
      "0\n",
      "3\n",
      "6\n",
      "1\n",
      "4\n",
      "7\n",
      "9\n",
      "4\n",
      "9\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "7\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "1\n",
      "8\n",
      "7\n",
      "3\n",
      "1\n",
      "3\n",
      "7\n",
      "2\n",
      "7\n",
      "4\n",
      "4\n",
      "1\n",
      "8\n",
      "2\n",
      "1\n",
      "9\n",
      "4\n",
      "9\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "9\n",
      "9\n",
      "4\n",
      "1\n",
      "8\n",
      "2\n",
      "3\n",
      "2\n",
      "0\n",
      "8\n",
      "2\n",
      "4\n",
      "8\n",
      "4\n",
      "3\n",
      "2\n",
      "9\n",
      "7\n",
      "3\n",
      "6\n",
      "1\n",
      "9\n",
      "0\n",
      "3\n",
      "6\n",
      "7\n",
      "0\n",
      "8\n",
      "3\n",
      "4\n",
      "3\n",
      "7\n",
      "5\n",
      "9\n",
      "8\n",
      "7\n",
      "3\n",
      "7\n",
      "0\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "9\n",
      "3\n",
      "7\n",
      "2\n",
      "6\n",
      "8\n",
      "9\n",
      "5\n",
      "7\n",
      "4\n",
      "1\n",
      "8\n",
      "4\n",
      "5\n",
      "3\n",
      "8\n",
      "1\n",
      "5\n",
      "5\n",
      "8\n",
      "1\n",
      "2\n",
      "6\n",
      "2\n",
      "4\n",
      "1\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "5\n",
      "1\n",
      "1\n",
      "7\n",
      "9\n",
      "6\n",
      "8\n",
      "1\n",
      "1\n",
      "7\n",
      "5\n",
      "0\n",
      "6\n",
      "2\n",
      "9\n",
      "1\n",
      "8\n",
      "4\n",
      "6\n",
      "9\n",
      "8\n",
      "7\n",
      "9\n",
      "7\n",
      "2\n",
      "4\n",
      "1\n",
      "8\n",
      "9\n",
      "7\n",
      "5\n",
      "6\n",
      "8\n",
      "8\n",
      "4\n",
      "5\n",
      "5\n",
      "9\n",
      "7\n",
      "7\n",
      "4\n",
      "6\n",
      "4\n",
      "1\n",
      "2\n",
      "9\n",
      "8\n",
      "0\n",
      "3\n",
      "7\n",
      "9\n",
      "1\n",
      "7\n",
      "5\n",
      "7\n",
      "9\n",
      "0\n",
      "9\n",
      "2\n",
      "1\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "9\n",
      "0\n",
      "1\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "4\n",
      "7\n",
      "2\n",
      "9\n",
      "7\n",
      "3\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "0\n",
      "1\n",
      "8\n",
      "2\n",
      "7\n",
      "1\n",
      "5\n",
      "2\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "7\n",
      "7\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "8\n",
      "1\n",
      "5\n",
      "5\n",
      "6\n",
      "8\n",
      "1\n",
      "9\n",
      "7\n",
      "5\n",
      "8\n",
      "7\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "9\n",
      "8\n",
      "5\n",
      "8\n",
      "7\n",
      "4\n",
      "6\n",
      "1\n",
      "3\n",
      "7\n",
      "9\n",
      "0\n",
      "2\n",
      "2\n",
      "8\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "2\n",
      "5\n",
      "4\n",
      "7\n",
      "6\n",
      "1\n",
      "7\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "7\n",
      "6\n",
      "7\n",
      "9\n",
      "9\n",
      "5\n",
      "2\n",
      "6\n",
      "5\n",
      "2\n",
      "8\n",
      "4\n",
      "6\n",
      "7\n",
      "8\n",
      "6\n",
      "8\n",
      "2\n",
      "6\n",
      "5\n",
      "9\n",
      "0\n",
      "3\n",
      "6\n",
      "8\n",
      "3\n",
      "8\n",
      "9\n",
      "5\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "8\n",
      "7\n",
      "8\n",
      "2\n",
      "3\n",
      "6\n",
      "2\n",
      "8\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "8\n",
      "4\n",
      "3\n",
      "8\n",
      "5\n",
      "9\n",
      "2\n",
      "7\n",
      "8\n",
      "2\n",
      "6\n",
      "1\n",
      "5\n",
      "3\n",
      "8\n",
      "4\n",
      "6\n",
      "0\n",
      "8\n",
      "3\n",
      "2\n",
      "5\n",
      "9\n",
      "6\n",
      "6\n",
      "1\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "9\n",
      "1\n",
      "5\n",
      "1\n",
      "5\n",
      "7\n",
      "2\n",
      "5\n",
      "0\n",
      "1\n",
      "7\n",
      "9\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "0\n",
      "9\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "2\n",
      "6\n",
      "9\n",
      "1\n",
      "5\n",
      "9\n",
      "5\n",
      "1\n",
      "5\n",
      "8\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "7\n",
      "9\n",
      "5\n",
      "6\n",
      "2\n",
      "9\n",
      "1\n",
      "1\n",
      "6\n",
      "0\n",
      "8\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "9\n",
      "2\n",
      "8\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "3\n",
      "1\n",
      "0\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "0\n",
      "7\n",
      "6\n",
      "5\n",
      "0\n",
      "8\n",
      "7\n",
      "0\n",
      "3\n",
      "9\n",
      "2\n",
      "4\n",
      "7\n",
      "9\n",
      "6\n",
      "7\n",
      "8\n",
      "7\n",
      "5\n",
      "5\n",
      "6\n",
      "1\n",
      "6\n",
      "9\n",
      "7\n",
      "0\n",
      "2\n",
      "5\n",
      "9\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "7\n",
      "2\n",
      "7\n",
      "1\n",
      "0\n",
      "8\n",
      "9\n",
      "9\n",
      "5\n",
      "7\n",
      "1\n",
      "1\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "4\n",
      "1\n",
      "9\n",
      "3\n",
      "2\n",
      "7\n",
      "2\n",
      "8\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "4\n",
      "9\n",
      "0\n",
      "5\n",
      "5\n",
      "0\n",
      "2\n",
      "6\n",
      "9\n",
      "9\n",
      "6\n",
      "7\n",
      "7\n",
      "5\n",
      "6\n",
      "4\n",
      "5\n",
      "1\n",
      "1\n",
      "9\n",
      "7\n",
      "1\n",
      "3\n",
      "8\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "7\n",
      "2\n",
      "5\n",
      "1\n",
      "7\n",
      "7\n",
      "1\n",
      "7\n",
      "6\n",
      "1\n",
      "0\n",
      "7\n",
      "6\n",
      "8\n",
      "2\n",
      "7\n",
      "8\n",
      "7\n",
      "3\n",
      "7\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "6\n",
      "1\n",
      "1\n",
      "6\n",
      "2\n",
      "9\n",
      "2\n",
      "1\n",
      "7\n",
      "4\n",
      "9\n",
      "6\n",
      "7\n",
      "5\n",
      "5\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "9\n",
      "4\n",
      "8\n",
      "0\n",
      "7\n",
      "8\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "2\n",
      "5\n",
      "8\n",
      "6\n",
      "4\n",
      "8\n",
      "8\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "5\n",
      "1\n",
      "0\n",
      "6\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "3\n",
      "6\n",
      "7\n",
      "6\n",
      "2\n",
      "0\n",
      "4\n",
      "2\n",
      "8\n",
      "4\n",
      "6\n",
      "7\n",
      "2\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "2\n",
      "8\n",
      "6\n",
      "7\n",
      "6\n",
      "8\n",
      "7\n",
      "0\n",
      "8\n",
      "5\n",
      "6\n",
      "6\n",
      "4\n",
      "9\n",
      "6\n",
      "3\n",
      "5\n",
      "6\n",
      "5\n",
      "8\n",
      "5\n",
      "8\n",
      "8\n",
      "5\n",
      "3\n",
      "2\n",
      "1\n",
      "8\n",
      "3\n",
      "6\n",
      "2\n",
      "4\n",
      "2\n",
      "7\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "6\n",
      "2\n",
      "9\n",
      "7\n",
      "5\n",
      "1\n",
      "9\n",
      "6\n",
      "2\n",
      "3\n",
      "6\n",
      "7\n",
      "8\n",
      "4\n",
      "1\n",
      "5\n",
      "9\n",
      "9\n",
      "9\n",
      "3\n",
      "0\n",
      "1\n",
      "5\n",
      "9\n",
      "0\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "0\n",
      "2\n",
      "8\n",
      "1\n",
      "7\n",
      "3\n",
      "3\n",
      "9\n",
      "7\n",
      "1\n",
      "5\n",
      "9\n",
      "2\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "5\n",
      "1\n",
      "6\n",
      "9\n",
      "9\n",
      "2\n",
      "4\n",
      "8\n",
      "1\n",
      "2\n",
      "2\n",
      "5\n",
      "7\n",
      "0\n",
      "4\n",
      "6\n",
      "0\n",
      "2\n",
      "7\n",
      "5\n",
      "9\n",
      "7\n",
      "3\n",
      "7\n",
      "8\n",
      "2\n",
      "8\n",
      "3\n",
      "2\n",
      "2\n",
      "6\n",
      "8\n",
      "3\n",
      "3\n",
      "5\n",
      "7\n",
      "2\n",
      "2\n",
      "2\n",
      "7\n",
      "8\n",
      "0\n",
      "6\n",
      "9\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "8\n",
      "7\n",
      "6\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "2\n",
      "9\n",
      "9\n",
      "8\n",
      "0\n",
      "2\n",
      "4\n",
      "8\n",
      "9\n",
      "3\n",
      "1\n",
      "7\n",
      "0\n",
      "0\n",
      "9\n",
      "0\n",
      "3\n",
      "1\n",
      "5\n",
      "8\n",
      "1\n",
      "3\n",
      "2\n",
      "6\n",
      "3\n",
      "0\n",
      "6\n",
      "2\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "1\n",
      "8\n",
      "7\n",
      "4\n",
      "8\n",
      "9\n",
      "6\n",
      "8\n",
      "2\n",
      "7\n",
      "3\n",
      "3\n",
      "8\n",
      "5\n",
      "8\n",
      "9\n",
      "8\n",
      "5\n",
      "1\n",
      "5\n",
      "2\n",
      "4\n",
      "4\n",
      "1\n",
      "5\n",
      "0\n",
      "3\n",
      "2\n",
      "8\n",
      "0\n",
      "1\n",
      "2\n",
      "8\n",
      "9\n",
      "0\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "4\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "8\n",
      "3\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "8\n",
      "3\n",
      "0\n",
      "1\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "5\n",
      "3\n",
      "9\n",
      "3\n",
      "8\n",
      "0\n",
      "2\n",
      "8\n",
      "7\n",
      "2\n",
      "2\n",
      "5\n",
      "1\n",
      "3\n",
      "3\n",
      "1\n",
      "6\n",
      "3\n",
      "6\n",
      "2\n",
      "2\n",
      "8\n",
      "0\n",
      "7\n",
      "4\n",
      "7\n",
      "6\n",
      "2\n",
      "1\n",
      "6\n",
      "4\n",
      "8\n",
      "0\n",
      "8\n",
      "4\n",
      "9\n",
      "2\n",
      "4\n",
      "2\n",
      "8\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "4\n",
      "7\n",
      "2\n",
      "3\n",
      "6\n",
      "2\n",
      "2\n",
      "7\n",
      "9\n",
      "9\n",
      "2\n",
      "1\n",
      "8\n",
      "2\n",
      "9\n",
      "7\n",
      "1\n",
      "7\n",
      "4\n",
      "4\n",
      "8\n",
      "5\n",
      "4\n",
      "5\n",
      "2\n",
      "6\n",
      "8\n",
      "6\n",
      "3\n",
      "2\n",
      "4\n",
      "5\n",
      "3\n",
      "1\n",
      "5\n",
      "9\n",
      "0\n",
      "3\n",
      "5\n",
      "8\n",
      "6\n",
      "6\n",
      "5\n",
      "0\n",
      "5\n",
      "4\n",
      "6\n",
      "5\n",
      "2\n",
      "9\n",
      "2\n",
      "1\n",
      "2\n",
      "7\n",
      "4\n",
      "8\n",
      "9\n",
      "1\n",
      "1\n",
      "3\n",
      "5\n",
      "2\n",
      "9\n",
      "2\n",
      "1\n",
      "5\n",
      "3\n",
      "0\n",
      "5\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "6\n",
      "7\n",
      "2\n",
      "8\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "9\n",
      "3\n",
      "2\n",
      "2\n",
      "6\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "4\n",
      "9\n",
      "2\n",
      "9\n",
      "2\n",
      "8\n",
      "7\n",
      "2\n",
      "0\n",
      "6\n",
      "0\n",
      "7\n",
      "8\n",
      "2\n",
      "4\n",
      "7\n",
      "9\n",
      "4\n",
      "9\n",
      "6\n",
      "3\n",
      "4\n",
      "9\n",
      "3\n",
      "5\n",
      "8\n",
      "6\n",
      "8\n",
      "1\n",
      "1\n",
      "5\n",
      "4\n",
      "3\n",
      "9\n",
      "5\n",
      "7\n",
      "9\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "6\n",
      "8\n",
      "8\n",
      "0\n",
      "5\n",
      "2\n",
      "1\n",
      "8\n",
      "2\n",
      "9\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "1\n",
      "7\n",
      "9\n",
      "2\n",
      "6\n",
      "6\n",
      "7\n",
      "1\n",
      "9\n",
      "6\n",
      "8\n",
      "5\n",
      "6\n",
      "3\n",
      "9\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "7\n",
      "7\n",
      "3\n",
      "8\n",
      "5\n",
      "8\n",
      "3\n",
      "3\n",
      "7\n",
      "9\n",
      "5\n",
      "1\n",
      "6\n",
      "6\n",
      "5\n",
      "0\n",
      "0\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "8\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "8\n",
      "3\n",
      "5\n",
      "3\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "2\n",
      "8\n",
      "5\n",
      "2\n",
      "8\n",
      "6\n",
      "6\n",
      "9\n",
      "0\n",
      "1\n",
      "8\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "6\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "7\n",
      "1\n",
      "3\n",
      "8\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "6\n",
      "8\n",
      "0\n",
      "8\n",
      "3\n",
      "7\n",
      "5\n",
      "2\n",
      "0\n",
      "5\n",
      "6\n",
      "9\n",
      "2\n",
      "1\n",
      "9\n",
      "7\n",
      "7\n",
      "2\n",
      "2\n",
      "8\n",
      "8\n",
      "3\n",
      "8\n",
      "2\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "0\n",
      "8\n",
      "5\n",
      "0\n",
      "4\n",
      "9\n",
      "1\n",
      "5\n",
      "1\n",
      "6\n",
      "4\n",
      "0\n",
      "6\n",
      "8\n",
      "5\n",
      "7\n",
      "5\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "0\n",
      "3\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "7\n",
      "4\n",
      "5\n",
      "8\n",
      "5\n",
      "1\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "8\n",
      "0\n",
      "6\n",
      "5\n",
      "9\n",
      "1\n",
      "6\n",
      "0\n",
      "7\n",
      "0\n",
      "9\n",
      "1\n",
      "2\n",
      "8\n",
      "4\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "4\n",
      "1\n",
      "2\n",
      "6\n",
      "1\n",
      "1\n",
      "9\n",
      "5\n",
      "7\n",
      "1\n",
      "5\n",
      "9\n",
      "3\n",
      "5\n",
      "9\n",
      "8\n",
      "3\n",
      "9\n",
      "5\n",
      "2\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "7\n",
      "8\n",
      "9\n",
      "7\n",
      "2\n",
      "0\n",
      "7\n",
      "2\n",
      "1\n",
      "1\n",
      "9\n",
      "0\n",
      "5\n",
      "5\n",
      "1\n",
      "6\n",
      "5\n",
      "1\n",
      "7\n",
      "1\n",
      "7\n",
      "1\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "9\n",
      "0\n",
      "2\n",
      "8\n",
      "6\n",
      "0\n",
      "6\n",
      "8\n",
      "9\n",
      "7\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "8\n",
      "1\n",
      "3\n",
      "2\n",
      "8\n",
      "2\n",
      "1\n",
      "9\n",
      "9\n",
      "1\n",
      "3\n",
      "9\n",
      "9\n",
      "1\n",
      "2\n",
      "8\n",
      "7\n",
      "2\n",
      "6\n",
      "8\n",
      "7\n",
      "9\n",
      "3\n",
      "2\n",
      "2\n",
      "7\n",
      "4\n",
      "1\n",
      "9\n",
      "2\n",
      "8\n",
      "5\n",
      "9\n",
      "6\n",
      "8\n",
      "0\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "2\n",
      "0\n",
      "9\n",
      "9\n",
      "2\n",
      "3\n",
      "1\n",
      "7\n",
      "2\n",
      "8\n",
      "1\n",
      "3\n",
      "5\n",
      "4\n",
      "0\n",
      "7\n",
      "1\n",
      "4\n",
      "3\n",
      "7\n",
      "3\n",
      "5\n",
      "0\n",
      "8\n",
      "6\n",
      "2\n",
      "8\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "9\n",
      "5\n",
      "9\n",
      "9\n",
      "4\n",
      "7\n",
      "9\n",
      "6\n",
      "6\n",
      "9\n",
      "3\n",
      "5\n",
      "9\n",
      "5\n",
      "9\n",
      "2\n",
      "0\n",
      "6\n",
      "4\n",
      "2\n",
      "0\n",
      "6\n",
      "6\n",
      "3\n",
      "8\n",
      "4\n",
      "2\n",
      "8\n",
      "1\n",
      "9\n",
      "0\n",
      "9\n",
      "0\n",
      "5\n",
      "3\n",
      "0\n",
      "7\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "4\n",
      "8\n",
      "6\n",
      "9\n",
      "1\n",
      "8\n",
      "9\n",
      "1\n",
      "3\n",
      "8\n",
      "1\n",
      "2\n",
      "9\n",
      "2\n",
      "9\n",
      "7\n",
      "1\n",
      "5\n",
      "6\n",
      "5\n",
      "1\n",
      "8\n",
      "7\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "7\n",
      "5\n",
      "7\n",
      "1\n",
      "0\n",
      "3\n",
      "7\n",
      "3\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "0\n",
      "0\n",
      "5\n",
      "7\n",
      "7\n",
      "6\n",
      "0\n",
      "7\n",
      "6\n",
      "7\n",
      "9\n",
      "7\n",
      "4\n",
      "8\n",
      "7\n",
      "2\n",
      "0\n",
      "6\n",
      "2\n",
      "7\n",
      "0\n",
      "6\n",
      "3\n",
      "7\n",
      "9\n",
      "4\n",
      "6\n",
      "5\n",
      "0\n",
      "7\n",
      "2\n",
      "0\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "6\n",
      "9\n",
      "9\n",
      "5\n",
      "9\n",
      "8\n",
      "7\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "7\n",
      "4\n",
      "0\n",
      "8\n",
      "7\n",
      "4\n",
      "6\n",
      "6\n",
      "2\n",
      "2\n",
      "0\n",
      "9\n",
      "0\n",
      "5\n",
      "2\n",
      "5\n",
      "4\n",
      "1\n",
      "6\n",
      "1\n",
      "6\n",
      "4\n",
      "0\n",
      "2\n",
      "2\n",
      "9\n",
      "4\n",
      "8\n",
      "2\n",
      "0\n",
      "6\n",
      "1\n",
      "2\n",
      "2\n",
      "8\n",
      "1\n",
      "8\n",
      "3\n",
      "9\n",
      "7\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "8\n",
      "8\n",
      "1\n",
      "8\n",
      "5\n",
      "5\n",
      "1\n",
      "5\n",
      "5\n",
      "2\n",
      "7\n",
      "6\n",
      "7\n",
      "3\n",
      "9\n",
      "5\n",
      "6\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "8\n",
      "1\n",
      "7\n",
      "8\n",
      "6\n",
      "6\n",
      "4\n",
      "9\n",
      "9\n",
      "1\n",
      "4\n",
      "4\n",
      "6\n",
      "1\n",
      "1\n",
      "7\n",
      "0\n",
      "0\n",
      "6\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "7\n",
      "7\n",
      "9\n",
      "1\n",
      "6\n",
      "9\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "0\n",
      "9\n",
      "5\n",
      "3\n",
      "4\n",
      "7\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "8\n",
      "3\n",
      "2\n",
      "0\n",
      "7\n",
      "4\n",
      "8\n",
      "7\n",
      "1\n",
      "5\n",
      "2\n",
      "8\n",
      "7\n",
      "9\n",
      "8\n",
      "4\n",
      "0\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "5\n",
      "7\n",
      "2\n",
      "9\n",
      "9\n",
      "1\n",
      "9\n",
      "9\n",
      "1\n",
      "5\n",
      "8\n",
      "6\n",
      "8\n",
      "6\n",
      "5\n",
      "8\n",
      "0\n",
      "1\n",
      "7\n",
      "0\n",
      "6\n",
      "9\n",
      "1\n",
      "8\n",
      "2\n",
      "9\n",
      "3\n",
      "0\n",
      "6\n",
      "3\n",
      "3\n",
      "0\n",
      "2\n",
      "1\n",
      "6\n",
      "5\n",
      "3\n",
      "8\n",
      "2\n",
      "1\n",
      "2\n",
      "4\n",
      "9\n",
      "4\n",
      "5\n",
      "1\n",
      "6\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "9\n",
      "5\n",
      "0\n",
      "4\n",
      "0\n",
      "4\n",
      "8\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "4\n",
      "8\n",
      "1\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "7\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "7\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "8\n",
      "6\n",
      "5\n",
      "1\n",
      "2\n",
      "8\n",
      "6\n",
      "8\n",
      "9\n",
      "0\n",
      "2\n",
      "8\n",
      "2\n",
      "8\n",
      "3\n",
      "0\n",
      "5\n",
      "8\n",
      "6\n",
      "7\n",
      "4\n",
      "8\n",
      "6\n",
      "9\n",
      "2\n",
      "7\n",
      "4\n",
      "0\n",
      "0\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "6\n",
      "0\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "5\n",
      "3\n",
      "9\n",
      "6\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "7\n",
      "8\n",
      "6\n",
      "4\n",
      "0\n",
      "6\n",
      "3\n",
      "6\n",
      "8\n",
      "7\n",
      "0\n",
      "5\n",
      "0\n",
      "7\n",
      "5\n",
      "7\n",
      "9\n",
      "1\n",
      "0\n",
      "5\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "8\n",
      "2\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "1\n",
      "2\n",
      "4\n",
      "5\n",
      "3\n",
      "7\n",
      "6\n",
      "3\n",
      "8\n",
      "0\n",
      "9\n",
      "1\n",
      "7\n",
      "4\n",
      "4\n",
      "8\n",
      "5\n",
      "7\n",
      "4\n",
      "3\n",
      "2\n",
      "8\n",
      "7\n",
      "2\n",
      "7\n",
      "8\n",
      "9\n",
      "2\n",
      "6\n",
      "2\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "3\n",
      "6\n",
      "4\n",
      "2\n",
      "6\n",
      "9\n",
      "1\n",
      "4\n",
      "8\n",
      "1\n",
      "2\n",
      "1\n",
      "9\n",
      "4\n",
      "0\n",
      "5\n",
      "9\n",
      "4\n",
      "6\n",
      "6\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "1\n",
      "9\n",
      "1\n",
      "0\n",
      "3\n",
      "6\n",
      "5\n",
      "3\n",
      "1\n",
      "8\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "8\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "2\n",
      "2\n",
      "8\n",
      "0\n",
      "2\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "1\n",
      "9\n",
      "1\n",
      "3\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "6\n",
      "0\n",
      "6\n",
      "9\n",
      "2\n",
      "8\n",
      "2\n",
      "9\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "6\n",
      "0\n",
      "9\n",
      "8\n",
      "5\n",
      "2\n",
      "5\n",
      "1\n",
      "7\n",
      "2\n",
      "2\n",
      "2\n",
      "8\n",
      "3\n",
      "4\n",
      "5\n",
      "8\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "6\n",
      "0\n",
      "6\n",
      "2\n",
      "6\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "4\n",
      "8\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "7\n",
      "0\n",
      "5\n",
      "4\n",
      "5\n",
      "1\n",
      "0\n",
      "5\n",
      "6\n",
      "0\n",
      "2\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "2\n",
      "2\n",
      "7\n",
      "3\n",
      "2\n",
      "0\n",
      "6\n",
      "6\n",
      "7\n",
      "1\n",
      "7\n",
      "2\n",
      "5\n",
      "1\n",
      "2\n",
      "5\n",
      "7\n",
      "6\n",
      "0\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "0\n",
      "4\n",
      "9\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "1\n",
      "7\n",
      "5\n",
      "9\n",
      "0\n",
      "5\n",
      "8\n",
      "5\n",
      "1\n",
      "3\n",
      "6\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "0\n",
      "2\n",
      "1\n",
      "7\n",
      "3\n",
      "5\n",
      "7\n",
      "6\n",
      "0\n",
      "6\n",
      "0\n",
      "0\n",
      "5\n",
      "5\n",
      "6\n",
      "2\n",
      "0\n",
      "6\n",
      "2\n",
      "5\n",
      "8\n",
      "0\n",
      "6\n",
      "9\n",
      "5\n",
      "9\n",
      "3\n",
      "7\n",
      "6\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "8\n",
      "8\n",
      "4\n",
      "2\n",
      "7\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "2\n",
      "7\n",
      "2\n",
      "8\n",
      "8\n",
      "6\n",
      "7\n",
      "8\n",
      "2\n",
      "1\n",
      "9\n",
      "3\n",
      "5\n",
      "1\n",
      "8\n",
      "0\n",
      "8\n",
      "5\n",
      "8\n",
      "9\n",
      "3\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "7\n",
      "1\n",
      "3\n",
      "5\n",
      "8\n",
      "7\n",
      "1\n",
      "2\n",
      "7\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "8\n",
      "2\n",
      "6\n",
      "5\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "9\n",
      "9\n",
      "9\n",
      "4\n",
      "9\n",
      "7\n",
      "5\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "6\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "1\n",
      "0\n",
      "9\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "9\n",
      "3\n",
      "8\n",
      "7\n",
      "8\n",
      "9\n",
      "8\n",
      "2\n",
      "9\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "8\n",
      "2\n",
      "3\n",
      "2\n",
      "6\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "9\n",
      "5\n",
      "1\n",
      "1\n",
      "8\n",
      "8\n",
      "5\n",
      "3\n",
      "5\n",
      "0\n",
      "1\n",
      "6\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "5\n",
      "2\n",
      "1\n",
      "3\n",
      "9\n",
      "5\n",
      "7\n",
      "8\n",
      "0\n",
      "6\n",
      "2\n",
      "3\n",
      "2\n",
      "7\n",
      "9\n",
      "2\n",
      "8\n",
      "4\n",
      "2\n",
      "1\n",
      "6\n",
      "0\n",
      "0\n",
      "2\n",
      "8\n",
      "4\n",
      "2\n",
      "3\n",
      "0\n",
      "8\n",
      "6\n",
      "9\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "1\n",
      "7\n",
      "3\n",
      "2\n",
      "3\n",
      "8\n",
      "0\n",
      "3\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "5\n",
      "2\n",
      "0\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "8\n",
      "6\n",
      "0\n",
      "1\n",
      "9\n",
      "6\n",
      "2\n",
      "0\n",
      "8\n",
      "0\n",
      "7\n",
      "8\n",
      "0\n",
      "4\n",
      "9\n",
      "5\n",
      "5\n",
      "2\n",
      "7\n",
      "1\n",
      "7\n",
      "3\n",
      "4\n",
      "7\n",
      "6\n",
      "1\n",
      "6\n",
      "6\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "0\n",
      "7\n",
      "1\n",
      "1\n",
      "7\n",
      "8\n",
      "1\n",
      "5\n",
      "8\n",
      "9\n",
      "6\n",
      "9\n",
      "6\n",
      "9\n",
      "6\n",
      "8\n",
      "6\n",
      "2\n",
      "8\n",
      "0\n",
      "1\n",
      "9\n",
      "6\n",
      "5\n",
      "1\n",
      "5\n",
      "0\n",
      "2\n",
      "9\n",
      "7\n",
      "2\n",
      "9\n",
      "2\n",
      "8\n",
      "2\n",
      "1\n",
      "5\n",
      "2\n",
      "8\n",
      "8\n",
      "6\n",
      "2\n",
      "7\n",
      "6\n",
      "4\n",
      "6\n",
      "2\n",
      "8\n",
      "3\n",
      "8\n",
      "9\n",
      "1\n",
      "1\n",
      "8\n",
      "2\n",
      "5\n",
      "1\n",
      "9\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "3\n",
      "5\n",
      "1\n",
      "3\n",
      "2\n",
      "4\n",
      "8\n",
      "3\n",
      "7\n",
      "2\n",
      "5\n",
      "8\n",
      "3\n",
      "2\n",
      "7\n",
      "6\n",
      "6\n",
      "2\n",
      "8\n",
      "4\n",
      "9\n",
      "9\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "8\n",
      "1\n",
      "6\n",
      "1\n",
      "5\n",
      "6\n",
      "7\n",
      "3\n",
      "1\n",
      "7\n",
      "3\n",
      "1\n",
      "7\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "8\n",
      "6\n",
      "2\n",
      "3\n",
      "1\n",
      "4\n",
      "8\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "9\n",
      "8\n",
      "6\n",
      "1\n",
      "5\n",
      "6\n",
      "2\n",
      "6\n",
      "2\n",
      "5\n",
      "7\n",
      "1\n",
      "2\n",
      "7\n",
      "2\n",
      "7\n",
      "8\n",
      "0\n",
      "0\n",
      "6\n",
      "1\n",
      "5\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "1\n",
      "4\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "8\n",
      "5\n",
      "4\n",
      "6\n",
      "5\n",
      "8\n",
      "4\n",
      "9\n",
      "6\n",
      "9\n",
      "4\n",
      "3\n",
      "9\n",
      "0\n",
      "1\n",
      "1\n",
      "3\n",
      "5\n",
      "8\n",
      "3\n",
      "4\n",
      "6\n",
      "8\n",
      "0\n",
      "6\n",
      "8\n",
      "4\n",
      "3\n",
      "5\n",
      "8\n",
      "7\n",
      "0\n",
      "6\n",
      "9\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "2\n",
      "7\n",
      "0\n",
      "6\n",
      "1\n",
      "1\n",
      "0\n",
      "9\n",
      "3\n",
      "1\n",
      "9\n",
      "8\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n",
      "7\n",
      "8\n",
      "1\n",
      "8\n",
      "6\n",
      "1\n",
      "8\n",
      "2\n",
      "5\n",
      "7\n",
      "0\n",
      "2\n",
      "6\n",
      "2\n",
      "3\n",
      "7\n",
      "0\n",
      "4\n",
      "8\n",
      "3\n",
      "5\n",
      "1\n",
      "3\n",
      "6\n",
      "7\n",
      "7\n",
      "3\n",
      "6\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "8\n",
      "6\n",
      "1\n",
      "2\n",
      "8\n",
      "9\n",
      "5\n",
      "9\n",
      "9\n",
      "6\n",
      "2\n",
      "9\n",
      "2\n",
      "2\n",
      "2\n",
      "9\n",
      "1\n",
      "0\n",
      "7\n",
      "8\n",
      "5\n",
      "2\n",
      "6\n",
      "3\n",
      "4\n",
      "0\n",
      "7\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n",
      "9\n",
      "3\n",
      "3\n",
      "3\n",
      "9\n",
      "7\n",
      "2\n",
      "8\n",
      "2\n",
      "8\n",
      "3\n",
      "2\n",
      "8\n",
      "0\n",
      "3\n",
      "1\n",
      "8\n",
      "2\n",
      "3\n",
      "8\n",
      "5\n",
      "4\n",
      "3\n",
      "7\n",
      "3\n",
      "8\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "9\n",
      "8\n",
      "5\n",
      "1\n",
      "6\n",
      "2\n",
      "6\n",
      "1\n",
      "7\n",
      "6\n",
      "2\n",
      "2\n",
      "9\n",
      "6\n",
      "5\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "1\n",
      "7\n",
      "8\n",
      "0\n",
      "7\n",
      "0\n",
      "3\n",
      "1\n",
      "1\n",
      "6\n",
      "9\n",
      "2\n",
      "0\n",
      "7\n",
      "7\n",
      "8\n",
      "4\n",
      "7\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "1\n",
      "6\n",
      "5\n",
      "8\n",
      "7\n",
      "5\n",
      "4\n",
      "9\n",
      "8\n",
      "0\n",
      "8\n",
      "6\n",
      "9\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "9\n",
      "9\n",
      "7\n",
      "7\n",
      "8\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "8\n",
      "1\n",
      "6\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "7\n",
      "7\n",
      "4\n",
      "0\n",
      "1\n",
      "9\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "7\n",
      "4\n",
      "0\n",
      "8\n",
      "5\n",
      "3\n",
      "0\n",
      "1\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "0\n",
      "5\n",
      "9\n",
      "2\n",
      "6\n",
      "9\n",
      "4\n",
      "5\n",
      "9\n",
      "2\n",
      "3\n",
      "2\n",
      "7\n",
      "7\n",
      "8\n",
      "2\n",
      "0\n",
      "7\n",
      "4\n",
      "8\n",
      "8\n",
      "1\n",
      "7\n",
      "1\n",
      "5\n",
      "8\n",
      "9\n",
      "3\n",
      "8\n",
      "3\n",
      "9\n",
      "2\n",
      "9\n",
      "2\n",
      "9\n",
      "2\n",
      "1\n",
      "8\n",
      "0\n",
      "5\n",
      "3\n",
      "9\n",
      "5\n",
      "5\n",
      "7\n",
      "3\n",
      "2\n",
      "9\n",
      "0\n",
      "5\n",
      "3\n",
      "8\n",
      "9\n",
      "0\n",
      "8\n",
      "6\n",
      "9\n",
      "4\n",
      "0\n",
      "9\n",
      "5\n",
      "9\n",
      "8\n",
      "0\n",
      "6\n",
      "4\n",
      "4\n",
      "8\n",
      "6\n",
      "8\n",
      "6\n",
      "2\n",
      "5\n",
      "8\n",
      "3\n",
      "1\n",
      "4\n",
      "9\n",
      "7\n",
      "1\n",
      "4\n",
      "7\n",
      "4\n",
      "0\n",
      "8\n",
      "1\n",
      "7\n",
      "3\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "8\n",
      "3\n",
      "9\n",
      "6\n",
      "0\n",
      "6\n",
      "5\n",
      "2\n",
      "6\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "9\n",
      "4\n",
      "2\n",
      "3\n",
      "8\n",
      "8\n",
      "5\n",
      "7\n",
      "2\n",
      "3\n",
      "0\n",
      "9\n",
      "2\n",
      "1\n",
      "0\n",
      "8\n",
      "5\n",
      "5\n",
      "3\n",
      "9\n",
      "8\n",
      "0\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "1\n",
      "8\n",
      "5\n",
      "7\n",
      "0\n",
      "7\n",
      "3\n",
      "5\n",
      "1\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "7\n",
      "4\n",
      "6\n",
      "9\n",
      "4\n",
      "9\n",
      "9\n",
      "3\n",
      "7\n",
      "0\n",
      "9\n",
      "4\n",
      "5\n",
      "3\n",
      "9\n",
      "8\n",
      "6\n",
      "5\n",
      "7\n",
      "9\n",
      "4\n",
      "5\n",
      "2\n",
      "4\n",
      "9\n",
      "6\n",
      "6\n",
      "1\n",
      "8\n",
      "4\n",
      "5\n",
      "0\n",
      "3\n",
      "8\n",
      "2\n",
      "0\n",
      "5\n",
      "3\n",
      "6\n",
      "5\n",
      "2\n",
      "6\n",
      "6\n",
      "0\n",
      "2\n",
      "5\n",
      "7\n",
      "2\n",
      "7\n",
      "1\n",
      "9\n",
      "8\n",
      "3\n",
      "0\n",
      "2\n",
      "8\n",
      "7\n",
      "3\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "8\n",
      "8\n",
      "1\n",
      "7\n",
      "4\n",
      "8\n",
      "2\n",
      "6\n",
      "1\n",
      "6\n",
      "9\n",
      "8\n",
      "0\n",
      "6\n",
      "7\n",
      "7\n",
      "0\n",
      "8\n",
      "8\n",
      "3\n",
      "9\n",
      "7\n",
      "4\n",
      "4\n",
      "8\n",
      "6\n",
      "2\n",
      "1\n",
      "8\n",
      "4\n",
      "7\n",
      "2\n",
      "9\n",
      "1\n",
      "3\n",
      "4\n",
      "8\n",
      "3\n",
      "6\n",
      "7\n",
      "1\n",
      "3\n",
      "1\n",
      "7\n",
      "2\n",
      "7\n",
      "5\n",
      "0\n",
      "7\n",
      "5\n",
      "8\n",
      "7\n",
      "0\n",
      "4\n",
      "8\n",
      "9\n",
      "1\n",
      "5\n",
      "9\n",
      "9\n",
      "5\n",
      "1\n",
      "2\n",
      "6\n",
      "6\n",
      "1\n",
      "0\n",
      "0\n",
      "4\n",
      "2\n",
      "8\n",
      "6\n",
      "6\n",
      "2\n",
      "6\n",
      "7\n",
      "4\n",
      "0\n",
      "0\n",
      "1\n",
      "6\n",
      "6\n",
      "1\n",
      "6\n",
      "2\n",
      "6\n",
      "1\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "4\n",
      "3\n",
      "0\n",
      "9\n",
      "6\n",
      "4\n",
      "2\n",
      "8\n",
      "8\n",
      "5\n",
      "4\n",
      "0\n",
      "0\n",
      "5\n",
      "1\n",
      "3\n",
      "7\n",
      "3\n",
      "2\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "y_preds=torch.argmax(cnn(X_test),dim=1).squeeze().cpu().numpy()\n",
    "for l in y_preds:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " #DataLoader Class\n",
    "# if BATCH_SIZE = N, dataloader returns images tensor of size [N, C, H, W] and labels [N]\n",
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_csv, train = True , img_transform=None):\n",
    "        \"\"\"\n",
    "        Dataset init function\n",
    "        \n",
    "        INPUT:\n",
    "        data_csv: Path to csv file containing [data, labels]\n",
    "        train: \n",
    "            True: if the csv file has [labels,data] (Train data and Public Test Data) \n",
    "            False: if the csv file has only [data] and labels are not present.\n",
    "        img_transform: List of preprocessing operations need to performed on image. \n",
    "        \"\"\"\n",
    "        \n",
    "        self.data_csv = data_csv\n",
    "        self.img_transform = img_transform\n",
    "        self.is_train = train\n",
    "        \n",
    "        data = pd.read_csv(data_csv, header=None)\n",
    "        if self.is_train:\n",
    "            images = data.iloc[:,1:].to_numpy()\n",
    "            labels = data.iloc[:,0].astype(int)\n",
    "        else:\n",
    "            images = data.iloc[:,:]\n",
    "            labels = None\n",
    "        \n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        print(\"Total Images: {}, Data Shape = {}\".format(len(self.images), images.shape))\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns total number of samples in the dataset\"\"\"\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Loads image of the given index and performs preprocessing.\n",
    "        \n",
    "        INPUT: \n",
    "        idx: index of the image to be loaded.\n",
    "        \n",
    "        OUTPUT:\n",
    "        sample: dictionary with keys images (Tensor of shape [1,C,H,W]) and labels (Tensor of labels [1]).\n",
    "        \"\"\"\n",
    "        image = self.images[idx]\n",
    "        image = np.array(image).astype(np.uint8).reshape((32, 32, 3),order='F')\n",
    "        if self.is_train:\n",
    "            label = self.labels[idx]\n",
    "        else:\n",
    "            label = -1\n",
    "        \n",
    "        image = self.img_transform(image)\n",
    "        \n",
    "        sample = {\"images\": image, \"labels\": label}\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images: 60000, Data Shape = (60000, 3072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images: 4000, Data Shape = (4000, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Data Loader Usage\n",
    "\n",
    "BATCH_SIZE = 200 # Batch Size. Adjust accordingly\n",
    "NUM_WORKERS = 0 # Number of threads to be used for image loading. Adjust accordingly.\n",
    "\n",
    "img_transforms = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])\n",
    "\n",
    "# Train DataLoader\n",
    "train_data = \"cifar10_data/train_data.csv\"\n",
    "train_dataset = ImageDataset(data_csv = train_data, train=True, img_transform=img_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)\n",
    "\n",
    "# Test DataLoader\n",
    "test_data = \"cifar10_data/public_test.csv\"\n",
    "\n",
    "test_dataset = ImageDataset(data_csv = test_data, train=True, img_transform=img_transforms)\n",
    "n=test_dataset.__len__()\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_B,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3)\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,64,3)\n",
    "        self.bn2=nn.BatchNorm2d(64)\n",
    "        self.c3=nn.Conv2d(64,512,3)\n",
    "        self.bn3=nn.BatchNorm2d(512)\n",
    "        self.c4=nn.Conv2d(512,1024,2)\n",
    "        self.fc1=nn.Linear(1024,256)\n",
    "        self.fc2=nn.Linear(256,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn1(self.c1(X))))\n",
    "        X=self.p2(F.relu(self.bn2(self.c2(X)))) \n",
    "        X=self.p2(F.relu(self.bn3(self.c3(X))))        \n",
    "        X=F.relu(self.c4(X))\n",
    "        X=X.view(-1,1024)\n",
    "        X=self.fc2(self.dropout(F.relu(self.fc1(X))))\n",
    "        return X\n",
    "def acc(y_true,y_preds):\n",
    "    y_preds=torch.argmax(y_preds,dim=1).squeeze()\n",
    "    return (y_true==y_preds).sum().item()/len(y_true)\n",
    "bs=200\n",
    "#train_data=DataLoader(dev_dataset(X_train,y_train),batch_size=bs,shuffle=False)\n",
    "# X_train,y_train=torch.from_numpy(X_train).cuda(),torch.LongTensor(y_train).cuda()\n",
    "#X_test,y_test=torch.from_numpy(X_test).cuda(),torch.LongTensor(y_test).cuda()\n",
    "torch.manual_seed(51)\n",
    "cnn=CNN_B()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.4273227107524873 test accuracy: 0.58725\n",
      "Epoch: 2 Train loss: 1.0499881029129028 test accuracy: 0.64875\n",
      "Epoch: 3 Train loss: 0.8823549230893453 test accuracy: 0.6785\n",
      "Epoch: 4 Train loss: 0.7514056183894475 test accuracy: 0.698\n",
      "Epoch: 5 Train loss: 0.6366782719890277 test accuracy: 0.703\n"
     ]
    }
   ],
   "source": [
    "def train(cnn,train_data,epochs,opt,loss,test_data):\n",
    "    losses=[]\n",
    "    accuracies=[]\n",
    "    for i in range(epochs):\n",
    "        l=0\n",
    "        for j,(X,y) in enumerate(train_data):\n",
    "            #print(X.shape,y.shape,type(X),type(y))\n",
    "            yh=cnn(X.cuda())\n",
    "            train_loss=loss(yh,y.type(torch.LongTensor).cuda())\n",
    "            opt.zero_grad()\n",
    "            l+=train_loss.item()\n",
    "            train_loss.backward()\n",
    "            opt.step()\n",
    "        with torch.no_grad():    \n",
    "            l/=len(train_data) \n",
    "            c=0\n",
    "            for j,(X,y) in enumerate(test_data):\n",
    "            \n",
    "                losses.append(l)\n",
    "                y_preds=cnn(X.cuda())\n",
    "                y_preds=torch.argmax(y_preds,dim=1).squeeze()\n",
    "                c+=(y.cuda()==y_preds).sum().item()\n",
    "            c/=n    \n",
    "            accuracies.append(c)\n",
    "            print(\"Epoch: \"+str(i+1)+\" Train loss: \"+str(losses[-1])+\" test accuracy: \" +str(accuracies[-1]))        \n",
    "    return losses,accuracies \n",
    "epochs=5\n",
    "l,a=train(cnn,train_loader,epochs,opt,loss,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2679178"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in CNN_B().parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_B,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3)\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,64,3)\n",
    "        self.bn2=nn.BatchNorm2d(64)\n",
    "        self.c3=nn.Conv2d(64,512,3)\n",
    "        self.bn3=nn.BatchNorm2d(512)\n",
    "        self.c4=nn.Conv2d(512,1024,2)\n",
    "        self.fc1=nn.Linear(1024,256)\n",
    "        self.fc2=nn.Linear(256,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn1(self.c1(X))))\n",
    "        X=self.p2(F.relu(self.bn2(self.c2(X)))) \n",
    "        X=self.p2(F.relu(self.bn3(self.c3(X))))        \n",
    "        X=F.relu(self.c4(X))\n",
    "        X=X.view(-1,1024)\n",
    "        X=self.fc2(self.dropout(F.relu(self.fc1(X))))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=CNN_B().cuda()\n",
    "cnn.load_state_dict(torch.load('./model.pth'))\n",
    "cnn.eval()\n",
    "X_test=pd.read_csv('cifar10_data/public_test.csv',header=None).iloc[:,1:].to_numpy().astype(np.float32).reshape((-1,3,32,32))\n",
    "X_test=torch.from_numpy(X_test).cuda()\n",
    "y_preds=torch.argmax(cnn(X_test),dim=1).squeeze().cpu().numpy()\n",
    "f=open('pred.txt','w')\n",
    "for l in y_preds:\n",
    "    f.write(str(l))\n",
    "    f.write('\\n')\n",
    "f.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n",
      "2\n",
      "7\n",
      "2\n",
      "9\n",
      "9\n",
      "5\n",
      "8\n",
      "0\n",
      "5\n",
      "0\n",
      "6\n",
      "1\n",
      "2\n",
      "6\n",
      "2\n",
      "5\n",
      "8\n",
      "6\n",
      "7\n",
      "9\n",
      "2\n",
      "4\n",
      "6\n",
      "2\n",
      "3\n",
      "2\n",
      "8\n",
      "1\n",
      "0\n",
      "2\n",
      "6\n",
      "1\n",
      "1\n",
      "3\n",
      "0\n",
      "9\n",
      "3\n",
      "9\n",
      "2\n",
      "2\n",
      "7\n",
      "8\n",
      "0\n",
      "7\n",
      "2\n",
      "9\n",
      "8\n",
      "4\n",
      "0\n",
      "3\n",
      "7\n",
      "0\n",
      "5\n",
      "5\n",
      "9\n",
      "5\n",
      "4\n",
      "5\n",
      "0\n",
      "5\n",
      "0\n",
      "3\n",
      "2\n",
      "8\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "9\n",
      "9\n",
      "1\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "6\n",
      "8\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "3\n",
      "0\n",
      "8\n",
      "3\n",
      "7\n",
      "8\n",
      "6\n",
      "5\n",
      "8\n",
      "8\n",
      "6\n",
      "5\n",
      "0\n",
      "7\n",
      "8\n",
      "3\n",
      "8\n",
      "7\n",
      "4\n",
      "6\n",
      "7\n",
      "1\n",
      "5\n",
      "6\n",
      "9\n",
      "3\n",
      "2\n",
      "9\n",
      "6\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "8\n",
      "9\n",
      "1\n",
      "5\n",
      "9\n",
      "1\n",
      "2\n",
      "8\n",
      "8\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "0\n",
      "6\n",
      "0\n",
      "5\n",
      "7\n",
      "0\n",
      "8\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "0\n",
      "2\n",
      "1\n",
      "9\n",
      "8\n",
      "1\n",
      "0\n",
      "0\n",
      "6\n",
      "8\n",
      "1\n",
      "2\n",
      "9\n",
      "5\n",
      "8\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "6\n",
      "7\n",
      "2\n",
      "5\n",
      "4\n",
      "9\n",
      "5\n",
      "0\n",
      "9\n",
      "7\n",
      "1\n",
      "7\n",
      "7\n",
      "5\n",
      "9\n",
      "8\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "7\n",
      "4\n",
      "6\n",
      "9\n",
      "2\n",
      "4\n",
      "9\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "7\n",
      "5\n",
      "3\n",
      "6\n",
      "1\n",
      "4\n",
      "5\n",
      "0\n",
      "5\n",
      "7\n",
      "9\n",
      "5\n",
      "3\n",
      "8\n",
      "7\n",
      "7\n",
      "2\n",
      "0\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "6\n",
      "3\n",
      "7\n",
      "0\n",
      "9\n",
      "9\n",
      "2\n",
      "9\n",
      "3\n",
      "5\n",
      "2\n",
      "1\n",
      "3\n",
      "7\n",
      "2\n",
      "9\n",
      "8\n",
      "9\n",
      "7\n",
      "3\n",
      "3\n",
      "2\n",
      "9\n",
      "1\n",
      "9\n",
      "7\n",
      "8\n",
      "7\n",
      "0\n",
      "5\n",
      "9\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "6\n",
      "7\n",
      "8\n",
      "5\n",
      "8\n",
      "8\n",
      "7\n",
      "3\n",
      "0\n",
      "3\n",
      "1\n",
      "6\n",
      "7\n",
      "3\n",
      "1\n",
      "6\n",
      "1\n",
      "9\n",
      "8\n",
      "6\n",
      "4\n",
      "1\n",
      "6\n",
      "1\n",
      "6\n",
      "6\n",
      "1\n",
      "3\n",
      "1\n",
      "6\n",
      "8\n",
      "9\n",
      "2\n",
      "3\n",
      "3\n",
      "9\n",
      "1\n",
      "0\n",
      "5\n",
      "2\n",
      "8\n",
      "3\n",
      "1\n",
      "8\n",
      "4\n",
      "1\n",
      "9\n",
      "5\n",
      "8\n",
      "1\n",
      "4\n",
      "3\n",
      "9\n",
      "1\n",
      "8\n",
      "5\n",
      "7\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "0\n",
      "6\n",
      "5\n",
      "5\n",
      "8\n",
      "2\n",
      "4\n",
      "4\n",
      "9\n",
      "9\n",
      "2\n",
      "6\n",
      "8\n",
      "8\n",
      "0\n",
      "2\n",
      "5\n",
      "7\n",
      "1\n",
      "8\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "2\n",
      "6\n",
      "8\n",
      "5\n",
      "7\n",
      "3\n",
      "5\n",
      "6\n",
      "2\n",
      "8\n",
      "6\n",
      "8\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "2\n",
      "7\n",
      "9\n",
      "7\n",
      "6\n",
      "2\n",
      "2\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "6\n",
      "8\n",
      "9\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "8\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "6\n",
      "9\n",
      "5\n",
      "9\n",
      "9\n",
      "3\n",
      "5\n",
      "5\n",
      "0\n",
      "9\n",
      "2\n",
      "1\n",
      "5\n",
      "6\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "9\n",
      "0\n",
      "5\n",
      "9\n",
      "7\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "8\n",
      "9\n",
      "8\n",
      "2\n",
      "9\n",
      "3\n",
      "4\n",
      "1\n",
      "5\n",
      "8\n",
      "3\n",
      "8\n",
      "9\n",
      "7\n",
      "1\n",
      "3\n",
      "8\n",
      "6\n",
      "2\n",
      "2\n",
      "1\n",
      "8\n",
      "2\n",
      "8\n",
      "0\n",
      "3\n",
      "2\n",
      "9\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "6\n",
      "3\n",
      "2\n",
      "9\n",
      "2\n",
      "1\n",
      "9\n",
      "8\n",
      "2\n",
      "6\n",
      "3\n",
      "1\n",
      "9\n",
      "9\n",
      "5\n",
      "2\n",
      "2\n",
      "7\n",
      "2\n",
      "1\n",
      "6\n",
      "2\n",
      "8\n",
      "8\n",
      "5\n",
      "4\n",
      "7\n",
      "8\n",
      "6\n",
      "1\n",
      "2\n",
      "9\n",
      "2\n",
      "5\n",
      "7\n",
      "5\n",
      "0\n",
      "9\n",
      "8\n",
      "1\n",
      "5\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "9\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "6\n",
      "7\n",
      "3\n",
      "3\n",
      "0\n",
      "7\n",
      "8\n",
      "8\n",
      "0\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "3\n",
      "7\n",
      "0\n",
      "7\n",
      "1\n",
      "5\n",
      "8\n",
      "6\n",
      "9\n",
      "3\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "8\n",
      "8\n",
      "0\n",
      "9\n",
      "5\n",
      "8\n",
      "3\n",
      "2\n",
      "7\n",
      "8\n",
      "2\n",
      "2\n",
      "9\n",
      "0\n",
      "8\n",
      "2\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "0\n",
      "6\n",
      "6\n",
      "2\n",
      "0\n",
      "5\n",
      "6\n",
      "5\n",
      "4\n",
      "9\n",
      "4\n",
      "1\n",
      "3\n",
      "6\n",
      "4\n",
      "1\n",
      "8\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "2\n",
      "9\n",
      "2\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "0\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "1\n",
      "2\n",
      "7\n",
      "3\n",
      "6\n",
      "9\n",
      "3\n",
      "3\n",
      "4\n",
      "8\n",
      "1\n",
      "3\n",
      "4\n",
      "0\n",
      "8\n",
      "5\n",
      "7\n",
      "5\n",
      "0\n",
      "2\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "5\n",
      "9\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "0\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "8\n",
      "2\n",
      "1\n",
      "5\n",
      "9\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "7\n",
      "2\n",
      "6\n",
      "5\n",
      "9\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "9\n",
      "4\n",
      "9\n",
      "2\n",
      "7\n",
      "5\n",
      "0\n",
      "5\n",
      "3\n",
      "9\n",
      "5\n",
      "3\n",
      "6\n",
      "6\n",
      "1\n",
      "0\n",
      "3\n",
      "7\n",
      "6\n",
      "0\n",
      "9\n",
      "7\n",
      "7\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "7\n",
      "0\n",
      "6\n",
      "4\n",
      "9\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "9\n",
      "0\n",
      "8\n",
      "6\n",
      "8\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "1\n",
      "0\n",
      "3\n",
      "4\n",
      "7\n",
      "2\n",
      "5\n",
      "3\n",
      "7\n",
      "7\n",
      "8\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "8\n",
      "6\n",
      "0\n",
      "3\n",
      "5\n",
      "7\n",
      "8\n",
      "5\n",
      "3\n",
      "9\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "6\n",
      "5\n",
      "8\n",
      "6\n",
      "2\n",
      "8\n",
      "3\n",
      "8\n",
      "2\n",
      "7\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "3\n",
      "7\n",
      "5\n",
      "8\n",
      "5\n",
      "7\n",
      "1\n",
      "8\n",
      "5\n",
      "8\n",
      "3\n",
      "2\n",
      "7\n",
      "9\n",
      "8\n",
      "8\n",
      "0\n",
      "3\n",
      "9\n",
      "6\n",
      "1\n",
      "8\n",
      "0\n",
      "3\n",
      "6\n",
      "4\n",
      "7\n",
      "3\n",
      "3\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "1\n",
      "9\n",
      "8\n",
      "0\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "7\n",
      "4\n",
      "9\n",
      "8\n",
      "8\n",
      "6\n",
      "5\n",
      "9\n",
      "9\n",
      "3\n",
      "4\n",
      "9\n",
      "7\n",
      "1\n",
      "2\n",
      "8\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "8\n",
      "8\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "5\n",
      "8\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "9\n",
      "2\n",
      "9\n",
      "6\n",
      "5\n",
      "2\n",
      "7\n",
      "0\n",
      "3\n",
      "7\n",
      "6\n",
      "2\n",
      "5\n",
      "3\n",
      "6\n",
      "0\n",
      "6\n",
      "3\n",
      "0\n",
      "5\n",
      "3\n",
      "9\n",
      "2\n",
      "5\n",
      "6\n",
      "6\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "8\n",
      "0\n",
      "7\n",
      "5\n",
      "8\n",
      "3\n",
      "8\n",
      "7\n",
      "4\n",
      "5\n",
      "3\n",
      "1\n",
      "5\n",
      "1\n",
      "2\n",
      "2\n",
      "5\n",
      "9\n",
      "7\n",
      "1\n",
      "7\n",
      "4\n",
      "4\n",
      "6\n",
      "1\n",
      "3\n",
      "2\n",
      "8\n",
      "5\n",
      "5\n",
      "9\n",
      "5\n",
      "7\n",
      "2\n",
      "6\n",
      "7\n",
      "6\n",
      "8\n",
      "5\n",
      "5\n",
      "6\n",
      "9\n",
      "4\n",
      "3\n",
      "6\n",
      "0\n",
      "9\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "8\n",
      "4\n",
      "7\n",
      "8\n",
      "2\n",
      "1\n",
      "0\n",
      "4\n",
      "6\n",
      "9\n",
      "9\n",
      "0\n",
      "3\n",
      "5\n",
      "2\n",
      "0\n",
      "7\n",
      "2\n",
      "7\n",
      "0\n",
      "7\n",
      "5\n",
      "7\n",
      "5\n",
      "1\n",
      "6\n",
      "2\n",
      "3\n",
      "2\n",
      "7\n",
      "7\n",
      "0\n",
      "5\n",
      "7\n",
      "0\n",
      "4\n",
      "0\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "6\n",
      "1\n",
      "4\n",
      "7\n",
      "9\n",
      "4\n",
      "9\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "7\n",
      "0\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "2\n",
      "1\n",
      "2\n",
      "7\n",
      "3\n",
      "1\n",
      "3\n",
      "7\n",
      "2\n",
      "7\n",
      "4\n",
      "4\n",
      "1\n",
      "8\n",
      "0\n",
      "1\n",
      "9\n",
      "4\n",
      "9\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "9\n",
      "9\n",
      "4\n",
      "1\n",
      "8\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "8\n",
      "2\n",
      "4\n",
      "8\n",
      "6\n",
      "3\n",
      "6\n",
      "9\n",
      "7\n",
      "3\n",
      "6\n",
      "1\n",
      "4\n",
      "0\n",
      "3\n",
      "6\n",
      "7\n",
      "0\n",
      "8\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "9\n",
      "3\n",
      "5\n",
      "3\n",
      "7\n",
      "0\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "9\n",
      "3\n",
      "7\n",
      "2\n",
      "6\n",
      "8\n",
      "9\n",
      "3\n",
      "7\n",
      "4\n",
      "1\n",
      "8\n",
      "4\n",
      "5\n",
      "3\n",
      "8\n",
      "1\n",
      "5\n",
      "5\n",
      "8\n",
      "1\n",
      "2\n",
      "6\n",
      "2\n",
      "4\n",
      "1\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "5\n",
      "1\n",
      "1\n",
      "2\n",
      "9\n",
      "6\n",
      "8\n",
      "1\n",
      "1\n",
      "2\n",
      "5\n",
      "0\n",
      "6\n",
      "0\n",
      "9\n",
      "1\n",
      "8\n",
      "2\n",
      "6\n",
      "9\n",
      "8\n",
      "7\n",
      "9\n",
      "7\n",
      "2\n",
      "4\n",
      "1\n",
      "8\n",
      "9\n",
      "7\n",
      "5\n",
      "6\n",
      "8\n",
      "8\n",
      "4\n",
      "5\n",
      "5\n",
      "9\n",
      "7\n",
      "7\n",
      "4\n",
      "6\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "0\n",
      "3\n",
      "7\n",
      "6\n",
      "1\n",
      "7\n",
      "5\n",
      "7\n",
      "9\n",
      "0\n",
      "9\n",
      "2\n",
      "1\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "9\n",
      "0\n",
      "1\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "4\n",
      "7\n",
      "2\n",
      "9\n",
      "7\n",
      "3\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "0\n",
      "9\n",
      "3\n",
      "6\n",
      "7\n",
      "1\n",
      "5\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "7\n",
      "7\n",
      "6\n",
      "8\n",
      "6\n",
      "2\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "6\n",
      "8\n",
      "1\n",
      "9\n",
      "7\n",
      "5\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "9\n",
      "8\n",
      "5\n",
      "8\n",
      "3\n",
      "4\n",
      "6\n",
      "1\n",
      "3\n",
      "7\n",
      "7\n",
      "0\n",
      "2\n",
      "2\n",
      "8\n",
      "9\n",
      "8\n",
      "7\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "7\n",
      "6\n",
      "1\n",
      "7\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "7\n",
      "9\n",
      "9\n",
      "5\n",
      "2\n",
      "6\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "7\n",
      "8\n",
      "6\n",
      "8\n",
      "2\n",
      "6\n",
      "5\n",
      "9\n",
      "0\n",
      "3\n",
      "6\n",
      "0\n",
      "3\n",
      "8\n",
      "9\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "8\n",
      "4\n",
      "8\n",
      "2\n",
      "3\n",
      "6\n",
      "2\n",
      "8\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "8\n",
      "4\n",
      "3\n",
      "8\n",
      "5\n",
      "9\n",
      "2\n",
      "7\n",
      "8\n",
      "2\n",
      "6\n",
      "1\n",
      "5\n",
      "3\n",
      "8\n",
      "4\n",
      "6\n",
      "0\n",
      "8\n",
      "5\n",
      "2\n",
      "5\n",
      "9\n",
      "6\n",
      "6\n",
      "1\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "9\n",
      "1\n",
      "7\n",
      "1\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "0\n",
      "1\n",
      "7\n",
      "9\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "0\n",
      "9\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "2\n",
      "6\n",
      "9\n",
      "2\n",
      "5\n",
      "9\n",
      "3\n",
      "1\n",
      "5\n",
      "8\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "7\n",
      "9\n",
      "5\n",
      "6\n",
      "2\n",
      "9\n",
      "1\n",
      "1\n",
      "6\n",
      "0\n",
      "8\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "9\n",
      "2\n",
      "8\n",
      "3\n",
      "7\n",
      "7\n",
      "7\n",
      "3\n",
      "1\n",
      "0\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "0\n",
      "7\n",
      "6\n",
      "5\n",
      "0\n",
      "8\n",
      "7\n",
      "0\n",
      "3\n",
      "9\n",
      "2\n",
      "2\n",
      "6\n",
      "9\n",
      "6\n",
      "7\n",
      "8\n",
      "3\n",
      "5\n",
      "5\n",
      "6\n",
      "1\n",
      "6\n",
      "9\n",
      "7\n",
      "2\n",
      "2\n",
      "5\n",
      "9\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "7\n",
      "2\n",
      "7\n",
      "9\n",
      "0\n",
      "8\n",
      "7\n",
      "9\n",
      "5\n",
      "7\n",
      "1\n",
      "1\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "4\n",
      "1\n",
      "8\n",
      "3\n",
      "2\n",
      "7\n",
      "2\n",
      "8\n",
      "7\n",
      "0\n",
      "2\n",
      "7\n",
      "4\n",
      "9\n",
      "0\n",
      "6\n",
      "5\n",
      "0\n",
      "2\n",
      "6\n",
      "9\n",
      "9\n",
      "6\n",
      "7\n",
      "7\n",
      "5\n",
      "6\n",
      "4\n",
      "5\n",
      "1\n",
      "1\n",
      "9\n",
      "4\n",
      "1\n",
      "3\n",
      "8\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "7\n",
      "2\n",
      "5\n",
      "1\n",
      "7\n",
      "7\n",
      "1\n",
      "7\n",
      "6\n",
      "1\n",
      "0\n",
      "7\n",
      "6\n",
      "0\n",
      "2\n",
      "7\n",
      "8\n",
      "7\n",
      "6\n",
      "7\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "6\n",
      "1\n",
      "1\n",
      "6\n",
      "2\n",
      "9\n",
      "2\n",
      "9\n",
      "7\n",
      "4\n",
      "9\n",
      "6\n",
      "7\n",
      "5\n",
      "5\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "9\n",
      "4\n",
      "8\n",
      "0\n",
      "5\n",
      "0\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "2\n",
      "5\n",
      "8\n",
      "6\n",
      "4\n",
      "8\n",
      "8\n",
      "3\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "5\n",
      "1\n",
      "0\n",
      "6\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "3\n",
      "6\n",
      "7\n",
      "6\n",
      "2\n",
      "5\n",
      "4\n",
      "2\n",
      "8\n",
      "4\n",
      "6\n",
      "7\n",
      "2\n",
      "4\n",
      "7\n",
      "6\n",
      "6\n",
      "2\n",
      "8\n",
      "6\n",
      "7\n",
      "6\n",
      "8\n",
      "7\n",
      "0\n",
      "8\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "9\n",
      "6\n",
      "3\n",
      "5\n",
      "6\n",
      "5\n",
      "8\n",
      "5\n",
      "8\n",
      "8\n",
      "5\n",
      "3\n",
      "2\n",
      "1\n",
      "8\n",
      "3\n",
      "6\n",
      "2\n",
      "5\n",
      "2\n",
      "7\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "6\n",
      "2\n",
      "9\n",
      "7\n",
      "5\n",
      "1\n",
      "9\n",
      "6\n",
      "2\n",
      "3\n",
      "6\n",
      "7\n",
      "8\n",
      "4\n",
      "1\n",
      "3\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "0\n",
      "9\n",
      "5\n",
      "9\n",
      "3\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "0\n",
      "2\n",
      "8\n",
      "1\n",
      "7\n",
      "3\n",
      "3\n",
      "9\n",
      "7\n",
      "1\n",
      "5\n",
      "9\n",
      "2\n",
      "0\n",
      "0\n",
      "4\n",
      "7\n",
      "5\n",
      "1\n",
      "6\n",
      "9\n",
      "9\n",
      "5\n",
      "4\n",
      "8\n",
      "1\n",
      "2\n",
      "2\n",
      "5\n",
      "4\n",
      "0\n",
      "4\n",
      "6\n",
      "0\n",
      "2\n",
      "7\n",
      "5\n",
      "9\n",
      "5\n",
      "3\n",
      "7\n",
      "8\n",
      "2\n",
      "8\n",
      "3\n",
      "5\n",
      "2\n",
      "6\n",
      "8\n",
      "5\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "6\n",
      "7\n",
      "3\n",
      "0\n",
      "6\n",
      "9\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "8\n",
      "4\n",
      "6\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "2\n",
      "9\n",
      "9\n",
      "8\n",
      "2\n",
      "2\n",
      "2\n",
      "8\n",
      "9\n",
      "3\n",
      "1\n",
      "6\n",
      "0\n",
      "0\n",
      "9\n",
      "0\n",
      "3\n",
      "1\n",
      "5\n",
      "8\n",
      "1\n",
      "3\n",
      "2\n",
      "6\n",
      "3\n",
      "0\n",
      "6\n",
      "2\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "3\n",
      "1\n",
      "3\n",
      "7\n",
      "4\n",
      "8\n",
      "9\n",
      "6\n",
      "8\n",
      "2\n",
      "7\n",
      "3\n",
      "3\n",
      "8\n",
      "5\n",
      "8\n",
      "9\n",
      "8\n",
      "5\n",
      "1\n",
      "5\n",
      "2\n",
      "4\n",
      "4\n",
      "1\n",
      "5\n",
      "0\n",
      "2\n",
      "2\n",
      "8\n",
      "0\n",
      "1\n",
      "2\n",
      "8\n",
      "9\n",
      "0\n",
      "6\n",
      "0\n",
      "6\n",
      "8\n",
      "6\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "8\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "8\n",
      "0\n",
      "2\n",
      "8\n",
      "7\n",
      "2\n",
      "2\n",
      "5\n",
      "1\n",
      "3\n",
      "3\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "2\n",
      "2\n",
      "8\n",
      "0\n",
      "7\n",
      "4\n",
      "7\n",
      "6\n",
      "2\n",
      "1\n",
      "6\n",
      "4\n",
      "8\n",
      "0\n",
      "8\n",
      "4\n",
      "9\n",
      "2\n",
      "4\n",
      "4\n",
      "8\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "4\n",
      "7\n",
      "2\n",
      "3\n",
      "6\n",
      "2\n",
      "2\n",
      "7\n",
      "0\n",
      "9\n",
      "2\n",
      "8\n",
      "8\n",
      "2\n",
      "9\n",
      "7\n",
      "1\n",
      "7\n",
      "4\n",
      "4\n",
      "8\n",
      "5\n",
      "4\n",
      "5\n",
      "2\n",
      "6\n",
      "8\n",
      "6\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "9\n",
      "0\n",
      "3\n",
      "5\n",
      "8\n",
      "6\n",
      "6\n",
      "3\n",
      "0\n",
      "5\n",
      "4\n",
      "6\n",
      "5\n",
      "2\n",
      "9\n",
      "2\n",
      "1\n",
      "2\n",
      "7\n",
      "4\n",
      "8\n",
      "9\n",
      "1\n",
      "1\n",
      "3\n",
      "5\n",
      "3\n",
      "9\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "6\n",
      "7\n",
      "2\n",
      "8\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "9\n",
      "3\n",
      "2\n",
      "2\n",
      "6\n",
      "2\n",
      "0\n",
      "5\n",
      "3\n",
      "4\n",
      "9\n",
      "2\n",
      "9\n",
      "2\n",
      "8\n",
      "7\n",
      "2\n",
      "0\n",
      "6\n",
      "0\n",
      "7\n",
      "8\n",
      "2\n",
      "4\n",
      "7\n",
      "9\n",
      "4\n",
      "9\n",
      "6\n",
      "3\n",
      "4\n",
      "9\n",
      "5\n",
      "5\n",
      "8\n",
      "6\n",
      "8\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "9\n",
      "5\n",
      "7\n",
      "9\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "6\n",
      "8\n",
      "8\n",
      "0\n",
      "5\n",
      "2\n",
      "1\n",
      "8\n",
      "2\n",
      "9\n",
      "5\n",
      "6\n",
      "6\n",
      "4\n",
      "1\n",
      "7\n",
      "9\n",
      "2\n",
      "6\n",
      "6\n",
      "4\n",
      "1\n",
      "9\n",
      "6\n",
      "8\n",
      "5\n",
      "6\n",
      "3\n",
      "9\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "7\n",
      "3\n",
      "8\n",
      "5\n",
      "8\n",
      "3\n",
      "3\n",
      "5\n",
      "1\n",
      "5\n",
      "1\n",
      "6\n",
      "6\n",
      "5\n",
      "0\n",
      "0\n",
      "8\n",
      "5\n",
      "8\n",
      "2\n",
      "2\n",
      "8\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "8\n",
      "3\n",
      "5\n",
      "3\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "2\n",
      "8\n",
      "5\n",
      "2\n",
      "8\n",
      "6\n",
      "6\n",
      "9\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "6\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "7\n",
      "1\n",
      "3\n",
      "8\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "6\n",
      "8\n",
      "0\n",
      "8\n",
      "3\n",
      "7\n",
      "3\n",
      "2\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "2\n",
      "1\n",
      "9\n",
      "7\n",
      "7\n",
      "2\n",
      "2\n",
      "8\n",
      "8\n",
      "3\n",
      "8\n",
      "2\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "0\n",
      "8\n",
      "5\n",
      "0\n",
      "4\n",
      "9\n",
      "1\n",
      "5\n",
      "1\n",
      "6\n",
      "4\n",
      "0\n",
      "6\n",
      "8\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "0\n",
      "3\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "2\n",
      "4\n",
      "5\n",
      "8\n",
      "5\n",
      "1\n",
      "3\n",
      "3\n",
      "6\n",
      "2\n",
      "2\n",
      "8\n",
      "0\n",
      "6\n",
      "5\n",
      "9\n",
      "1\n",
      "6\n",
      "0\n",
      "7\n",
      "0\n",
      "9\n",
      "1\n",
      "2\n",
      "8\n",
      "4\n",
      "9\n",
      "6\n",
      "9\n",
      "7\n",
      "4\n",
      "1\n",
      "2\n",
      "6\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "7\n",
      "1\n",
      "5\n",
      "9\n",
      "3\n",
      "5\n",
      "9\n",
      "8\n",
      "5\n",
      "1\n",
      "3\n",
      "2\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "7\n",
      "8\n",
      "9\n",
      "7\n",
      "2\n",
      "0\n",
      "7\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "5\n",
      "5\n",
      "1\n",
      "6\n",
      "5\n",
      "1\n",
      "7\n",
      "1\n",
      "7\n",
      "1\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "9\n",
      "0\n",
      "2\n",
      "8\n",
      "6\n",
      "0\n",
      "6\n",
      "8\n",
      "9\n",
      "7\n",
      "2\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "8\n",
      "1\n",
      "5\n",
      "2\n",
      "8\n",
      "2\n",
      "6\n",
      "9\n",
      "9\n",
      "1\n",
      "3\n",
      "7\n",
      "9\n",
      "8\n",
      "2\n",
      "8\n",
      "7\n",
      "5\n",
      "6\n",
      "0\n",
      "5\n",
      "9\n",
      "3\n",
      "2\n",
      "2\n",
      "7\n",
      "4\n",
      "9\n",
      "9\n",
      "2\n",
      "8\n",
      "5\n",
      "9\n",
      "6\n",
      "8\n",
      "0\n",
      "0\n",
      "6\n",
      "8\n",
      "8\n",
      "2\n",
      "0\n",
      "9\n",
      "9\n",
      "2\n",
      "3\n",
      "3\n",
      "7\n",
      "2\n",
      "8\n",
      "8\n",
      "3\n",
      "5\n",
      "4\n",
      "0\n",
      "7\n",
      "1\n",
      "4\n",
      "3\n",
      "7\n",
      "3\n",
      "5\n",
      "0\n",
      "8\n",
      "6\n",
      "2\n",
      "8\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "9\n",
      "5\n",
      "9\n",
      "7\n",
      "4\n",
      "7\n",
      "9\n",
      "6\n",
      "6\n",
      "9\n",
      "3\n",
      "5\n",
      "9\n",
      "5\n",
      "9\n",
      "4\n",
      "0\n",
      "6\n",
      "4\n",
      "2\n",
      "0\n",
      "6\n",
      "3\n",
      "3\n",
      "8\n",
      "4\n",
      "2\n",
      "8\n",
      "1\n",
      "9\n",
      "0\n",
      "8\n",
      "0\n",
      "5\n",
      "3\n",
      "0\n",
      "7\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "8\n",
      "6\n",
      "6\n",
      "0\n",
      "6\n",
      "4\n",
      "8\n",
      "6\n",
      "9\n",
      "1\n",
      "8\n",
      "9\n",
      "1\n",
      "3\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "9\n",
      "7\n",
      "1\n",
      "5\n",
      "6\n",
      "5\n",
      "1\n",
      "8\n",
      "7\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "2\n",
      "3\n",
      "7\n",
      "3\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "0\n",
      "0\n",
      "5\n",
      "7\n",
      "7\n",
      "6\n",
      "0\n",
      "7\n",
      "6\n",
      "7\n",
      "9\n",
      "7\n",
      "4\n",
      "8\n",
      "7\n",
      "2\n",
      "0\n",
      "6\n",
      "2\n",
      "7\n",
      "2\n",
      "6\n",
      "3\n",
      "7\n",
      "9\n",
      "4\n",
      "6\n",
      "3\n",
      "0\n",
      "7\n",
      "2\n",
      "0\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "6\n",
      "9\n",
      "9\n",
      "2\n",
      "9\n",
      "0\n",
      "7\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "5\n",
      "5\n",
      "4\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "0\n",
      "8\n",
      "7\n",
      "7\n",
      "6\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "9\n",
      "2\n",
      "5\n",
      "2\n",
      "5\n",
      "4\n",
      "1\n",
      "6\n",
      "1\n",
      "6\n",
      "4\n",
      "0\n",
      "3\n",
      "2\n",
      "9\n",
      "6\n",
      "8\n",
      "2\n",
      "2\n",
      "6\n",
      "1\n",
      "2\n",
      "2\n",
      "8\n",
      "1\n",
      "8\n",
      "3\n",
      "9\n",
      "7\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "8\n",
      "3\n",
      "8\n",
      "5\n",
      "5\n",
      "1\n",
      "5\n",
      "5\n",
      "2\n",
      "7\n",
      "6\n",
      "7\n",
      "3\n",
      "9\n",
      "3\n",
      "6\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "8\n",
      "1\n",
      "7\n",
      "8\n",
      "6\n",
      "6\n",
      "4\n",
      "1\n",
      "9\n",
      "1\n",
      "4\n",
      "4\n",
      "6\n",
      "1\n",
      "1\n",
      "7\n",
      "0\n",
      "0\n",
      "6\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "7\n",
      "7\n",
      "9\n",
      "1\n",
      "6\n",
      "9\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "0\n",
      "9\n",
      "5\n",
      "3\n",
      "5\n",
      "7\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "8\n",
      "3\n",
      "2\n",
      "0\n",
      "7\n",
      "4\n",
      "8\n",
      "7\n",
      "1\n",
      "5\n",
      "2\n",
      "8\n",
      "7\n",
      "9\n",
      "8\n",
      "4\n",
      "0\n",
      "3\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "4\n",
      "9\n",
      "9\n",
      "1\n",
      "9\n",
      "9\n",
      "1\n",
      "5\n",
      "8\n",
      "6\n",
      "8\n",
      "6\n",
      "5\n",
      "8\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "6\n",
      "8\n",
      "1\n",
      "8\n",
      "2\n",
      "9\n",
      "3\n",
      "0\n",
      "6\n",
      "3\n",
      "3\n",
      "0\n",
      "2\n",
      "1\n",
      "6\n",
      "5\n",
      "3\n",
      "8\n",
      "2\n",
      "5\n",
      "5\n",
      "4\n",
      "8\n",
      "4\n",
      "5\n",
      "1\n",
      "6\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "4\n",
      "0\n",
      "4\n",
      "8\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "4\n",
      "8\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "6\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "7\n",
      "1\n",
      "3\n",
      "2\n",
      "5\n",
      "8\n",
      "6\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "6\n",
      "8\n",
      "9\n",
      "0\n",
      "2\n",
      "8\n",
      "2\n",
      "8\n",
      "3\n",
      "0\n",
      "5\n",
      "8\n",
      "6\n",
      "5\n",
      "4\n",
      "8\n",
      "6\n",
      "9\n",
      "2\n",
      "5\n",
      "4\n",
      "0\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "4\n",
      "0\n",
      "6\n",
      "0\n",
      "1\n",
      "6\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "5\n",
      "3\n",
      "8\n",
      "6\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "7\n",
      "8\n",
      "6\n",
      "4\n",
      "0\n",
      "6\n",
      "5\n",
      "6\n",
      "8\n",
      "7\n",
      "0\n",
      "5\n",
      "0\n",
      "5\n",
      "5\n",
      "7\n",
      "9\n",
      "9\n",
      "0\n",
      "5\n",
      "3\n",
      "1\n",
      "4\n",
      "3\n",
      "8\n",
      "2\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "2\n",
      "4\n",
      "5\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "8\n",
      "0\n",
      "9\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "8\n",
      "5\n",
      "7\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "7\n",
      "2\n",
      "7\n",
      "8\n",
      "7\n",
      "2\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "3\n",
      "6\n",
      "4\n",
      "2\n",
      "6\n",
      "9\n",
      "1\n",
      "4\n",
      "8\n",
      "1\n",
      "2\n",
      "1\n",
      "9\n",
      "4\n",
      "0\n",
      "5\n",
      "9\n",
      "5\n",
      "6\n",
      "6\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "1\n",
      "9\n",
      "9\n",
      "0\n",
      "3\n",
      "6\n",
      "5\n",
      "3\n",
      "1\n",
      "8\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "8\n",
      "5\n",
      "4\n",
      "0\n",
      "4\n",
      "2\n",
      "2\n",
      "8\n",
      "0\n",
      "2\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "1\n",
      "9\n",
      "1\n",
      "5\n",
      "2\n",
      "2\n",
      "4\n",
      "1\n",
      "6\n",
      "0\n",
      "2\n",
      "9\n",
      "2\n",
      "8\n",
      "2\n",
      "9\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "6\n",
      "0\n",
      "9\n",
      "8\n",
      "5\n",
      "2\n",
      "5\n",
      "1\n",
      "7\n",
      "2\n",
      "2\n",
      "3\n",
      "8\n",
      "3\n",
      "4\n",
      "5\n",
      "8\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "6\n",
      "0\n",
      "6\n",
      "2\n",
      "6\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "4\n",
      "8\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "7\n",
      "0\n",
      "5\n",
      "4\n",
      "3\n",
      "1\n",
      "0\n",
      "5\n",
      "6\n",
      "0\n",
      "2\n",
      "8\n",
      "7\n",
      "5\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "2\n",
      "2\n",
      "7\n",
      "3\n",
      "2\n",
      "0\n",
      "6\n",
      "6\n",
      "7\n",
      "1\n",
      "7\n",
      "2\n",
      "5\n",
      "1\n",
      "5\n",
      "5\n",
      "2\n",
      "6\n",
      "0\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "0\n",
      "4\n",
      "7\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "1\n",
      "7\n",
      "5\n",
      "9\n",
      "0\n",
      "5\n",
      "8\n",
      "5\n",
      "1\n",
      "3\n",
      "6\n",
      "3\n",
      "2\n",
      "9\n",
      "8\n",
      "0\n",
      "2\n",
      "1\n",
      "7\n",
      "3\n",
      "5\n",
      "7\n",
      "6\n",
      "4\n",
      "6\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "6\n",
      "2\n",
      "0\n",
      "6\n",
      "2\n",
      "5\n",
      "8\n",
      "0\n",
      "6\n",
      "9\n",
      "5\n",
      "9\n",
      "3\n",
      "7\n",
      "6\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "8\n",
      "8\n",
      "4\n",
      "2\n",
      "7\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "5\n",
      "3\n",
      "5\n",
      "2\n",
      "7\n",
      "2\n",
      "8\n",
      "8\n",
      "6\n",
      "7\n",
      "0\n",
      "2\n",
      "1\n",
      "9\n",
      "3\n",
      "5\n",
      "1\n",
      "8\n",
      "0\n",
      "8\n",
      "5\n",
      "8\n",
      "9\n",
      "3\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "7\n",
      "1\n",
      "3\n",
      "5\n",
      "8\n",
      "2\n",
      "1\n",
      "6\n",
      "7\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "8\n",
      "2\n",
      "6\n",
      "5\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "9\n",
      "9\n",
      "9\n",
      "4\n",
      "9\n",
      "7\n",
      "5\n",
      "1\n",
      "3\n",
      "1\n",
      "5\n",
      "6\n",
      "2\n",
      "5\n",
      "0\n",
      "3\n",
      "1\n",
      "0\n",
      "9\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "9\n",
      "3\n",
      "8\n",
      "7\n",
      "8\n",
      "9\n",
      "8\n",
      "2\n",
      "9\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "8\n",
      "2\n",
      "3\n",
      "2\n",
      "6\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "9\n",
      "5\n",
      "1\n",
      "2\n",
      "8\n",
      "8\n",
      "5\n",
      "3\n",
      "5\n",
      "0\n",
      "1\n",
      "6\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "5\n",
      "2\n",
      "1\n",
      "3\n",
      "9\n",
      "5\n",
      "7\n",
      "9\n",
      "2\n",
      "6\n",
      "2\n",
      "3\n",
      "0\n",
      "7\n",
      "9\n",
      "2\n",
      "8\n",
      "4\n",
      "2\n",
      "1\n",
      "6\n",
      "0\n",
      "0\n",
      "2\n",
      "8\n",
      "4\n",
      "2\n",
      "3\n",
      "0\n",
      "8\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "1\n",
      "7\n",
      "3\n",
      "6\n",
      "3\n",
      "8\n",
      "0\n",
      "3\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "5\n",
      "2\n",
      "0\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "8\n",
      "6\n",
      "0\n",
      "8\n",
      "9\n",
      "6\n",
      "2\n",
      "2\n",
      "8\n",
      "0\n",
      "7\n",
      "8\n",
      "0\n",
      "4\n",
      "9\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "1\n",
      "7\n",
      "3\n",
      "7\n",
      "5\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "0\n",
      "7\n",
      "1\n",
      "1\n",
      "7\n",
      "8\n",
      "1\n",
      "5\n",
      "8\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "8\n",
      "6\n",
      "2\n",
      "8\n",
      "0\n",
      "1\n",
      "3\n",
      "6\n",
      "5\n",
      "1\n",
      "5\n",
      "0\n",
      "2\n",
      "9\n",
      "7\n",
      "2\n",
      "9\n",
      "2\n",
      "8\n",
      "2\n",
      "8\n",
      "5\n",
      "2\n",
      "8\n",
      "8\n",
      "6\n",
      "2\n",
      "7\n",
      "6\n",
      "4\n",
      "6\n",
      "2\n",
      "8\n",
      "3\n",
      "1\n",
      "9\n",
      "1\n",
      "9\n",
      "8\n",
      "2\n",
      "5\n",
      "1\n",
      "9\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "5\n",
      "1\n",
      "3\n",
      "2\n",
      "4\n",
      "8\n",
      "3\n",
      "7\n",
      "2\n",
      "5\n",
      "8\n",
      "5\n",
      "2\n",
      "7\n",
      "6\n",
      "6\n",
      "2\n",
      "8\n",
      "4\n",
      "1\n",
      "9\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "1\n",
      "5\n",
      "6\n",
      "7\n",
      "3\n",
      "1\n",
      "7\n",
      "6\n",
      "1\n",
      "7\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "8\n",
      "6\n",
      "2\n",
      "3\n",
      "1\n",
      "4\n",
      "8\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "9\n",
      "8\n",
      "6\n",
      "1\n",
      "5\n",
      "6\n",
      "3\n",
      "6\n",
      "2\n",
      "5\n",
      "7\n",
      "1\n",
      "2\n",
      "7\n",
      "2\n",
      "7\n",
      "8\n",
      "0\n",
      "0\n",
      "6\n",
      "1\n",
      "5\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "1\n",
      "6\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "8\n",
      "5\n",
      "4\n",
      "6\n",
      "5\n",
      "8\n",
      "4\n",
      "7\n",
      "6\n",
      "9\n",
      "4\n",
      "3\n",
      "9\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "5\n",
      "8\n",
      "3\n",
      "4\n",
      "6\n",
      "8\n",
      "3\n",
      "6\n",
      "8\n",
      "4\n",
      "3\n",
      "5\n",
      "8\n",
      "7\n",
      "2\n",
      "6\n",
      "9\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "2\n",
      "7\n",
      "2\n",
      "6\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "3\n",
      "1\n",
      "9\n",
      "8\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "7\n",
      "8\n",
      "1\n",
      "8\n",
      "6\n",
      "1\n",
      "6\n",
      "2\n",
      "5\n",
      "7\n",
      "0\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "7\n",
      "0\n",
      "4\n",
      "8\n",
      "3\n",
      "5\n",
      "1\n",
      "3\n",
      "6\n",
      "7\n",
      "7\n",
      "3\n",
      "6\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "8\n",
      "6\n",
      "1\n",
      "2\n",
      "8\n",
      "9\n",
      "5\n",
      "8\n",
      "9\n",
      "6\n",
      "2\n",
      "9\n",
      "2\n",
      "2\n",
      "5\n",
      "9\n",
      "1\n",
      "0\n",
      "7\n",
      "8\n",
      "5\n",
      "7\n",
      "6\n",
      "3\n",
      "3\n",
      "0\n",
      "7\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n",
      "9\n",
      "3\n",
      "3\n",
      "3\n",
      "9\n",
      "3\n",
      "2\n",
      "8\n",
      "2\n",
      "0\n",
      "3\n",
      "2\n",
      "8\n",
      "0\n",
      "6\n",
      "9\n",
      "8\n",
      "2\n",
      "3\n",
      "8\n",
      "5\n",
      "4\n",
      "3\n",
      "7\n",
      "3\n",
      "8\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "9\n",
      "8\n",
      "5\n",
      "3\n",
      "6\n",
      "2\n",
      "6\n",
      "1\n",
      "7\n",
      "6\n",
      "2\n",
      "2\n",
      "9\n",
      "6\n",
      "5\n",
      "4\n",
      "1\n",
      "3\n",
      "1\n",
      "0\n",
      "1\n",
      "7\n",
      "8\n",
      "0\n",
      "5\n",
      "0\n",
      "5\n",
      "1\n",
      "1\n",
      "6\n",
      "9\n",
      "2\n",
      "0\n",
      "2\n",
      "7\n",
      "8\n",
      "4\n",
      "7\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "1\n",
      "6\n",
      "5\n",
      "8\n",
      "7\n",
      "5\n",
      "4\n",
      "9\n",
      "8\n",
      "0\n",
      "8\n",
      "6\n",
      "9\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "9\n",
      "9\n",
      "7\n",
      "7\n",
      "8\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "8\n",
      "1\n",
      "6\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "7\n",
      "7\n",
      "4\n",
      "0\n",
      "1\n",
      "9\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "7\n",
      "4\n",
      "0\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "1\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "0\n",
      "5\n",
      "9\n",
      "2\n",
      "6\n",
      "0\n",
      "4\n",
      "5\n",
      "9\n",
      "2\n",
      "3\n",
      "2\n",
      "7\n",
      "3\n",
      "8\n",
      "2\n",
      "0\n",
      "7\n",
      "6\n",
      "8\n",
      "8\n",
      "1\n",
      "7\n",
      "1\n",
      "5\n",
      "8\n",
      "9\n",
      "2\n",
      "8\n",
      "3\n",
      "9\n",
      "3\n",
      "9\n",
      "2\n",
      "9\n",
      "2\n",
      "1\n",
      "8\n",
      "0\n",
      "5\n",
      "3\n",
      "0\n",
      "5\n",
      "5\n",
      "3\n",
      "6\n",
      "2\n",
      "9\n",
      "0\n",
      "5\n",
      "3\n",
      "8\n",
      "9\n",
      "2\n",
      "8\n",
      "6\n",
      "9\n",
      "3\n",
      "8\n",
      "9\n",
      "5\n",
      "8\n",
      "8\n",
      "0\n",
      "6\n",
      "2\n",
      "4\n",
      "8\n",
      "3\n",
      "8\n",
      "6\n",
      "2\n",
      "5\n",
      "8\n",
      "3\n",
      "2\n",
      "4\n",
      "0\n",
      "7\n",
      "1\n",
      "4\n",
      "7\n",
      "4\n",
      "0\n",
      "8\n",
      "1\n",
      "7\n",
      "3\n",
      "0\n",
      "3\n",
      "1\n",
      "5\n",
      "8\n",
      "3\n",
      "9\n",
      "6\n",
      "0\n",
      "6\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "9\n",
      "3\n",
      "2\n",
      "3\n",
      "8\n",
      "8\n",
      "5\n",
      "7\n",
      "2\n",
      "3\n",
      "0\n",
      "9\n",
      "2\n",
      "1\n",
      "8\n",
      "8\n",
      "5\n",
      "5\n",
      "3\n",
      "9\n",
      "8\n",
      "0\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "1\n",
      "2\n",
      "5\n",
      "7\n",
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "9\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "7\n",
      "2\n",
      "6\n",
      "0\n",
      "4\n",
      "9\n",
      "9\n",
      "3\n",
      "7\n",
      "0\n",
      "9\n",
      "4\n",
      "5\n",
      "3\n",
      "9\n",
      "8\n",
      "6\n",
      "5\n",
      "7\n",
      "9\n",
      "4\n",
      "5\n",
      "2\n",
      "4\n",
      "9\n",
      "6\n",
      "6\n",
      "1\n",
      "8\n",
      "4\n",
      "5\n",
      "0\n",
      "3\n",
      "8\n",
      "2\n",
      "0\n",
      "5\n",
      "3\n",
      "2\n",
      "8\n",
      "2\n",
      "6\n",
      "6\n",
      "2\n",
      "7\n",
      "5\n",
      "4\n",
      "2\n",
      "7\n",
      "1\n",
      "9\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "8\n",
      "5\n",
      "3\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "8\n",
      "8\n",
      "1\n",
      "7\n",
      "4\n",
      "8\n",
      "2\n",
      "6\n",
      "1\n",
      "6\n",
      "9\n",
      "8\n",
      "0\n",
      "6\n",
      "7\n",
      "3\n",
      "0\n",
      "8\n",
      "8\n",
      "3\n",
      "9\n",
      "7\n",
      "4\n",
      "3\n",
      "8\n",
      "6\n",
      "2\n",
      "1\n",
      "8\n",
      "4\n",
      "7\n",
      "2\n",
      "9\n",
      "1\n",
      "3\n",
      "4\n",
      "8\n",
      "3\n",
      "6\n",
      "7\n",
      "1\n",
      "3\n",
      "1\n",
      "7\n",
      "2\n",
      "7\n",
      "5\n",
      "0\n",
      "5\n",
      "5\n",
      "8\n",
      "7\n",
      "0\n",
      "4\n",
      "8\n",
      "9\n",
      "1\n",
      "5\n",
      "3\n",
      "9\n",
      "5\n",
      "1\n",
      "2\n",
      "6\n",
      "6\n",
      "1\n",
      "4\n",
      "0\n",
      "3\n",
      "2\n",
      "8\n",
      "6\n",
      "6\n",
      "0\n",
      "6\n",
      "7\n",
      "4\n",
      "0\n",
      "2\n",
      "1\n",
      "6\n",
      "6\n",
      "1\n",
      "6\n",
      "2\n",
      "6\n",
      "1\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "9\n",
      "6\n",
      "4\n",
      "2\n",
      "8\n",
      "8\n",
      "5\n",
      "4\n",
      "0\n",
      "0\n",
      "5\n",
      "1\n",
      "3\n",
      "7\n",
      "3\n",
      "2\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for l in y_preds:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 3, 32, 32),\n",
       " (60000,),\n",
       " torch.Size([4000, 3, 32, 32]),\n",
       " torch.Size([4000]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=pd.read_csv('cifar10_data/train_data.csv',header=None)\n",
    "X_test=pd.read_csv('cifar10_data/public_test.csv',header=None)\n",
    "X_train,y_train=X_train.iloc[:,1:].to_numpy().astype(np.float32),X_train.iloc[:,0].to_numpy().astype(np.float32)\n",
    "X_test,y_test=torch.from_numpy(X_test.iloc[:,1:].to_numpy().astype(np.float32)).cuda(),torch.LongTensor(X_test.iloc[:,0].to_numpy().astype(np.float32)).cuda()\n",
    "X_train,X_test=X_train.reshape((-1,3,32,32)),X_test.reshape((-1,3,32,32))\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#.reshape(3,32,32).transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b809fe5db38>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((X_train[97].astype(np.uint8)/255).reshape((3,32,32)).transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cifar10_dataset(Dataset):\n",
    "    X=y=l=0\n",
    "    def __init__(self,X,y):\n",
    "        self.l=X.shape[0]\n",
    "        self.X=torch.from_numpy(X).cuda()\n",
    "        self.y=torch.LongTensor(y).cuda()\n",
    "    def __len__(self):\n",
    "        return self.l\n",
    "    def __getitem__(self,i):\n",
    "        return self.X[i],self.y[i]\n",
    "def acc(y_true,y_preds):\n",
    "    y_preds=torch.argmax(y_preds,dim=1).squeeze()\n",
    "    return (y_true==y_preds).sum().item()/len(y_true)  \n",
    "\n",
    "# def train(cnn,train_data,epochs,opt,loss,X_test,y_test,t):\n",
    "#     tcounter=0\n",
    "#     th=time()\n",
    "# #     losses=[]\n",
    "# #     accuracies=[]\n",
    "#     a=0\n",
    "#     amax=0\n",
    "#     t+=time()-th\n",
    "#     for i in range(epochs):\n",
    "#         th=time()\n",
    "#         l=0\n",
    "#         t+=time()-th\n",
    "#         for j,(X,y) in enumerate(train_data):\n",
    "#             th=time()    \n",
    "#             #print(X.shape,y.shape,type(X),type(y))\n",
    "#             yh=cnn(X)\n",
    "#             train_loss=loss(yh,y)\n",
    "#             opt.zero_grad()\n",
    "#             l+=train_loss.item()\n",
    "#             train_loss.backward()\n",
    "#             opt.step()\n",
    "#             t+=time()-th\n",
    "#         th=time()\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "# #             losses.append(l)\n",
    "#             l/=len(train_data) \n",
    "#             y_preds=cnn(X_test)\n",
    "#             a=acc(y_test,y_preds)\n",
    "# #             accuracies.append()\n",
    "#             print(\"Epoch: \"+str(i+1)+\" Train loss: \"+str(l)+\" test accuracy: \" +str(a))  \n",
    "#             t+=time()-th\n",
    "#             th=time()\n",
    "#         if((t>0 and a>amax)):\n",
    "#             amax=a\n",
    "#             #torch.save(cnn.state_dict(),'./model.pth')\n",
    "#         t+=time()-th\n",
    "#         if(t>10*60):\n",
    "#             return amax\n",
    "            \n",
    "#     return amax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cnn,train_data,epochs,opt,loss,test_data,n,t):\n",
    "    tcounter=0\n",
    "    th=time()\n",
    "#     losses=[]\n",
    "#     accuracies=[]\n",
    "    a=0\n",
    "    amax=0\n",
    "    t+=time()-th\n",
    "    for i in range(epochs):\n",
    "        th=time()\n",
    "        l=0\n",
    "        t+=time()-th\n",
    "        for j,(X,y) in enumerate(train_data):\n",
    "            th=time()    \n",
    "            #print(X.shape,y.shape,type(X),type(y))\n",
    "            yh=cnn(X.cuda())\n",
    "            train_loss=loss(yh,y.type(torch.LongTensor).cuda())\n",
    "            opt.zero_grad()\n",
    "            l+=train_loss.item()\n",
    "            train_loss.backward()\n",
    "            opt.step()\n",
    "            t+=time()-th\n",
    "        th=time()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "#             losses.append(l)\n",
    "            l/=len(train_data) \n",
    "            a=0\n",
    "            for k,(X,y) in enumerate(test_data):\n",
    "                y_preds=cnn(X.cuda())\n",
    "                y_preds=torch.argmax(y_preds,dim=1).squeeze()\n",
    "                a+=(y.cuda()==y_preds).sum().item()\n",
    "            a/=n\n",
    "#             ac=0\n",
    "#             for k,(X,y) in enumerate(test):\n",
    "#                 y_preds=cnn(X)\n",
    "#                 y_preds=torch.argmax(y_preds,dim=1).squeeze()\n",
    "#                 ac+=(y==y_preds).sum().item()\n",
    "#             ac/=n    \n",
    "#            accuracies.append()\n",
    "            print(\"Epoch: \"+str(i+1)+\" Train loss: \"+str(l)+\" test accuracy: \" +str(a))  \n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            if((t>0 and a>amax)):\n",
    "                amax=a\n",
    "                #torch.save(cnn.state_dict(),'./model.pth')\n",
    "            t+=time()-th\n",
    "        if(t>10*60):\n",
    "            return amax\n",
    "            \n",
    "    return amax "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING DIFFERENT PREPROCESSING CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3)\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,64,3)\n",
    "        self.bn2=nn.BatchNorm2d(64)\n",
    "        self.c3=nn.Conv2d(64,512,3)\n",
    "        self.bn3=nn.BatchNorm2d(512)\n",
    "        self.c4=nn.Conv2d(512,1024,2)\n",
    "        self.fc1=nn.Linear(1024,256)\n",
    "        self.fc2=nn.Linear(256,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn1(self.c1(X))))\n",
    "        X=self.p2(F.relu(self.bn2(self.c2(X)))) \n",
    "        X=self.p2(F.relu(self.bn3(self.c3(X))))        \n",
    "        X=F.relu(self.c4(X))\n",
    "        X=X.view(-1,1024)\n",
    "        X=self.fc2(self.dropout(F.relu(self.fc1(X))))\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cifar10_dataset(Dataset):\n",
    "    X=y=l=0\n",
    "    def __init__(self,X,y):\n",
    "        self.l=X.shape[0]\n",
    "        self.X=torch.from_numpy(X)\n",
    "        self.y=torch.LongTensor(y)\n",
    "    def __len__(self):\n",
    "        return self.l\n",
    "    def __getitem__(self,i):\n",
    "        return self.X[i],self.y[i]\n",
    "    \n",
    "X_train=pd.read_csv('cifar10_data/train_data.csv',header=None)\n",
    "X_test=pd.read_csv('cifar10_data/public_test.csv',header=None)\n",
    "X_train,y_train=X_train.iloc[:,1:].to_numpy().astype(np.float32),X_train.iloc[:,0].to_numpy().astype(np.float32)\n",
    "X_test,y_test=X_test.iloc[:,1:].to_numpy().astype(np.float32),X_test.iloc[:,0].to_numpy().astype(np.float32)\n",
    "X_train,X_test=X_train.reshape((-1,3,32,32)),X_test.reshape((-1,3,32,32))\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape\n",
    "bs=200\n",
    "train_data=DataLoader(cifar10_dataset(X_train,y_train),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "test_data=DataLoader(cifar10_dataset(X_test,y_test),batch_size=bs,shuffle=False,num_workers=0)\n",
    "# #X_test,y_test=torch.from_numpy(X_test).cuda(),torch.LongTensor(y_test).cuda()\n",
    "# # X_train,y_train=torch.from_numpy(X_train).cuda(),torch.LongTensor(y_train).cuda()\n",
    "# test=DataLoader(cifar10_dataset(X_test,y_test),batch_size=200,shuffle=False)\n",
    "\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.4583529567718505 test accuracy: 0.5765\n",
      "Epoch: 2 Train loss: 1.0740951937437058 test accuracy: 0.643\n",
      "Epoch: 3 Train loss: 0.9122755732138952 test accuracy: 0.65875\n",
      "Epoch: 4 Train loss: 0.7874665158987045 test accuracy: 0.676\n",
      "Epoch: 5 Train loss: 0.674628387093544 test accuracy: 0.68525\n",
      "Epoch: 6 Train loss: 0.5746658616264662 test accuracy: 0.685\n",
      "Epoch: 7 Train loss: 0.4847498751680056 test accuracy: 0.68625\n",
      "Epoch: 8 Train loss: 0.40390435556570686 test accuracy: 0.684\n",
      "Epoch: 9 Train loss: 0.3342757673561573 test accuracy: 0.69025\n",
      "Epoch: 10 Train loss: 0.28040341605742775 test accuracy: 0.687\n",
      "Epoch: 11 Train loss: 0.24272904222210248 test accuracy: 0.686\n",
      "Epoch: 12 Train loss: 0.21280323637028536 test accuracy: 0.693\n",
      "Epoch: 13 Train loss: 0.19179743881026903 test accuracy: 0.676\n",
      "Epoch: 14 Train loss: 0.17191277749836445 test accuracy: 0.6835\n",
      "Epoch: 15 Train loss: 0.16067721882214148 test accuracy: 0.69925\n",
      "Epoch: 16 Train loss: 0.15061305183917284 test accuracy: 0.6745\n",
      "Epoch: 17 Train loss: 0.12776811813314756 test accuracy: 0.6805\n",
      "Epoch: 18 Train loss: 0.10712990641593934 test accuracy: 0.6885\n",
      "Epoch: 19 Train loss: 0.0939018110682567 test accuracy: 0.6795\n",
      "Epoch: 20 Train loss: 0.08697479373464982 test accuracy: 0.66575\n",
      "Epoch: 21 Train loss: 0.08491611018156012 test accuracy: 0.657\n",
      "Epoch: 22 Train loss: 0.07176848185248673 test accuracy: 0.6805\n",
      "Epoch: 23 Train loss: 0.06801227381763358 test accuracy: 0.695\n",
      "Epoch: 24 Train loss: 0.061158674573525786 test accuracy: 0.6745\n",
      "Epoch: 25 Train loss: 0.05367844933333496 test accuracy: 0.691\n",
      "Epoch: 26 Train loss: 0.04509541599235187 test accuracy: 0.705\n",
      "Epoch: 27 Train loss: 0.036968633566672605 test accuracy: 0.699\n",
      "Epoch: 28 Train loss: 0.029593178404805562 test accuracy: 0.7015\n",
      "Epoch: 29 Train loss: 0.021933857911111167 test accuracy: 0.703\n",
      "Epoch: 30 Train loss: 0.021360509481746705 test accuracy: 0.698\n",
      "Epoch: 31 Train loss: 0.02212199706506605 test accuracy: 0.69925\n",
      "Epoch: 32 Train loss: 0.02391853361778582 test accuracy: 0.69425\n",
      "Epoch: 33 Train loss: 0.028841859115442882 test accuracy: 0.70575\n",
      "Epoch: 34 Train loss: 0.024525092027227705 test accuracy: 0.6965\n",
      "Epoch: 35 Train loss: 0.019357305011168745 test accuracy: 0.7045\n",
      "Epoch: 36 Train loss: 0.02336279601013909 test accuracy: 0.708\n",
      "Epoch: 37 Train loss: 0.020694443428268035 test accuracy: 0.684\n",
      "Epoch: 38 Train loss: 0.019884866459760814 test accuracy: 0.70025\n",
      "Epoch: 39 Train loss: 0.02306072182720527 test accuracy: 0.70225\n",
      "Epoch: 40 Train loss: 0.026760425857889156 test accuracy: 0.68825\n",
      "Epoch: 41 Train loss: 0.02129045335110277 test accuracy: 0.705\n",
      "Epoch: 42 Train loss: 0.02187945515771086 test accuracy: 0.6955\n",
      "Epoch: 43 Train loss: 0.021057312591389443 test accuracy: 0.6965\n",
      "Epoch: 44 Train loss: 0.019580433995773396 test accuracy: 0.69675\n",
      "Epoch: 45 Train loss: 0.014339283450196187 test accuracy: 0.7015\n",
      "Epoch: 46 Train loss: 0.018473365496223172 test accuracy: 0.70325\n",
      "Epoch: 47 Train loss: 0.015175069790372314 test accuracy: 0.70975\n",
      "Epoch: 48 Train loss: 0.016957552922346318 test accuracy: 0.69675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.70975"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class cifar10_dataset(Dataset):\n",
    "#     X=y=l=0\n",
    "#     def __init__(self,X,y):\n",
    "#         self.l=X.shape[0]\n",
    "#         self.X=torch.from_numpy(X).cuda()\n",
    "#         self.y=torch.LongTensor(y).cuda()\n",
    "#     def __len__(self):\n",
    "#         return self.l\n",
    "#     def __getitem__(self,i):\n",
    "#         return self.X[i],self.y[i]\n",
    "class cifar10_dataset(Dataset):    \n",
    "    def __init__(self,data,train = True,img_transform=None):\n",
    "        self.img_transform = img_transform\n",
    "        self.is_train = train   \n",
    "#         data = pd.read_csv(data_csv, header=None)\n",
    "        if self.is_train:\n",
    "            self.images,self.labels=data[0],data[1]            \n",
    "#             images = data.iloc[:,1:].to_numpy()\n",
    "#             labels = data.iloc[:,0].astype(int)\n",
    "        else:\n",
    "            self.images=data\n",
    "#             images = data.iloc[:,:]\n",
    "#             labels = None  \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        image = self.images[i]\n",
    "        image = np.array(image).astype(np.uint8).reshape((32, 32, 3),order='F')\n",
    "        if self.is_train:\n",
    "            label = self.labels[i]\n",
    "        else:\n",
    "            label = -1\n",
    "        image = self.img_transform(image)\n",
    "        return image,label\n",
    "    \n",
    "X_train=pd.read_csv('cifar10_data/train_data.csv',header=None)\n",
    "X_test=pd.read_csv('cifar10_data/public_test.csv',header=None)\n",
    "# X_train,y_train=X_train.iloc[:,1:].to_numpy(),X_train.iloc[:,0].to_numpy().astype(int)\n",
    "# X_test,y_test=X_test.iloc[:,1:].to_numpy(),X_test.iloc[:,0].to_numpy().astype(int)\n",
    "X_train,y_train=np.array(X_train.iloc[:,1:],dtype=np.uint8),np.array(X_train.iloc[:,0],dtype=int)\n",
    "X_test,y_test=np.array(X_test.iloc[:,1:],dtype=np.uint8),np.array(X_test.iloc[:,0],dtype=int)\n",
    "\n",
    "#X_train,X_test=X_train.reshape((-1,3,32,32)),X_test.reshape((-1,3,32,32))\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape\n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()]  )                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "# #X_test,y_test=torch.from_numpy(X_test).cuda(),torch.LongTensor(y_test).cuda()\n",
    "# # X_train,y_train=torch.from_numpy(X_train).cuda(),torch.LongTensor(y_train).cuda()\n",
    "# test=DataLoader(cifar10_dataset(X_test,y_test),batch_size=200,shuffle=False)\n",
    "\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.4582800833384195 test accuracy: 0.57725\n",
      "Epoch: 2 Train loss: 1.0738604845603308 test accuracy: 0.64075\n",
      "Epoch: 3 Train loss: 0.9085040332873663 test accuracy: 0.66725\n",
      "Epoch: 4 Train loss: 0.7823814008633295 test accuracy: 0.68525\n",
      "Epoch: 5 Train loss: 0.6746595605214437 test accuracy: 0.69725\n",
      "Epoch: 6 Train loss: 0.5750470388929049 test accuracy: 0.70525\n",
      "Epoch: 7 Train loss: 0.4831218994657199 test accuracy: 0.708\n",
      "Epoch: 8 Train loss: 0.4007604005932808 test accuracy: 0.706\n",
      "Epoch: 9 Train loss: 0.3329774000744025 test accuracy: 0.69825\n",
      "Epoch: 10 Train loss: 0.27348528360327085 test accuracy: 0.68475\n",
      "Epoch: 11 Train loss: 0.2461324534813563 test accuracy: 0.7015\n",
      "Epoch: 12 Train loss: 0.23460144569476446 test accuracy: 0.7035\n",
      "Epoch: 13 Train loss: 0.21269343324005605 test accuracy: 0.6935\n",
      "Epoch: 14 Train loss: 0.18779620982706546 test accuracy: 0.68325\n",
      "Epoch: 15 Train loss: 0.1632710656026999 test accuracy: 0.682\n",
      "Epoch: 16 Train loss: 0.13911446766306956 test accuracy: 0.6815\n",
      "Epoch: 17 Train loss: 0.12255939147124688 test accuracy: 0.68425\n",
      "Epoch: 18 Train loss: 0.10701267976934711 test accuracy: 0.67825\n",
      "Epoch: 19 Train loss: 0.08862092183281978 test accuracy: 0.6965\n",
      "Epoch: 20 Train loss: 0.08079787831753492 test accuracy: 0.68875\n",
      "Epoch: 21 Train loss: 0.07429489406446615 test accuracy: 0.70425\n",
      "Epoch: 22 Train loss: 0.055342470786223806 test accuracy: 0.68925\n",
      "Epoch: 23 Train loss: 0.04721213259578993 test accuracy: 0.6945\n",
      "Epoch: 24 Train loss: 0.042155629424378276 test accuracy: 0.697\n",
      "Epoch: 25 Train loss: 0.03942708742183944 test accuracy: 0.703\n",
      "Epoch: 26 Train loss: 0.035250589211160935 test accuracy: 0.712\n",
      "Epoch: 27 Train loss: 0.03162552812602371 test accuracy: 0.71275\n",
      "Epoch: 28 Train loss: 0.029300654175846527 test accuracy: 0.70975\n",
      "Epoch: 29 Train loss: 0.027315345757330457 test accuracy: 0.71175\n",
      "Epoch: 30 Train loss: 0.03218833295628429 test accuracy: 0.71425\n",
      "Epoch: 31 Train loss: 0.03242047675574819 test accuracy: 0.70825\n",
      "Epoch: 32 Train loss: 0.023667082516476513 test accuracy: 0.69275\n",
      "Epoch: 33 Train loss: 0.02762620790783937 test accuracy: 0.706\n",
      "Epoch: 34 Train loss: 0.022785000044774885 test accuracy: 0.705\n",
      "Epoch: 35 Train loss: 0.02519791835375751 test accuracy: 0.6985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71425"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 32, 32, 3), (60000,), (4000, 32, 32, 3), (4000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class cifar10_dataset(Dataset):    \n",
    "    def __init__(self,data,train = True,img_transform=None):\n",
    "        self.img_transform = img_transform\n",
    "        self.is_train = train   \n",
    "#         data = pd.read_csv(data_csv, header=None)\n",
    "        if self.is_train:\n",
    "            self.images,self.labels=data[0],data[1]            \n",
    "#             images = data.iloc[:,1:].to_numpy()\n",
    "#             labels = data.iloc[:,0].astype(int)\n",
    "        else:\n",
    "            self.images=data\n",
    "#             images = data.iloc[:,:]\n",
    "#             labels = None  \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        image = self.images[i]\n",
    "        #image = np.array(image).astype(np.uint8).reshape((32, 32, 3),order='F')\n",
    "        if self.is_train:\n",
    "            label = self.labels[i]\n",
    "        else:\n",
    "            label = -1\n",
    "        image = self.img_transform(image)\n",
    "        return image,label\n",
    "    \n",
    "X_train=pd.read_csv('cifar10_data/train_data.csv',header=None)\n",
    "X_test=pd.read_csv('cifar10_data/public_test.csv',header=None)\n",
    "X_train,y_train=np.array(X_train.iloc[:,1:],dtype=np.uint8),np.array(X_train.iloc[:,0],dtype=int)\n",
    "X_test,y_test=np.array(X_test.iloc[:,1:],dtype=np.uint8),np.array(X_test.iloc[:,0],dtype=int)\n",
    "X_train,X_test=X_train.reshape((-1,3,32,32)).transpose(0,2,3,1),X_test.reshape((-1,3,32,32)).transpose(0,2,3,1)\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()]  )                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "# #X_test,y_test=torch.from_numpy(X_test).cuda(),torch.LongTensor(y_test).cuda()\n",
    "# # X_train,y_train=torch.from_numpy(X_train).cuda(),torch.LongTensor(y_train).cuda()\n",
    "# test=DataLoader(cifar10_dataset(X_test,y_test),batch_size=200,shuffle=False)\n",
    "\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.4368593700726826 test accuracy: 0.58375\n",
      "Epoch: 2 Train loss: 1.0585507303476334 test accuracy: 0.63725\n",
      "Epoch: 3 Train loss: 0.8894233570496242 test accuracy: 0.66175\n",
      "Epoch: 4 Train loss: 0.7606638060013453 test accuracy: 0.68175\n",
      "Epoch: 5 Train loss: 0.6491920384764671 test accuracy: 0.6965\n",
      "Epoch: 6 Train loss: 0.5478086313605308 test accuracy: 0.6945\n",
      "Epoch: 7 Train loss: 0.45520499378442764 test accuracy: 0.70475\n",
      "Epoch: 8 Train loss: 0.375292926132679 test accuracy: 0.701\n",
      "Epoch: 9 Train loss: 0.31461823229988417 test accuracy: 0.6915\n",
      "Epoch: 10 Train loss: 0.2613475757837296 test accuracy: 0.68125\n",
      "Epoch: 11 Train loss: 0.23292541240652404 test accuracy: 0.67975\n",
      "Epoch: 12 Train loss: 0.22155862274269264 test accuracy: 0.66825\n",
      "Epoch: 13 Train loss: 0.21243215362230936 test accuracy: 0.692\n",
      "Epoch: 14 Train loss: 0.17121706686913968 test accuracy: 0.68975\n",
      "Epoch: 15 Train loss: 0.12759359973172346 test accuracy: 0.6955\n",
      "Epoch: 16 Train loss: 0.10902978758017222 test accuracy: 0.6915\n",
      "Epoch: 17 Train loss: 0.10037978315725922 test accuracy: 0.67675\n",
      "Epoch: 18 Train loss: 0.09326257377242049 test accuracy: 0.6975\n",
      "Epoch: 19 Train loss: 0.08837156757091483 test accuracy: 0.69\n",
      "Epoch: 20 Train loss: 0.08647585885599256 test accuracy: 0.683\n",
      "Epoch: 21 Train loss: 0.07749798221513629 test accuracy: 0.68225\n",
      "Epoch: 22 Train loss: 0.06331801778326432 test accuracy: 0.69675\n",
      "Epoch: 23 Train loss: 0.049996395437046884 test accuracy: 0.69575\n",
      "Epoch: 24 Train loss: 0.03935211782964567 test accuracy: 0.69275\n",
      "Epoch: 25 Train loss: 0.03196132995188236 test accuracy: 0.692\n",
      "Epoch: 26 Train loss: 0.026112011785929402 test accuracy: 0.6915\n",
      "Epoch: 27 Train loss: 0.024351087920367716 test accuracy: 0.69875\n",
      "Epoch: 28 Train loss: 0.02349724479485303 test accuracy: 0.68925\n",
      "Epoch: 29 Train loss: 0.027069690694722037 test accuracy: 0.69275\n",
      "Epoch: 30 Train loss: 0.021968701159736762 test accuracy: 0.7\n",
      "Epoch: 31 Train loss: 0.02696768515355264 test accuracy: 0.69275\n",
      "Epoch: 32 Train loss: 0.028102942469219367 test accuracy: 0.68975\n",
      "Epoch: 33 Train loss: 0.02442930530446271 test accuracy: 0.7055\n",
      "Epoch: 34 Train loss: 0.02137500384822488 test accuracy: 0.70475\n",
      "Epoch: 35 Train loss: 0.02233839488821104 test accuracy: 0.69575\n",
      "Epoch: 36 Train loss: 0.027562838743906467 test accuracy: 0.70225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7055"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.5106280533472698 test accuracy: 0.5435\n",
      "Epoch: 2 Train loss: 1.1362868694464365 test accuracy: 0.6165\n",
      "Epoch: 3 Train loss: 0.9721474047501882 test accuracy: 0.64975\n",
      "Epoch: 4 Train loss: 0.8506886422634125 test accuracy: 0.66925\n",
      "Epoch: 5 Train loss: 0.7459475209315618 test accuracy: 0.68375\n",
      "Epoch: 6 Train loss: 0.6494903988639513 test accuracy: 0.694\n",
      "Epoch: 7 Train loss: 0.5651257514953614 test accuracy: 0.6995\n",
      "Epoch: 8 Train loss: 0.4849318284789721 test accuracy: 0.70075\n",
      "Epoch: 9 Train loss: 0.4117158429821332 test accuracy: 0.702\n",
      "Epoch: 10 Train loss: 0.3456249438226223 test accuracy: 0.70525\n",
      "Epoch: 11 Train loss: 0.28842060223221777 test accuracy: 0.69925\n",
      "Epoch: 12 Train loss: 0.2430620046456655 test accuracy: 0.704\n",
      "Epoch: 13 Train loss: 0.21111059551437697 test accuracy: 0.68325\n",
      "Epoch: 14 Train loss: 0.20083301998674868 test accuracy: 0.676\n",
      "Epoch: 15 Train loss: 0.19370142752925554 test accuracy: 0.6805\n",
      "Epoch: 16 Train loss: 0.16502976797521116 test accuracy: 0.68875\n",
      "Epoch: 17 Train loss: 0.14598412092775107 test accuracy: 0.679\n",
      "Epoch: 18 Train loss: 0.127541177260379 test accuracy: 0.66425\n",
      "Epoch: 19 Train loss: 0.10973988814900319 test accuracy: 0.694\n",
      "Epoch: 20 Train loss: 0.09589773315936327 test accuracy: 0.6985\n",
      "Epoch: 21 Train loss: 0.0842245538160205 test accuracy: 0.708\n",
      "Epoch: 22 Train loss: 0.07257885100940863 test accuracy: 0.697\n",
      "Epoch: 23 Train loss: 0.06949210369959474 test accuracy: 0.683\n",
      "Epoch: 24 Train loss: 0.06681908960764607 test accuracy: 0.68125\n",
      "Epoch: 25 Train loss: 0.057707205740734936 test accuracy: 0.69675\n",
      "Epoch: 26 Train loss: 0.05849132800474763 test accuracy: 0.7095\n",
      "Epoch: 27 Train loss: 0.0316086768048505 test accuracy: 0.7095\n",
      "Epoch: 28 Train loss: 0.025346890767104925 test accuracy: 0.70175\n",
      "Epoch: 29 Train loss: 0.018842000249618043 test accuracy: 0.69825\n",
      "Epoch: 30 Train loss: 0.019070710352777194 test accuracy: 0.711\n",
      "Epoch: 31 Train loss: 0.013043599844677374 test accuracy: 0.70375\n",
      "Epoch: 32 Train loss: 0.016422276949354758 test accuracy: 0.69975\n",
      "Epoch: 33 Train loss: 0.01557099839594836 test accuracy: 0.68575\n",
      "Epoch: 34 Train loss: 0.02127002889988944 test accuracy: 0.70475\n",
      "Epoch: 35 Train loss: 0.022060247849828254 test accuracy: 0.6905\n",
      "Epoch: 36 Train loss: 0.02027490422828123 test accuracy: 0.70825\n",
      "Epoch: 37 Train loss: 0.025212529644680518 test accuracy: 0.69725\n",
      "Epoch: 38 Train loss: 0.021842847029523303 test accuracy: 0.698\n",
      "Epoch: 39 Train loss: 0.02081622281111777 test accuracy: 0.70425\n",
      "Epoch: 40 Train loss: 0.021202626665278026 test accuracy: 0.70375\n",
      "Epoch: 41 Train loss: 0.01927643114157642 test accuracy: 0.70275\n",
      "Epoch: 42 Train loss: 0.014605557854132105 test accuracy: 0.6915\n",
      "Epoch: 43 Train loss: 0.018826058676155905 test accuracy: 0.69525\n",
      "Epoch: 44 Train loss: 0.0206597521652778 test accuracy: 0.71275\n",
      "Epoch: 45 Train loss: 0.014986559708292286 test accuracy: 0.7025\n",
      "Epoch: 46 Train loss: 0.016404373969805118 test accuracy: 0.70625\n",
      "Epoch: 47 Train loss: 0.015395437227174019 test accuracy: 0.69875\n",
      "Epoch: 48 Train loss: 0.013635413178708405 test accuracy: 0.6955\n",
      "Epoch: 49 Train loss: 0.01585296433263769 test accuracy: 0.6955\n",
      "Epoch: 50 Train loss: 0.016282384989317507 test accuracy: 0.712\n",
      "Epoch: 51 Train loss: 0.015223401131418844 test accuracy: 0.7035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71275"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cnn,train_data,epochs,opt,loss,test_data,n,b,t):\n",
    "    tcounter=0\n",
    "    th=time()\n",
    "#     losses=[]\n",
    "#     accuracies=[]\n",
    "    a=0\n",
    "    amax=0\n",
    "    t+=time()-th\n",
    "    for i in range(epochs):\n",
    "        th=time()\n",
    "        l=0\n",
    "        for j,(X,y) in enumerate(train_data):\n",
    "                \n",
    "            #print(X.shape,y.shape,type(X),type(y))\n",
    "            yh=cnn(X.cuda())\n",
    "            train_loss=loss(yh,y.type(torch.LongTensor).cuda())\n",
    "            opt.zero_grad()\n",
    "            l+=train_loss.item()\n",
    "            train_loss.backward()\n",
    "            opt.step()\n",
    "        t+=time()-th\n",
    "        th=time()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "#             losses.append(l)\n",
    "            l/=len(train_data) \n",
    "            a=0\n",
    "            for k,(X,y) in enumerate(test_data):\n",
    "                y_preds=cnn(X.cuda())\n",
    "                y_preds=torch.argmax(y_preds,dim=1).squeeze()\n",
    "                a+=(y.cuda()==y_preds).sum().item()\n",
    "            a/=n\n",
    "#             ac=0\n",
    "#             for k,(X,y) in enumerate(test):\n",
    "#                 y_preds=cnn(X)\n",
    "#                 y_preds=torch.argmax(y_preds,dim=1).squeeze()\n",
    "#                 ac+=(y==y_preds).sum().item()\n",
    "#             ac/=n    \n",
    "#            accuracies.append()\n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            print(\"Epoch: \"+str(i+1)+\" Train loss: \"+str(l)+\" test accuracy: \" +str(a)+\" time: \"+str(t))  \n",
    "            if((t>0 and a>amax)):\n",
    "                amax=a\n",
    "                #torch.save(cnn.state_dict(),'./model.pth')\n",
    "            t+=time()-th\n",
    "        if(t>b*60):\n",
    "            return amax\n",
    "            \n",
    "    return amax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.4791285308202107 test accuracy: 0.57375\n",
      "Epoch: 2 Train loss: 1.138863796989123 test accuracy: 0.6255\n",
      "Epoch: 3 Train loss: 1.0089709442853927 test accuracy: 0.66525\n",
      "Epoch: 4 Train loss: 0.9193498277664185 test accuracy: 0.672\n",
      "Epoch: 5 Train loss: 0.8530985208352407 test accuracy: 0.68775\n",
      "Epoch: 6 Train loss: 0.7930918898185094 test accuracy: 0.70675\n",
      "Epoch: 7 Train loss: 0.7401097889741262 test accuracy: 0.713\n",
      "Epoch: 8 Train loss: 0.697019768555959 test accuracy: 0.72775\n",
      "Epoch: 9 Train loss: 0.6590139192342758 test accuracy: 0.7255\n",
      "Epoch: 10 Train loss: 0.6256713570157687 test accuracy: 0.7365\n",
      "Epoch: 11 Train loss: 0.5912368218104045 test accuracy: 0.73425\n",
      "Epoch: 12 Train loss: 0.5560082403818766 test accuracy: 0.7415\n",
      "Epoch: 13 Train loss: 0.5299967016776402 test accuracy: 0.741\n",
      "Epoch: 14 Train loss: 0.5042611532409986 test accuracy: 0.739\n",
      "Epoch: 15 Train loss: 0.47668815424044925 test accuracy: 0.752\n",
      "Epoch: 16 Train loss: 0.45920849571625394 test accuracy: 0.753\n",
      "Epoch: 17 Train loss: 0.4420387331644694 test accuracy: 0.751\n",
      "Epoch: 18 Train loss: 0.41847790280977887 test accuracy: 0.75375\n",
      "Epoch: 19 Train loss: 0.4022555991013845 test accuracy: 0.76025\n",
      "Epoch: 20 Train loss: 0.3862358126540979 test accuracy: 0.75875\n",
      "Epoch: 21 Train loss: 0.37088345681627594 test accuracy: 0.7575\n",
      "Epoch: 22 Train loss: 0.3568629427750905 test accuracy: 0.76475\n",
      "Epoch: 23 Train loss: 0.3431503038108349 test accuracy: 0.766\n",
      "Epoch: 24 Train loss: 0.3244065634906292 test accuracy: 0.76425\n",
      "Epoch: 25 Train loss: 0.3180265156924725 test accuracy: 0.76825\n",
      "Epoch: 26 Train loss: 0.30642885650197665 test accuracy: 0.77\n",
      "Epoch: 27 Train loss: 0.29316908210515974 test accuracy: 0.7645\n",
      "Epoch: 28 Train loss: 0.28978848829865456 test accuracy: 0.768\n",
      "Epoch: 29 Train loss: 0.2734989197055499 test accuracy: 0.769\n",
      "Epoch: 30 Train loss: 0.2659971892337004 test accuracy: 0.76775\n",
      "Epoch: 31 Train loss: 0.25473181789120036 test accuracy: 0.773\n",
      "Epoch: 32 Train loss: 0.24852425396442412 test accuracy: 0.7725\n",
      "Epoch: 33 Train loss: 0.2429450700432062 test accuracy: 0.774\n",
      "Epoch: 34 Train loss: 0.23676726358632247 test accuracy: 0.77875\n",
      "Epoch: 35 Train loss: 0.22405284489194552 test accuracy: 0.77975\n",
      "Epoch: 36 Train loss: 0.22670472284158072 test accuracy: 0.77075\n",
      "Epoch: 37 Train loss: 0.21395989681283634 test accuracy: 0.774\n",
      "Epoch: 38 Train loss: 0.21258557041486104 test accuracy: 0.7605\n",
      "Epoch: 39 Train loss: 0.20707626923918723 test accuracy: 0.76975\n",
      "Epoch: 40 Train loss: 0.1993888233602047 test accuracy: 0.773\n",
      "Epoch: 41 Train loss: 0.19214051748315494 test accuracy: 0.782\n",
      "Epoch: 42 Train loss: 0.1930474278330803 test accuracy: 0.77125\n",
      "Epoch: 43 Train loss: 0.18120685577392578 test accuracy: 0.7765\n",
      "Epoch: 44 Train loss: 0.1754578501234452 test accuracy: 0.775\n",
      "Epoch: 45 Train loss: 0.1765245940039555 test accuracy: 0.7795\n",
      "Epoch: 46 Train loss: 0.16659782732526462 test accuracy: 0.77775\n",
      "Epoch: 47 Train loss: 0.17226563356816768 test accuracy: 0.78625\n",
      "Epoch: 48 Train loss: 0.165388242478172 test accuracy: 0.78\n",
      "Epoch: 49 Train loss: 0.16215739091237386 test accuracy: 0.78925\n",
      "Epoch: 50 Train loss: 0.15604315208892028 test accuracy: 0.78425\n",
      "Epoch: 51 Train loss: 0.14788314985732237 test accuracy: 0.78\n",
      "Epoch: 52 Train loss: 0.15184577256441117 test accuracy: 0.78725\n",
      "Epoch: 53 Train loss: 0.1413806753233075 test accuracy: 0.78375\n",
      "Epoch: 54 Train loss: 0.14544915227840344 test accuracy: 0.79125\n",
      "Epoch: 55 Train loss: 0.141871565853556 test accuracy: 0.79325\n",
      "Epoch: 56 Train loss: 0.1391068842758735 test accuracy: 0.78575\n",
      "Epoch: 57 Train loss: 0.13733082223683596 test accuracy: 0.78375\n",
      "Epoch: 58 Train loss: 0.13204145969202122 test accuracy: 0.7785\n",
      "Epoch: 59 Train loss: 0.13002267125993966 test accuracy: 0.7805\n",
      "Epoch: 60 Train loss: 0.12603403271486363 test accuracy: 0.7895\n",
      "Epoch: 61 Train loss: 0.12483097210526467 test accuracy: 0.77825\n",
      "Epoch: 62 Train loss: 0.12268263037006061 test accuracy: 0.78375\n",
      "Epoch: 63 Train loss: 0.1170097237577041 test accuracy: 0.7925\n",
      "Epoch: 64 Train loss: 0.11661776335289081 test accuracy: 0.7805\n",
      "Epoch: 65 Train loss: 0.11402788414309423 test accuracy: 0.7875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79325"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.3365628174940745 test accuracy: 0.64475\n",
      "Epoch: 2 Train loss: 0.9597099647919337 test accuracy: 0.6855\n",
      "Epoch: 3 Train loss: 0.8119729803005854 test accuracy: 0.733\n",
      "Epoch: 4 Train loss: 0.7026382486025492 test accuracy: 0.74275\n",
      "Epoch: 5 Train loss: 0.628559831182162 test accuracy: 0.756\n",
      "Epoch: 6 Train loss: 0.572629913687706 test accuracy: 0.759\n",
      "Epoch: 7 Train loss: 0.5234321040908495 test accuracy: 0.76825\n",
      "Epoch: 8 Train loss: 0.4759476273258527 test accuracy: 0.76975\n",
      "Epoch: 9 Train loss: 0.44751542071501416 test accuracy: 0.78\n",
      "Epoch: 10 Train loss: 0.41567339112361273 test accuracy: 0.784\n",
      "Epoch: 11 Train loss: 0.383553538719813 test accuracy: 0.78175\n",
      "Epoch: 12 Train loss: 0.3633268170058727 test accuracy: 0.79\n",
      "Epoch: 13 Train loss: 0.33663046757380166 test accuracy: 0.7865\n",
      "Epoch: 14 Train loss: 0.31258124589920044 test accuracy: 0.78775\n",
      "Epoch: 15 Train loss: 0.292830065091451 test accuracy: 0.795\n",
      "Epoch: 16 Train loss: 0.275471866329511 test accuracy: 0.79975\n",
      "Epoch: 17 Train loss: 0.26076295947035155 test accuracy: 0.7985\n",
      "Epoch: 18 Train loss: 0.24437246575951577 test accuracy: 0.79075\n",
      "Epoch: 19 Train loss: 0.2276507368683815 test accuracy: 0.804\n",
      "Epoch: 20 Train loss: 0.21268197004993758 test accuracy: 0.801\n",
      "Epoch: 21 Train loss: 0.20580045580863954 test accuracy: 0.80075\n",
      "Epoch: 22 Train loss: 0.19894658717016378 test accuracy: 0.8105\n",
      "Epoch: 23 Train loss: 0.1878328911215067 test accuracy: 0.8005\n",
      "Epoch: 24 Train loss: 0.18013473083575568 test accuracy: 0.80625\n",
      "Epoch: 25 Train loss: 0.17308155124386151 test accuracy: 0.805\n",
      "Epoch: 26 Train loss: 0.16311634086072446 test accuracy: 0.804\n",
      "Epoch: 27 Train loss: 0.16280082086722056 test accuracy: 0.80925\n",
      "Epoch: 28 Train loss: 0.1507749633366863 test accuracy: 0.8055\n",
      "Epoch: 29 Train loss: 0.15118959878881771 test accuracy: 0.80125\n",
      "Epoch: 30 Train loss: 0.13852673939118781 test accuracy: 0.8055\n",
      "Epoch: 31 Train loss: 0.1411478573580583 test accuracy: 0.80225\n",
      "Epoch: 32 Train loss: 0.13551657828191915 test accuracy: 0.81725\n",
      "Epoch: 33 Train loss: 0.12685342131803434 test accuracy: 0.80775\n",
      "Epoch: 34 Train loss: 0.127964106661578 test accuracy: 0.8115\n",
      "Epoch: 35 Train loss: 0.12390550459424654 test accuracy: 0.811\n",
      "Epoch: 36 Train loss: 0.11602907549589872 test accuracy: 0.81775\n",
      "Epoch: 37 Train loss: 0.1138861345499754 test accuracy: 0.814\n",
      "Epoch: 38 Train loss: 0.11013134532918532 test accuracy: 0.82225\n",
      "Epoch: 39 Train loss: 0.10741904120892286 test accuracy: 0.81625\n",
      "Epoch: 40 Train loss: 0.10311545912797253 test accuracy: 0.8235\n",
      "Epoch: 41 Train loss: 0.10173396687954664 test accuracy: 0.8265\n",
      "Epoch: 42 Train loss: 0.09867397411415975 test accuracy: 0.82025\n",
      "Epoch: 43 Train loss: 0.09865833094964425 test accuracy: 0.815\n",
      "Epoch: 44 Train loss: 0.09688972324132919 test accuracy: 0.82575\n",
      "Epoch: 45 Train loss: 0.0944580954996248 test accuracy: 0.81225\n",
      "Epoch: 46 Train loss: 0.0889882230758667 test accuracy: 0.819\n",
      "Epoch: 47 Train loss: 0.09192249614124497 test accuracy: 0.8185\n",
      "Epoch: 48 Train loss: 0.08636270155509312 test accuracy: 0.81725\n",
      "Epoch: 49 Train loss: 0.08293693616365393 test accuracy: 0.81925\n",
      "Epoch: 50 Train loss: 0.08427455491696795 test accuracy: 0.82025\n",
      "Epoch: 51 Train loss: 0.07721714490403732 test accuracy: 0.827\n",
      "Epoch: 52 Train loss: 0.0820804860877494 test accuracy: 0.82075\n",
      "Epoch: 53 Train loss: 0.07433248966311415 test accuracy: 0.816\n",
      "Epoch: 54 Train loss: 0.07754668299108744 test accuracy: 0.82625\n",
      "Epoch: 55 Train loss: 0.07126327802116672 test accuracy: 0.82\n",
      "Epoch: 56 Train loss: 0.07750247254346808 test accuracy: 0.82325\n",
      "Epoch: 57 Train loss: 0.072764832675457 test accuracy: 0.81875\n",
      "Epoch: 58 Train loss: 0.07400719465687872 test accuracy: 0.826\n",
      "Epoch: 59 Train loss: 0.0711038191926976 test accuracy: 0.82025\n",
      "Epoch: 60 Train loss: 0.06886122365792592 test accuracy: 0.832\n",
      "Epoch: 61 Train loss: 0.0683868038157622 test accuracy: 0.81375\n",
      "Epoch: 62 Train loss: 0.06784526702327033 test accuracy: 0.82275\n",
      "Epoch: 63 Train loss: 0.0619262031527857 test accuracy: 0.827\n",
      "Epoch: 64 Train loss: 0.06180355009933313 test accuracy: 0.824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.832"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.5362402975559235 test accuracy: 0.55875\n",
      "Epoch: 2 Train loss: 1.195812590122223 test accuracy: 0.63175\n",
      "Epoch: 3 Train loss: 1.0665685979525248 test accuracy: 0.6645\n",
      "Epoch: 4 Train loss: 0.9783242696523666 test accuracy: 0.68425\n",
      "Epoch: 5 Train loss: 0.9158724635839463 test accuracy: 0.70275\n",
      "Epoch: 6 Train loss: 0.8647970634698868 test accuracy: 0.70725\n",
      "Epoch: 7 Train loss: 0.8238718944787979 test accuracy: 0.7145\n",
      "Epoch: 8 Train loss: 0.7781943696737289 test accuracy: 0.717\n",
      "Epoch: 9 Train loss: 0.7504495282967886 test accuracy: 0.7355\n",
      "Epoch: 10 Train loss: 0.7125309226910274 test accuracy: 0.7375\n",
      "Epoch: 11 Train loss: 0.683325301706791 test accuracy: 0.74825\n",
      "Epoch: 12 Train loss: 0.657204718987147 test accuracy: 0.75525\n",
      "Epoch: 13 Train loss: 0.6371838546792666 test accuracy: 0.7525\n",
      "Epoch: 14 Train loss: 0.610690900584062 test accuracy: 0.75325\n",
      "Epoch: 15 Train loss: 0.5876956505576769 test accuracy: 0.77025\n",
      "Epoch: 16 Train loss: 0.5673097996910413 test accuracy: 0.76275\n",
      "Epoch: 17 Train loss: 0.5517561946312587 test accuracy: 0.76875\n",
      "Epoch: 18 Train loss: 0.5303228289882342 test accuracy: 0.7715\n",
      "Epoch: 19 Train loss: 0.5142899163564046 test accuracy: 0.77125\n",
      "Epoch: 20 Train loss: 0.49621913452943167 test accuracy: 0.7785\n",
      "Epoch: 21 Train loss: 0.47848686734835305 test accuracy: 0.776\n",
      "Epoch: 22 Train loss: 0.4618094366788864 test accuracy: 0.785\n",
      "Epoch: 23 Train loss: 0.44692633400360743 test accuracy: 0.78\n",
      "Epoch: 24 Train loss: 0.43871020575364433 test accuracy: 0.78175\n",
      "Epoch: 25 Train loss: 0.42349441051483155 test accuracy: 0.785\n",
      "Epoch: 26 Train loss: 0.4084121758739154 test accuracy: 0.78575\n",
      "Epoch: 27 Train loss: 0.3961562692125638 test accuracy: 0.7855\n",
      "Epoch: 28 Train loss: 0.3829676548639933 test accuracy: 0.7845\n",
      "Epoch: 29 Train loss: 0.3741522379716237 test accuracy: 0.78575\n",
      "Epoch: 30 Train loss: 0.3635768133898576 test accuracy: 0.78175\n",
      "Epoch: 31 Train loss: 0.34763630494475367 test accuracy: 0.7895\n",
      "Epoch: 32 Train loss: 0.343411858578523 test accuracy: 0.78525\n",
      "Epoch: 33 Train loss: 0.3357435248295466 test accuracy: 0.79\n",
      "Epoch: 34 Train loss: 0.32250123759110766 test accuracy: 0.79125\n",
      "Epoch: 35 Train loss: 0.3100435801347097 test accuracy: 0.791\n",
      "Epoch: 36 Train loss: 0.30553633203109104 test accuracy: 0.785\n",
      "Epoch: 37 Train loss: 0.30000891104340555 test accuracy: 0.7895\n",
      "Epoch: 38 Train loss: 0.29076808378100394 test accuracy: 0.7855\n",
      "Epoch: 39 Train loss: 0.27894651055336 test accuracy: 0.78675\n",
      "Epoch: 40 Train loss: 0.27244079639514285 test accuracy: 0.7905\n",
      "Epoch: 41 Train loss: 0.2635354622701804 test accuracy: 0.78025\n",
      "Epoch: 42 Train loss: 0.2565533476074537 test accuracy: 0.7805\n",
      "Epoch: 43 Train loss: 0.24856577451030412 test accuracy: 0.79025\n",
      "Epoch: 44 Train loss: 0.24412563850482305 test accuracy: 0.7875\n",
      "Epoch: 45 Train loss: 0.2377638294051091 test accuracy: 0.79525\n",
      "Epoch: 46 Train loss: 0.22863374645511308 test accuracy: 0.79825\n",
      "Epoch: 47 Train loss: 0.22429619958003363 test accuracy: 0.78975\n",
      "Epoch: 48 Train loss: 0.22159142861763637 test accuracy: 0.79025\n",
      "Epoch: 49 Train loss: 0.21761911779642104 test accuracy: 0.78775\n",
      "Epoch: 50 Train loss: 0.20515473917126656 test accuracy: 0.7935\n",
      "Epoch: 51 Train loss: 0.20558696009218694 test accuracy: 0.797\n",
      "Epoch: 52 Train loss: 0.19818344766894977 test accuracy: 0.7865\n",
      "Epoch: 53 Train loss: 0.19408072878917057 test accuracy: 0.78675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79825"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1)),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.8458565433820089 test accuracy: 0.45575\n",
      "Epoch: 2 Train loss: 1.6181017390886943 test accuracy: 0.522\n",
      "Epoch: 3 Train loss: 1.5159276096026102 test accuracy: 0.55275\n",
      "Epoch: 4 Train loss: 1.448677495320638 test accuracy: 0.562\n",
      "Epoch: 5 Train loss: 1.3931771930058796 test accuracy: 0.58225\n",
      "Epoch: 6 Train loss: 1.352813413143158 test accuracy: 0.5915\n",
      "Epoch: 7 Train loss: 1.319721027612686 test accuracy: 0.603\n",
      "Epoch: 8 Train loss: 1.2829634670416514 test accuracy: 0.6075\n",
      "Epoch: 9 Train loss: 1.257999189297358 test accuracy: 0.6135\n",
      "Epoch: 10 Train loss: 1.2306222816308339 test accuracy: 0.617\n",
      "Epoch: 11 Train loss: 1.2142322518428166 test accuracy: 0.63175\n",
      "Epoch: 12 Train loss: 1.1893927264213562 test accuracy: 0.63825\n",
      "Epoch: 13 Train loss: 1.161974161863327 test accuracy: 0.64175\n",
      "Epoch: 14 Train loss: 1.1451287770271301 test accuracy: 0.64275\n",
      "Epoch: 15 Train loss: 1.126673681139946 test accuracy: 0.643\n",
      "Epoch: 16 Train loss: 1.1152107614278792 test accuracy: 0.64825\n",
      "Epoch: 17 Train loss: 1.0942297182480494 test accuracy: 0.6605\n",
      "Epoch: 18 Train loss: 1.0824892141421636 test accuracy: 0.6535\n",
      "Epoch: 19 Train loss: 1.071462993423144 test accuracy: 0.6575\n",
      "Epoch: 20 Train loss: 1.0569590346018474 test accuracy: 0.66875\n",
      "Epoch: 21 Train loss: 1.046668485403061 test accuracy: 0.6685\n",
      "Epoch: 22 Train loss: 1.0381546290715535 test accuracy: 0.67625\n",
      "Epoch: 23 Train loss: 1.0221932971477508 test accuracy: 0.66525\n",
      "Epoch: 24 Train loss: 1.011220265229543 test accuracy: 0.6715\n",
      "Epoch: 25 Train loss: 0.9953925659259161 test accuracy: 0.68225\n",
      "Epoch: 26 Train loss: 0.9877254249652226 test accuracy: 0.6805\n",
      "Epoch: 27 Train loss: 0.9755494356155395 test accuracy: 0.6925\n",
      "Epoch: 28 Train loss: 0.969602069457372 test accuracy: 0.69275\n",
      "Epoch: 29 Train loss: 0.9607345338662465 test accuracy: 0.68775\n",
      "Epoch: 30 Train loss: 0.9497246154149374 test accuracy: 0.69175\n",
      "Epoch: 31 Train loss: 0.9444162491957346 test accuracy: 0.69125\n",
      "Epoch: 32 Train loss: 0.9335519733031591 test accuracy: 0.6975\n",
      "Epoch: 33 Train loss: 0.9220931321382523 test accuracy: 0.69275\n",
      "Epoch: 34 Train loss: 0.9167591067155202 test accuracy: 0.69275\n",
      "Epoch: 35 Train loss: 0.9106397863229115 test accuracy: 0.6885\n",
      "Epoch: 36 Train loss: 0.9081579172611236 test accuracy: 0.7005\n",
      "Epoch: 37 Train loss: 0.8848919455210368 test accuracy: 0.70125\n",
      "Epoch: 38 Train loss: 0.888552660147349 test accuracy: 0.701\n",
      "Epoch: 39 Train loss: 0.8788074145714442 test accuracy: 0.7015\n",
      "Epoch: 40 Train loss: 0.8713688415288925 test accuracy: 0.6975\n",
      "Epoch: 41 Train loss: 0.8700793049732845 test accuracy: 0.70975\n",
      "Epoch: 42 Train loss: 0.8577264781792958 test accuracy: 0.70675\n",
      "Epoch: 43 Train loss: 0.8496494106451671 test accuracy: 0.7075\n",
      "Epoch: 44 Train loss: 0.8497340492407481 test accuracy: 0.712\n",
      "Epoch: 45 Train loss: 0.8369512897729874 test accuracy: 0.70875\n",
      "Epoch: 46 Train loss: 0.8311961994568506 test accuracy: 0.7155\n",
      "Epoch: 47 Train loss: 0.8290306721131007 test accuracy: 0.71425\n",
      "Epoch: 48 Train loss: 0.8236379824082056 test accuracy: 0.71725\n",
      "Epoch: 49 Train loss: 0.8102271231015523 test accuracy: 0.70975\n",
      "Epoch: 50 Train loss: 0.8090090866883596 test accuracy: 0.716\n",
      "Epoch: 51 Train loss: 0.80388687590758 test accuracy: 0.71475\n",
      "Epoch: 52 Train loss: 0.7976268841822942 test accuracy: 0.71325\n",
      "Epoch: 53 Train loss: 0.7930380272865295 test accuracy: 0.7135\n",
      "Epoch: 54 Train loss: 0.7918825970093409 test accuracy: 0.71725\n",
      "Epoch: 55 Train loss: 0.7840306067466736 test accuracy: 0.7175\n",
      "Epoch: 56 Train loss: 0.7717503011226654 test accuracy: 0.71825\n",
      "Epoch: 57 Train loss: 0.7736608360211055 test accuracy: 0.719\n",
      "Epoch: 58 Train loss: 0.7668886683384577 test accuracy: 0.7185\n",
      "Epoch: 59 Train loss: 0.7652572661638259 test accuracy: 0.71825\n",
      "Epoch: 60 Train loss: 0.7583148906628291 test accuracy: 0.71125\n",
      "Epoch: 61 Train loss: 0.7531038743257522 test accuracy: 0.72325\n",
      "Epoch: 62 Train loss: 0.7517584188779195 test accuracy: 0.72825\n",
      "Epoch: 63 Train loss: 0.7417313822110494 test accuracy: 0.72475\n",
      "Epoch: 64 Train loss: 0.7446683639287949 test accuracy: 0.732\n",
      "Epoch: 65 Train loss: 0.7316155411799748 test accuracy: 0.73325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73325"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(45),\n",
    "                                    transforms.RandomAffine(0,translate=(.5,.5))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.5883764346440634 test accuracy: 0.54225\n",
      "Epoch: 2 Train loss: 1.2746693714459738 test accuracy: 0.614\n",
      "Epoch: 3 Train loss: 1.1581920530398686 test accuracy: 0.6295\n",
      "Epoch: 4 Train loss: 1.0815490021308263 test accuracy: 0.65375\n",
      "Epoch: 5 Train loss: 1.011561239361763 test accuracy: 0.67125\n",
      "Epoch: 6 Train loss: 0.9582570962111155 test accuracy: 0.68575\n",
      "Epoch: 7 Train loss: 0.9112810371319453 test accuracy: 0.69875\n",
      "Epoch: 8 Train loss: 0.8741180471579234 test accuracy: 0.704\n",
      "Epoch: 9 Train loss: 0.8375645039478937 test accuracy: 0.712\n",
      "Epoch: 10 Train loss: 0.8005728326241175 test accuracy: 0.726\n",
      "Epoch: 11 Train loss: 0.773664763768514 test accuracy: 0.7315\n",
      "Epoch: 12 Train loss: 0.7436660017569859 test accuracy: 0.73075\n",
      "Epoch: 13 Train loss: 0.7250090118249257 test accuracy: 0.737\n",
      "Epoch: 14 Train loss: 0.703873139222463 test accuracy: 0.74175\n",
      "Epoch: 15 Train loss: 0.6788691352804502 test accuracy: 0.74425\n",
      "Epoch: 16 Train loss: 0.6549577588836352 test accuracy: 0.751\n",
      "Epoch: 17 Train loss: 0.637837363978227 test accuracy: 0.75775\n",
      "Epoch: 18 Train loss: 0.6195564610759418 test accuracy: 0.75875\n",
      "Epoch: 19 Train loss: 0.6004551705718041 test accuracy: 0.75975\n",
      "Epoch: 20 Train loss: 0.590637944539388 test accuracy: 0.7675\n",
      "Epoch: 21 Train loss: 0.5739402543505033 test accuracy: 0.7635\n",
      "Epoch: 22 Train loss: 0.5624436621864637 test accuracy: 0.7645\n",
      "Epoch: 23 Train loss: 0.5433310748140017 test accuracy: 0.7725\n",
      "Epoch: 24 Train loss: 0.527724671860536 test accuracy: 0.77425\n",
      "Epoch: 25 Train loss: 0.5181582108139992 test accuracy: 0.7785\n",
      "Epoch: 26 Train loss: 0.5061826009551684 test accuracy: 0.77575\n",
      "Epoch: 27 Train loss: 0.49509990165630974 test accuracy: 0.7725\n",
      "Epoch: 28 Train loss: 0.4764924435814222 test accuracy: 0.78125\n",
      "Epoch: 29 Train loss: 0.46835872103770576 test accuracy: 0.78025\n",
      "Epoch: 30 Train loss: 0.4571503879626592 test accuracy: 0.7825\n",
      "Epoch: 31 Train loss: 0.44959505726893745 test accuracy: 0.78325\n",
      "Epoch: 32 Train loss: 0.4422526017824809 test accuracy: 0.78125\n",
      "Epoch: 33 Train loss: 0.42945813169082003 test accuracy: 0.7765\n",
      "Epoch: 34 Train loss: 0.4232499056557814 test accuracy: 0.7825\n",
      "Epoch: 35 Train loss: 0.41185416241486866 test accuracy: 0.78875\n",
      "Epoch: 36 Train loss: 0.40530441810687384 test accuracy: 0.78525\n",
      "Epoch: 37 Train loss: 0.3971639470259349 test accuracy: 0.79175\n",
      "Epoch: 38 Train loss: 0.3919725891947746 test accuracy: 0.786\n",
      "Epoch: 39 Train loss: 0.3875688041249911 test accuracy: 0.789\n",
      "Epoch: 40 Train loss: 0.37284960339466733 test accuracy: 0.78475\n",
      "Epoch: 41 Train loss: 0.36679764290650685 test accuracy: 0.7905\n",
      "Epoch: 42 Train loss: 0.35378643805782 test accuracy: 0.78375\n",
      "Epoch: 43 Train loss: 0.35742731814583145 test accuracy: 0.79\n",
      "Epoch: 44 Train loss: 0.3459654340644677 test accuracy: 0.799\n",
      "Epoch: 45 Train loss: 0.3404912820458412 test accuracy: 0.78975\n",
      "Epoch: 46 Train loss: 0.3300151727596919 test accuracy: 0.792\n",
      "Epoch: 47 Train loss: 0.335071206142505 test accuracy: 0.79775\n",
      "Epoch: 48 Train loss: 0.3219122115770976 test accuracy: 0.79325\n",
      "Epoch: 49 Train loss: 0.31741683383782704 test accuracy: 0.79375\n",
      "Epoch: 50 Train loss: 0.313230494260788 test accuracy: 0.79\n",
      "Epoch: 51 Train loss: 0.3073394909997781 test accuracy: 0.79575\n",
      "Epoch: 52 Train loss: 0.3035785781343778 test accuracy: 0.7905\n",
      "Epoch: 53 Train loss: 0.2983440300325553 test accuracy: 0.78975\n",
      "Epoch: 54 Train loss: 0.30018599435687066 test accuracy: 0.791\n",
      "Epoch: 55 Train loss: 0.294232024649779 test accuracy: 0.78875\n",
      "Epoch: 56 Train loss: 0.28686281775434813 test accuracy: 0.78125\n",
      "Epoch: 57 Train loss: 0.2831617446740468 test accuracy: 0.7925\n",
      "Epoch: 58 Train loss: 0.28216176037987073 test accuracy: 0.79075\n",
      "Epoch: 59 Train loss: 0.27474839294950165 test accuracy: 0.788\n",
      "Epoch: 60 Train loss: 0.27118206391731897 test accuracy: 0.7955\n",
      "Epoch: 61 Train loss: 0.26923956781625746 test accuracy: 0.7945\n",
      "Epoch: 62 Train loss: 0.266616209646066 test accuracy: 0.7965\n",
      "Epoch: 63 Train loss: 0.2655129261314869 test accuracy: 0.7945\n",
      "Epoch: 64 Train loss: 0.25650339081883433 test accuracy: 0.7965\n",
      "Epoch: 65 Train loss: 0.2511734806001186 test accuracy: 0.7995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7995"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(10),\n",
    "                                    transforms.RandomAffine(0,translate=(.2,.2))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.5316474243005116 test accuracy: 0.56375\n",
      "Epoch: 2 Train loss: 1.2001941517988841 test accuracy: 0.632\n",
      "Epoch: 3 Train loss: 1.0724805591503779 test accuracy: 0.66125\n",
      "Epoch: 4 Train loss: 0.9807864946126937 test accuracy: 0.68525\n",
      "Epoch: 5 Train loss: 0.9121509255965551 test accuracy: 0.69225\n",
      "Epoch: 6 Train loss: 0.8563719469308854 test accuracy: 0.71575\n",
      "Epoch: 7 Train loss: 0.8053501409292221 test accuracy: 0.72075\n",
      "Epoch: 8 Train loss: 0.7604859296480815 test accuracy: 0.71725\n",
      "Epoch: 9 Train loss: 0.7173475756247838 test accuracy: 0.732\n",
      "Epoch: 10 Train loss: 0.6825959210594496 test accuracy: 0.732\n",
      "Epoch: 11 Train loss: 0.6463489691416423 test accuracy: 0.739\n",
      "Epoch: 12 Train loss: 0.6168507223327955 test accuracy: 0.736\n",
      "Epoch: 13 Train loss: 0.5881875465313594 test accuracy: 0.7455\n",
      "Epoch: 14 Train loss: 0.5617748008171717 test accuracy: 0.74475\n",
      "Epoch: 15 Train loss: 0.5423966286579768 test accuracy: 0.74925\n",
      "Epoch: 16 Train loss: 0.5219365414977074 test accuracy: 0.74525\n",
      "Epoch: 17 Train loss: 0.5001235163211822 test accuracy: 0.749\n",
      "Epoch: 18 Train loss: 0.4835523583491643 test accuracy: 0.7565\n",
      "Epoch: 19 Train loss: 0.46159901152054467 test accuracy: 0.75375\n",
      "Epoch: 20 Train loss: 0.4514320264259974 test accuracy: 0.75625\n",
      "Epoch: 21 Train loss: 0.43323503335316976 test accuracy: 0.74875\n",
      "Epoch: 22 Train loss: 0.41753460466861725 test accuracy: 0.755\n",
      "Epoch: 23 Train loss: 0.4051046178738276 test accuracy: 0.7525\n",
      "Epoch: 24 Train loss: 0.39639876117308936 test accuracy: 0.74925\n",
      "Epoch: 25 Train loss: 0.38002651030818624 test accuracy: 0.757\n",
      "Epoch: 26 Train loss: 0.37681051592032117 test accuracy: 0.75675\n",
      "Epoch: 27 Train loss: 0.3689284772674243 test accuracy: 0.75575\n",
      "Epoch: 28 Train loss: 0.3490365639825662 test accuracy: 0.763\n",
      "Epoch: 29 Train loss: 0.3424283589919408 test accuracy: 0.76225\n",
      "Epoch: 30 Train loss: 0.33138770138223966 test accuracy: 0.7635\n",
      "Epoch: 31 Train loss: 0.3273883814116319 test accuracy: 0.763\n",
      "Epoch: 32 Train loss: 0.3238151932756106 test accuracy: 0.7675\n",
      "Epoch: 33 Train loss: 0.3125780130426089 test accuracy: 0.76025\n",
      "Epoch: 34 Train loss: 0.3063254863520463 test accuracy: 0.75525\n",
      "Epoch: 35 Train loss: 0.29566998903950054 test accuracy: 0.75575\n",
      "Epoch: 36 Train loss: 0.2887170845766862 test accuracy: 0.76225\n",
      "Epoch: 37 Train loss: 0.28879920532306036 test accuracy: 0.77\n",
      "Epoch: 38 Train loss: 0.27594878658652305 test accuracy: 0.769\n",
      "Epoch: 39 Train loss: 0.2756043996910254 test accuracy: 0.76075\n",
      "Epoch: 40 Train loss: 0.2673705121378104 test accuracy: 0.76225\n",
      "Epoch: 41 Train loss: 0.2641733480989933 test accuracy: 0.7635\n",
      "Epoch: 42 Train loss: 0.2531209337711334 test accuracy: 0.76925\n",
      "Epoch: 43 Train loss: 0.2527250290910403 test accuracy: 0.76375\n",
      "Epoch: 44 Train loss: 0.24528759494423866 test accuracy: 0.75775\n",
      "Epoch: 45 Train loss: 0.24443629538019498 test accuracy: 0.76\n",
      "Epoch: 46 Train loss: 0.24149626143276692 test accuracy: 0.7695\n",
      "Epoch: 47 Train loss: 0.23877592518925667 test accuracy: 0.7725\n",
      "Epoch: 48 Train loss: 0.2311485766371091 test accuracy: 0.765\n",
      "Epoch: 49 Train loss: 0.22662346050143242 test accuracy: 0.7655\n",
      "Epoch: 50 Train loss: 0.22495710951586564 test accuracy: 0.76725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7725"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1)),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomVerticalFlip(),\n",
    "                                    transforms.ColorJitter(.1,.1,.1,.1)                                 \n",
    "                                    ]),transforms.ToTensor()])\n",
    "                                   \n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.5929689224561054 test accuracy: 0.54425\n",
      "Epoch: 2 Train loss: 1.2554393935203552 test accuracy: 0.613\n",
      "Epoch: 3 Train loss: 1.123969785173734 test accuracy: 0.6505\n",
      "Epoch: 4 Train loss: 1.0410797135035197 test accuracy: 0.65825\n",
      "Epoch: 5 Train loss: 0.9682439255714417 test accuracy: 0.67375\n",
      "Epoch: 6 Train loss: 0.9148829694588979 test accuracy: 0.685\n",
      "Epoch: 7 Train loss: 0.8623027755816778 test accuracy: 0.701\n",
      "Epoch: 8 Train loss: 0.8159777208169301 test accuracy: 0.7115\n",
      "Epoch: 9 Train loss: 0.7798100165526072 test accuracy: 0.72325\n",
      "Epoch: 10 Train loss: 0.7434915312131246 test accuracy: 0.716\n",
      "Epoch: 11 Train loss: 0.7095279332002004 test accuracy: 0.72425\n",
      "Epoch: 12 Train loss: 0.6824593282739322 test accuracy: 0.73325\n",
      "Epoch: 13 Train loss: 0.650688408811887 test accuracy: 0.7365\n",
      "Epoch: 14 Train loss: 0.6271319509545962 test accuracy: 0.74\n",
      "Epoch: 15 Train loss: 0.6005726822217305 test accuracy: 0.74475\n",
      "Epoch: 16 Train loss: 0.5780155084530513 test accuracy: 0.749\n",
      "Epoch: 17 Train loss: 0.5530281021197637 test accuracy: 0.752\n",
      "Epoch: 18 Train loss: 0.5396789986888567 test accuracy: 0.7555\n",
      "Epoch: 19 Train loss: 0.5197935388485591 test accuracy: 0.75325\n",
      "Epoch: 20 Train loss: 0.5016792778174083 test accuracy: 0.758\n",
      "Epoch: 21 Train loss: 0.48812019199132917 test accuracy: 0.749\n",
      "Epoch: 22 Train loss: 0.4736470819513003 test accuracy: 0.7575\n",
      "Epoch: 23 Train loss: 0.4569233499964078 test accuracy: 0.76975\n",
      "Epoch: 24 Train loss: 0.4384364141027133 test accuracy: 0.7565\n",
      "Epoch: 25 Train loss: 0.4305115847786268 test accuracy: 0.761\n",
      "Epoch: 26 Train loss: 0.4157239011923472 test accuracy: 0.7635\n",
      "Epoch: 27 Train loss: 0.4017044665416082 test accuracy: 0.75225\n",
      "Epoch: 28 Train loss: 0.38750617737571397 test accuracy: 0.75775\n",
      "Epoch: 29 Train loss: 0.3800307414929072 test accuracy: 0.764\n",
      "Epoch: 30 Train loss: 0.3732835415502389 test accuracy: 0.7655\n",
      "Epoch: 31 Train loss: 0.35873142098387084 test accuracy: 0.76625\n",
      "Epoch: 32 Train loss: 0.35032700980703035 test accuracy: 0.76\n",
      "Epoch: 33 Train loss: 0.3454004961252213 test accuracy: 0.76825\n",
      "Epoch: 34 Train loss: 0.33809678321083386 test accuracy: 0.761\n",
      "Epoch: 35 Train loss: 0.32949098298947016 test accuracy: 0.77025\n",
      "Epoch: 36 Train loss: 0.3208791187902292 test accuracy: 0.7535\n",
      "Epoch: 37 Train loss: 0.3128597382207712 test accuracy: 0.763\n",
      "Epoch: 38 Train loss: 0.30525653103987377 test accuracy: 0.766\n",
      "Epoch: 39 Train loss: 0.30455032060543696 test accuracy: 0.77225\n",
      "Epoch: 40 Train loss: 0.29986662819981574 test accuracy: 0.76175\n",
      "Epoch: 41 Train loss: 0.29375730444987613 test accuracy: 0.77125\n",
      "Epoch: 42 Train loss: 0.28395482927560806 test accuracy: 0.77\n",
      "Epoch: 43 Train loss: 0.27838409463564556 test accuracy: 0.76375\n",
      "Epoch: 44 Train loss: 0.2788667612274488 test accuracy: 0.76325\n",
      "Epoch: 45 Train loss: 0.26999594524502757 test accuracy: 0.76025\n",
      "Epoch: 46 Train loss: 0.26387975687781967 test accuracy: 0.777\n",
      "Epoch: 47 Train loss: 0.26352826625108716 test accuracy: 0.7655\n",
      "Epoch: 48 Train loss: 0.26138186586399875 test accuracy: 0.76875\n",
      "Epoch: 49 Train loss: 0.24904391234119733 test accuracy: 0.7725\n",
      "Epoch: 50 Train loss: 0.2501558742423852 test accuracy: 0.763\n",
      "Epoch: 51 Train loss: 0.24597210178772608 test accuracy: 0.777\n",
      "Epoch: 52 Train loss: 0.23792276551326116 test accuracy: 0.772\n",
      "Epoch: 53 Train loss: 0.23456087544560433 test accuracy: 0.76875\n",
      "Epoch: 54 Train loss: 0.23859051555395128 test accuracy: 0.7765\n",
      "Epoch: 55 Train loss: 0.2322018020351728 test accuracy: 0.769\n",
      "Epoch: 56 Train loss: 0.2253300326814254 test accuracy: 0.778\n",
      "Epoch: 57 Train loss: 0.22178866853316626 test accuracy: 0.76375\n",
      "Epoch: 58 Train loss: 0.21811209090054035 test accuracy: 0.772\n",
      "Epoch: 59 Train loss: 0.2150035434216261 test accuracy: 0.7775\n",
      "Epoch: 60 Train loss: 0.21740099002917607 test accuracy: 0.77625\n",
      "Epoch: 61 Train loss: 0.21106421063343683 test accuracy: 0.78325\n",
      "Epoch: 62 Train loss: 0.20694713460902373 test accuracy: 0.77125\n",
      "Epoch: 63 Train loss: 0.20641870312392713 test accuracy: 0.77425\n",
      "Epoch: 64 Train loss: 0.2016415263712406 test accuracy: 0.78475\n",
      "Epoch: 65 Train loss: 0.20550452304383118 test accuracy: 0.78275\n",
      "Epoch: 66 Train loss: 0.1970103454341491 test accuracy: 0.77325\n",
      "Epoch: 67 Train loss: 0.1910721492022276 test accuracy: 0.77775\n",
      "Epoch: 68 Train loss: 0.19182025435070196 test accuracy: 0.776\n",
      "Epoch: 69 Train loss: 0.1916351171086232 test accuracy: 0.77975\n",
      "Epoch: 70 Train loss: 0.18767285779118537 test accuracy: 0.78625\n",
      "Epoch: 71 Train loss: 0.18243139157692592 test accuracy: 0.77825\n",
      "Epoch: 72 Train loss: 0.18177604717512927 test accuracy: 0.79125\n",
      "Epoch: 73 Train loss: 0.17876369083921115 test accuracy: 0.78375\n",
      "Epoch: 74 Train loss: 0.17461360335350037 test accuracy: 0.7775\n",
      "Epoch: 75 Train loss: 0.17136067440112432 test accuracy: 0.77725\n",
      "Epoch: 76 Train loss: 0.174388427734375 test accuracy: 0.76925\n",
      "Epoch: 77 Train loss: 0.1682666006932656 test accuracy: 0.7765\n",
      "Epoch: 78 Train loss: 0.16398331264654795 test accuracy: 0.782\n",
      "Epoch: 79 Train loss: 0.1644297031313181 test accuracy: 0.779\n",
      "Epoch: 80 Train loss: 0.16626390469570954 test accuracy: 0.77625\n",
      "Epoch: 81 Train loss: 0.16277635589241982 test accuracy: 0.77\n",
      "Epoch: 82 Train loss: 0.15724480157097181 test accuracy: 0.78075\n",
      "Epoch: 83 Train loss: 0.1577413340906302 test accuracy: 0.77375\n",
      "Epoch: 84 Train loss: 0.15607992416868607 test accuracy: 0.77725\n",
      "Epoch: 85 Train loss: 0.15485094105203948 test accuracy: 0.7845\n",
      "Epoch: 86 Train loss: 0.15257561969260375 test accuracy: 0.78425\n",
      "Epoch: 87 Train loss: 0.15297046647717555 test accuracy: 0.79725\n",
      "Epoch: 88 Train loss: 0.1506007067114115 test accuracy: 0.788\n",
      "Epoch: 89 Train loss: 0.14967256483932337 test accuracy: 0.7775\n",
      "Epoch: 90 Train loss: 0.1489239671329657 test accuracy: 0.7865\n",
      "Epoch: 91 Train loss: 0.14424971900880337 test accuracy: 0.7835\n",
      "Epoch: 92 Train loss: 0.1404366519053777 test accuracy: 0.7775\n",
      "Epoch: 93 Train loss: 0.1409926087036729 test accuracy: 0.785\n",
      "Epoch: 94 Train loss: 0.14182989963640769 test accuracy: 0.77625\n",
      "Epoch: 95 Train loss: 0.14081028098861376 test accuracy: 0.78075\n",
      "Epoch: 96 Train loss: 0.13703662811468045 test accuracy: 0.7805\n",
      "Epoch: 97 Train loss: 0.13358035791665315 test accuracy: 0.78875\n",
      "Epoch: 98 Train loss: 0.1326709023738901 test accuracy: 0.783\n",
      "Epoch: 99 Train loss: 0.1338734241699179 test accuracy: 0.79\n",
      "Epoch: 100 Train loss: 0.13309966233869394 test accuracy: 0.78625\n",
      "Epoch: 101 Train loss: 0.13039692475150028 test accuracy: 0.7855\n",
      "Epoch: 102 Train loss: 0.1283372522890568 test accuracy: 0.79075\n",
      "Epoch: 103 Train loss: 0.12450710233300924 test accuracy: 0.79825\n",
      "Epoch: 104 Train loss: 0.12360801223665475 test accuracy: 0.793\n",
      "Epoch: 105 Train loss: 0.12731215488165618 test accuracy: 0.7895\n",
      "Epoch: 106 Train loss: 0.12218078589687745 test accuracy: 0.78825\n",
      "Epoch: 107 Train loss: 0.11746871267134945 test accuracy: 0.783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79825"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1)),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomVerticalFlip(),\n",
    "                                    transforms.ColorJitter(.1,.1,.1,.1)                                 \n",
    "                                    ]),transforms.ToTensor()])\n",
    "                                   \n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.6212873129049936 test accuracy: 0.55375\n",
      "Epoch: 2 Train loss: 1.276105173031489 test accuracy: 0.6045\n",
      "Epoch: 3 Train loss: 1.1363818037509918 test accuracy: 0.6365\n",
      "Epoch: 4 Train loss: 1.0496725988388063 test accuracy: 0.65725\n",
      "Epoch: 5 Train loss: 0.9742652634779613 test accuracy: 0.669\n",
      "Epoch: 6 Train loss: 0.9137145392100017 test accuracy: 0.6835\n",
      "Epoch: 7 Train loss: 0.8609927533070246 test accuracy: 0.69\n",
      "Epoch: 8 Train loss: 0.8135087770223618 test accuracy: 0.69275\n",
      "Epoch: 9 Train loss: 0.7656823732455571 test accuracy: 0.7005\n",
      "Epoch: 10 Train loss: 0.7250172120332717 test accuracy: 0.71475\n",
      "Epoch: 11 Train loss: 0.6880072471499443 test accuracy: 0.71875\n",
      "Epoch: 12 Train loss: 0.6498067251841227 test accuracy: 0.72175\n",
      "Epoch: 13 Train loss: 0.6158524353305499 test accuracy: 0.71725\n",
      "Epoch: 14 Train loss: 0.5806658943494161 test accuracy: 0.72575\n",
      "Epoch: 15 Train loss: 0.5561448423067729 test accuracy: 0.72925\n",
      "Epoch: 16 Train loss: 0.5301192142566045 test accuracy: 0.725\n",
      "Epoch: 17 Train loss: 0.5048916883269946 test accuracy: 0.72225\n",
      "Epoch: 18 Train loss: 0.4830243876576424 test accuracy: 0.72525\n",
      "Epoch: 19 Train loss: 0.46434594223896664 test accuracy: 0.71975\n",
      "Epoch: 20 Train loss: 0.44774675418933235 test accuracy: 0.73175\n",
      "Epoch: 21 Train loss: 0.43107530097166696 test accuracy: 0.73225\n",
      "Epoch: 22 Train loss: 0.4106360141436259 test accuracy: 0.73\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.2518920.pbshpc/ipykernel_9948/2657105861.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.2518920.pbshpc/ipykernel_9948/3800871613.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cnn, train_data, epochs, opt, loss, test_data, n, b, t)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m#print(X.shape,y.shape,type(X),type(y))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0myh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),                               \n",
    "                                    transforms.ToTensor(),\n",
    "                                   transforms.RandomErasing()])\n",
    "                                   \n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.4436044430732726 test accuracy: 0.57625\n",
      "Epoch: 2 Train loss: 1.0514435815811156 test accuracy: 0.646\n",
      "Epoch: 3 Train loss: 0.8785825900236766 test accuracy: 0.66975\n",
      "Epoch: 4 Train loss: 0.7514605957269669 test accuracy: 0.68175\n",
      "Epoch: 5 Train loss: 0.6383389148116112 test accuracy: 0.6965\n",
      "Epoch: 6 Train loss: 0.5340346145629883 test accuracy: 0.6995\n",
      "Epoch: 7 Train loss: 0.44014868130286533 test accuracy: 0.7015\n",
      "Epoch: 8 Train loss: 0.36341391732295353 test accuracy: 0.70875\n",
      "Epoch: 9 Train loss: 0.29465453694264093 test accuracy: 0.706\n",
      "Epoch: 10 Train loss: 0.2490854666630427 test accuracy: 0.70425\n",
      "Epoch: 11 Train loss: 0.2282127759108941 test accuracy: 0.68675\n",
      "Epoch: 12 Train loss: 0.20369748259584108 test accuracy: 0.69275\n",
      "Epoch: 13 Train loss: 0.17512628967563312 test accuracy: 0.70525\n",
      "Epoch: 14 Train loss: 0.15597077531119188 test accuracy: 0.68975\n",
      "Epoch: 15 Train loss: 0.14458562755336365 test accuracy: 0.67725\n",
      "Epoch: 16 Train loss: 0.14603340795884528 test accuracy: 0.6735\n",
      "Epoch: 17 Train loss: 0.11892949347694715 test accuracy: 0.69\n",
      "Epoch: 18 Train loss: 0.09341498345757525 test accuracy: 0.70875\n",
      "Epoch: 19 Train loss: 0.06790749341870347 test accuracy: 0.69475\n",
      "Epoch: 20 Train loss: 0.06035675103465716 test accuracy: 0.68925\n",
      "Epoch: 21 Train loss: 0.06310161715373397 test accuracy: 0.71025\n",
      "Epoch: 22 Train loss: 0.06380069268246492 test accuracy: 0.7005\n",
      "Epoch: 23 Train loss: 0.06081226559045414 test accuracy: 0.70025\n",
      "Epoch: 24 Train loss: 0.046661494825966654 test accuracy: 0.69325\n",
      "Epoch: 25 Train loss: 0.032002319182890156 test accuracy: 0.684\n",
      "Epoch: 26 Train loss: 0.023516458738595248 test accuracy: 0.693\n",
      "Epoch: 27 Train loss: 0.023263916827272624 test accuracy: 0.6825\n",
      "Epoch: 28 Train loss: 0.020221190709465493 test accuracy: 0.708\n",
      "Epoch: 29 Train loss: 0.020164521150290965 test accuracy: 0.7115\n",
      "Epoch: 30 Train loss: 0.01901802549061055 test accuracy: 0.7145\n",
      "Epoch: 31 Train loss: 0.020586838168868173 test accuracy: 0.6995\n",
      "Epoch: 32 Train loss: 0.02346612811554223 test accuracy: 0.7085\n",
      "Epoch: 33 Train loss: 0.023048659610406808 test accuracy: 0.6995\n",
      "Epoch: 34 Train loss: 0.023221694035455584 test accuracy: 0.70775\n",
      "Epoch: 35 Train loss: 0.025661841020919382 test accuracy: 0.7025\n",
      "Epoch: 36 Train loss: 0.022820999076745164 test accuracy: 0.70425\n",
      "Epoch: 37 Train loss: 0.025111104022168245 test accuracy: 0.69775\n",
      "Epoch: 38 Train loss: 0.024696446269905817 test accuracy: 0.711\n",
      "Epoch: 39 Train loss: 0.023019932181729624 test accuracy: 0.7055\n",
      "Epoch: 40 Train loss: 0.02217743534129113 test accuracy: 0.711\n",
      "Epoch: 41 Train loss: 0.018274752642416084 test accuracy: 0.69875\n",
      "Epoch: 42 Train loss: 0.0166869698119505 test accuracy: 0.70525\n",
      "Epoch: 43 Train loss: 0.018442473320756107 test accuracy: 0.7045\n",
      "Epoch: 44 Train loss: 0.01278475468532027 test accuracy: 0.72325\n",
      "Epoch: 45 Train loss: 0.016349671403877438 test accuracy: 0.708\n",
      "Epoch: 46 Train loss: 0.02355021595295208 test accuracy: 0.70975\n",
      "Epoch: 47 Train loss: 0.018839135429783105 test accuracy: 0.7105\n",
      "Epoch: 48 Train loss: 0.01527420684423608 test accuracy: 0.69675\n",
      "Epoch: 49 Train loss: 0.021148589736937236 test accuracy: 0.7075\n",
      "Epoch: 50 Train loss: 0.012901252762336906 test accuracy: 0.70975\n",
      "Epoch: 51 Train loss: 0.015507274330205595 test accuracy: 0.719\n",
      "Epoch: 52 Train loss: 0.013384025316530218 test accuracy: 0.70675\n",
      "Epoch: 53 Train loss: 0.021227555391378702 test accuracy: 0.71175\n",
      "Epoch: 54 Train loss: 0.012848824575000133 test accuracy: 0.72\n",
      "Epoch: 55 Train loss: 0.016843258040995956 test accuracy: 0.71025\n",
      "Epoch: 56 Train loss: 0.014764093826330888 test accuracy: 0.70975\n",
      "Epoch: 57 Train loss: 0.01743120620919702 test accuracy: 0.7155\n",
      "Epoch: 58 Train loss: 0.013716377715269724 test accuracy: 0.718\n",
      "Epoch: 59 Train loss: 0.016874831281990434 test accuracy: 0.71525\n",
      "Epoch: 60 Train loss: 0.009857632056664442 test accuracy: 0.703\n",
      "Epoch: 61 Train loss: 0.016600940188315386 test accuracy: 0.725\n",
      "Epoch: 62 Train loss: 0.011858052318372453 test accuracy: 0.70275\n",
      "Epoch: 63 Train loss: 0.012102929759324373 test accuracy: 0.70725\n",
      "Epoch: 64 Train loss: 0.015147591421943314 test accuracy: 0.7165\n",
      "Epoch: 65 Train loss: 0.011735558534564917 test accuracy: 0.71325\n",
      "Epoch: 66 Train loss: 0.016575547126994935 test accuracy: 0.6885\n",
      "Epoch: 67 Train loss: 0.013147068447433413 test accuracy: 0.7035\n",
      "Epoch: 68 Train loss: 0.011390382799969909 test accuracy: 0.712\n",
      "Epoch: 69 Train loss: 0.012162966870140129 test accuracy: 0.72175\n",
      "Epoch: 70 Train loss: 0.012924322108253061 test accuracy: 0.717\n",
      "Epoch: 71 Train loss: 0.01623675580485724 test accuracy: 0.71675\n",
      "Epoch: 72 Train loss: 0.012286993445207676 test accuracy: 0.711\n",
      "Epoch: 73 Train loss: 0.007831321204042372 test accuracy: 0.718\n",
      "Epoch: 74 Train loss: 0.01399783988124303 test accuracy: 0.711\n",
      "Epoch: 75 Train loss: 0.00935869086223344 test accuracy: 0.72125\n",
      "Epoch: 76 Train loss: 0.013936137988542516 test accuracy: 0.708\n",
      "Epoch: 77 Train loss: 0.011740209653895968 test accuracy: 0.71325\n",
      "Epoch: 78 Train loss: 0.01680827133609758 test accuracy: 0.71475\n",
      "Epoch: 79 Train loss: 0.010158030182259001 test accuracy: 0.715\n",
      "Epoch: 80 Train loss: 0.009099192318002073 test accuracy: 0.72275\n",
      "Epoch: 81 Train loss: 0.010136184021636534 test accuracy: 0.70875\n",
      "Epoch: 82 Train loss: 0.01576870954440286 test accuracy: 0.715\n",
      "Epoch: 83 Train loss: 0.008187367217906284 test accuracy: 0.72025\n",
      "Epoch: 84 Train loss: 0.010578272695759854 test accuracy: 0.712\n",
      "Epoch: 85 Train loss: 0.009220663719315781 test accuracy: 0.7135\n",
      "Epoch: 86 Train loss: 0.01075107232638402 test accuracy: 0.709\n",
      "Epoch: 87 Train loss: 0.01592675887339283 test accuracy: 0.712\n",
      "Epoch: 88 Train loss: 0.007626358159565522 test accuracy: 0.70125\n",
      "Epoch: 89 Train loss: 0.008273001437701169 test accuracy: 0.706\n",
      "Epoch: 90 Train loss: 0.01027621241810266 test accuracy: 0.716\n",
      "Epoch: 91 Train loss: 0.008087280792872964 test accuracy: 0.7225\n",
      "Epoch: 92 Train loss: 0.012241109201774332 test accuracy: 0.71075\n",
      "Epoch: 93 Train loss: 0.012453935047378763 test accuracy: 0.71725\n",
      "Epoch: 94 Train loss: 0.012031217992140833 test accuracy: 0.71925\n",
      "Epoch: 95 Train loss: 0.009367126363116162 test accuracy: 0.70775\n",
      "Epoch: 96 Train loss: 0.009209445558711499 test accuracy: 0.7195\n",
      "Epoch: 97 Train loss: 0.005108289321991227 test accuracy: 0.72175\n",
      "Epoch: 98 Train loss: 0.016643828593369107 test accuracy: 0.705\n",
      "Epoch: 99 Train loss: 0.012777947543751604 test accuracy: 0.722\n",
      "Epoch: 100 Train loss: 0.006487860721390462 test accuracy: 0.72575\n",
      "Epoch: 101 Train loss: 0.0029641247898568204 test accuracy: 0.7325\n",
      "Epoch: 102 Train loss: 0.009027109350269407 test accuracy: 0.71725\n",
      "Epoch: 103 Train loss: 0.011499827043783929 test accuracy: 0.72675\n",
      "Epoch: 104 Train loss: 0.011416545509224912 test accuracy: 0.71675\n",
      "Epoch: 105 Train loss: 0.008524156625790057 test accuracy: 0.7145\n",
      "Epoch: 106 Train loss: 0.008144123592307248 test accuracy: 0.7165\n",
      "Epoch: 107 Train loss: 0.01073850932099352 test accuracy: 0.7165\n",
      "Epoch: 108 Train loss: 0.00860637311100921 test accuracy: 0.7205\n",
      "Epoch: 109 Train loss: 0.004199069291207707 test accuracy: 0.721\n",
      "Epoch: 110 Train loss: 0.014712940827254594 test accuracy: 0.71925\n",
      "Epoch: 111 Train loss: 0.0052422740826538455 test accuracy: 0.7225\n",
      "Epoch: 112 Train loss: 0.00926106954284478 test accuracy: 0.72025\n",
      "Epoch: 113 Train loss: 0.008004170408360854 test accuracy: 0.70825\n",
      "Epoch: 114 Train loss: 0.00990025162594975 test accuracy: 0.7135\n",
      "Epoch: 115 Train loss: 0.012810251397604588 test accuracy: 0.7255\n",
      "Epoch: 116 Train loss: 0.00478383451103582 test accuracy: 0.71325\n",
      "Epoch: 117 Train loss: 0.009855112297082087 test accuracy: 0.7145\n",
      "Epoch: 118 Train loss: 0.0054765492955872715 test accuracy: 0.70525\n",
      "Epoch: 119 Train loss: 0.009535677116534013 test accuracy: 0.709\n",
      "Epoch: 120 Train loss: 0.01119623810397267 test accuracy: 0.721\n",
      "Epoch: 121 Train loss: 0.00950732542154583 test accuracy: 0.71075\n",
      "Epoch: 122 Train loss: 0.007544181621148407 test accuracy: 0.71325\n",
      "Epoch: 123 Train loss: 0.0034971648059278476 test accuracy: 0.714\n",
      "Epoch: 124 Train loss: 0.011784692934112778 test accuracy: 0.718\n",
      "Epoch: 125 Train loss: 0.004782406834322804 test accuracy: 0.714\n",
      "Epoch: 126 Train loss: 0.010120904939588702 test accuracy: 0.7065\n",
      "Epoch: 127 Train loss: 0.005172614435647726 test accuracy: 0.7145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 128 Train loss: 0.005736733756105726 test accuracy: 0.71625\n",
      "Epoch: 129 Train loss: 0.00975758524495177 test accuracy: 0.70875\n",
      "Epoch: 130 Train loss: 0.009537823773061973 test accuracy: 0.7175\n",
      "Epoch: 131 Train loss: 0.0068125844928241955 test accuracy: 0.71425\n",
      "Epoch: 132 Train loss: 0.005549084893524802 test accuracy: 0.72775\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.2518920.pbshpc/ipykernel_9948/1957627520.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.2518920.pbshpc/ipykernel_9948/3800871613.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cnn, train_data, epochs, opt, loss, test_data, n, b, t)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m#print(X.shape,y.shape,type(X),type(y))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),                               \n",
    "                                    transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0,0,0],[1,1,1])])\n",
    "                                   \n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.4977054437001547 test accuracy: 0.5695 time: 39.48702073097229\n",
      "Epoch: 2 Train loss: 1.1493236392736434 test accuracy: 0.626 time: 69.10966348648071\n",
      "Epoch: 3 Train loss: 1.0201028162240982 test accuracy: 0.65225 time: 99.20093297958374\n",
      "Epoch: 4 Train loss: 0.9305745544036229 test accuracy: 0.68575 time: 128.66833186149597\n",
      "Epoch: 5 Train loss: 0.8596844871838888 test accuracy: 0.69675 time: 158.15997433662415\n",
      "Epoch: 6 Train loss: 0.8037485049168269 test accuracy: 0.70825 time: 187.59843587875366\n",
      "Epoch: 7 Train loss: 0.7520570824543635 test accuracy: 0.72075 time: 217.714768409729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2b81414f7670>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Train loss: 0.7055864204963048 test accuracy: 0.72225 time: 247.51780319213867\n",
      "Epoch: 9 Train loss: 0.6648671241601308 test accuracy: 0.73775 time: 276.98492217063904\n",
      "Epoch: 10 Train loss: 0.6253752627968788 test accuracy: 0.73675 time: 306.3425147533417\n",
      "Epoch: 11 Train loss: 0.59093371540308 test accuracy: 0.73325 time: 336.36740946769714\n",
      "Epoch: 12 Train loss: 0.5620168121655782 test accuracy: 0.73325 time: 365.8326325416565\n",
      "Epoch: 13 Train loss: 0.5299008946617444 test accuracy: 0.74525 time: 395.2275421619415\n",
      "Epoch: 14 Train loss: 0.5075177260239919 test accuracy: 0.752 time: 424.61577105522156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2b81414f7670>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 Train loss: 0.48219981412092844 test accuracy: 0.74125 time: 454.68247985839844\n",
      "Epoch: 16 Train loss: 0.461693067351977 test accuracy: 0.751 time: 484.06590723991394\n",
      "Epoch: 17 Train loss: 0.43711158325274785 test accuracy: 0.74875 time: 513.4575991630554\n",
      "Epoch: 18 Train loss: 0.42032947182655334 test accuracy: 0.7645 time: 542.807816028595\n",
      "Epoch: 19 Train loss: 0.4019600468873978 test accuracy: 0.74675 time: 572.9186623096466\n",
      "Epoch: 20 Train loss: 0.3819040235877037 test accuracy: 0.75525 time: 602.3002190589905\n",
      "Epoch: 21 Train loss: 0.369445996483167 test accuracy: 0.75725 time: 631.6757373809814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2b81414f7670>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 Train loss: 0.359738820840915 test accuracy: 0.7575 time: 661.1725993156433\n",
      "Epoch: 23 Train loss: 0.3422026188671589 test accuracy: 0.761 time: 691.1375470161438\n",
      "Epoch: 24 Train loss: 0.32834473441044487 test accuracy: 0.764 time: 720.5332174301147\n",
      "Epoch: 25 Train loss: 0.31725414857268336 test accuracy: 0.7615 time: 749.9365403652191\n",
      "Epoch: 26 Train loss: 0.30416385864218076 test accuracy: 0.7745 time: 779.3349084854126\n",
      "Epoch: 27 Train loss: 0.2938410727183024 test accuracy: 0.77025 time: 809.4435024261475\n",
      "Epoch: 28 Train loss: 0.2845648516714573 test accuracy: 0.76825 time: 838.8449602127075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2b81414f7670>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 Train loss: 0.27835203369458517 test accuracy: 0.76825 time: 868.3051354885101\n",
      "Epoch: 30 Train loss: 0.2635517611106237 test accuracy: 0.77 time: 897.6907787322998\n",
      "Epoch: 31 Train loss: 0.25718472530444464 test accuracy: 0.768 time: 927.7054481506348\n",
      "Epoch: 32 Train loss: 0.24996719732880593 test accuracy: 0.77775 time: 957.0389401912689\n",
      "Epoch: 33 Train loss: 0.2430725461244583 test accuracy: 0.772 time: 986.3521220684052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2b81414f7670>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 Train loss: 0.23461695849895478 test accuracy: 0.77425 time: 1015.8334991931915\n",
      "Epoch: 35 Train loss: 0.22713217129309973 test accuracy: 0.76625 time: 1045.9588844776154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2b81414f7670>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 Train loss: 0.21865922515590985 test accuracy: 0.768 time: 1075.4611268043518\n",
      "Epoch: 37 Train loss: 0.21217367311318716 test accuracy: 0.77225 time: 1104.8783602714539\n",
      "Epoch: 38 Train loss: 0.2056362572312355 test accuracy: 0.77875 time: 1134.3158013820648\n",
      "Epoch: 39 Train loss: 0.20233263274033864 test accuracy: 0.77 time: 1164.3374316692352\n",
      "Epoch: 40 Train loss: 0.1967469949275255 test accuracy: 0.7795 time: 1193.6502017974854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2b81414f7670>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 Train loss: 0.18652439897259077 test accuracy: 0.76825 time: 1223.1346771717072\n",
      "Epoch: 42 Train loss: 0.18496758801241717 test accuracy: 0.774 time: 1252.8305118083954\n",
      "Epoch: 43 Train loss: 0.18127009128530822 test accuracy: 0.77925 time: 1282.4199666976929\n",
      "Epoch: 44 Train loss: 0.17630380099018414 test accuracy: 0.77225 time: 1312.2934219837189\n",
      "Epoch: 45 Train loss: 0.16989522335429985 test accuracy: 0.777 time: 1341.967027425766\n",
      "Epoch: 46 Train loss: 0.16602406593660513 test accuracy: 0.78225 time: 1371.7057211399078\n",
      "Epoch: 47 Train loss: 0.16304934598505497 test accuracy: 0.78125 time: 1402.042465686798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2b81414f7670>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 Train loss: 0.15998592399060726 test accuracy: 0.78425 time: 1431.8002316951752\n",
      "Epoch: 49 Train loss: 0.15581695802509785 test accuracy: 0.7905 time: 1462.1450548171997\n",
      "Epoch: 50 Train loss: 0.15232944541921217 test accuracy: 0.77625 time: 1492.0191547870636\n",
      "Epoch: 51 Train loss: 0.1493382376929124 test accuracy: 0.78225 time: 1521.7087309360504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7905"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0,0,0],[1,1,1])])                                   \n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.799192054271698 test accuracy: 0.5455 time: 50.27506685256958\n",
      "Epoch: 2 Train loss: 1.4686600840091706 test accuracy: 0.60175 time: 90.57878875732422\n",
      "Epoch: 3 Train loss: 1.3512931140263875 test accuracy: 0.63325 time: 130.949387550354\n",
      "Epoch: 4 Train loss: 1.2690032653013865 test accuracy: 0.6455 time: 172.05096077919006\n",
      "Epoch: 5 Train loss: 1.1986507628361385 test accuracy: 0.6645 time: 212.1780149936676\n",
      "Epoch: 6 Train loss: 1.1415375890334447 test accuracy: 0.674 time: 252.23282289505005\n",
      "Epoch: 7 Train loss: 1.0891870256265004 test accuracy: 0.68275 time: 292.11539030075073\n",
      "Epoch: 8 Train loss: 1.0424853853384655 test accuracy: 0.69275 time: 331.9574365615845\n",
      "Epoch: 9 Train loss: 0.9997239585717519 test accuracy: 0.7035 time: 372.3929693698883\n",
      "Epoch: 10 Train loss: 0.9605072369178136 test accuracy: 0.7185 time: 412.2611753940582\n",
      "Epoch: 11 Train loss: 0.9288392406702042 test accuracy: 0.71675 time: 451.98407912254333\n",
      "Epoch: 12 Train loss: 0.8958071718613306 test accuracy: 0.71225 time: 491.75119042396545\n",
      "Epoch: 13 Train loss: 0.8661596316099167 test accuracy: 0.72975 time: 531.5818314552307\n",
      "Epoch: 14 Train loss: 0.8410239132245382 test accuracy: 0.721 time: 571.9896857738495\n",
      "Epoch: 15 Train loss: 0.8127104789018631 test accuracy: 0.73375 time: 611.6306273937225\n",
      "Epoch: 16 Train loss: 0.7870903370777765 test accuracy: 0.73275 time: 651.3877077102661\n",
      "Epoch: 17 Train loss: 0.7707255180676779 test accuracy: 0.7385 time: 691.0478420257568\n",
      "Epoch: 18 Train loss: 0.7436475382248561 test accuracy: 0.7285 time: 730.6619911193848\n",
      "Epoch: 19 Train loss: 0.7289550236860911 test accuracy: 0.74075 time: 771.0077233314514\n",
      "Epoch: 20 Train loss: 0.7005969893932342 test accuracy: 0.7345 time: 810.6796214580536\n",
      "Epoch: 21 Train loss: 0.6821284076571464 test accuracy: 0.737 time: 850.3116528987885\n",
      "Epoch: 22 Train loss: 0.6650115473071734 test accuracy: 0.738 time: 890.0028493404388\n",
      "Epoch: 23 Train loss: 0.6478775907556216 test accuracy: 0.74075 time: 929.6693217754364\n",
      "Epoch: 24 Train loss: 0.6367796877026558 test accuracy: 0.73675 time: 970.0059461593628\n",
      "Epoch: 25 Train loss: 0.62238997032245 test accuracy: 0.7465 time: 1009.6410584449768\n",
      "Epoch: 26 Train loss: 0.6001487676302592 test accuracy: 0.7485 time: 1049.2484056949615\n",
      "Epoch: 27 Train loss: 0.5965197559197744 test accuracy: 0.75225 time: 1088.806811094284\n",
      "Epoch: 28 Train loss: 0.5823026413718859 test accuracy: 0.74325 time: 1128.447163105011\n",
      "Epoch: 29 Train loss: 0.5713558379809062 test accuracy: 0.744 time: 1168.5513706207275\n",
      "Epoch: 30 Train loss: 0.5546187975009282 test accuracy: 0.74025 time: 1208.1972761154175\n",
      "Epoch: 31 Train loss: 0.541381397942702 test accuracy: 0.7555 time: 1247.830620765686\n",
      "Epoch: 32 Train loss: 0.5314986515045166 test accuracy: 0.74975 time: 1287.4185950756073\n",
      "Epoch: 33 Train loss: 0.5146963545680046 test accuracy: 0.7395 time: 1326.9719977378845\n",
      "Epoch: 34 Train loss: 0.5137380590041478 test accuracy: 0.749 time: 1367.1967124938965\n",
      "Epoch: 35 Train loss: 0.5086894676089286 test accuracy: 0.74575 time: 1406.7812304496765\n",
      "Epoch: 36 Train loss: 0.4973547365268072 test accuracy: 0.7535 time: 1446.356154680252\n",
      "Epoch: 37 Train loss: 0.48573908229668933 test accuracy: 0.74125 time: 1485.8739216327667\n",
      "Epoch: 38 Train loss: 0.4831766336162885 test accuracy: 0.744 time: 1525.4983463287354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7555"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.AutoAugment(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0,0,0],[1,1,1])])                                   \n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.540492668946584 test accuracy: 0.55775 time: 58.081937313079834\n",
      "Epoch: 2 Train loss: 1.2067346048355103 test accuracy: 0.63375 time: 105.57040882110596\n",
      "Epoch: 3 Train loss: 1.082468300461769 test accuracy: 0.65975 time: 153.61708569526672\n",
      "Epoch: 4 Train loss: 1.004332132935524 test accuracy: 0.6785 time: 200.97578024864197\n",
      "Epoch: 5 Train loss: 0.9337979080279668 test accuracy: 0.70575 time: 248.31539392471313\n",
      "Epoch: 6 Train loss: 0.8827671507994334 test accuracy: 0.71075 time: 295.73346185684204\n",
      "Epoch: 7 Train loss: 0.8431127611796061 test accuracy: 0.708 time: 343.0912494659424\n",
      "Epoch: 8 Train loss: 0.7996239743630091 test accuracy: 0.71675 time: 391.1371202468872\n",
      "Epoch: 9 Train loss: 0.7666138780117034 test accuracy: 0.72875 time: 438.4712197780609\n",
      "Epoch: 10 Train loss: 0.7345975397030512 test accuracy: 0.73625 time: 485.7498619556427\n",
      "Epoch: 11 Train loss: 0.702104351023833 test accuracy: 0.73975 time: 532.8762364387512\n",
      "Epoch: 12 Train loss: 0.6802355442444483 test accuracy: 0.74525 time: 580.9763691425323\n",
      "Epoch: 13 Train loss: 0.6515232451756795 test accuracy: 0.753 time: 627.9902441501617\n",
      "Epoch: 14 Train loss: 0.6289198778072993 test accuracy: 0.7535 time: 674.9519374370575\n",
      "Epoch: 15 Train loss: 0.6040313707788786 test accuracy: 0.762 time: 721.851526260376\n",
      "Epoch: 16 Train loss: 0.5835279097159703 test accuracy: 0.7585 time: 769.3320572376251\n",
      "Epoch: 17 Train loss: 0.5688589758674304 test accuracy: 0.7705 time: 816.2335770130157\n",
      "Epoch: 18 Train loss: 0.5500881351033846 test accuracy: 0.76375 time: 863.1200053691864\n",
      "Epoch: 19 Train loss: 0.5290983429551125 test accuracy: 0.77075 time: 909.9724435806274\n",
      "Epoch: 20 Train loss: 0.5153250994284948 test accuracy: 0.7665 time: 957.5635793209076\n",
      "Epoch: 21 Train loss: 0.4962970197200775 test accuracy: 0.76675 time: 1004.4614136219025\n",
      "Epoch: 22 Train loss: 0.48148356477419535 test accuracy: 0.7835 time: 1051.4142730236053\n",
      "Epoch: 23 Train loss: 0.4669021209081014 test accuracy: 0.77425 time: 1098.341013431549\n",
      "Epoch: 24 Train loss: 0.45571798890829085 test accuracy: 0.77825 time: 1145.2847146987915\n",
      "Epoch: 25 Train loss: 0.4380186076958974 test accuracy: 0.7835 time: 1193.45903134346\n",
      "Epoch: 26 Train loss: 0.429015257358551 test accuracy: 0.7775 time: 1240.355324268341\n",
      "Epoch: 27 Train loss: 0.4104553509751956 test accuracy: 0.78175 time: 1287.1588456630707\n",
      "Epoch: 28 Train loss: 0.40268101533253986 test accuracy: 0.783 time: 1333.9617040157318\n",
      "Epoch: 29 Train loss: 0.3939326664805412 test accuracy: 0.782 time: 1382.0421707630157\n",
      "Epoch: 30 Train loss: 0.38392276123166086 test accuracy: 0.782 time: 1428.9852271080017\n",
      "Epoch: 31 Train loss: 0.3715092000365257 test accuracy: 0.7895 time: 1475.9236314296722\n",
      "Epoch: 32 Train loss: 0.3640923065940539 test accuracy: 0.78825 time: 1522.7686519622803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7895"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                   transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1)), \n",
    "                                    transforms.ColorJitter(.1,.1,0,0)                                 \n",
    "                                    ,transforms.ToTensor()])\n",
    "\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.5566804929574332 test accuracy: 0.555 time: 41.58093309402466\n",
      "Epoch: 2 Train loss: 1.217819416920344 test accuracy: 0.6115 time: 73.11767315864563\n",
      "Epoch: 3 Train loss: 1.1004086842139562 test accuracy: 0.64925 time: 104.6369514465332\n",
      "Epoch: 4 Train loss: 1.0124977497259775 test accuracy: 0.668 time: 136.2021141052246\n",
      "Epoch: 5 Train loss: 0.9550197440385818 test accuracy: 0.685 time: 167.8355269432068\n",
      "Epoch: 6 Train loss: 0.9026418370008469 test accuracy: 0.69325 time: 199.7764973640442\n",
      "Epoch: 7 Train loss: 0.8627730284134547 test accuracy: 0.70675 time: 232.44542407989502\n",
      "Epoch: 8 Train loss: 0.824023167292277 test accuracy: 0.72275 time: 264.349817276001\n",
      "Epoch: 9 Train loss: 0.786134437918663 test accuracy: 0.7195 time: 296.2857747077942\n",
      "Epoch: 10 Train loss: 0.7531578824917475 test accuracy: 0.74 time: 328.16941022872925\n",
      "Epoch: 11 Train loss: 0.724064134756724 test accuracy: 0.7395 time: 360.08136439323425\n",
      "Epoch: 12 Train loss: 0.7031170690059662 test accuracy: 0.748 time: 391.9134635925293\n",
      "Epoch: 13 Train loss: 0.671503619949023 test accuracy: 0.75025 time: 424.4344365596771\n",
      "Epoch: 14 Train loss: 0.6503587601582209 test accuracy: 0.7455 time: 456.4778356552124\n",
      "Epoch: 15 Train loss: 0.631007241209348 test accuracy: 0.758 time: 488.33893513679504\n",
      "Epoch: 16 Train loss: 0.6046838389833769 test accuracy: 0.76625 time: 520.2014343738556\n",
      "Epoch: 17 Train loss: 0.5878937492767969 test accuracy: 0.7645 time: 552.034921169281\n",
      "Epoch: 18 Train loss: 0.5724515336751937 test accuracy: 0.76675 time: 584.0063028335571\n",
      "Epoch: 19 Train loss: 0.5507836771011353 test accuracy: 0.77125 time: 616.4398453235626\n",
      "Epoch: 20 Train loss: 0.536640446682771 test accuracy: 0.76875 time: 648.2137160301208\n",
      "Epoch: 21 Train loss: 0.5213588112592697 test accuracy: 0.77675 time: 679.9210729598999\n",
      "Epoch: 22 Train loss: 0.5008350885907809 test accuracy: 0.7775 time: 711.6274201869965\n",
      "Epoch: 23 Train loss: 0.49043458531300227 test accuracy: 0.7795 time: 743.2967293262482\n",
      "Epoch: 24 Train loss: 0.47763340691725414 test accuracy: 0.78025 time: 775.1145303249359\n",
      "Epoch: 25 Train loss: 0.4671433457732201 test accuracy: 0.78075 time: 807.5265233516693\n",
      "Epoch: 26 Train loss: 0.45349401473999024 test accuracy: 0.77975 time: 839.2008683681488\n",
      "Epoch: 27 Train loss: 0.44085037529468535 test accuracy: 0.77925 time: 870.9091925621033\n",
      "Epoch: 28 Train loss: 0.42905330737431846 test accuracy: 0.78175 time: 902.4933788776398\n",
      "Epoch: 29 Train loss: 0.4183674388130506 test accuracy: 0.7835 time: 934.1414592266083\n",
      "Epoch: 30 Train loss: 0.4049161140124003 test accuracy: 0.7795 time: 965.7589194774628\n",
      "Epoch: 31 Train loss: 0.3970912591616313 test accuracy: 0.78125 time: 997.3671312332153\n",
      "Epoch: 32 Train loss: 0.38254809752106667 test accuracy: 0.78575 time: 1029.6209111213684\n",
      "Epoch: 33 Train loss: 0.37259677787621814 test accuracy: 0.782 time: 1061.209261894226\n",
      "Epoch: 34 Train loss: 0.3611465820670128 test accuracy: 0.7875 time: 1092.821753025055\n",
      "Epoch: 35 Train loss: 0.35231587405006093 test accuracy: 0.78375 time: 1124.4538660049438\n",
      "Epoch: 36 Train loss: 0.34322439874211946 test accuracy: 0.78225 time: 1156.0475342273712\n",
      "Epoch: 37 Train loss: 0.343162791877985 test accuracy: 0.78375 time: 1187.677083492279\n",
      "Epoch: 38 Train loss: 0.32661838655670483 test accuracy: 0.7905 time: 1219.8819057941437\n",
      "Epoch: 39 Train loss: 0.31956036791205406 test accuracy: 0.79 time: 1251.5029788017273\n",
      "Epoch: 40 Train loss: 0.3121814865370591 test accuracy: 0.79425 time: 1283.0654363632202\n",
      "Epoch: 41 Train loss: 0.3024636582036813 test accuracy: 0.78875 time: 1314.6485846042633\n",
      "Epoch: 42 Train loss: 0.2971893737713496 test accuracy: 0.78625 time: 1346.2269945144653\n",
      "Epoch: 43 Train loss: 0.29211361656586327 test accuracy: 0.78525 time: 1377.8181841373444\n",
      "Epoch: 44 Train loss: 0.2826972006758054 test accuracy: 0.783 time: 1410.0471601486206\n",
      "Epoch: 45 Train loss: 0.2769771755735079 test accuracy: 0.78725 time: 1441.5785336494446\n",
      "Epoch: 46 Train loss: 0.2702028892934322 test accuracy: 0.787 time: 1473.1393749713898\n",
      "Epoch: 47 Train loss: 0.2626665350298087 test accuracy: 0.7905 time: 1504.7027416229248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79425"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                   transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1)), \n",
    "                                    transforms.RandomGrayscale(.05)\n",
    "                                    ,transforms.ToTensor()])\n",
    "\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.5577394604682921 test accuracy: 0.53225 time: 62.971163511276245\n",
      "Epoch: 2 Train loss: 1.2461743927001954 test accuracy: 0.57975 time: 115.99799752235413\n",
      "Epoch: 3 Train loss: 1.1061289032300314 test accuracy: 0.60125 time: 169.1418273448944\n",
      "Epoch: 4 Train loss: 1.0034367501735688 test accuracy: 0.6215 time: 222.73021960258484\n",
      "Epoch: 5 Train loss: 0.9177515701452891 test accuracy: 0.63525 time: 275.6442174911499\n",
      "Epoch: 6 Train loss: 0.8461856172482173 test accuracy: 0.64925 time: 329.7745690345764\n",
      "Epoch: 7 Train loss: 0.7720630804697672 test accuracy: 0.6595 time: 383.4400734901428\n",
      "Epoch: 8 Train loss: 0.7069924851258595 test accuracy: 0.666 time: 437.80947637557983\n",
      "Epoch: 9 Train loss: 0.646087683737278 test accuracy: 0.67075 time: 491.4178309440613\n",
      "Epoch: 10 Train loss: 0.587795724272728 test accuracy: 0.67 time: 545.0422039031982\n",
      "Epoch: 11 Train loss: 0.5308773323893548 test accuracy: 0.67225 time: 599.1467089653015\n",
      "Epoch: 12 Train loss: 0.4811442560950915 test accuracy: 0.67 time: 652.6945013999939\n",
      "Epoch: 13 Train loss: 0.43619961629311244 test accuracy: 0.66725 time: 706.4211966991425\n",
      "Epoch: 14 Train loss: 0.40068431476751964 test accuracy: 0.66925 time: 760.9058668613434\n",
      "Epoch: 15 Train loss: 0.359249563117822 test accuracy: 0.66575 time: 815.4496908187866\n",
      "Epoch: 16 Train loss: 0.3348043922583262 test accuracy: 0.67325 time: 869.2827756404877\n",
      "Epoch: 17 Train loss: 0.30843261688947676 test accuracy: 0.669 time: 923.0811340808868\n",
      "Epoch: 18 Train loss: 0.29750512694319087 test accuracy: 0.65325 time: 977.5400702953339\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.2518920.pbshpc/ipykernel_9948/1047962502.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.2518920.pbshpc/ipykernel_9948/3675889058.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cnn, train_data, epochs, opt, loss, test_data, n, b, t)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m#print(X.shape,y.shape,type(X),type(y))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "#                                    transforms.RandomRotation(5),\n",
    "#                                     transforms.RandomAffine(0,translate=(.1,.1)), \n",
    "                                    transforms.RandomApply([transforms.GaussianBlur(5)],1)                                 \n",
    "                                    ,transforms.ToTensor()])\n",
    "\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                   transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1)), \n",
    "                                    transforms.RandomApply([transforms.ColorJitter(.1,.1,0,0)],.1)                                 \n",
    "                                    ,transforms.ToTensor()])\n",
    "\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.4821476085980734 test accuracy: 0.562 time: 45.87855505943298\n",
      "Epoch: 2 Train loss: 1.1432311753431956 test accuracy: 0.616 time: 78.9062397480011\n",
      "Epoch: 3 Train loss: 1.0027479871114096 test accuracy: 0.65025 time: 114.89893174171448\n",
      "Epoch: 4 Train loss: 0.9108185011148453 test accuracy: 0.6705 time: 151.5019724369049\n",
      "Epoch: 5 Train loss: 0.8331673814853032 test accuracy: 0.68725 time: 186.0408856868744\n",
      "Epoch: 6 Train loss: 0.7690029559532802 test accuracy: 0.6995 time: 223.33709478378296\n",
      "Epoch: 7 Train loss: 0.7184927368164062 test accuracy: 0.71325 time: 259.0610320568085\n",
      "Epoch: 8 Train loss: 0.6638700303435325 test accuracy: 0.71325 time: 296.24543738365173\n",
      "Epoch: 9 Train loss: 0.6233581643303235 test accuracy: 0.724 time: 332.12297773361206\n",
      "Epoch: 10 Train loss: 0.5796642801165581 test accuracy: 0.72775 time: 369.6432454586029\n",
      "Epoch: 11 Train loss: 0.5392588152488073 test accuracy: 0.725 time: 407.1233060359955\n",
      "Epoch: 12 Train loss: 0.508023444712162 test accuracy: 0.7355 time: 444.02842807769775\n",
      "Epoch: 13 Train loss: 0.47296349267164867 test accuracy: 0.7355 time: 480.5012946128845\n",
      "Epoch: 14 Train loss: 0.4402200581630071 test accuracy: 0.74225 time: 517.476309299469\n",
      "Epoch: 15 Train loss: 0.4111657910545667 test accuracy: 0.74425 time: 556.6999003887177\n",
      "Epoch: 16 Train loss: 0.38646684199571607 test accuracy: 0.7425 time: 592.7464036941528\n",
      "Epoch: 17 Train loss: 0.36371359636386236 test accuracy: 0.7555 time: 628.5045003890991\n",
      "Epoch: 18 Train loss: 0.3401120027403037 test accuracy: 0.7565 time: 662.6700179576874\n",
      "Epoch: 19 Train loss: 0.31430653363466265 test accuracy: 0.7505 time: 699.8555886745453\n",
      "Epoch: 20 Train loss: 0.3055976787706216 test accuracy: 0.75475 time: 736.9591295719147\n",
      "Epoch: 21 Train loss: 0.27819225619236626 test accuracy: 0.7575 time: 772.7164947986603\n",
      "Epoch: 22 Train loss: 0.26146037369966507 test accuracy: 0.7515 time: 808.8853795528412\n",
      "Epoch: 23 Train loss: 0.24773349066575368 test accuracy: 0.7575 time: 845.6989939212799\n",
      "Epoch: 24 Train loss: 0.22928780605395635 test accuracy: 0.748 time: 883.7513127326965\n",
      "Epoch: 25 Train loss: 0.22064511140187582 test accuracy: 0.749 time: 920.0708086490631\n",
      "Epoch: 26 Train loss: 0.20799065584937731 test accuracy: 0.74625 time: 957.4732990264893\n",
      "Epoch: 27 Train loss: 0.19874359565476576 test accuracy: 0.74325 time: 993.5449006557465\n",
      "Epoch: 28 Train loss: 0.1902812793602546 test accuracy: 0.74375 time: 1030.721941947937\n",
      "Epoch: 29 Train loss: 0.18209746373196442 test accuracy: 0.7455 time: 1068.3341393470764\n",
      "Epoch: 30 Train loss: 0.1739831535766522 test accuracy: 0.7315 time: 1102.3965780735016\n",
      "Epoch: 31 Train loss: 0.15911325347920258 test accuracy: 0.74925 time: 1137.3069858551025\n",
      "Epoch: 32 Train loss: 0.14905169416218997 test accuracy: 0.7455 time: 1173.5270822048187\n",
      "Epoch: 33 Train loss: 0.14298863244553406 test accuracy: 0.7595 time: 1208.8541383743286\n",
      "Epoch: 34 Train loss: 0.14005481485277416 test accuracy: 0.75475 time: 1244.2790632247925\n",
      "Epoch: 35 Train loss: 0.13586505907277266 test accuracy: 0.755 time: 1278.1365172863007\n",
      "Epoch: 36 Train loss: 0.1281920230636994 test accuracy: 0.77425 time: 1315.2242136001587\n",
      "Epoch: 37 Train loss: 0.12155863786737124 test accuracy: 0.755 time: 1351.9961564540863\n",
      "Epoch: 38 Train loss: 0.11636311744650205 test accuracy: 0.762 time: 1388.0103662014008\n",
      "Epoch: 39 Train loss: 0.11140835539748271 test accuracy: 0.7555 time: 1423.9298582077026\n",
      "Epoch: 40 Train loss: 0.10413357632855574 test accuracy: 0.758 time: 1461.2349107265472\n",
      "Epoch: 41 Train loss: 0.10396008849143983 test accuracy: 0.77 time: 1498.7272374629974\n",
      "Epoch: 42 Train loss: 0.09562016403923432 test accuracy: 0.76075 time: 1536.8626036643982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.77425"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomCrop(32,1,True)\n",
    "#                                    transforms.RandomRotation(5),\n",
    "#                                     transforms.RandomAffine(0,translate=(.1,.1)), \n",
    "#                                     transforms.RandomApply([transforms.ColorJitter(.1,.1,0,0)],.1)                                 \n",
    "                                    ,transforms.ToTensor()])\n",
    "\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-4)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.330652518471082 test accuracy: 0.63225 time: 68.06009197235107\n",
      "Epoch: 2 Train loss: 0.946091268658638 test accuracy: 0.70975 time: 125.25888156890869\n",
      "Epoch: 3 Train loss: 0.7938787633180618 test accuracy: 0.74475 time: 184.6778666973114\n",
      "Epoch: 4 Train loss: 0.691278994679451 test accuracy: 0.75875 time: 243.94431853294373\n",
      "Epoch: 5 Train loss: 0.6182808873057365 test accuracy: 0.75625 time: 301.09860157966614\n",
      "Epoch: 6 Train loss: 0.569794067343076 test accuracy: 0.78075 time: 359.67694568634033\n",
      "Epoch: 7 Train loss: 0.5163327479362487 test accuracy: 0.77775 time: 418.395653963089\n",
      "Epoch: 8 Train loss: 0.47054280797640485 test accuracy: 0.783 time: 478.6303017139435\n",
      "Epoch: 9 Train loss: 0.43693035433689753 test accuracy: 0.786 time: 537.8452634811401\n",
      "Epoch: 10 Train loss: 0.40672569304704664 test accuracy: 0.799 time: 595.3987114429474\n",
      "Epoch: 11 Train loss: 0.3775063062210878 test accuracy: 0.7855 time: 658.4365692138672\n",
      "Epoch: 12 Train loss: 0.36325770924488704 test accuracy: 0.79375 time: 716.6164035797119\n",
      "Epoch: 13 Train loss: 0.3346095425387224 test accuracy: 0.80975 time: 774.9517409801483\n",
      "Epoch: 14 Train loss: 0.3126310649017493 test accuracy: 0.795 time: 834.9662430286407\n",
      "Epoch: 15 Train loss: 0.2923160646359126 test accuracy: 0.79975 time: 893.4809882640839\n",
      "Epoch: 16 Train loss: 0.27588302607337634 test accuracy: 0.8 time: 952.839390039444\n",
      "Epoch: 17 Train loss: 0.2597946663200855 test accuracy: 0.8075 time: 1011.6604659557343\n",
      "Epoch: 18 Train loss: 0.2405617944151163 test accuracy: 0.803 time: 1070.9074039459229\n",
      "Epoch: 19 Train loss: 0.2349447217086951 test accuracy: 0.804 time: 1131.197809934616\n",
      "Epoch: 20 Train loss: 0.21794422169526417 test accuracy: 0.8115 time: 1188.8517343997955\n",
      "Epoch: 21 Train loss: 0.21132679055134454 test accuracy: 0.8075 time: 1249.3776166439056\n",
      "Epoch: 22 Train loss: 0.19780154787003995 test accuracy: 0.8075 time: 1307.454466342926\n",
      "Epoch: 23 Train loss: 0.1890795159091552 test accuracy: 0.80275 time: 1366.6212692260742\n",
      "Epoch: 24 Train loss: 0.1838382032389442 test accuracy: 0.8055 time: 1427.7670948505402\n",
      "Epoch: 25 Train loss: 0.1739800898482402 test accuracy: 0.80875 time: 1487.6048979759216\n",
      "Epoch: 26 Train loss: 0.16472390236953893 test accuracy: 0.811 time: 1547.3265264034271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8115"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.RandomApply([transforms.RandomCrop(32,1,True)],0.2),                                    \n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.4501807423432669 test accuracy: 0.61775 time: 61.401177644729614\n",
      "Epoch: 2 Train loss: 1.086655056476593 test accuracy: 0.6765 time: 115.29822826385498\n",
      "Epoch: 3 Train loss: 0.9482248840729396 test accuracy: 0.70925 time: 167.0893030166626\n",
      "Epoch: 4 Train loss: 0.8503906927506129 test accuracy: 0.74125 time: 222.22696733474731\n",
      "Epoch: 5 Train loss: 0.7764003326495489 test accuracy: 0.74375 time: 273.24004578590393\n",
      "Epoch: 6 Train loss: 0.7233646064003308 test accuracy: 0.768 time: 325.96072936058044\n",
      "Epoch: 7 Train loss: 0.6771003890037537 test accuracy: 0.77025 time: 377.9215531349182\n",
      "Epoch: 8 Train loss: 0.6341239043076833 test accuracy: 0.785 time: 428.85303807258606\n",
      "Epoch: 9 Train loss: 0.5991191790501277 test accuracy: 0.78225 time: 480.9408121109009\n",
      "Epoch: 10 Train loss: 0.5683237891395887 test accuracy: 0.781 time: 533.0098042488098\n",
      "Epoch: 11 Train loss: 0.5441146250565847 test accuracy: 0.788 time: 586.5214092731476\n",
      "Epoch: 12 Train loss: 0.5169980430603027 test accuracy: 0.7955 time: 638.3340740203857\n",
      "Epoch: 13 Train loss: 0.4949957021077474 test accuracy: 0.79075 time: 689.5332753658295\n",
      "Epoch: 14 Train loss: 0.47664254655440647 test accuracy: 0.79475 time: 741.626339673996\n",
      "Epoch: 15 Train loss: 0.45768162031968435 test accuracy: 0.80325 time: 795.0935587882996\n",
      "Epoch: 16 Train loss: 0.43822530607382454 test accuracy: 0.805 time: 845.5670363903046\n",
      "Epoch: 17 Train loss: 0.4177554816007614 test accuracy: 0.798 time: 898.9502415657043\n",
      "Epoch: 18 Train loss: 0.40764754941066106 test accuracy: 0.8035 time: 951.2116529941559\n",
      "Epoch: 19 Train loss: 0.3864012363553047 test accuracy: 0.80075 time: 1002.8782618045807\n",
      "Epoch: 20 Train loss: 0.3783881147702535 test accuracy: 0.7945 time: 1056.0603115558624\n",
      "Epoch: 21 Train loss: 0.36331716671586034 test accuracy: 0.809 time: 1108.7762048244476\n",
      "Epoch: 22 Train loss: 0.35498590777317685 test accuracy: 0.80675 time: 1163.2788124084473\n",
      "Epoch: 23 Train loss: 0.3403569887081782 test accuracy: 0.811 time: 1217.8584790229797\n",
      "Epoch: 24 Train loss: 0.32719445834557215 test accuracy: 0.8025 time: 1272.585530757904\n",
      "Epoch: 25 Train loss: 0.32228301748633387 test accuracy: 0.808 time: 1328.4856700897217\n",
      "Epoch: 26 Train loss: 0.3115343270699183 test accuracy: 0.8075 time: 1382.5261821746826\n",
      "Epoch: 27 Train loss: 0.3041756815711657 test accuracy: 0.8025 time: 1438.2009553909302\n",
      "Epoch: 28 Train loss: 0.29086593771974245 test accuracy: 0.80675 time: 1491.7737760543823\n",
      "Epoch: 29 Train loss: 0.28511711458365124 test accuracy: 0.8105 time: 1545.7319884300232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.811"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(10),\n",
    "                                    transforms.RandomAffine(0,translate=(.2,.2))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.5438231380780538 test accuracy: 0.564 time: 71.52702975273132\n",
      "Epoch: 2 Train loss: 1.2171825989087424 test accuracy: 0.6345 time: 133.7003195285797\n",
      "Epoch: 3 Train loss: 1.0881083005666732 test accuracy: 0.672 time: 195.05453824996948\n",
      "Epoch: 4 Train loss: 0.9991550425688426 test accuracy: 0.704 time: 256.7860004901886\n",
      "Epoch: 5 Train loss: 0.9243501255909602 test accuracy: 0.72525 time: 318.5083382129669\n",
      "Epoch: 6 Train loss: 0.8709747594594955 test accuracy: 0.7415 time: 380.3237566947937\n",
      "Epoch: 7 Train loss: 0.8340376337369283 test accuracy: 0.744 time: 441.8989362716675\n",
      "Epoch: 8 Train loss: 0.7980590877930324 test accuracy: 0.75175 time: 503.83137369155884\n",
      "Epoch: 9 Train loss: 0.7642764500776926 test accuracy: 0.7635 time: 565.0013794898987\n",
      "Epoch: 10 Train loss: 0.7361879771947861 test accuracy: 0.7695 time: 627.6136972904205\n",
      "Epoch: 11 Train loss: 0.7047495476404826 test accuracy: 0.76425 time: 688.1895406246185\n",
      "Epoch: 12 Train loss: 0.6881149365504583 test accuracy: 0.77875 time: 749.8173267841339\n",
      "Epoch: 13 Train loss: 0.6669581336776416 test accuracy: 0.77525 time: 811.0482659339905\n",
      "Epoch: 14 Train loss: 0.6473953717947006 test accuracy: 0.775 time: 873.6097121238708\n",
      "Epoch: 15 Train loss: 0.6304716283082962 test accuracy: 0.7715 time: 935.1568522453308\n",
      "Epoch: 16 Train loss: 0.6146376458803813 test accuracy: 0.778 time: 998.1139795780182\n",
      "Epoch: 17 Train loss: 0.5958636783560117 test accuracy: 0.78675 time: 1059.1336369514465\n",
      "Epoch: 18 Train loss: 0.5774786355098088 test accuracy: 0.7905 time: 1121.7830197811127\n",
      "Epoch: 19 Train loss: 0.5694669061899185 test accuracy: 0.782 time: 1182.9349403381348\n",
      "Epoch: 20 Train loss: 0.5519920923312505 test accuracy: 0.797 time: 1245.7276465892792\n",
      "Epoch: 21 Train loss: 0.5362876056631406 test accuracy: 0.7955 time: 1306.7505943775177\n",
      "Epoch: 22 Train loss: 0.5206871901949247 test accuracy: 0.79875 time: 1369.8367757797241\n",
      "Epoch: 23 Train loss: 0.5114747488498688 test accuracy: 0.7985 time: 1432.4420065879822\n",
      "Epoch: 24 Train loss: 0.5042617575327555 test accuracy: 0.7905 time: 1495.5019154548645\n",
      "Epoch: 25 Train loss: 0.48893658896287284 test accuracy: 0.799 time: 1557.4578680992126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.799"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomRotation(10),\n",
    "                                    transforms.RandomAffine(0,translate=(.2,.2)),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.2607257012526194 test accuracy: 0.6465 time: 62.291348457336426\n",
      "Epoch: 2 Train loss: 0.876192189057668 test accuracy: 0.69275 time: 113.59563970565796\n",
      "Epoch: 3 Train loss: 0.7047317124406497 test accuracy: 0.72375 time: 166.29455995559692\n",
      "Epoch: 4 Train loss: 0.5813896186153094 test accuracy: 0.734 time: 218.1548993587494\n",
      "Epoch: 5 Train loss: 0.49829625884691875 test accuracy: 0.7285 time: 269.77325987815857\n",
      "Epoch: 6 Train loss: 0.42566302796204886 test accuracy: 0.73975 time: 320.58992981910706\n",
      "Epoch: 7 Train loss: 0.37264653260509173 test accuracy: 0.76075 time: 372.1278328895569\n",
      "Epoch: 8 Train loss: 0.324858130166928 test accuracy: 0.75775 time: 423.34737372398376\n",
      "Epoch: 9 Train loss: 0.27558774332205455 test accuracy: 0.75875 time: 474.15427350997925\n",
      "Epoch: 10 Train loss: 0.2368324824422598 test accuracy: 0.7485 time: 525.2502524852753\n",
      "Epoch: 11 Train loss: 0.20340011211733022 test accuracy: 0.752 time: 577.2802202701569\n",
      "Epoch: 12 Train loss: 0.18680946437021095 test accuracy: 0.74175 time: 628.6939165592194\n",
      "Epoch: 13 Train loss: 0.16117368896802267 test accuracy: 0.75025 time: 680.0900511741638\n",
      "Epoch: 14 Train loss: 0.1494310831402739 test accuracy: 0.765 time: 731.23876786232\n",
      "Epoch: 15 Train loss: 0.13677456335475047 test accuracy: 0.758 time: 783.9054653644562\n",
      "Epoch: 16 Train loss: 0.11903237191339334 test accuracy: 0.77725 time: 835.3384695053101\n",
      "Epoch: 17 Train loss: 0.11087553415447474 test accuracy: 0.768 time: 885.9637413024902\n",
      "Epoch: 18 Train loss: 0.10824690368647377 test accuracy: 0.77175 time: 937.8336679935455\n",
      "Epoch: 19 Train loss: 0.08647040337945024 test accuracy: 0.784 time: 989.6764335632324\n",
      "Epoch: 20 Train loss: 0.08547674975047509 test accuracy: 0.78025 time: 1039.9312443733215\n",
      "Epoch: 21 Train loss: 0.0850833912131687 test accuracy: 0.76925 time: 1091.368711233139\n",
      "Epoch: 22 Train loss: 0.07716790948063135 test accuracy: 0.76725 time: 1143.8209130764008\n",
      "Epoch: 23 Train loss: 0.07891168668245276 test accuracy: 0.7695 time: 1193.6819875240326\n",
      "Epoch: 24 Train loss: 0.06832105374274154 test accuracy: 0.778 time: 1245.0987100601196\n",
      "Epoch: 25 Train loss: 0.06400800311937928 test accuracy: 0.776 time: 1296.7715764045715\n",
      "Epoch: 26 Train loss: 0.06406551356427372 test accuracy: 0.772 time: 1349.2450652122498\n",
      "Epoch: 27 Train loss: 0.05684222760299842 test accuracy: 0.77025 time: 1399.673475265503\n",
      "Epoch: 28 Train loss: 0.05678960903547704 test accuracy: 0.7785 time: 1451.6484215259552\n",
      "Epoch: 29 Train loss: 0.059440233279019594 test accuracy: 0.779 time: 1503.0484759807587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.784"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomRotation(5),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.3541279500722885 test accuracy: 0.626 time: 64.4545087814331\n",
      "Epoch: 2 Train loss: 0.9826176601648331 test accuracy: 0.68725 time: 118.56478643417358\n",
      "Epoch: 3 Train loss: 0.834977111419042 test accuracy: 0.72225 time: 172.63995218276978\n",
      "Epoch: 4 Train loss: 0.7375881854693095 test accuracy: 0.75225 time: 227.68949055671692\n",
      "Epoch: 5 Train loss: 0.6677150547504425 test accuracy: 0.75575 time: 282.0405306816101\n",
      "Epoch: 6 Train loss: 0.6138019302487373 test accuracy: 0.7745 time: 337.3197178840637\n",
      "Epoch: 7 Train loss: 0.5728931172688803 test accuracy: 0.766 time: 391.59947752952576\n",
      "Epoch: 8 Train loss: 0.5309883003433545 test accuracy: 0.7765 time: 446.08366107940674\n",
      "Epoch: 9 Train loss: 0.4951628236969312 test accuracy: 0.78425 time: 501.0167911052704\n",
      "Epoch: 10 Train loss: 0.460824199616909 test accuracy: 0.799 time: 554.5132377147675\n",
      "Epoch: 11 Train loss: 0.4392235975464185 test accuracy: 0.78925 time: 610.1118433475494\n",
      "Epoch: 12 Train loss: 0.40521724859873454 test accuracy: 0.78825 time: 662.8691034317017\n",
      "Epoch: 13 Train loss: 0.38584942554434143 test accuracy: 0.789 time: 717.0759847164154\n",
      "Epoch: 14 Train loss: 0.36483060926198957 test accuracy: 0.79175 time: 772.1569111347198\n",
      "Epoch: 15 Train loss: 0.3453376214702924 test accuracy: 0.78725 time: 824.4382355213165\n",
      "Epoch: 16 Train loss: 0.32323169708251953 test accuracy: 0.80375 time: 877.8032536506653\n",
      "Epoch: 17 Train loss: 0.3037111456195513 test accuracy: 0.80075 time: 930.628744840622\n",
      "Epoch: 18 Train loss: 0.29105863576134045 test accuracy: 0.80125 time: 983.3049767017365\n",
      "Epoch: 19 Train loss: 0.27677128141125046 test accuracy: 0.802 time: 1036.6083409786224\n",
      "Epoch: 20 Train loss: 0.2633132637043794 test accuracy: 0.80425 time: 1086.9699909687042\n",
      "Epoch: 21 Train loss: 0.24626790386935074 test accuracy: 0.80525 time: 1142.9269762039185\n",
      "Epoch: 22 Train loss: 0.22807460675636929 test accuracy: 0.80775 time: 1193.9250106811523\n",
      "Epoch: 23 Train loss: 0.2294073175638914 test accuracy: 0.798 time: 1249.1289875507355\n",
      "Epoch: 24 Train loss: 0.21204079451660315 test accuracy: 0.81025 time: 1300.6682283878326\n",
      "Epoch: 25 Train loss: 0.2037163906544447 test accuracy: 0.81025 time: 1354.0276544094086\n",
      "Epoch: 26 Train loss: 0.18928220609823862 test accuracy: 0.8055 time: 1407.797622203827\n",
      "Epoch: 27 Train loss: 0.18230705127120017 test accuracy: 0.8115 time: 1459.2430138587952\n",
      "Epoch: 28 Train loss: 0.17862818864484628 test accuracy: 0.81375 time: 1512.1537437438965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81375"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                     transforms.RandomAffine(0,translate=(.1,.1)),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING DIFFERENT MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2679178"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3)\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,64,3)\n",
    "        self.bn2=nn.BatchNorm2d(64)\n",
    "        self.c3=nn.Conv2d(64,512,3)\n",
    "        self.bn3=nn.BatchNorm2d(512)\n",
    "        self.c4=nn.Conv2d(512,1024,2)\n",
    "        self.fc1=nn.Linear(1024,256)\n",
    "        self.fc2=nn.Linear(256,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn1(self.c1(X))))\n",
    "        X=self.p2(F.relu(self.bn2(self.c2(X)))) \n",
    "        X=self.p2(F.relu(self.bn3(self.c3(X))))        \n",
    "        X=F.relu(self.c4(X))\n",
    "        X=X.view(-1,1024)\n",
    "        X=self.fc2(self.dropout(F.relu(self.fc1(X))))\n",
    "        return X\n",
    "sum(p.numel() for p in CNN().parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2812446"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deeper FCN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3)\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,64,3)\n",
    "        self.bn2=nn.BatchNorm2d(64)\n",
    "        self.c3=nn.Conv2d(64,512,3)\n",
    "        self.bn3=nn.BatchNorm2d(512)\n",
    "        self.c4=nn.Conv2d(512,1024,2)\n",
    "        self.fc1=nn.Linear(1024,256)\n",
    "        self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,10)\n",
    "        self.fc4=nn.Linear(128,10)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn1(self.c1(X))))\n",
    "        X=self.p2(F.relu(self.bn2(self.c2(X)))) \n",
    "        X=self.p2(F.relu(self.bn3(self.c3(X))))        \n",
    "        X=F.relu(self.c4(X))\n",
    "        X=X.view(-1,1024)\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(F.relu(self.fc2(self.dropout(F.relu(self.fc1(X))))))))))\n",
    "        return X\n",
    "sum(p.numel() for p in CNN().parameters())\n",
    "# a=CNN_B().cuda()\n",
    "# b=cifar10_dataset(X_train,y_train)\n",
    "# d=a.forward(b.__getitem__(0)[0].reshape(1,3,32,32))\n",
    "# d.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.335420708656311 test accuracy: 0.657 time: 64.7016110420227\n",
      "Epoch: 2 Train loss: 0.9489365748564402 test accuracy: 0.7095 time: 119.74433255195618\n",
      "Epoch: 3 Train loss: 0.7951028935114542 test accuracy: 0.7435 time: 175.04571342468262\n",
      "Epoch: 4 Train loss: 0.6923758488893509 test accuracy: 0.757 time: 229.98001623153687\n",
      "Epoch: 5 Train loss: 0.620520735780398 test accuracy: 0.7585 time: 283.7158000469208\n",
      "Epoch: 6 Train loss: 0.5635943968097369 test accuracy: 0.77625 time: 338.94573736190796\n",
      "Epoch: 7 Train loss: 0.5099677692850431 test accuracy: 0.77275 time: 393.17236161231995\n",
      "Epoch: 8 Train loss: 0.4679200378060341 test accuracy: 0.78025 time: 448.07105827331543\n",
      "Epoch: 9 Train loss: 0.4254749521613121 test accuracy: 0.7885 time: 501.9364025592804\n",
      "Epoch: 10 Train loss: 0.3950006791949272 test accuracy: 0.79 time: 556.6523904800415\n",
      "Epoch: 11 Train loss: 0.37624777292211853 test accuracy: 0.79275 time: 609.6299903392792\n",
      "Epoch: 12 Train loss: 0.35083161110679306 test accuracy: 0.78975 time: 665.5700116157532\n",
      "Epoch: 13 Train loss: 0.32717153723041215 test accuracy: 0.7865 time: 719.6408486366272\n",
      "Epoch: 14 Train loss: 0.3042482669154803 test accuracy: 0.788 time: 775.3498463630676\n",
      "Epoch: 15 Train loss: 0.2802143235504627 test accuracy: 0.79725 time: 829.4624581336975\n",
      "Epoch: 16 Train loss: 0.26974682256579396 test accuracy: 0.79225 time: 883.5194535255432\n",
      "Epoch: 17 Train loss: 0.251622064585487 test accuracy: 0.78675 time: 937.4770085811615\n",
      "Epoch: 18 Train loss: 0.23666717102130255 test accuracy: 0.804 time: 993.3981084823608\n",
      "Epoch: 19 Train loss: 0.2230321785559257 test accuracy: 0.80325 time: 1047.0689902305603\n",
      "Epoch: 20 Train loss: 0.21461701604227226 test accuracy: 0.79725 time: 1102.0605087280273\n",
      "Epoch: 21 Train loss: 0.19894296035170556 test accuracy: 0.79875 time: 1156.7888996601105\n",
      "Epoch: 22 Train loss: 0.1990711461752653 test accuracy: 0.79575 time: 1211.8694562911987\n",
      "Epoch: 23 Train loss: 0.18979966677725316 test accuracy: 0.79975 time: 1265.1014909744263\n",
      "Epoch: 24 Train loss: 0.17561276147762933 test accuracy: 0.804 time: 1320.3173913955688\n",
      "Epoch: 25 Train loss: 0.17102659739553927 test accuracy: 0.8075 time: 1373.7132406234741\n",
      "Epoch: 26 Train loss: 0.1608712602655093 test accuracy: 0.80325 time: 1428.9520075321198\n",
      "Epoch: 27 Train loss: 0.15807595439255237 test accuracy: 0.8145 time: 1482.9813096523285\n",
      "Epoch: 28 Train loss: 0.14871504109352826 test accuracy: 0.81825 time: 1537.86447763443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81825"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1872106"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VGG Based\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(64)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn5=nn.BatchNorm2d(128)\n",
    "        self.bn6=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "        self.bn7=nn.BatchNorm2d(256)\n",
    "        self.bn8=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        # self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        # self.c10=nn.Conv2d(512,1024,2)\n",
    "        # self.bn5=nn.BatchNorm2d(512)\n",
    "        # self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc1=nn.Linear(1024,512)\n",
    "        self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn2(F.relu(self.c2(F.relu(self.bn1(self.c1(X))))))))\n",
    "        X=self.p2(F.relu(self.bn4(F.relu(self.c4(F.relu(self.bn3(self.c3(X))))))))\n",
    "        X=self.p2(F.relu(self.bn6(F.relu(self.c6(F.relu(self.bn5(self.c5(X))))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=self.p2(F.relu(self.bn8(F.relu(self.c8(F.relu(self.bn7(self.c7(X))))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,1024)       \n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(F.relu(self.fc2(self.dropout(F.relu(self.fc1(X))))))))))\n",
    "        return X\n",
    "    \n",
    "sum(p.numel() for p in CNN().parameters())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.4562279752890268 test accuracy: 0.6255 time: 53.05144429206848\n",
      "Epoch: 2 Train loss: 0.9249736978610357 test accuracy: 0.7085 time: 96.12781262397766\n",
      "Epoch: 3 Train loss: 0.736960699558258 test accuracy: 0.7585 time: 139.15706515312195\n",
      "Epoch: 4 Train loss: 0.6037033932407697 test accuracy: 0.7865 time: 182.08458375930786\n",
      "Epoch: 5 Train loss: 0.5233810791373252 test accuracy: 0.79075 time: 225.45615482330322\n",
      "Epoch: 6 Train loss: 0.45707995563745496 test accuracy: 0.80475 time: 268.60526943206787\n",
      "Epoch: 7 Train loss: 0.4042119578023752 test accuracy: 0.82225 time: 311.54846143722534\n",
      "Epoch: 8 Train loss: 0.36224018012483916 test accuracy: 0.825 time: 354.69612884521484\n",
      "Epoch: 9 Train loss: 0.3242809188365936 test accuracy: 0.83025 time: 398.2312729358673\n",
      "Epoch: 10 Train loss: 0.2971658101677895 test accuracy: 0.829 time: 441.4491147994995\n",
      "Epoch: 11 Train loss: 0.2672389254470666 test accuracy: 0.832 time: 484.6292142868042\n",
      "Epoch: 12 Train loss: 0.24958608190218606 test accuracy: 0.83975 time: 527.891722202301\n",
      "Epoch: 13 Train loss: 0.22172642365098 test accuracy: 0.8355 time: 571.4481625556946\n",
      "Epoch: 14 Train loss: 0.20672688784698645 test accuracy: 0.83825 time: 614.5982496738434\n",
      "Epoch: 15 Train loss: 0.18882842160761357 test accuracy: 0.839 time: 657.8288607597351\n",
      "Epoch: 16 Train loss: 0.17977643584211667 test accuracy: 0.84675 time: 700.7065052986145\n",
      "Epoch: 17 Train loss: 0.16186647919317088 test accuracy: 0.83475 time: 744.2556080818176\n",
      "Epoch: 18 Train loss: 0.15304041285067796 test accuracy: 0.83575 time: 787.3633952140808\n",
      "Epoch: 19 Train loss: 0.14386934701353313 test accuracy: 0.838 time: 830.547404050827\n",
      "Epoch: 20 Train loss: 0.13742459985117117 test accuracy: 0.8445 time: 873.7260475158691\n",
      "Epoch: 21 Train loss: 0.13120612872143586 test accuracy: 0.84275 time: 917.0350368022919\n",
      "Epoch: 22 Train loss: 0.11618310223023097 test accuracy: 0.84525 time: 960.2301046848297\n",
      "Epoch: 23 Train loss: 0.11234018001084527 test accuracy: 0.84075 time: 1003.377358675003\n",
      "Epoch: 24 Train loss: 0.1012846833653748 test accuracy: 0.8465 time: 1046.7184014320374\n",
      "Epoch: 25 Train loss: 0.10486410660048326 test accuracy: 0.849 time: 1090.040978193283\n",
      "Epoch: 26 Train loss: 0.09573773540556431 test accuracy: 0.84725 time: 1133.262870311737\n",
      "Epoch: 27 Train loss: 0.09432201528300842 test accuracy: 0.84875 time: 1176.4398050308228\n",
      "Epoch: 28 Train loss: 0.09292246517414848 test accuracy: 0.84275 time: 1219.8990454673767\n",
      "Epoch: 29 Train loss: 0.08780368267868956 test accuracy: 0.849 time: 1262.8157925605774\n",
      "Epoch: 30 Train loss: 0.08201739518592754 test accuracy: 0.845 time: 1305.9509408473969\n",
      "Epoch: 31 Train loss: 0.0847496483847499 test accuracy: 0.84475 time: 1349.0508501529694\n",
      "Epoch: 32 Train loss: 0.08201006601875027 test accuracy: 0.8525 time: 1392.0183534622192\n",
      "Epoch: 33 Train loss: 0.07752634241556128 test accuracy: 0.8415 time: 1434.9464902877808\n",
      "Epoch: 34 Train loss: 0.0777701715597262 test accuracy: 0.84075 time: 1478.3779747486115\n",
      "Epoch: 35 Train loss: 0.07554082566251358 test accuracy: 0.84825 time: 1521.6414422988892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8525"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1872106"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VGG Based, correct order of bn, relu\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(64)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn5=nn.BatchNorm2d(128)\n",
    "        self.bn6=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "        self.bn7=nn.BatchNorm2d(256)\n",
    "        self.bn8=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        # self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        # self.c10=nn.Conv2d(512,1024,2)\n",
    "        # self.bn5=nn.BatchNorm2d(512)\n",
    "        # self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc1=nn.Linear(1024,512)\n",
    "        self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X)))))))\n",
    "        X=self.p2(F.relu(self.bn4(self.c4(F.relu(self.bn3(self.c3(X)))))))\n",
    "        X=self.p2(F.relu(self.bn6(self.c6(F.relu(self.bn5(self.c5(X)))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=self.p2(F.relu(self.bn8(self.c8(F.relu(self.bn7(self.c7(X)))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,1024)       \n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(F.relu(self.fc2(self.dropout(F.relu(self.fc1(X))))))))))\n",
    "        return X\n",
    "    \n",
    "sum(p.numel() for p in CNN().parameters())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.4404330583413443 test accuracy: 0.624 time: 52.78881597518921\n",
      "Epoch: 2 Train loss: 0.9511392949024836 test accuracy: 0.719 time: 95.70484709739685\n",
      "Epoch: 3 Train loss: 0.7489076014359792 test accuracy: 0.761 time: 138.5812644958496\n",
      "Epoch: 4 Train loss: 0.6296023226777713 test accuracy: 0.7915 time: 181.59400153160095\n",
      "Epoch: 5 Train loss: 0.537713716129462 test accuracy: 0.80675 time: 224.78408002853394\n",
      "Epoch: 6 Train loss: 0.47038890759150187 test accuracy: 0.81975 time: 267.68390369415283\n",
      "Epoch: 7 Train loss: 0.42250141441822053 test accuracy: 0.82175 time: 310.8067774772644\n",
      "Epoch: 8 Train loss: 0.38065199568867686 test accuracy: 0.8315 time: 353.88093852996826\n",
      "Epoch: 9 Train loss: 0.3404747254649798 test accuracy: 0.834 time: 397.0957248210907\n",
      "Epoch: 10 Train loss: 0.3098311799764633 test accuracy: 0.835 time: 439.9985888004303\n",
      "Epoch: 11 Train loss: 0.2794028079509735 test accuracy: 0.84225 time: 483.28748631477356\n",
      "Epoch: 12 Train loss: 0.254479819710056 test accuracy: 0.84225 time: 526.2260978221893\n",
      "Epoch: 13 Train loss: 0.2385791372011105 test accuracy: 0.84375 time: 569.3205420970917\n",
      "Epoch: 14 Train loss: 0.21811239289740722 test accuracy: 0.848 time: 612.2169208526611\n",
      "Epoch: 15 Train loss: 0.2002198843161265 test accuracy: 0.846 time: 655.0340340137482\n",
      "Epoch: 16 Train loss: 0.18688043867548307 test accuracy: 0.8495 time: 698.2615897655487\n",
      "Epoch: 17 Train loss: 0.16901372843732437 test accuracy: 0.84575 time: 740.6983289718628\n",
      "Epoch: 18 Train loss: 0.15862631380558015 test accuracy: 0.85225 time: 783.6423754692078\n",
      "Epoch: 19 Train loss: 0.14793713295211394 test accuracy: 0.84375 time: 826.1982185840607\n",
      "Epoch: 20 Train loss: 0.13894389748573302 test accuracy: 0.84825 time: 869.6275618076324\n",
      "Epoch: 21 Train loss: 0.136857160727183 test accuracy: 0.85875 time: 912.5431232452393\n",
      "Epoch: 22 Train loss: 0.1273898545652628 test accuracy: 0.853 time: 955.3771317005157\n",
      "Epoch: 23 Train loss: 0.11859590013201038 test accuracy: 0.8555 time: 997.9262535572052\n",
      "Epoch: 24 Train loss: 0.10966061389694612 test accuracy: 0.86225 time: 1040.93448138237\n",
      "Epoch: 25 Train loss: 0.10524661544710398 test accuracy: 0.85525 time: 1084.2471265792847\n",
      "Epoch: 26 Train loss: 0.09982337545603513 test accuracy: 0.8615 time: 1127.1156136989594\n",
      "Epoch: 27 Train loss: 0.09523689274986585 test accuracy: 0.862 time: 1170.3810288906097\n",
      "Epoch: 28 Train loss: 0.09404042062660058 test accuracy: 0.8605 time: 1213.3902246952057\n",
      "Epoch: 29 Train loss: 0.08754665401453773 test accuracy: 0.8635 time: 1256.022071838379\n",
      "Epoch: 30 Train loss: 0.08928194979826609 test accuracy: 0.8575 time: 1298.5973620414734\n",
      "Epoch: 31 Train loss: 0.0827858353468279 test accuracy: 0.85925 time: 1341.4731040000916\n",
      "Epoch: 32 Train loss: 0.07575525605119765 test accuracy: 0.8565 time: 1384.9178581237793\n",
      "Epoch: 33 Train loss: 0.07434506750976046 test accuracy: 0.85675 time: 1427.6839756965637\n",
      "Epoch: 34 Train loss: 0.07394352868199348 test accuracy: 0.86225 time: 1470.4421129226685\n",
      "Epoch: 35 Train loss: 0.07070093010241786 test accuracy: 0.86225 time: 1513.1671617031097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8635"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2264810\n",
      "Epoch: 1 Train loss: 1.3836492721239726 test accuracy: 0.6425 time: 53.574042081832886\n",
      "Epoch: 2 Train loss: 0.9005601340532303 test accuracy: 0.74 time: 96.77295732498169\n",
      "Epoch: 3 Train loss: 0.7055519510308902 test accuracy: 0.7575 time: 140.2084231376648\n",
      "Epoch: 4 Train loss: 0.5819109463691712 test accuracy: 0.79625 time: 183.5829417705536\n",
      "Epoch: 5 Train loss: 0.5012856873869896 test accuracy: 0.80325 time: 226.94815230369568\n",
      "Epoch: 6 Train loss: 0.4329609106977781 test accuracy: 0.81225 time: 270.28664684295654\n",
      "Epoch: 7 Train loss: 0.38140664239724476 test accuracy: 0.8195 time: 313.3133637905121\n",
      "Epoch: 8 Train loss: 0.3419881337384383 test accuracy: 0.821 time: 356.44992423057556\n",
      "Epoch: 9 Train loss: 0.3066712711751461 test accuracy: 0.8305 time: 399.6552233695984\n",
      "Epoch: 10 Train loss: 0.272561580290397 test accuracy: 0.832 time: 443.0736343860626\n",
      "Epoch: 11 Train loss: 0.244205112606287 test accuracy: 0.8305 time: 486.40055108070374\n",
      "Epoch: 12 Train loss: 0.22509667135775088 test accuracy: 0.831 time: 529.6701605319977\n",
      "Epoch: 13 Train loss: 0.20570447884500026 test accuracy: 0.8275 time: 572.8507611751556\n",
      "Epoch: 14 Train loss: 0.18536261700093745 test accuracy: 0.84 time: 616.0968749523163\n",
      "Epoch: 15 Train loss: 0.17098069194704293 test accuracy: 0.84 time: 659.5611283779144\n",
      "Epoch: 16 Train loss: 0.16115132744113606 test accuracy: 0.8415 time: 702.7578914165497\n",
      "Epoch: 17 Train loss: 0.1525740287452936 test accuracy: 0.83825 time: 745.7208771705627\n",
      "Epoch: 18 Train loss: 0.13782768894607822 test accuracy: 0.83725 time: 788.8117918968201\n",
      "Epoch: 19 Train loss: 0.13006396950532992 test accuracy: 0.84275 time: 831.967045545578\n",
      "Epoch: 20 Train loss: 0.12479638669639825 test accuracy: 0.84425 time: 874.9376404285431\n",
      "Epoch: 21 Train loss: 0.1245245711505413 test accuracy: 0.84825 time: 917.8930032253265\n",
      "Epoch: 22 Train loss: 0.11154529972622793 test accuracy: 0.83875 time: 961.1016061306\n",
      "Epoch: 23 Train loss: 0.10356666886558136 test accuracy: 0.84175 time: 1004.4569804668427\n",
      "Epoch: 24 Train loss: 0.104431748551627 test accuracy: 0.8495 time: 1047.2134900093079\n",
      "Epoch: 25 Train loss: 0.09561448674649001 test accuracy: 0.84 time: 1090.272649049759\n",
      "Epoch: 26 Train loss: 0.08986763273986677 test accuracy: 0.836 time: 1133.2305409908295\n",
      "Epoch: 27 Train loss: 0.09055820473780235 test accuracy: 0.83975 time: 1176.0155503749847\n",
      "Epoch: 28 Train loss: 0.08432984599843621 test accuracy: 0.8425 time: 1219.3851397037506\n",
      "Epoch: 29 Train loss: 0.08379427701855699 test accuracy: 0.8415 time: 1262.6240241527557\n",
      "Epoch: 30 Train loss: 0.08055609868839383 test accuracy: 0.845 time: 1306.0869619846344\n",
      "Epoch: 31 Train loss: 0.07880591750144958 test accuracy: 0.8435 time: 1349.0491688251495\n",
      "Epoch: 32 Train loss: 0.07424519897749027 test accuracy: 0.8485 time: 1392.2425968647003\n",
      "Epoch: 33 Train loss: 0.07334565116403004 test accuracy: 0.855 time: 1435.4622223377228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670><function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670><function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: Exception ignored in:   File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "            <function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670><function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>Exception ignored in: Exception ignored in:     self._shutdown_workers()self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670><function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>self._shutdown_workers()\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: \n",
      "\n",
      "\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>Traceback (most recent call last):\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "                    \n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>    <function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>if w.is_alive():if w.is_alive():if w.is_alive():Exception ignored in: self._shutdown_workers()self._shutdown_workers()Traceback (most recent call last):\n",
      "Exception ignored in:         \n",
      "if w.is_alive():\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>self._shutdown_workers()self._shutdown_workers()Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    \n",
      "\n",
      "\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>    Traceback (most recent call last):\n",
      "    self._shutdown_workers()Traceback (most recent call last):\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    Exception ignored in:     \n",
      "Exception ignored in: if w.is_alive():  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "Exception ignored in: if w.is_alive():\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "        self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>            self._shutdown_workers()    Exception ignored in: Traceback (most recent call last):\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>    <function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "if w.is_alive():    if w.is_alive():\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    \n",
      "self._shutdown_workers()\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "    if w.is_alive():  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "      File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "AssertionErrorAssertionError    AssertionErrorAssertionErrorTraceback (most recent call last):\n",
      "self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "      File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():    : : :   File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      ": if w.is_alive():\n",
      "\n",
      "            \n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "self._shutdown_workers()can only test a child processcan only test a child processcan only test a child process  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "\n",
      "can only test a child processself._shutdown_workers()    AssertionErrorif w.is_alive():self._shutdown_workers()AssertionError\n",
      "      File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "if w.is_alive():\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    self._shutdown_workers(): \n",
      "\n",
      "\n",
      ": AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "        if w.is_alive():\n",
      "can only test a child process  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "can only test a child process: \n",
      ":   File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "            \n",
      "can only test a child processAssertionErrorcan only test a child process\n",
      "    if w.is_alive():\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    Exception ignored in: if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
      ": \n",
      "AssertionError\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError    if w.is_alive():\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>\n",
      "\n",
      "can only test a child process:   File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      ": assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in: \n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "can only test a child process    AssertionErrorcan only test a child process\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2b6c62d78670>Traceback (most recent call last):\n",
      "    :     \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process': \n",
      "AssertionError    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "can only test a child process: assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
      "\n",
      "    \n",
      "\n",
      "AssertionError\n",
      "can only test a child process\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "AssertionErrorself._shutdown_workers()AssertionError: \n",
      "AssertionError    : \n",
      ": can only test a child process: self._shutdown_workers()can only test a child process  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "can only test a child process\n",
      "can only test a child process\n",
      "\n",
      "    \n",
      "\n",
      "  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "if w.is_alive():    \n",
      "if w.is_alive():  File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "      File \"/home/textile/btech/tt1180958/myenv/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
      ": AssertionErrorcan only test a child process: \n",
      "can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 Train loss: 0.06890524767339229 test accuracy: 0.8495 time: 1483.582394361496\n",
      "Epoch: 35 Train loss: 0.06898250001172225 test accuracy: 0.853 time: 1526.9416267871857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.855"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removed final pooling layer\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(64)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn5=nn.BatchNorm2d(128)\n",
    "        self.bn6=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn7=nn.BatchNorm2d(256)\n",
    "        self.bn8=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc0=nn.Linear(4096,256)\n",
    "        #self.fc1=nn.Linear(1024,512)\n",
    "        #self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn2(F.relu(self.c2(F.relu(self.bn1(self.c1(X))))))))\n",
    "        X=self.p2(F.relu(self.bn4(F.relu(self.c4(F.relu(self.bn3(self.c3(X))))))))\n",
    "        X=self.p2(F.relu(self.bn6(F.relu(self.c6(F.relu(self.bn5(self.c5(X))))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn8(F.relu(self.c8(F.relu(self.bn7(self.c7(X)))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,256*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(self.dropout(F.relu(self.fc0(X))))))))\n",
    "        return X\n",
    "        \n",
    "print(sum(p.numel() for p in CNN().parameters())) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.345347482363383 test accuracy: 0.6485 time: 52.9421911239624\n",
      "Epoch: 2 Train loss: 0.862149597009023 test accuracy: 0.7415 time: 96.66772389411926\n",
      "Epoch: 3 Train loss: 0.6714612422386805 test accuracy: 0.779 time: 140.1503643989563\n",
      "Epoch: 4 Train loss: 0.5619830100735028 test accuracy: 0.807 time: 183.54303765296936\n",
      "Epoch: 5 Train loss: 0.48865325113137564 test accuracy: 0.8085 time: 226.6786425113678\n",
      "Epoch: 6 Train loss: 0.4285627185801665 test accuracy: 0.8155 time: 269.8924353122711\n",
      "Epoch: 7 Train loss: 0.3773352071642876 test accuracy: 0.83075 time: 313.30586075782776\n",
      "Epoch: 8 Train loss: 0.33936522737145425 test accuracy: 0.8305 time: 356.7460973262787\n",
      "Epoch: 9 Train loss: 0.2996366846561432 test accuracy: 0.8385 time: 399.78175044059753\n",
      "Epoch: 10 Train loss: 0.27194959272940955 test accuracy: 0.84425 time: 442.8702836036682\n",
      "Epoch: 11 Train loss: 0.24904472703735034 test accuracy: 0.837 time: 486.4328739643097\n",
      "Epoch: 12 Train loss: 0.22528924018144608 test accuracy: 0.851 time: 529.7429339885712\n",
      "Epoch: 13 Train loss: 0.2065991832067569 test accuracy: 0.8415 time: 572.9981062412262\n",
      "Epoch: 14 Train loss: 0.1931237235913674 test accuracy: 0.8435 time: 616.140218257904\n",
      "Epoch: 15 Train loss: 0.1715826102097829 test accuracy: 0.84525 time: 659.2258048057556\n",
      "Epoch: 16 Train loss: 0.16606504725913207 test accuracy: 0.851 time: 702.3843591213226\n",
      "Epoch: 17 Train loss: 0.14828156786660354 test accuracy: 0.85375 time: 745.5781126022339\n",
      "Epoch: 18 Train loss: 0.13913090445101262 test accuracy: 0.84625 time: 788.9912331104279\n",
      "Epoch: 19 Train loss: 0.13170075391729671 test accuracy: 0.843 time: 832.0631940364838\n",
      "Epoch: 20 Train loss: 0.12220851431290308 test accuracy: 0.85125 time: 875.2414062023163\n",
      "Epoch: 21 Train loss: 0.11764547385275365 test accuracy: 0.84525 time: 918.4647557735443\n",
      "Epoch: 22 Train loss: 0.11099681581060092 test accuracy: 0.85075 time: 961.7041807174683\n",
      "Epoch: 23 Train loss: 0.10552185498798887 test accuracy: 0.8525 time: 1004.8738005161285\n",
      "Epoch: 24 Train loss: 0.10045632312695185 test accuracy: 0.85125 time: 1047.9023768901825\n",
      "Epoch: 25 Train loss: 0.09702660083770752 test accuracy: 0.8535 time: 1091.0761332511902\n",
      "Epoch: 26 Train loss: 0.0927968540849785 test accuracy: 0.85325 time: 1134.6837513446808\n",
      "Epoch: 27 Train loss: 0.08855806963518262 test accuracy: 0.855 time: 1177.8738255500793\n",
      "Epoch: 28 Train loss: 0.08883803812786936 test accuracy: 0.85325 time: 1220.8393621444702\n",
      "Epoch: 29 Train loss: 0.08495870283494393 test accuracy: 0.8605 time: 1264.030301809311\n",
      "Epoch: 30 Train loss: 0.07889928596715133 test accuracy: 0.85875 time: 1306.9840595722198\n",
      "Epoch: 31 Train loss: 0.07865072315558791 test accuracy: 0.86325 time: 1350.3209800720215\n",
      "Epoch: 32 Train loss: 0.074180693042775 test accuracy: 0.85925 time: 1393.5020473003387\n",
      "Epoch: 33 Train loss: 0.06959389279286067 test accuracy: 0.85375 time: 1436.9010696411133\n",
      "Epoch: 34 Train loss: 0.07337891604751348 test accuracy: 0.86025 time: 1480.0682978630066\n",
      "Epoch: 35 Train loss: 0.06627409211670358 test accuracy: 0.85425 time: 1523.0808968544006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86325"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(64)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn5=nn.BatchNorm2d(128)\n",
    "        self.bn6=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn7=nn.BatchNorm2d(256)\n",
    "        self.bn8=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc0=nn.Linear(4096,256)\n",
    "        #self.fc1=nn.Linear(1024,512)\n",
    "        #self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn2(F.relu(self.c2(F.relu(self.bn1(self.c1(X))))))))\n",
    "        X=self.p2(F.relu(self.bn4(F.relu(self.c4(F.relu(self.bn3(self.c3(X))))))))\n",
    "        X=self.p2(F.relu(self.bn6(F.relu(self.c6(F.relu(self.bn5(self.c5(X))))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn8(F.relu(self.c8(F.relu(self.bn7(self.c7(X)))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,256*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(self.dropout(F.relu(self.fc0(X))))))))\n",
    "        return X\n",
    "        \n",
    "print(sum(p.numel() for p in CNN().parameters())) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2559850\n",
      "Epoch: 1 Train loss: 1.3724033675591152 test accuracy: 0.6425 time: 52.77963733673096\n",
      "Epoch: 2 Train loss: 0.8976599357525508 test accuracy: 0.736 time: 95.84326481819153\n",
      "Epoch: 3 Train loss: 0.7103493789831797 test accuracy: 0.77325 time: 138.62260460853577\n",
      "Epoch: 4 Train loss: 0.6016502231359482 test accuracy: 0.8005 time: 181.58708572387695\n",
      "Epoch: 5 Train loss: 0.5214641544222832 test accuracy: 0.80425 time: 224.42731142044067\n",
      "Epoch: 6 Train loss: 0.4608692462245623 test accuracy: 0.803 time: 267.6542818546295\n",
      "Epoch: 7 Train loss: 0.42120756988724073 test accuracy: 0.828 time: 310.31874990463257\n",
      "Epoch: 8 Train loss: 0.3725384076933066 test accuracy: 0.82025 time: 353.1581566333771\n",
      "Epoch: 9 Train loss: 0.34141199161609015 test accuracy: 0.83025 time: 396.41535544395447\n",
      "Epoch: 10 Train loss: 0.3122329891224702 test accuracy: 0.83225 time: 439.45842933654785\n",
      "Epoch: 11 Train loss: 0.2812271489202976 test accuracy: 0.83875 time: 482.37206530570984\n",
      "Epoch: 12 Train loss: 0.2588184364636739 test accuracy: 0.8275 time: 525.2532134056091\n",
      "Epoch: 13 Train loss: 0.2395259641110897 test accuracy: 0.838 time: 568.307683467865\n",
      "Epoch: 14 Train loss: 0.21654179836312928 test accuracy: 0.84625 time: 611.3650739192963\n",
      "Epoch: 15 Train loss: 0.20382590785622598 test accuracy: 0.8335 time: 654.1752533912659\n",
      "Epoch: 16 Train loss: 0.18426960224906602 test accuracy: 0.84225 time: 697.1773338317871\n",
      "Epoch: 17 Train loss: 0.17591437006990115 test accuracy: 0.84225 time: 740.2894370555878\n",
      "Epoch: 18 Train loss: 0.16592046849429606 test accuracy: 0.85 time: 783.2719316482544\n",
      "Epoch: 19 Train loss: 0.1505686341226101 test accuracy: 0.85675 time: 826.3857574462891\n",
      "Epoch: 20 Train loss: 0.14419117957353592 test accuracy: 0.847 time: 869.6495373249054\n",
      "Epoch: 21 Train loss: 0.13145951511959234 test accuracy: 0.84575 time: 912.6517663002014\n",
      "Epoch: 22 Train loss: 0.12607931952923537 test accuracy: 0.85425 time: 955.4191765785217\n",
      "Epoch: 23 Train loss: 0.12467762945840756 test accuracy: 0.8475 time: 998.3704907894135\n",
      "Epoch: 24 Train loss: 0.11253495288391908 test accuracy: 0.859 time: 1041.504203081131\n",
      "Epoch: 25 Train loss: 0.10715094420438011 test accuracy: 0.8485 time: 1084.3894214630127\n",
      "Epoch: 26 Train loss: 0.10112413415064414 test accuracy: 0.85675 time: 1127.0984091758728\n",
      "Epoch: 27 Train loss: 0.0991331036388874 test accuracy: 0.849 time: 1170.0834684371948\n",
      "Epoch: 28 Train loss: 0.09430312676976124 test accuracy: 0.856 time: 1213.336033821106\n",
      "Epoch: 29 Train loss: 0.09184608731418847 test accuracy: 0.8625 time: 1256.2617251873016\n",
      "Epoch: 30 Train loss: 0.08742289117226998 test accuracy: 0.85375 time: 1299.2260103225708\n",
      "Epoch: 31 Train loss: 0.08179828974728783 test accuracy: 0.8595 time: 1342.137639284134\n",
      "Epoch: 32 Train loss: 0.08109301854545871 test accuracy: 0.85 time: 1385.0713324546814\n",
      "Epoch: 33 Train loss: 0.07854966117069125 test accuracy: 0.86025 time: 1427.8532721996307\n",
      "Epoch: 34 Train loss: 0.07418338392550747 test accuracy: 0.85675 time: 1470.579950094223\n",
      "Epoch: 35 Train loss: 0.07545937073106566 test accuracy: 0.863 time: 1513.4871881008148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.863"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correct order of bn, relu, without final pooling layer\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(64)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn5=nn.BatchNorm2d(128)\n",
    "        self.bn6=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn7=nn.BatchNorm2d(256)\n",
    "        self.bn8=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc0=nn.Linear(4096,256)\n",
    "        #self.fc1=nn.Linear(1024,512)\n",
    "        #self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X)))))))\n",
    "        X=self.p2(F.relu(self.bn4(self.c4(F.relu(self.bn3(self.c3(X)))))))\n",
    "        X=self.p2(F.relu(self.bn6(self.c6(F.relu(self.bn5(self.c5(X)))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn8(self.c8(F.relu(self.bn7(self.c7(X))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,256*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(self.dropout(F.relu(self.fc0(X))))))))\n",
    "        return X\n",
    "\n",
    "print(sum(p.numel() for p in CNN().parameters()))         \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2559850\n",
      "Epoch: 1 Train loss: 1.3607045358419418 test accuracy: 0.64725 time: 52.87334609031677\n",
      "Epoch: 2 Train loss: 0.8794887208938599 test accuracy: 0.75225 time: 96.33597707748413\n",
      "Epoch: 3 Train loss: 0.6923429859677951 test accuracy: 0.78075 time: 139.19944024085999\n",
      "Epoch: 4 Train loss: 0.5778747869531313 test accuracy: 0.80675 time: 182.49507856369019\n",
      "Epoch: 5 Train loss: 0.5059599234660467 test accuracy: 0.8065 time: 225.50992894172668\n",
      "Epoch: 6 Train loss: 0.44483218481143316 test accuracy: 0.816 time: 268.3812630176544\n",
      "Epoch: 7 Train loss: 0.39164197598894435 test accuracy: 0.82775 time: 311.50412487983704\n",
      "Epoch: 8 Train loss: 0.3543466098109881 test accuracy: 0.82025 time: 354.443395614624\n",
      "Epoch: 9 Train loss: 0.32072503979007405 test accuracy: 0.84325 time: 397.5127692222595\n",
      "Epoch: 10 Train loss: 0.29331698154409724 test accuracy: 0.84525 time: 440.9784345626831\n",
      "Epoch: 11 Train loss: 0.2630017728358507 test accuracy: 0.83825 time: 484.1547648906708\n",
      "Epoch: 12 Train loss: 0.24710284516215325 test accuracy: 0.83125 time: 527.1106054782867\n",
      "Epoch: 13 Train loss: 0.2218611174573501 test accuracy: 0.84825 time: 570.6764576435089\n",
      "Epoch: 14 Train loss: 0.2051059026022752 test accuracy: 0.85275 time: 613.6814200878143\n",
      "Epoch: 15 Train loss: 0.18926862080891926 test accuracy: 0.84825 time: 656.9545867443085\n",
      "Epoch: 16 Train loss: 0.177959673255682 test accuracy: 0.85525 time: 699.917918920517\n",
      "Epoch: 17 Train loss: 0.16434234348436197 test accuracy: 0.8555 time: 742.8186767101288\n",
      "Epoch: 18 Train loss: 0.15075571954250336 test accuracy: 0.8645 time: 785.9386649131775\n",
      "Epoch: 19 Train loss: 0.1429045787702004 test accuracy: 0.8625 time: 828.9410099983215\n",
      "Epoch: 20 Train loss: 0.13303085811436177 test accuracy: 0.86575 time: 871.8983552455902\n",
      "Epoch: 21 Train loss: 0.12033707071095705 test accuracy: 0.8635 time: 915.0980024337769\n",
      "Epoch: 22 Train loss: 0.114659745550404 test accuracy: 0.86175 time: 958.0137295722961\n",
      "Epoch: 23 Train loss: 0.10861823213597138 test accuracy: 0.8665 time: 1000.9082069396973\n",
      "Epoch: 24 Train loss: 0.10304050472875437 test accuracy: 0.8565 time: 1044.0894746780396\n",
      "Epoch: 25 Train loss: 0.10052857119590045 test accuracy: 0.86 time: 1087.0056450366974\n",
      "Epoch: 26 Train loss: 0.09374332730968793 test accuracy: 0.8655 time: 1130.0733091831207\n",
      "Epoch: 27 Train loss: 0.08976499689742923 test accuracy: 0.8695 time: 1173.6960248947144\n",
      "Epoch: 28 Train loss: 0.08869016016523043 test accuracy: 0.85675 time: 1216.488079547882\n",
      "Epoch: 29 Train loss: 0.08642172327886025 test accuracy: 0.8685 time: 1259.6372420787811\n",
      "Epoch: 30 Train loss: 0.08123434140657385 test accuracy: 0.85975 time: 1303.1160941123962\n",
      "Epoch: 31 Train loss: 0.07910170279753705 test accuracy: 0.865 time: 1346.1572427749634\n",
      "Epoch: 32 Train loss: 0.07182530745243033 test accuracy: 0.86525 time: 1389.545604467392\n",
      "Epoch: 33 Train loss: 0.07333144160918892 test accuracy: 0.86 time: 1432.5153970718384\n",
      "Epoch: 34 Train loss: 0.07096553504467011 test accuracy: 0.8625 time: 1475.4880588054657\n",
      "Epoch: 35 Train loss: 0.06708891605337461 test accuracy: 0.867 time: 1518.7488462924957\n",
      "Epoch: 36 Train loss: 0.06813844711830219 test accuracy: 0.871 time: 1561.6381387710571\n",
      "Epoch: 37 Train loss: 0.06388068047352136 test accuracy: 0.87075 time: 1604.7357952594757\n",
      "Epoch: 38 Train loss: 0.06221945983978609 test accuracy: 0.87075 time: 1648.1833548545837\n",
      "Epoch: 39 Train loss: 0.060233460403978825 test accuracy: 0.86975 time: 1691.3865773677826\n",
      "Epoch: 40 Train loss: 0.05913487582001835 test accuracy: 0.864 time: 1734.395474910736\n",
      "Epoch: 41 Train loss: 0.055409992737695576 test accuracy: 0.8685 time: 1777.4628374576569\n",
      "Epoch: 42 Train loss: 0.05376456206043561 test accuracy: 0.867 time: 1820.4449870586395\n",
      "Epoch: 43 Train loss: 0.053834014683961866 test accuracy: 0.871 time: 1863.3160905838013\n",
      "Epoch: 44 Train loss: 0.05640489845536649 test accuracy: 0.87125 time: 1906.405532836914\n",
      "Epoch: 45 Train loss: 0.04905956991482526 test accuracy: 0.87075 time: 1949.4368793964386\n",
      "Epoch: 46 Train loss: 0.049969979976303876 test accuracy: 0.86725 time: 1992.5880763530731\n",
      "Epoch: 47 Train loss: 0.05232702383926759 test accuracy: 0.86725 time: 2035.4577877521515\n",
      "Epoch: 48 Train loss: 0.04826287416741252 test accuracy: 0.86425 time: 2078.434970855713\n",
      "Epoch: 49 Train loss: 0.04629591194757571 test accuracy: 0.87025 time: 2121.8726682662964\n",
      "Epoch: 50 Train loss: 0.04702220280111457 test accuracy: 0.862 time: 2164.808534145355\n",
      "Epoch: 51 Train loss: 0.04744903869150827 test accuracy: 0.8665 time: 2207.7332530021667\n",
      "Epoch: 52 Train loss: 0.04340009820026656 test accuracy: 0.85975 time: 2250.979046344757\n",
      "Epoch: 53 Train loss: 0.04381573122305175 test accuracy: 0.878 time: 2293.976441383362\n",
      "Epoch: 54 Train loss: 0.044685815307311715 test accuracy: 0.868 time: 2337.50426530838\n",
      "Epoch: 55 Train loss: 0.04313525821237514 test accuracy: 0.865 time: 2380.7305397987366\n",
      "Epoch: 56 Train loss: 0.04122378481707225 test accuracy: 0.86475 time: 2424.1014659404755\n",
      "Epoch: 57 Train loss: 0.041180064288588863 test accuracy: 0.86325 time: 2467.3002564907074\n",
      "Epoch: 58 Train loss: 0.03879283577979853 test accuracy: 0.873 time: 2510.3219273090363\n",
      "Epoch: 59 Train loss: 0.039413635969006766 test accuracy: 0.86975 time: 2553.2129492759705\n",
      "Epoch: 60 Train loss: 0.03934335840322698 test accuracy: 0.8685 time: 2596.336942911148\n",
      "Epoch: 61 Train loss: 0.03870015965231384 test accuracy: 0.8715 time: 2639.342328310013\n",
      "Epoch: 62 Train loss: 0.03805428289653112 test accuracy: 0.8715 time: 2682.3161103725433\n",
      "Epoch: 63 Train loss: 0.03831408643745817 test accuracy: 0.86725 time: 2725.5487744808197\n",
      "Epoch: 64 Train loss: 0.03506117096170783 test accuracy: 0.8745 time: 2768.5708808898926\n",
      "Epoch: 65 Train loss: 0.036525074644790344 test accuracy: 0.87025 time: 2811.354856967926\n",
      "Epoch: 66 Train loss: 0.0366686844965443 test accuracy: 0.8695 time: 2854.6828939914703\n",
      "Epoch: 67 Train loss: 0.030530076125481476 test accuracy: 0.875 time: 2897.768222093582\n",
      "Epoch: 68 Train loss: 0.03655464325721065 test accuracy: 0.8735 time: 2940.924610376358\n",
      "Epoch: 69 Train loss: 0.0366073434233355 test accuracy: 0.86575 time: 2983.9772820472717\n",
      "Epoch: 70 Train loss: 0.03318960465413208 test accuracy: 0.87875 time: 3026.9569053649902\n",
      "Epoch: 71 Train loss: 0.03283634699648246 test accuracy: 0.87675 time: 3070.2644412517548\n",
      "Epoch: 72 Train loss: 0.03269316969051336 test accuracy: 0.86925 time: 3113.2999238967896\n",
      "Epoch: 73 Train loss: 0.03069459626994406 test accuracy: 0.87225 time: 3156.352303504944\n",
      "Epoch: 74 Train loss: 0.03143055956500272 test accuracy: 0.8725 time: 3199.599447488785\n",
      "Epoch: 75 Train loss: 0.032548843114636836 test accuracy: 0.8745 time: 3242.4602601528168\n",
      "Epoch: 76 Train loss: 0.03022237602621317 test accuracy: 0.876 time: 3285.395174741745\n",
      "Epoch: 77 Train loss: 0.029326923255963873 test accuracy: 0.8715 time: 3330.7995088100433\n",
      "Epoch: 78 Train loss: 0.02909941215844204 test accuracy: 0.87125 time: 3373.7730951309204\n",
      "Epoch: 79 Train loss: 0.028007711497290682 test accuracy: 0.881 time: 3417.0026626586914\n",
      "Epoch: 80 Train loss: 0.029275189661808934 test accuracy: 0.8715 time: 3460.093202352524\n",
      "Epoch: 81 Train loss: 0.028956210668353986 test accuracy: 0.8665 time: 3503.184413433075\n",
      "Epoch: 82 Train loss: 0.025488684888308247 test accuracy: 0.86525 time: 3546.2638463974\n",
      "Epoch: 83 Train loss: 0.030962099712342026 test accuracy: 0.87325 time: 3589.4344227313995\n",
      "Epoch: 84 Train loss: 0.029484665787313135 test accuracy: 0.87525 time: 3632.515393972397\n",
      "Epoch: 85 Train loss: 0.026834044359857215 test accuracy: 0.87 time: 3675.8481438159943\n",
      "Epoch: 86 Train loss: 0.027742695046278337 test accuracy: 0.8715 time: 3718.959520339966\n",
      "Epoch: 87 Train loss: 0.028011309676027548 test accuracy: 0.86625 time: 3761.9730846881866\n",
      "Epoch: 88 Train loss: 0.024404702769437184 test accuracy: 0.872 time: 3805.2454736232758\n",
      "Epoch: 89 Train loss: 0.028663569026393818 test accuracy: 0.8695 time: 3848.338267803192\n",
      "Epoch: 90 Train loss: 0.025462417606419572 test accuracy: 0.877 time: 3891.41673207283\n",
      "Epoch: 91 Train loss: 0.025314126508310438 test accuracy: 0.87225 time: 3934.7783925533295\n",
      "Epoch: 92 Train loss: 0.023269794129688912 test accuracy: 0.875 time: 3977.877518415451\n",
      "Epoch: 93 Train loss: 0.025978114099707454 test accuracy: 0.8725 time: 4021.1215171813965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94 Train loss: 0.025711217453548065 test accuracy: 0.87775 time: 4064.2302191257477\n",
      "Epoch: 95 Train loss: 0.02494154658750631 test accuracy: 0.8725 time: 4107.24671459198\n",
      "Epoch: 96 Train loss: 0.025571654172381386 test accuracy: 0.87275 time: 4150.6228132247925\n",
      "Epoch: 97 Train loss: 0.023556890472148855 test accuracy: 0.8645 time: 4193.705153465271\n",
      "Epoch: 98 Train loss: 0.023339419299348567 test accuracy: 0.879 time: 4236.942409276962\n",
      "Epoch: 99 Train loss: 0.02304256477645443 test accuracy: 0.87625 time: 4280.500133275986\n",
      "Epoch: 100 Train loss: 0.019854139522455322 test accuracy: 0.87625 time: 4323.983592748642\n",
      "Epoch: 101 Train loss: 0.021793302410903076 test accuracy: 0.875 time: 4367.11797952652\n",
      "Epoch: 102 Train loss: 0.027452337112821017 test accuracy: 0.88025 time: 4410.455096483231\n",
      "Epoch: 103 Train loss: 0.023470982927052925 test accuracy: 0.86875 time: 4453.637397289276\n",
      "Epoch: 104 Train loss: 0.025188836653251202 test accuracy: 0.87725 time: 4496.376274585724\n",
      "Epoch: 105 Train loss: 0.02159603608364705 test accuracy: 0.8775 time: 4539.258830308914\n",
      "Epoch: 106 Train loss: 0.020865951316081918 test accuracy: 0.87675 time: 4582.255661487579\n",
      "Epoch: 107 Train loss: 0.021834219529409893 test accuracy: 0.86975 time: 4625.126727342606\n",
      "Epoch: 108 Train loss: 0.024219217851447563 test accuracy: 0.87175 time: 4668.050763607025\n",
      "Epoch: 109 Train loss: 0.023270014534161117 test accuracy: 0.87775 time: 4710.802752733231\n",
      "Epoch: 110 Train loss: 0.021918118880324376 test accuracy: 0.8735 time: 4754.086849927902\n",
      "Epoch: 111 Train loss: 0.022024166700818266 test accuracy: 0.8735 time: 4797.039518594742\n",
      "Epoch: 112 Train loss: 0.022247960677098794 test accuracy: 0.87025 time: 4840.075503587723\n",
      "Epoch: 113 Train loss: 0.02105031639182319 test accuracy: 0.8715 time: 4883.303488731384\n",
      "Epoch: 114 Train loss: 0.021019767871087728 test accuracy: 0.877 time: 4926.183675289154\n",
      "Epoch: 115 Train loss: 0.018157006863427038 test accuracy: 0.8755 time: 4969.041330337524\n",
      "Epoch: 116 Train loss: 0.020385758831786612 test accuracy: 0.8755 time: 5012.224282503128\n",
      "Epoch: 117 Train loss: 0.020134559895377605 test accuracy: 0.873 time: 5055.120270252228\n",
      "Epoch: 118 Train loss: 0.021632491287309676 test accuracy: 0.87525 time: 5098.2281947135925\n",
      "Epoch: 119 Train loss: 0.019043151644485383 test accuracy: 0.875 time: 5141.177442550659\n",
      "Epoch: 120 Train loss: 0.02069488101580646 test accuracy: 0.8755 time: 5184.224973917007\n",
      "Epoch: 121 Train loss: 0.021766521331931774 test accuracy: 0.87875 time: 5227.724538564682\n",
      "Epoch: 122 Train loss: 0.019950568213049944 test accuracy: 0.8695 time: 5270.723685979843\n",
      "Epoch: 123 Train loss: 0.01996912946808152 test accuracy: 0.8725 time: 5313.834147930145\n",
      "Epoch: 124 Train loss: 0.020239141532219947 test accuracy: 0.87275 time: 5357.243505239487\n",
      "Epoch: 125 Train loss: 0.019458320812943082 test accuracy: 0.8795 time: 5400.053983926773\n",
      "Epoch: 126 Train loss: 0.016721704497079676 test accuracy: 0.87125 time: 5442.915345430374\n",
      "Epoch: 127 Train loss: 0.020223994682310148 test accuracy: 0.8775 time: 5486.351576089859\n",
      "Epoch: 128 Train loss: 0.017796319157738858 test accuracy: 0.8775 time: 5529.162812232971\n",
      "Epoch: 129 Train loss: 0.01940343915077392 test accuracy: 0.878 time: 5572.186686754227\n"
     ]
    }
   ],
   "source": [
    "#correct order of bn, relu\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(64)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn5=nn.BatchNorm2d(128)\n",
    "        self.bn6=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn7=nn.BatchNorm2d(256)\n",
    "        self.bn8=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc0=nn.Linear(4096,256)\n",
    "        #self.fc1=nn.Linear(1024,512)\n",
    "        #self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X)))))))\n",
    "        X=self.p2(F.relu(self.bn4(self.c4(F.relu(self.bn3(self.c3(X)))))))\n",
    "        X=self.p2(F.relu(self.bn6(self.c6(F.relu(self.bn5(self.c5(X)))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn8(self.c8(F.relu(self.bn7(self.c7(X))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,256*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(self.dropout(F.relu(self.fc0(X))))))))\n",
    "        return X\n",
    "\n",
    "print(sum(p.numel() for p in CNN().parameters()))         \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,120,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2459018\n",
      "Epoch: 1 Train loss: 1.450851461092631 test accuracy: 0.62525 time: 63.535900831222534\n",
      "Epoch: 2 Train loss: 0.9616206083695094 test accuracy: 0.72025 time: 117.05839419364929\n",
      "Epoch: 3 Train loss: 0.7602747307221095 test accuracy: 0.7555 time: 170.72761011123657\n",
      "Epoch: 4 Train loss: 0.639732506275177 test accuracy: 0.79225 time: 224.1498830318451\n",
      "Epoch: 5 Train loss: 0.5542400101820628 test accuracy: 0.80475 time: 278.01174116134644\n",
      "Epoch: 6 Train loss: 0.4826849776506424 test accuracy: 0.81025 time: 331.71610975265503\n",
      "Epoch: 7 Train loss: 0.43135447551806766 test accuracy: 0.81425 time: 385.6661765575409\n",
      "Epoch: 8 Train loss: 0.3954454564551512 test accuracy: 0.8315 time: 439.3413655757904\n",
      "Epoch: 9 Train loss: 0.35470233872532847 test accuracy: 0.834 time: 493.53022742271423\n",
      "Epoch: 10 Train loss: 0.32390610794226327 test accuracy: 0.84425 time: 547.0543341636658\n",
      "Epoch: 11 Train loss: 0.29574341759085654 test accuracy: 0.848 time: 600.6796436309814\n",
      "Epoch: 12 Train loss: 0.27130400761961937 test accuracy: 0.84475 time: 654.4470705986023\n",
      "Epoch: 13 Train loss: 0.2506125935415427 test accuracy: 0.846 time: 708.0689132213593\n",
      "Epoch: 14 Train loss: 0.23052560970187186 test accuracy: 0.85575 time: 761.7131278514862\n",
      "Epoch: 15 Train loss: 0.2139777688930432 test accuracy: 0.85625 time: 815.6746380329132\n",
      "Epoch: 16 Train loss: 0.20169791899621486 test accuracy: 0.865 time: 869.2813918590546\n",
      "Epoch: 17 Train loss: 0.18262263976037502 test accuracy: 0.857 time: 922.9882206916809\n",
      "Epoch: 18 Train loss: 0.1749237031241258 test accuracy: 0.861 time: 976.9686975479126\n",
      "Epoch: 19 Train loss: 0.16336656905710698 test accuracy: 0.85725 time: 1030.6496365070343\n",
      "Epoch: 20 Train loss: 0.15101052094250916 test accuracy: 0.86425 time: 1084.7399518489838\n",
      "Epoch: 21 Train loss: 0.1401055059581995 test accuracy: 0.85775 time: 1138.625022649765\n",
      "Epoch: 22 Train loss: 0.1319688381627202 test accuracy: 0.861 time: 1192.0738217830658\n",
      "Epoch: 23 Train loss: 0.13059522749235233 test accuracy: 0.86325 time: 1245.5480813980103\n",
      "Epoch: 24 Train loss: 0.11900664043923219 test accuracy: 0.871 time: 1299.2938132286072\n",
      "Epoch: 25 Train loss: 0.11289314682284991 test accuracy: 0.86625 time: 1352.8037192821503\n",
      "Epoch: 26 Train loss: 0.11428945634514093 test accuracy: 0.87225 time: 1406.3224716186523\n",
      "Epoch: 27 Train loss: 0.10541501360634963 test accuracy: 0.865 time: 1459.9139006137848\n",
      "Epoch: 28 Train loss: 0.09771719752500455 test accuracy: 0.867 time: 1513.2362530231476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87225"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.bn3=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c2_1=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.bn5=nn.BatchNorm2d(64)\n",
    "        self.bn6=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c4_1=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn7=nn.BatchNorm2d(128)\n",
    "        self.bn8=nn.BatchNorm2d(128)\n",
    "        self.bn9=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c6_1=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn10=nn.BatchNorm2d(256)\n",
    "        self.bn11=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc0=nn.Linear(4096,256)\n",
    "        #self.fc1=nn.Linear(1024,512)\n",
    "        #self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn3(self.c2_1(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X))))))))))\n",
    "        X=self.p2(F.relu(self.bn6(self.c4_1(F.relu(self.bn5(self.c4(F.relu(self.bn4(self.c3(X))))))))))\n",
    "        X=self.p2(F.relu(self.bn9(self.c6_1(F.relu(self.bn8(self.c6(F.relu(self.bn7(self.c5(X))))))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn11(self.c8(F.relu(self.bn10(self.c7(X))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,256*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(self.dropout(F.relu(self.fc0(X))))))))\n",
    "        return X\n",
    "        \n",
    "print(sum(p.numel() for p in CNN().parameters())) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)           \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2459018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.4822894461949667 test accuracy: 0.59275 time: 62.95367455482483\n",
      "Epoch: 2 Train loss: 1.0307214804490408 test accuracy: 0.69325 time: 116.73873734474182\n",
      "Epoch: 3 Train loss: 0.842994679013888 test accuracy: 0.73025 time: 170.15671801567078\n",
      "Epoch: 4 Train loss: 0.7084760605295499 test accuracy: 0.774 time: 223.8081512451172\n",
      "Epoch: 5 Train loss: 0.6096944323182106 test accuracy: 0.782 time: 277.23688197135925\n",
      "Epoch: 6 Train loss: 0.5341667810082436 test accuracy: 0.8035 time: 330.42750883102417\n",
      "Epoch: 7 Train loss: 0.4860285226504008 test accuracy: 0.8155 time: 384.10822105407715\n",
      "Epoch: 8 Train loss: 0.43990615804990135 test accuracy: 0.82375 time: 437.5238401889801\n",
      "Epoch: 9 Train loss: 0.40424713551998137 test accuracy: 0.82225 time: 491.1032028198242\n",
      "Epoch: 10 Train loss: 0.3704437717795372 test accuracy: 0.83125 time: 544.4776363372803\n",
      "Epoch: 11 Train loss: 0.33997236917416257 test accuracy: 0.82875 time: 598.1520531177521\n",
      "Epoch: 12 Train loss: 0.3136888020733992 test accuracy: 0.836 time: 651.5757727622986\n",
      "Epoch: 13 Train loss: 0.29094319785634676 test accuracy: 0.84525 time: 705.2292633056641\n",
      "Epoch: 14 Train loss: 0.2698780963321527 test accuracy: 0.85275 time: 758.975930929184\n",
      "Epoch: 15 Train loss: 0.2561089907089869 test accuracy: 0.84475 time: 812.5241363048553\n",
      "Epoch: 16 Train loss: 0.23332243834932645 test accuracy: 0.8425 time: 866.4126765727997\n",
      "Epoch: 17 Train loss: 0.22500369471808274 test accuracy: 0.84675 time: 920.0241956710815\n",
      "Epoch: 18 Train loss: 0.20912173991401992 test accuracy: 0.8525 time: 973.7187464237213\n",
      "Epoch: 19 Train loss: 0.19526385374367236 test accuracy: 0.8505 time: 1027.3513116836548\n",
      "Epoch: 22 Train loss: 0.16485108102361362 test accuracy: 0.8615 time: 1188.267422914505\n",
      "Epoch: 23 Train loss: 0.15437545597553254 test accuracy: 0.863 time: 1241.915020942688\n",
      "Epoch: 24 Train loss: 0.1483561668669184 test accuracy: 0.855 time: 1295.4515607357025\n",
      "Epoch: 25 Train loss: 0.13991107052812973 test accuracy: 0.86425 time: 1349.1220457553864\n",
      "Epoch: 26 Train loss: 0.1331653806194663 test accuracy: 0.87175 time: 1402.7978036403656\n",
      "Epoch: 27 Train loss: 0.12246123585850001 test accuracy: 0.871 time: 1456.5029525756836\n",
      "Epoch: 28 Train loss: 0.11974634446203708 test accuracy: 0.86475 time: 1510.182288646698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87175"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.bn3=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c2_1=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.bn5=nn.BatchNorm2d(64)\n",
    "        self.bn6=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c4_1=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn7=nn.BatchNorm2d(128)\n",
    "        self.bn8=nn.BatchNorm2d(128)\n",
    "        self.bn9=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c6_1=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn10=nn.BatchNorm2d(256)\n",
    "        self.bn11=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc0=nn.Linear(4096,256)\n",
    "        #self.fc1=nn.Linear(1024,512)\n",
    "        #self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout2=nn.Dropout(.2)\n",
    "        self.dropout1=nn.Dropout(0.1)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(self.dropout1(F.relu(self.bn3(self.c2_1(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X)))))))))))\n",
    "        X=self.p2(self.dropout1(F.relu(self.bn6(self.c4_1(F.relu(self.bn5(self.c4(F.relu(self.bn4(self.c3(X)))))))))))\n",
    "        X=self.p2(self.dropout1(F.relu(self.bn9(self.c6_1(F.relu(self.bn8(self.c6(F.relu(self.bn7(self.c5(X)))))))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn11(self.c8(F.relu(self.bn10(self.c7(X))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,256*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(self.dropout2(F.relu(self.fc0(X))))))))\n",
    "        return X\n",
    "        \n",
    "print(sum(p.numel() for p in CNN().parameters())) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2459018\n",
      "Epoch: 1 Train loss: 1.5355374292532602 test accuracy: 0.56975 time: 63.25798487663269\n",
      "Epoch: 2 Train loss: 1.0805088192224503 test accuracy: 0.67275 time: 116.5919668674469\n",
      "Epoch: 3 Train loss: 0.8858270704746246 test accuracy: 0.7235 time: 169.8277771472931\n",
      "Epoch: 4 Train loss: 0.7490988618135452 test accuracy: 0.7595 time: 223.25267457962036\n",
      "Epoch: 5 Train loss: 0.6575749817490578 test accuracy: 0.77575 time: 276.5029857158661\n",
      "Epoch: 6 Train loss: 0.5864034752051036 test accuracy: 0.80025 time: 329.9797692298889\n",
      "Epoch: 7 Train loss: 0.5275732321540515 test accuracy: 0.808 time: 382.94322872161865\n",
      "Epoch: 8 Train loss: 0.48133036146561303 test accuracy: 0.80975 time: 436.4385850429535\n",
      "Epoch: 9 Train loss: 0.44545238703489304 test accuracy: 0.82425 time: 489.62915802001953\n",
      "Epoch: 10 Train loss: 0.4174853945771853 test accuracy: 0.824 time: 542.9799544811249\n",
      "Epoch: 11 Train loss: 0.38410318061709403 test accuracy: 0.8225 time: 595.8147962093353\n",
      "Epoch: 12 Train loss: 0.36161804884672166 test accuracy: 0.82875 time: 649.0754306316376\n",
      "Epoch: 13 Train loss: 0.3384673743446668 test accuracy: 0.8395 time: 702.1563808917999\n",
      "Epoch: 14 Train loss: 0.31361465180913606 test accuracy: 0.84075 time: 755.4908792972565\n",
      "Epoch: 15 Train loss: 0.30613791674375535 test accuracy: 0.84575 time: 808.954268693924\n",
      "Epoch: 16 Train loss: 0.2828738342225552 test accuracy: 0.84775 time: 862.1518733501434\n",
      "Epoch: 17 Train loss: 0.2629381436109543 test accuracy: 0.8475 time: 915.455691576004\n",
      "Epoch: 18 Train loss: 0.24946377923091254 test accuracy: 0.84925 time: 968.5350856781006\n",
      "Epoch: 19 Train loss: 0.2352306575824817 test accuracy: 0.843 time: 1022.1671245098114\n",
      "Epoch: 20 Train loss: 0.2293968383471171 test accuracy: 0.86225 time: 1075.3945581912994\n",
      "Epoch: 21 Train loss: 0.21229622299472492 test accuracy: 0.862 time: 1128.8465564250946\n",
      "Epoch: 22 Train loss: 0.19346015038589637 test accuracy: 0.8645 time: 1182.2932765483856\n",
      "Epoch: 23 Train loss: 0.19079465128481388 test accuracy: 0.8615 time: 1235.7649064064026\n",
      "Epoch: 24 Train loss: 0.18166611020763715 test accuracy: 0.85875 time: 1289.3016662597656\n",
      "Epoch: 25 Train loss: 0.17280129993955295 test accuracy: 0.85275 time: 1342.6889309883118\n",
      "Epoch: 26 Train loss: 0.1651641248166561 test accuracy: 0.8645 time: 1396.4722218513489\n",
      "Epoch: 27 Train loss: 0.1544462601095438 test accuracy: 0.866 time: 1450.4126996994019\n",
      "Epoch: 28 Train loss: 0.14794413280983765 test accuracy: 0.8615 time: 1504.0851492881775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.866"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.bn3=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c2_1=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.bn5=nn.BatchNorm2d(64)\n",
    "        self.bn6=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c4_1=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn7=nn.BatchNorm2d(128)\n",
    "        self.bn8=nn.BatchNorm2d(128)\n",
    "        self.bn9=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c6_1=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn10=nn.BatchNorm2d(256)\n",
    "        self.bn11=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc0=nn.Linear(4096,256)\n",
    "        #self.fc1=nn.Linear(1024,512)\n",
    "        #self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn3(self.c2_1(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X))))))))))\n",
    "        X=self.p2(F.relu(self.bn6(self.c4_1(F.relu(self.bn5(self.c4(F.relu(self.bn4(self.c3(X))))))))))\n",
    "        X=self.p2(F.relu(self.bn9(self.c6_1(F.relu(self.bn8(self.c6(F.relu(self.bn7(self.c5(X))))))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn11(self.c8(F.relu(self.bn10(self.c7(X))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,256*4*4)\n",
    "\n",
    "        X=self.fc5(torch.tanh(self.fc4(torch.tanh(self.fc3(self.dropout(torch.tanh(self.fc0(X))))))))\n",
    "        return X\n",
    "        \n",
    "print(sum(p.numel() for p in CNN().parameters())) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)           \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2459018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.438898610472679 test accuracy: 0.59175 time: 66.399010181427\n",
      "Epoch: 2 Train loss: 1.0483637976646423 test accuracy: 0.68 time: 119.38237476348877\n",
      "Epoch: 3 Train loss: 0.8694466978311539 test accuracy: 0.73025 time: 172.44319224357605\n",
      "Epoch: 4 Train loss: 0.7649493632713954 test accuracy: 0.7415 time: 225.37091851234436\n",
      "Epoch: 5 Train loss: 0.6915572297573089 test accuracy: 0.76225 time: 278.5644516944885\n",
      "Epoch: 6 Train loss: 0.6322610051433245 test accuracy: 0.7795 time: 331.52440905570984\n",
      "Epoch: 7 Train loss: 0.5919170225660007 test accuracy: 0.79225 time: 384.95575761795044\n",
      "Epoch: 8 Train loss: 0.54450227389733 test accuracy: 0.798 time: 437.9248631000519\n",
      "Epoch: 9 Train loss: 0.5142250639200211 test accuracy: 0.80625 time: 490.8916778564453\n",
      "Epoch: 10 Train loss: 0.47853585849205654 test accuracy: 0.816 time: 544.1745204925537\n",
      "Epoch: 11 Train loss: 0.44956462254126867 test accuracy: 0.81875 time: 597.224761724472\n",
      "Epoch: 12 Train loss: 0.4175583275655905 test accuracy: 0.80525 time: 650.3768241405487\n",
      "Epoch: 13 Train loss: 0.4013267810146014 test accuracy: 0.8245 time: 703.2276077270508\n",
      "Epoch: 14 Train loss: 0.3770561733345191 test accuracy: 0.83075 time: 756.3208703994751\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.2520822.pbshpc/ipykernel_32643/3531302907.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/tmp/pbs.2520822.pbshpc/ipykernel_32643/3675889058.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cnn, train_data, epochs, opt, loss, test_data, n, b, t)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m#print(X.shape,y.shape,type(X),type(y))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0myh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.bn3=nn.BatchNorm2d(32)\n",
    "        self.elu=nn.ELU()\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c2_1=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.bn5=nn.BatchNorm2d(64)\n",
    "        self.bn6=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c4_1=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn7=nn.BatchNorm2d(128)\n",
    "        self.bn8=nn.BatchNorm2d(128)\n",
    "        self.bn9=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c6_1=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn10=nn.BatchNorm2d(256)\n",
    "        self.bn11=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc0=nn.Linear(4096,256)\n",
    "        #self.fc1=nn.Linear(1024,512)\n",
    "        #self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "        self.elu \n",
    "    def forward(self,X):\n",
    "        X=self.p2(self.elu(self.bn3(self.c2_1(self.elu(self.bn2(self.c2(self.elu(self.bn1(self.c1(X))))))))))\n",
    "        X=self.p2(self.elu(self.bn6(self.c4_1(self.elu(self.bn5(self.c4(self.elu(self.bn4(self.c3(X))))))))))\n",
    "        X=self.p2(self.elu(self.bn9(self.c6_1(self.elu(self.bn8(self.c6(self.elu(self.bn7(self.c5(X))))))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn11(self.c8(self.elu(self.bn10(self.c7(X))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,256*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(self.dropout(F.relu(self.fc0(X))))))))\n",
    "        return X\n",
    "        \n",
    "print(sum(p.numel() for p in CNN().parameters())) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)           \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2788234\n",
      "Epoch: 1 Train loss: 1.6436848982175192 test accuracy: 0.51275 time: 72.93217277526855\n",
      "Epoch: 2 Train loss: 1.189873073498408 test accuracy: 0.635 time: 135.62862396240234\n",
      "Epoch: 3 Train loss: 0.9592708752552668 test accuracy: 0.696 time: 198.5220193862915\n",
      "Epoch: 4 Train loss: 0.817539168993632 test accuracy: 0.7355 time: 261.34761810302734\n",
      "Epoch: 5 Train loss: 0.7145215961337089 test accuracy: 0.755 time: 324.4489595890045\n",
      "Epoch: 6 Train loss: 0.6337214110294977 test accuracy: 0.783 time: 387.26079773902893\n",
      "Epoch: 7 Train loss: 0.5729835919539134 test accuracy: 0.78625 time: 449.96434903144836\n",
      "Epoch: 8 Train loss: 0.5112879986564318 test accuracy: 0.7965 time: 512.6293034553528\n",
      "Epoch: 9 Train loss: 0.46904434740543366 test accuracy: 0.804 time: 575.6947779655457\n",
      "Epoch: 10 Train loss: 0.4299485403299332 test accuracy: 0.8045 time: 638.9803736209869\n",
      "Epoch: 11 Train loss: 0.394980881412824 test accuracy: 0.816 time: 701.6833937168121\n",
      "Epoch: 12 Train loss: 0.36535891344149907 test accuracy: 0.812 time: 764.6295013427734\n",
      "Epoch: 13 Train loss: 0.3400711823999882 test accuracy: 0.8195 time: 827.5274496078491\n",
      "Epoch: 14 Train loss: 0.3139818685253461 test accuracy: 0.8275 time: 890.4161486625671\n",
      "Epoch: 15 Train loss: 0.29463625892996786 test accuracy: 0.82925 time: 953.0670561790466\n",
      "Epoch: 16 Train loss: 0.2733563695847988 test accuracy: 0.82975 time: 1016.217931509018\n",
      "Epoch: 17 Train loss: 0.25390786801775295 test accuracy: 0.835 time: 1078.8713579177856\n",
      "Epoch: 18 Train loss: 0.23759765326976776 test accuracy: 0.83275 time: 1142.0399422645569\n",
      "Epoch: 19 Train loss: 0.22587812937796115 test accuracy: 0.83525 time: 1204.927329301834\n",
      "Epoch: 20 Train loss: 0.2139531712482373 test accuracy: 0.82725 time: 1267.9477598667145\n",
      "Epoch: 21 Train loss: 0.19612983067830403 test accuracy: 0.839 time: 1330.8437085151672\n",
      "Epoch: 22 Train loss: 0.1894396411627531 test accuracy: 0.841 time: 1393.65127825737\n",
      "Epoch: 23 Train loss: 0.17737857438623905 test accuracy: 0.8445 time: 1456.7931988239288\n",
      "Epoch: 24 Train loss: 0.1690837720533212 test accuracy: 0.84125 time: 1519.6390552520752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8445"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Added extra convolution layers: c2_1,c4_1,c6_1\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,5,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.bn3=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,5,padding='same')\n",
    "        self.c2_1=nn.Conv2d(32,32,5,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,5,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.bn5=nn.BatchNorm2d(64)\n",
    "        self.bn6=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,5,padding='same')\n",
    "        self.c4_1=nn.Conv2d(64,64,5,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,5,padding='same')\n",
    "        self.bn7=nn.BatchNorm2d(128)\n",
    "        self.bn8=nn.BatchNorm2d(128)\n",
    "        self.bn9=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c6_1=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn10=nn.BatchNorm2d(256)\n",
    "        self.bn11=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc0=nn.Linear(4096,256)\n",
    "        #self.fc1=nn.Linear(1024,512)\n",
    "        #self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn3(self.c2_1(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X))))))))))\n",
    "        X=self.p2(F.relu(self.bn6(self.c4_1(F.relu(self.bn5(self.c4(F.relu(self.bn4(self.c3(X))))))))))\n",
    "        X=self.p2(F.relu(self.bn9(self.c6_1(F.relu(self.bn8(self.c6(F.relu(self.bn7(self.c5(X))))))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn11(self.c8(F.relu(self.bn10(self.c7(X))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,256*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(self.dropout(F.relu(self.fc0(X))))))))\n",
    "        return X\n",
    "        \n",
    "print(sum(p.numel() for p in CNN().parameters())) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)           \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2426218\n",
      "Epoch: 1 Train loss: 1.6513421432177227 test accuracy: 0.4915 time: 57.65009093284607\n",
      "Epoch: 2 Train loss: 1.203518313964208 test accuracy: 0.6245 time: 105.00208759307861\n",
      "Epoch: 3 Train loss: 0.9589283692836762 test accuracy: 0.712 time: 152.9525716304779\n",
      "Epoch: 4 Train loss: 0.790394211212794 test accuracy: 0.7585 time: 200.8481228351593\n",
      "Epoch: 5 Train loss: 0.6848483251531919 test accuracy: 0.7795 time: 248.81889653205872\n",
      "Epoch: 6 Train loss: 0.5997768126924833 test accuracy: 0.79575 time: 296.6018617153168\n",
      "Epoch: 7 Train loss: 0.5342201048135757 test accuracy: 0.79775 time: 344.31335496902466\n",
      "Epoch: 8 Train loss: 0.48334344377120336 test accuracy: 0.80575 time: 391.8602075576782\n",
      "Epoch: 9 Train loss: 0.44099754353364307 test accuracy: 0.81475 time: 439.4571897983551\n",
      "Epoch: 10 Train loss: 0.4008863304555416 test accuracy: 0.818 time: 487.0986409187317\n",
      "Epoch: 11 Train loss: 0.36576675886909166 test accuracy: 0.83325 time: 534.611346244812\n",
      "Epoch: 12 Train loss: 0.33703113968173665 test accuracy: 0.83125 time: 582.2222745418549\n",
      "Epoch: 13 Train loss: 0.31743535021940866 test accuracy: 0.845 time: 630.0950829982758\n",
      "Epoch: 14 Train loss: 0.29195328081647554 test accuracy: 0.8415 time: 677.8516261577606\n",
      "Epoch: 15 Train loss: 0.2729802282651265 test accuracy: 0.84425 time: 725.2123394012451\n",
      "Epoch: 16 Train loss: 0.2503460975488027 test accuracy: 0.846 time: 773.0921235084534\n",
      "Epoch: 17 Train loss: 0.23504345660408338 test accuracy: 0.845 time: 820.8256497383118\n",
      "Epoch: 18 Train loss: 0.22828949600458145 test accuracy: 0.848 time: 868.507241487503\n",
      "Epoch: 19 Train loss: 0.2124266768246889 test accuracy: 0.8395 time: 916.1012082099915\n",
      "Epoch: 20 Train loss: 0.1941870219508807 test accuracy: 0.85425 time: 963.6312046051025\n",
      "Epoch: 21 Train loss: 0.18559881153206031 test accuracy: 0.84275 time: 1011.3078866004944\n",
      "Epoch: 22 Train loss: 0.17554944867889086 test accuracy: 0.856 time: 1058.8619439601898\n",
      "Epoch: 23 Train loss: 0.16704472906887533 test accuracy: 0.85275 time: 1106.5577006340027\n",
      "Epoch: 24 Train loss: 0.15937973394989968 test accuracy: 0.85025 time: 1154.0625336170197\n",
      "Epoch: 25 Train loss: 0.14907831036796174 test accuracy: 0.85075 time: 1201.5205645561218\n",
      "Epoch: 26 Train loss: 0.1453251276910305 test accuracy: 0.85325 time: 1249.2537360191345\n",
      "Epoch: 27 Train loss: 0.1352941297988097 test accuracy: 0.8505 time: 1296.974628686905\n",
      "Epoch: 28 Train loss: 0.12860713120549916 test accuracy: 0.86125 time: 1344.6046795845032\n",
      "Epoch: 29 Train loss: 0.12030344605445861 test accuracy: 0.859 time: 1392.251532793045\n",
      "Epoch: 30 Train loss: 0.12287285619725784 test accuracy: 0.859 time: 1439.5748481750488\n",
      "Epoch: 31 Train loss: 0.10930499333888292 test accuracy: 0.856 time: 1486.9691689014435\n",
      "Epoch: 32 Train loss: 0.10546929839377601 test accuracy: 0.8595 time: 1534.64341878891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86125"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modified  FCN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        #self.c2_1=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(64)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        #self.c4_1=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn5=nn.BatchNorm2d(128)\n",
    "        self.bn6=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        #self.c6_1=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn7=nn.BatchNorm2d(256)\n",
    "        self.bn8=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        self.bn9=nn.BatchNorm2d(128)\n",
    "        self.c10=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.bn10=nn.BatchNorm2d(128)\n",
    "        self.c11=nn.Conv2d(128,64,3,padding='same')\n",
    "        self.bn11=nn.BatchNorm2d(64)\n",
    "        self.c12=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.bn12=nn.BatchNorm2d(64)\n",
    "        \n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        #self.fc0=nn.Linear(4096,256)\n",
    "        self.fc1=nn.Linear(1024,512)\n",
    "        self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X)))))))\n",
    "        X=self.p2(F.relu(self.bn4(self.c4(F.relu(self.bn3(self.c3(X)))))))\n",
    "        X=self.p2(F.relu(self.bn6(self.c6(F.relu(self.bn5(self.c5(X)))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn8(self.c8(F.relu(self.bn7(self.c7(X))))))\n",
    "        X=F.relu(self.bn10(self.c10(F.relu(self.bn9(self.c9(X))))))\n",
    "        X=F.relu(self.bn12(self.c12(F.relu(self.bn11(self.c11(X))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,64*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(F.relu(self.fc2(self.dropout(F.relu(self.fc1(X))))))))))\n",
    "        return X\n",
    "    \n",
    "print(sum(p.numel() for p in CNN().parameters())) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2426218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.60029124101003 test accuracy: 0.54525 time: 60.52647042274475\n",
      "Epoch: 2 Train loss: 1.0983395208915074 test accuracy: 0.679 time: 107.9574613571167\n",
      "Epoch: 3 Train loss: 0.8555484028657278 test accuracy: 0.74425 time: 155.2199945449829\n",
      "Epoch: 4 Train loss: 0.7183110998074214 test accuracy: 0.78175 time: 202.86077690124512\n",
      "Epoch: 5 Train loss: 0.6247893076141675 test accuracy: 0.78775 time: 250.49664735794067\n",
      "Epoch: 6 Train loss: 0.5538546338677406 test accuracy: 0.8055 time: 298.2181704044342\n",
      "Epoch: 7 Train loss: 0.49768567403157554 test accuracy: 0.8165 time: 345.8945918083191\n",
      "Epoch: 8 Train loss: 0.4534325263897578 test accuracy: 0.813 time: 393.5196602344513\n",
      "Epoch: 9 Train loss: 0.4192682913939158 test accuracy: 0.82175 time: 441.3454728126526\n",
      "Epoch: 10 Train loss: 0.3784266367057959 test accuracy: 0.82975 time: 489.11904406547546\n",
      "Epoch: 11 Train loss: 0.34607970411578814 test accuracy: 0.83825 time: 537.1548166275024\n",
      "Epoch: 12 Train loss: 0.3217829174300035 test accuracy: 0.83575 time: 584.8296208381653\n",
      "Epoch: 13 Train loss: 0.2983213572204113 test accuracy: 0.844 time: 632.524652004242\n",
      "Epoch: 14 Train loss: 0.2754682623843352 test accuracy: 0.84175 time: 680.3838591575623\n",
      "Epoch: 15 Train loss: 0.25444539219141005 test accuracy: 0.84825 time: 728.0702993869781\n",
      "Epoch: 16 Train loss: 0.24032999614874523 test accuracy: 0.84475 time: 776.0755124092102\n",
      "Epoch: 17 Train loss: 0.22069441370666026 test accuracy: 0.84425 time: 823.7650282382965\n",
      "Epoch: 18 Train loss: 0.21091597639024257 test accuracy: 0.84775 time: 871.5651297569275\n",
      "Epoch: 19 Train loss: 0.19948361781736215 test accuracy: 0.84225 time: 919.4866857528687\n",
      "Epoch: 20 Train loss: 0.18456893978019556 test accuracy: 0.8605 time: 967.1363306045532\n",
      "Epoch: 21 Train loss: 0.17234319519251584 test accuracy: 0.855 time: 1014.8925249576569\n",
      "Epoch: 22 Train loss: 0.16638273334751527 test accuracy: 0.85425 time: 1062.6928179264069\n",
      "Epoch: 23 Train loss: 0.1593547496199608 test accuracy: 0.85475 time: 1110.4709062576294\n",
      "Epoch: 24 Train loss: 0.1477942551424106 test accuracy: 0.8575 time: 1158.3441660404205\n",
      "Epoch: 25 Train loss: 0.14041010887672503 test accuracy: 0.85925 time: 1206.155062675476\n",
      "Epoch: 26 Train loss: 0.13421255256980658 test accuracy: 0.852 time: 1253.878568649292\n",
      "Epoch: 27 Train loss: 0.12963020045310258 test accuracy: 0.851 time: 1301.7102031707764\n",
      "Epoch: 28 Train loss: 0.12621940467506648 test accuracy: 0.8495 time: 1349.4445283412933\n",
      "Epoch: 29 Train loss: 0.1155503162741661 test accuracy: 0.86025 time: 1397.3486654758453\n",
      "Epoch: 30 Train loss: 0.11683470387011767 test accuracy: 0.8575 time: 1445.4085490703583\n",
      "Epoch: 31 Train loss: 0.10772992517799139 test accuracy: 0.85975 time: 1493.211909532547\n",
      "Epoch: 32 Train loss: 0.10190020096798738 test accuracy: 0.854 time: 1540.5731332302094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8605"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        #self.c2_1=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(64)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        #self.c4_1=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn5=nn.BatchNorm2d(128)\n",
    "        self.bn6=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        #self.c6_1=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn7=nn.BatchNorm2d(256)\n",
    "        self.bn8=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        self.bn9=nn.BatchNorm2d(128)\n",
    "        self.c10=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.bn10=nn.BatchNorm2d(128)\n",
    "        self.c11=nn.Conv2d(128,64,3,padding='same')\n",
    "        self.bn11=nn.BatchNorm2d(64)\n",
    "        self.c12=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.bn12=nn.BatchNorm2d(64)\n",
    "        \n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        #self.fc0=nn.Linear(4096,256)\n",
    "        self.fc1=nn.Linear(1024,512)\n",
    "        self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X)))))))\n",
    "        X=self.p2(F.relu(self.bn4(self.c4(F.relu(self.bn3(self.c3(X)))))))\n",
    "        X=self.p2(F.relu(self.bn6(self.c6(F.relu(self.bn5(self.c5(X)))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn8(self.c8(F.relu(self.bn7(self.c7(X))))))\n",
    "        X=F.relu(self.bn10(self.c10(F.relu(self.bn9(self.c9(X))))))\n",
    "        X=F.relu(self.bn12(self.c12(F.relu(self.bn11(self.c11(X))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,64*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(F.relu(self.fc2(self.dropout(F.relu(self.fc1(X))))))))))\n",
    "        return X\n",
    "    \n",
    "print(sum(p.numel() for p in CNN().parameters())) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########NEW MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.507978\n",
      "Epoch: 1 Train loss: 1.3518321053187052 test accuracy: 0.653 time: 115.29217219352722\n",
      "Epoch: 2 Train loss: 0.8675784422953924 test accuracy: 0.73075 time: 220.62748193740845\n",
      "Epoch: 3 Train loss: 0.6671549011270205 test accuracy: 0.76775 time: 325.91545271873474\n",
      "Epoch: 4 Train loss: 0.5438122670849165 test accuracy: 0.78775 time: 431.07151889801025\n",
      "Epoch: 5 Train loss: 0.45598160177469255 test accuracy: 0.808 time: 536.6027402877808\n",
      "Epoch: 6 Train loss: 0.38276645049452784 test accuracy: 0.807 time: 641.9399011135101\n",
      "Epoch: 7 Train loss: 0.3220507711668809 test accuracy: 0.81375 time: 747.3290753364563\n",
      "Epoch: 8 Train loss: 0.2802714344859123 test accuracy: 0.822 time: 852.6661767959595\n",
      "Epoch: 9 Train loss: 0.2408251706759135 test accuracy: 0.8225 time: 957.9534752368927\n",
      "Epoch: 10 Train loss: 0.21170883245766162 test accuracy: 0.828 time: 1063.344983100891\n",
      "Epoch: 11 Train loss: 0.18178330048918723 test accuracy: 0.82525 time: 1168.7110302448273\n",
      "Epoch: 12 Train loss: 0.1556871664772431 test accuracy: 0.827 time: 1274.157955646515\n",
      "Epoch: 13 Train loss: 0.1368306505183379 test accuracy: 0.833 time: 1379.423453092575\n",
      "Epoch: 14 Train loss: 0.12394906026621659 test accuracy: 0.826 time: 1484.8309707641602\n",
      "Epoch: 15 Train loss: 0.10971307353427012 test accuracy: 0.833 time: 1590.1360359191895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.833"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inception module with dimensionality reductions:  https://arxiv.org/pdf/1409.4842v1.pdf\n",
    "# Used 1x1 max ppoling in the inception block instead of 3x3 due to smaller image size (32x32)\n",
    "\n",
    "# Only 1 fully connected layer\n",
    "\n",
    "class inception(nn.Module):\n",
    "    def __init__(self,i):\n",
    "        super(inception, self).__init__()\n",
    "        self.br1_c1 = nn.Conv2d(i,64,1)\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.br2_c1 = nn.Conv2d(i,96,1)\n",
    "        self.bn2=nn.BatchNorm2d(96)\n",
    "        self.br2_c2 = nn.Conv2d(96,128,3,padding=1)\n",
    "        self.bn3=nn.BatchNorm2d(128)\n",
    "        self.br3_c1 = nn.Conv2d(i,16,1)\n",
    "        self.bn4=nn.BatchNorm2d(16)\n",
    "        self.br3_c2 = nn.Conv2d(16,32,5,padding=2)\n",
    "        self.bn5=nn.BatchNorm2d(32)\n",
    "        self.br4_p1 = nn.MaxPool2d(i,1, padding=1)\n",
    "        self.br4_c1 = nn.Conv2d(i,32,1)\n",
    "        self.bn6=nn.BatchNorm2d(32)\n",
    "    def forward(self, X):\n",
    "        br1=F.relu(self.bn1(self.br1_c1(X)))\n",
    "        br2=F.relu(self.bn3(self.br2_c2(F.relu(self.bn2(self.br2_c1(X))))))\n",
    "        br3=F.relu(self.bn5(self.br3_c2(F.relu(self.bn4(self.br3_c1(X))))))\n",
    "        br4= F.relu(self.bn6(self.br4_c1(self.br4_p1(X))))\n",
    "        c=(br1, br2, br3, br4)\n",
    "        return torch.cat(c, dim=1)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.i1=inception(3)\n",
    "        self.p1=nn.MaxPool2d(2,2)\n",
    "        self.c1=nn.Conv2d(256,256,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(256)\n",
    "        self.c2=nn.Conv2d(256,256,3,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(256)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "        self.c3=nn.Conv2d(256,512,3,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(512)\n",
    "        self.p3=nn.MaxPool2d(3,3)\n",
    "        self.fc0=nn.Linear(2048,10)\n",
    "        #self.fc1=nn.Linear(128,10)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        X=self.p1(self.i1.forward(X))\n",
    "        X=self.p2(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X)))))))\n",
    "        X=self.p3(F.relu(self.bn3(self.c3(X))))\n",
    "        X=X.view(-1,2048)\n",
    "        X=self.fc0(X)\n",
    "        return X\n",
    "\n",
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 FC Layers\n",
    "class inception(nn.Module):\n",
    "    def __init__(self,i):\n",
    "        super(inception, self).__init__()\n",
    "        self.br1_c1 = nn.Conv2d(i,64,1)\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.br2_c1 = nn.Conv2d(i,96,1)\n",
    "        self.bn2=nn.BatchNorm2d(96)\n",
    "        self.br2_c2 = nn.Conv2d(96,128,3,padding=1)\n",
    "        self.bn3=nn.BatchNorm2d(128)\n",
    "        self.br3_c1 = nn.Conv2d(i,16,1)\n",
    "        self.bn4=nn.BatchNorm2d(16)\n",
    "        self.br3_c2 = nn.Conv2d(16,32,5,padding=2)\n",
    "        self.bn5=nn.BatchNorm2d(32)\n",
    "        self.br4_p1 = nn.MaxPool2d(i,1, padding=1)\n",
    "        self.br4_c1 = nn.Conv2d(i,32,1)\n",
    "        self.bn6=nn.BatchNorm2d(32)\n",
    "    def forward(self, X):\n",
    "        br1=F.relu(self.bn1(self.br1_c1(X)))\n",
    "        br2=F.relu(self.bn3(self.br2_c2(F.relu(self.bn2(self.br2_c1(X))))))\n",
    "        br3=F.relu(self.bn5(self.br3_c2(F.relu(self.bn4(self.br3_c1(X))))))\n",
    "        br4= F.relu(self.bn6(self.br4_c1(self.br4_p1(X))))\n",
    "        c=(br1, br2, br3, br4)\n",
    "        return torch.cat(c, dim=1)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.i1=inception(3)\n",
    "        self.p1=nn.MaxPool2d(2,2)\n",
    "        self.c1=nn.Conv2d(256,256,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(256)\n",
    "        self.c2=nn.Conv2d(256,256,3,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(256)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "        self.c3=nn.Conv2d(256,512,3,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(512)\n",
    "        self.p3=nn.MaxPool2d(3,3)\n",
    "        self.fc0=nn.Linear(2048,128)\n",
    "        self.fc1=nn.Linear(128,10)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        X=self.p1(self.i1.forward(X))\n",
    "        X=self.p2(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X)))))))\n",
    "        X=self.p3(F.relu(self.bn3(self.c3(X))))\n",
    "        X=X.view(-1,2048)\n",
    "        X=self.fc1(F.relu(self.fc0(X)))\n",
    "        return X\n",
    "\n",
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,60,10)\n",
    "\n",
    "#2.75 M Params\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competitive style inception using an architecture similar in https://arxiv.org/pdf/1511.05635v1.pdf \n",
    "class inception(nn.Module):\n",
    "    def __init__(self,i,o):\n",
    "        super(inception, self).__init__()\n",
    "        self.br1_c1 = nn.Conv2d(i,o,1,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(o)\n",
    "        self.br2_c1 = nn.Conv2d(i,o,3,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(o)\n",
    "        self.br3_c1 = nn.Conv2d(i,o,5,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(o)\n",
    "        self.br4_c1 = nn.Conv2d(i,o,7,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(o)\n",
    "    def forward(self, X):\n",
    "        br1=F.relu(self.bn1(self.br1_c1(X)))\n",
    "        br2=F.relu(self.bn2(self.br2_c1(X)))\n",
    "        br3=F.relu(self.bn3(self.br3_c1(X)))\n",
    "        br4=F.relu(self.bn4(self.br4_c1(X)))\n",
    "        c=(br1, br2, br3, br4)\n",
    "        return torch.cat(c, dim=1)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.i1=inception(3,16)\n",
    "        self.i2=inception(64,32)\n",
    "        self.p1=nn.MaxPool2d(2,2)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "        self.p3=nn.MaxPool2d(2,2)\n",
    "        self.i3=inception(128,64)\n",
    "        self.c1=nn.Conv2d(256,256,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(256)\n",
    "        self.c2=nn.Conv2d(256,512,3,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(512)\n",
    "        self.p4=nn.MaxPool2d(2,2)\n",
    "        self.bn1=nn.BatchNorm2d(256)\n",
    "        self.fc0=nn.Linear(2048,128)\n",
    "        self.fc1=nn.Linear(128,64)\n",
    "        self.fc2=nn.Linear(64,10)\n",
    "        # self.fc0=nn.Linear(2048,128)\n",
    "        # self.fc1=nn.Linear(128,10)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        X=self.p1(self.i1(X))\n",
    "        X=self.p2(self.i2(X))\n",
    "        X=self.p3(self.i3(X))\n",
    "        X=self.p4(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X)))))))\n",
    "        X=X.view(-1,2048)\n",
    "        X=self.fc2(F.relu(self.fc1(F.relu(self.fc0(X)))))\n",
    "        return X\n",
    "    \n",
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,60,10)   \n",
    "# 2.90849M P\n",
    "#0.8485"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed i1 output channels\n",
    "class inception(nn.Module):\n",
    "    def __init__(self,i,o):\n",
    "        super(inception, self).__init__()\n",
    "        self.br1_c1 = nn.Conv2d(i,o,1,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(o)\n",
    "        self.br2_c1 = nn.Conv2d(i,o,3,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(o)\n",
    "        self.br3_c1 = nn.Conv2d(i,o,5,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(o)\n",
    "        self.br4_c1 = nn.Conv2d(i,o,7,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(o)\n",
    "    def forward(self, X):\n",
    "        br1=F.relu(self.bn1(self.br1_c1(X)))\n",
    "        br2=F.relu(self.bn2(self.br2_c1(X)))\n",
    "        br3=F.relu(self.bn3(self.br3_c1(X)))\n",
    "        br4=F.relu(self.bn4(self.br4_c1(X)))\n",
    "        c=torch.maximum(torch.maximum(br1, br2), torch.maximum(br3, br4))\n",
    "        return c\n",
    "        #return torch.cat(c, dim=1)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.i1=inception(3,64)\n",
    "        self.i2=inception(64,128)\n",
    "        self.p1=nn.MaxPool2d(2,2)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "        self.p3=nn.MaxPool2d(2,2)\n",
    "        self.c1=nn.Conv2d(128,256,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(256)\n",
    "        self.c2=nn.Conv2d(256,256,3,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(256)\n",
    "        self.c3=nn.Conv2d(256,512,3,padding='same')\n",
    "        self.p5=nn.MaxPool2d(2,2)\n",
    "        self.bn3=nn.BatchNorm2d(512)\n",
    "        #self.i3=inception(128,256)\n",
    "        # self.c1=nn.Conv2d(256,256,3,padding='same')\n",
    "        \n",
    "        # self.c2=nn.Conv2d(256,512,3,padding='same')\n",
    "        # self.bn2=nn.BatchNorm2d(512)\n",
    "        self.p4=nn.MaxPool2d(2,2)\n",
    "        # self.bn1=nn.BatchNorm2d(256)\n",
    "        self.fc0=nn.Linear(2048,64)\n",
    "        self.fc1=nn.Linear(64,10)\n",
    "        #self.fc2=nn.Linear(64,10)\n",
    "        # self.fc0=nn.Linear(2048,128)\n",
    "        # self.fc1=nn.Linear(128,10)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        X=self.p1(self.i1(X))\n",
    "        X=self.p2(self.i2(X))\n",
    "        X=self.p4(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X)))))))\n",
    "        X=self.p5(F.relu(self.bn3(self.c3(X))))\n",
    "        X=X.view(-1,2048)\n",
    "        X=(self.fc1(F.relu(self.fc0(X))))\n",
    "        return X\n",
    "    \n",
    "    \n",
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,60,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With dropout\n",
    "class inception(nn.Module):\n",
    "    def __init__(self,i,o):\n",
    "        super(inception, self).__init__()\n",
    "        self.br1_c1 = nn.Conv2d(i,o,1,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(o)\n",
    "        self.br2_c1 = nn.Conv2d(i,o,3,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(o)\n",
    "        self.br3_c1 = nn.Conv2d(i,o,5,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(o)\n",
    "        self.br4_c1 = nn.Conv2d(i,o,7,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(o)\n",
    "    def forward(self, X):\n",
    "        br1=F.relu(self.bn1(self.br1_c1(X)))\n",
    "        br2=F.relu(self.bn2(self.br2_c1(X)))\n",
    "        br3=F.relu(self.bn3(self.br3_c1(X)))\n",
    "        br4=F.relu(self.bn4(self.br4_c1(X)))\n",
    "        c=torch.maximum(torch.maximum(br1, br2), torch.maximum(br3, br4))\n",
    "        return c\n",
    "        #return torch.cat(c, dim=1)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.i1=inception(3,64)\n",
    "        self.i2=inception(64,128)\n",
    "        self.p1=nn.MaxPool2d(2,2)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "        self.p3=nn.MaxPool2d(2,2)\n",
    "        self.c1=nn.Conv2d(128,256,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(256)\n",
    "        self.c2=nn.Conv2d(256,256,3,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(256)\n",
    "        self.c3=nn.Conv2d(256,512,3,padding='same')\n",
    "        self.p5=nn.MaxPool2d(2,2)\n",
    "        self.bn3=nn.BatchNorm2d(512)\n",
    "        #self.i3=inception(128,256)\n",
    "        # self.c1=nn.Conv2d(256,256,3,padding='same')\n",
    "        \n",
    "        # self.c2=nn.Conv2d(256,512,3,padding='same')\n",
    "        # self.bn2=nn.BatchNorm2d(512)\n",
    "        self.p4=nn.MaxPool2d(2,2)\n",
    "        # self.bn1=nn.BatchNorm2d(256)\n",
    "        self.fc0=nn.Linear(2048,64)\n",
    "        self.fc1=nn.Linear(64,10)\n",
    "        #self.fc2=nn.Linear(64,10)\n",
    "        # self.fc0=nn.Linear(2048,128)\n",
    "        # self.fc1=nn.Linear(128,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X=self.p1(self.i1(X))\n",
    "        X=self.p2(self.i2(X))\n",
    "        X=self.p4(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X)))))))\n",
    "        X=self.p5(F.relu(self.bn3(self.c3(X))))\n",
    "        X=X.view(-1,2048)\n",
    "        X=(self.fc1(self.dropout(F.relu(self.fc0(X)))))\n",
    "        return X\n",
    "    \n",
    "    \n",
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,60,10)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.ColorJitter(.1,.1,.1,.1)                                 \n",
    "                                    ,transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2459018\n",
      "Epoch: 1 Train loss: 1.4829193150997162 test accuracy: 0.61375 time: 91.69415831565857\n",
      "Epoch: 2 Train loss: 0.9673939774433772 test accuracy: 0.70875 time: 172.67755389213562\n",
      "Epoch: 3 Train loss: 0.7501340534289678 test accuracy: 0.7615 time: 254.33457446098328\n",
      "Epoch: 4 Train loss: 0.6038242356975874 test accuracy: 0.7885 time: 335.4857232570648\n",
      "Epoch: 5 Train loss: 0.5034876189629237 test accuracy: 0.79925 time: 416.57243728637695\n",
      "Epoch: 6 Train loss: 0.4305350364247958 test accuracy: 0.80225 time: 498.44789600372314\n",
      "Epoch: 7 Train loss: 0.37463813145955405 test accuracy: 0.8145 time: 580.0779674053192\n",
      "Epoch: 8 Train loss: 0.316415825287501 test accuracy: 0.8125 time: 661.397539138794\n",
      "Epoch: 9 Train loss: 0.2753007148206234 test accuracy: 0.81625 time: 743.2368013858795\n",
      "Epoch: 10 Train loss: 0.2467126299192508 test accuracy: 0.82625 time: 825.168478012085\n",
      "Epoch: 11 Train loss: 0.2122915810594956 test accuracy: 0.83425 time: 906.5237205028534\n",
      "Epoch: 12 Train loss: 0.18656219609081745 test accuracy: 0.827 time: 988.6740713119507\n",
      "Epoch: 13 Train loss: 0.15932627675433952 test accuracy: 0.83125 time: 1070.165936946869\n",
      "Epoch: 14 Train loss: 0.13895725790411234 test accuracy: 0.83875 time: 1152.568305015564\n",
      "Epoch: 15 Train loss: 0.12671574376523495 test accuracy: 0.83975 time: 1234.9196918010712\n",
      "Epoch: 16 Train loss: 0.11467883855104447 test accuracy: 0.84475 time: 1316.8934562206268\n",
      "Epoch: 17 Train loss: 0.10315839932610592 test accuracy: 0.8395 time: 1398.5744106769562\n",
      "Epoch: 18 Train loss: 0.09112582909564178 test accuracy: 0.842 time: 1480.6142148971558\n",
      "Epoch: 19 Train loss: 0.08501341345409552 test accuracy: 0.84225 time: 1562.254378080368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84475"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More vgg testing\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.bn3=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c2_1=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.bn5=nn.BatchNorm2d(64)\n",
    "        self.bn6=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c4_1=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn7=nn.BatchNorm2d(128)\n",
    "        self.bn8=nn.BatchNorm2d(128)\n",
    "        self.bn9=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c6_1=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn10=nn.BatchNorm2d(256)\n",
    "        self.bn11=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc0=nn.Linear(4096,256)\n",
    "        #self.fc1=nn.Linear(1024,512)\n",
    "        #self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn3(self.c2_1(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X))))))))))\n",
    "        X=self.p2(F.relu(self.bn6(self.c4_1(F.relu(self.bn5(self.c4(F.relu(self.bn4(self.c3(X))))))))))\n",
    "        X=self.p2(F.relu(self.bn9(self.c6_1(F.relu(self.bn8(self.c6(F.relu(self.bn7(self.c5(X))))))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn11(self.c8(F.relu(self.bn10(self.c7(X))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,256*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(self.dropout(F.relu(self.fc0(X))))))))\n",
    "        return X\n",
    "        \n",
    "print(sum(p.numel() for p in CNN().parameters())) \n",
    "bs=200\n",
    "# img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "#                                     transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "#                                     transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "#                                     transforms.ToTensor()])\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.ColorJitter(.1,.1,.1,.1)                                 \n",
    "                                    ,transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)           \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resnet\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.bn3=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c2_1=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.bn5=nn.BatchNorm2d(64)\n",
    "        self.bn6=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c4_1=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn7=nn.BatchNorm2d(128)\n",
    "        self.bn8=nn.BatchNorm2d(128)\n",
    "        self.bn9=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c6_1=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn10=nn.BatchNorm2d(256)\n",
    "        self.bn11=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc0=nn.Linear(4096,256)\n",
    "        #self.fc1=nn.Linear(1024,512)\n",
    "        #self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        temp=F.relu(self.bn1(self.c1(X)))\n",
    "        X=self.bn3(self.c2_1(F.relu(self.bn2(self.c2(temp)))))\n",
    "        X+=temp\n",
    "        X=self.p2(F.relu(X))\n",
    "        temp=F.relu(self.bn4(self.c3(X)))\n",
    "        X=self.bn6(self.c4_1(F.relu(self.bn5(self.c4(temp)))))\n",
    "        X+=temp\n",
    "        X=self.p2(F.relu(X))\n",
    "        temp=F.relu(self.bn7(self.c5(X)))\n",
    "        X=self.bn9(self.c6_1(F.relu(self.bn8(self.c6(temp)))))\n",
    "        X+=temp\n",
    "        X=self.p2(F.relu(X))\n",
    "        # #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn11(self.c8(F.relu(self.bn10(self.c7(X))))))\n",
    "        # # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,256*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(self.dropout(F.relu(self.fc0(X))))))))\n",
    "        return X\n",
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,60,10)      \n",
    "  \n",
    "# Acc: 0.88075 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No bias\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same',bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.bn3=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same',bias=False)\n",
    "        self.c2_1=nn.Conv2d(32,32,3,padding='same',bias=False)\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same',bias=False)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.bn5=nn.BatchNorm2d(64)\n",
    "        self.bn6=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same',bias=False)\n",
    "        self.c4_1=nn.Conv2d(64,64,3,padding='same',bias=False)\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same',bias=False)\n",
    "        self.bn7=nn.BatchNorm2d(128)\n",
    "        self.bn8=nn.BatchNorm2d(128)\n",
    "        self.bn9=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same',bias=False)\n",
    "        self.c6_1=nn.Conv2d(128,128,3,padding='same',bias=False)\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn10=nn.BatchNorm2d(256)\n",
    "        self.bn11=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc0=nn.Linear(4096,256)\n",
    "        #self.fc1=nn.Linear(1024,512)\n",
    "        #self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        temp=F.relu(self.bn1(self.c1(X)))\n",
    "        X=self.bn3(self.c2_1(F.relu(self.bn2(self.c2(temp)))))\n",
    "        X+=temp\n",
    "        X=self.p2(F.relu(X))\n",
    "        temp=F.relu(self.bn4(self.c3(X)))\n",
    "        X=self.bn6(self.c4_1(F.relu(self.bn5(self.c4(temp)))))\n",
    "        X+=temp\n",
    "        X=self.p2(F.relu(X))\n",
    "        temp=F.relu(self.bn7(self.c5(X)))\n",
    "        X=self.bn9(self.c6_1(F.relu(self.bn8(self.c6(temp)))))\n",
    "        X+=temp\n",
    "        X=self.p2(F.relu(X))\n",
    "        # #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn11(self.c8(F.relu(self.bn10(self.c7(X))))))\n",
    "        # # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,256*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(self.dropout(F.relu(self.fc0(X))))))))\n",
    "        return X\n",
    "    \n",
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,60,10)  \n",
    "\n",
    "# Acc: 0.88075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.653226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.5508522550264994 test accuracy: 0.56425 time: 74.896968126297\n",
      "Epoch: 2 Train loss: 1.0830678157011668 test accuracy: 0.67175 time: 139.62054204940796\n",
      "Epoch: 3 Train loss: 0.8840698897838593 test accuracy: 0.7215 time: 204.55180883407593\n",
      "Epoch: 4 Train loss: 0.7711607180039088 test accuracy: 0.7635 time: 269.29728603363037\n",
      "Epoch: 5 Train loss: 0.6800587936242422 test accuracy: 0.777 time: 334.43788957595825\n",
      "Epoch: 6 Train loss: 0.6001702223221461 test accuracy: 0.79325 time: 399.24432158470154\n",
      "Epoch: 7 Train loss: 0.5383928555250168 test accuracy: 0.80725 time: 463.98289155960083\n",
      "Epoch: 8 Train loss: 0.48887463947137194 test accuracy: 0.8085 time: 529.0620119571686\n",
      "Epoch: 9 Train loss: 0.4505198315779368 test accuracy: 0.81625 time: 593.8663280010223\n",
      "Epoch: 10 Train loss: 0.4158848209679127 test accuracy: 0.83375 time: 658.7878828048706\n",
      "Epoch: 11 Train loss: 0.376104789574941 test accuracy: 0.83375 time: 723.607613325119\n",
      "Epoch: 12 Train loss: 0.35633858770132065 test accuracy: 0.83675 time: 788.5649988651276\n",
      "Epoch: 13 Train loss: 0.32559056267142295 test accuracy: 0.83725 time: 853.7744700908661\n",
      "Epoch: 14 Train loss: 0.308741970260938 test accuracy: 0.849 time: 919.7021863460541\n",
      "Epoch: 15 Train loss: 0.2904882138967514 test accuracy: 0.84275 time: 985.2986443042755\n",
      "Epoch: 16 Train loss: 0.2661039283374945 test accuracy: 0.84675 time: 1050.9296116828918\n",
      "Epoch: 17 Train loss: 0.25115402619043986 test accuracy: 0.8425 time: 1116.2479622364044\n",
      "Epoch: 18 Train loss: 0.23748736801246803 test accuracy: 0.8475 time: 1181.7031335830688\n",
      "Epoch: 19 Train loss: 0.22526096192499 test accuracy: 0.855 time: 1247.2966825962067\n",
      "Epoch: 20 Train loss: 0.21259883522987366 test accuracy: 0.84475 time: 1312.632239818573\n",
      "Epoch: 21 Train loss: 0.20273344472050667 test accuracy: 0.8505 time: 1378.2877023220062\n",
      "Epoch: 22 Train loss: 0.18567847055693468 test accuracy: 0.85475 time: 1443.808377981186\n",
      "Epoch: 23 Train loss: 0.18083541038135686 test accuracy: 0.857 time: 1509.7967581748962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.857"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 layered vgg\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(32)\n",
    "        self.bn2=nn.BatchNorm2d(32)\n",
    "        self.bn3=nn.BatchNorm2d(32)\n",
    "        self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c2_1=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c2_2=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.bn2_2=nn.BatchNorm2d(32)\n",
    "        self.c3=nn.Conv2d(32,64,3,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.bn5=nn.BatchNorm2d(64)\n",
    "        self.bn6=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c4_1=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c4_2=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.bn4_2=nn.BatchNorm2d(64)\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn7=nn.BatchNorm2d(128)\n",
    "        self.bn8=nn.BatchNorm2d(128)\n",
    "        self.bn9=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c6_1=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c6_2=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.bn6_2=nn.BatchNorm2d(128)\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn10=nn.BatchNorm2d(256)\n",
    "        self.bn11=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc0=nn.Linear(4096,256)\n",
    "        #self.fc1=nn.Linear(1024,512)\n",
    "        #self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        X=self.p2(F.relu(self.bn2_2(self.c2_2(F.relu(self.bn3(self.c2_1(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X)))))))))))))\n",
    "        X=self.p2(F.relu(self.bn4_2(self.c4_2(F.relu(self.bn6(self.c4_1(F.relu(self.bn5(self.c4(F.relu(self.bn4(self.c3(X)))))))))))))\n",
    "        X=self.p2(F.relu(self.bn6_2(self.c6_2(F.relu(self.bn9(self.c6_1(F.relu(self.bn8(self.c6(F.relu(self.bn7(self.c5(X)))))))))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=F.relu(self.bn11(self.c8(F.relu(self.bn10(self.c7(X))))))\n",
    "        # X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,256*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(self.dropout(F.relu(self.fc0(X))))))))\n",
    "        return X\n",
    "\n",
    "    \n",
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,25,10)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.42273\n",
      "Epoch: 1 Train loss: 1.4263784299294153 test accuracy: 0.64525 time: 99.47530770301819\n",
      "Epoch: 2 Train loss: 0.9305811327695847 test accuracy: 0.73025 time: 190.3661971092224\n",
      "Epoch: 3 Train loss: 0.7282561250527699 test accuracy: 0.77825 time: 278.6123037338257\n",
      "Epoch: 4 Train loss: 0.6092158669233322 test accuracy: 0.7985 time: 367.6954803466797\n",
      "Epoch: 5 Train loss: 0.5228041145205498 test accuracy: 0.821 time: 455.83930683135986\n",
      "Epoch: 6 Train loss: 0.4570396131277084 test accuracy: 0.8255 time: 543.9140813350677\n",
      "Epoch: 7 Train loss: 0.39867778211832045 test accuracy: 0.83325 time: 632.1369581222534\n",
      "Epoch: 8 Train loss: 0.3582992468277613 test accuracy: 0.84175 time: 720.2763731479645\n",
      "Epoch: 9 Train loss: 0.31772209733724593 test accuracy: 0.841 time: 808.5648353099823\n",
      "Epoch: 10 Train loss: 0.28954285219311715 test accuracy: 0.84875 time: 897.1887638568878\n",
      "Epoch: 11 Train loss: 0.2586772740383943 test accuracy: 0.85675 time: 985.4076352119446\n",
      "Epoch: 12 Train loss: 0.23794197934369246 test accuracy: 0.85175 time: 1073.7015180587769\n",
      "Epoch: 13 Train loss: 0.21125616292158764 test accuracy: 0.86125 time: 1161.9807193279266\n",
      "Epoch: 14 Train loss: 0.19863217107951642 test accuracy: 0.859 time: 1257.0068316459656\n",
      "Epoch: 15 Train loss: 0.18398424391945203 test accuracy: 0.86075 time: 1345.2602245807648\n",
      "Epoch: 16 Train loss: 0.16340590400000413 test accuracy: 0.86425 time: 1433.6656656265259\n",
      "Epoch: 17 Train loss: 0.1497727527966102 test accuracy: 0.87275 time: 1522.0144040584564\n",
      "Epoch: 18 Train loss: 0.14172091881434123 test accuracy: 0.86825 time: 1610.1616389751434\n",
      "Epoch: 19 Train loss: 0.12911137245595455 test accuracy: 0.87325 time: 1698.485738992691\n",
      "Epoch: 20 Train loss: 0.12085524744043748 test accuracy: 0.87125 time: 1786.462891817093\n",
      "Epoch: 21 Train loss: 0.11502277866005897 test accuracy: 0.8725 time: 1874.8299553394318\n",
      "Epoch: 22 Train loss: 0.10842399707684915 test accuracy: 0.87375 time: 1962.9601421356201\n",
      "Epoch: 23 Train loss: 0.09659964637830853 test accuracy: 0.879 time: 2051.2652978897095\n",
      "Epoch: 24 Train loss: 0.09602574827770392 test accuracy: 0.87675 time: 2139.4810485839844\n",
      "Epoch: 25 Train loss: 0.08688619075343013 test accuracy: 0.879 time: 2227.612062215805\n",
      "Epoch: 26 Train loss: 0.08432481041178107 test accuracy: 0.878 time: 2315.7224481105804\n",
      "Epoch: 27 Train loss: 0.08340668799355626 test accuracy: 0.882 time: 2404.3590145111084\n",
      "Epoch: 28 Train loss: 0.07206537106384833 test accuracy: 0.88225 time: 2493.550619840622\n",
      "Epoch: 29 Train loss: 0.06994444931857288 test accuracy: 0.88 time: 2582.8105041980743\n",
      "Epoch: 30 Train loss: 0.06684071800050637 test accuracy: 0.88525 time: 2672.0913393497467\n",
      "Epoch: 31 Train loss: 0.06364030344722171 test accuracy: 0.8765 time: 2761.3105902671814\n",
      "Epoch: 32 Train loss: 0.059911508463944 test accuracy: 0.87025 time: 2850.550540447235\n",
      "Epoch: 33 Train loss: 0.060223554389861725 test accuracy: 0.8805 time: 2940.051203727722\n",
      "Epoch: 34 Train loss: 0.056558526704708734 test accuracy: 0.88175 time: 3029.282070875168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88525"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removed 32x32 convolution block\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        # self.c1=nn.Conv2d(3,32,3,padding='same')\n",
    "        # self.bn1=nn.BatchNorm2d(32)\n",
    "        # self.bn2=nn.BatchNorm2d(32)\n",
    "        # self.bn3=nn.BatchNorm2d(32)\n",
    "        # self.c2=nn.Conv2d(32,32,3,padding='same')\n",
    "        # self.c2_1=nn.Conv2d(32,32,3,padding='same')\n",
    "        self.c3=nn.Conv2d(3,64,3,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        self.bn5=nn.BatchNorm2d(64)\n",
    "        self.bn6=nn.BatchNorm2d(64)\n",
    "        self.c4=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c4_1=nn.Conv2d(64,64,3,padding='same')\n",
    "        self.c5=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn7=nn.BatchNorm2d(128)\n",
    "        self.bn8=nn.BatchNorm2d(128)\n",
    "        self.bn9=nn.BatchNorm2d(128)\n",
    "        self.c6=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c6_1=nn.Conv2d(128,128,3,padding='same')\n",
    "        self.c7=nn.Conv2d(128,256,3,padding='same')\n",
    "\n",
    "        self.bn10=nn.BatchNorm2d(256)\n",
    "        self.bn11=nn.BatchNorm2d(256)\n",
    "        self.c8=nn.Conv2d(256,256,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,128,3,padding='same')\n",
    "        #self.c9=nn.Conv2d(256,512,3,padding='same')\n",
    "        #self.c10=nn.Conv2d(512,1024,2)\n",
    "        #self.bn5=nn.BatchNorm2d(512)\n",
    "        #self.bn6=nn.BatchNorm2d(1024)\n",
    "        self.fc0=nn.Linear(4096,256)\n",
    "        #self.fc1=nn.Linear(1024,512)\n",
    "        #self.fc2=nn.Linear(512,256)\n",
    "        self.fc3=nn.Linear(256,128)\n",
    "        self.fc4=nn.Linear(128,64)\n",
    "        self.fc5=nn.Linear(64,10)\n",
    "        self.dropout=nn.Dropout(.2)\n",
    "        #self.p1=nn.MaxPool2d(2,1)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,X):\n",
    "        #X=self.p2(F.relu(self.bn3(self.c2_1(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X))))))))))\n",
    "        X=self.p2(F.relu(self.bn6(self.c4_1(F.relu(self.bn5(self.c4(F.relu(self.bn4(self.c3(X))))))))))\n",
    "        X=self.p2(F.relu(self.bn9(self.c6_1(F.relu(self.bn8(self.c6(F.relu(self.bn7(self.c5(X))))))))))\n",
    "        #X=nn.Conv2d(512,1024,2)(nn.MaxPool2d(2,2)(nn.Conv2d(256,512,3,padding='same')(nn.Conv2d(256,256,3,padding='same')(self.c7(X)))))\n",
    "        X=self.p2(F.relu(self.bn11(self.c8(F.relu(self.bn10(self.c7(X)))))))\n",
    "        #X=F.relu(self.bn6(self.c10(F.relu(self.bn5(self.c9(X))))))\n",
    "        X=X.view(-1,256*4*4)\n",
    "\n",
    "        X=self.fc5(F.relu(self.fc4(F.relu(self.fc3(self.dropout(F.relu(self.fc0(X))))))))\n",
    "        return X\n",
    "    \n",
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,50,10)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.933706\n",
      "Epoch: 1 Train loss: 1.201251789132754 test accuracy: 0.71125 time: 127.24305462837219\n",
      "Epoch: 2 Train loss: 0.7102335299054782 test accuracy: 0.7805 time: 239.8765995502472\n",
      "Epoch: 3 Train loss: 0.5418390446901321 test accuracy: 0.8125 time: 352.545526266098\n",
      "Epoch: 4 Train loss: 0.44828786383072533 test accuracy: 0.83125 time: 465.6197226047516\n",
      "Epoch: 5 Train loss: 0.3712246669828892 test accuracy: 0.843 time: 578.4304602146149\n",
      "Epoch: 6 Train loss: 0.31553178081909816 test accuracy: 0.852 time: 691.0256295204163\n",
      "Epoch: 7 Train loss: 0.270948078930378 test accuracy: 0.8525 time: 803.8841559886932\n",
      "Epoch: 8 Train loss: 0.23761877184112867 test accuracy: 0.866 time: 916.6905372142792\n",
      "Epoch: 9 Train loss: 0.20946702875196935 test accuracy: 0.865 time: 1029.5319137573242\n",
      "Epoch: 10 Train loss: 0.18485409162938596 test accuracy: 0.856 time: 1142.2911536693573\n",
      "Epoch: 11 Train loss: 0.16621926600734394 test accuracy: 0.87475 time: 1255.2371091842651\n",
      "Epoch: 12 Train loss: 0.14427411377429963 test accuracy: 0.87575 time: 1368.0564768314362\n",
      "Epoch: 13 Train loss: 0.13348946250975133 test accuracy: 0.85275 time: 1480.5495200157166\n",
      "Epoch: 14 Train loss: 0.11967042531818152 test accuracy: 0.855 time: 1593.1222212314606\n",
      "Epoch: 15 Train loss: 0.11216867102930943 test accuracy: 0.87075 time: 1706.013379573822\n",
      "Epoch: 16 Train loss: 0.10684654654935002 test accuracy: 0.85125 time: 1818.8767647743225\n",
      "Epoch: 17 Train loss: 0.10005341875056425 test accuracy: 0.8845 time: 1931.6878316402435\n",
      "Epoch: 18 Train loss: 0.08790299986178676 test accuracy: 0.88175 time: 2044.8107635974884\n",
      "Epoch: 19 Train loss: 0.07997644557928045 test accuracy: 0.8655 time: 2157.5528168678284\n",
      "Epoch: 20 Train loss: 0.07764212643417219 test accuracy: 0.8735 time: 2270.5497834682465\n",
      "Epoch: 21 Train loss: 0.07142460904705028 test accuracy: 0.88375 time: 2383.7048325538635\n",
      "Epoch: 22 Train loss: 0.06900938513067861 test accuracy: 0.887 time: 2496.574686527252\n",
      "Epoch: 23 Train loss: 0.06392128774585823 test accuracy: 0.88425 time: 2609.3035078048706\n",
      "Epoch: 24 Train loss: 0.06132510795878867 test accuracy: 0.88775 time: 2722.164885997772\n",
      "Epoch: 25 Train loss: 0.05859087323459486 test accuracy: 0.872 time: 2835.1926543712616\n",
      "Epoch: 26 Train loss: 0.05347384945799907 test accuracy: 0.87875 time: 2948.0975062847137\n",
      "Epoch: 27 Train loss: 0.05585936201115449 test accuracy: 0.88725 time: 3061.1569843292236\n",
      "Epoch: 28 Train loss: 0.05107685846742242 test accuracy: 0.88325 time: 3174.0100343227386\n",
      "Epoch: 29 Train loss: 0.0519131338254859 test accuracy: 0.88875 time: 3287.1814913749695\n",
      "Epoch: 30 Train loss: 0.04846671715999643 test accuracy: 0.8885 time: 3399.907082796097\n",
      "Epoch: 31 Train loss: 0.04396635617439946 test accuracy: 0.8875 time: 3512.735225200653\n",
      "Epoch: 32 Train loss: 0.04442547123568753 test accuracy: 0.8845 time: 3625.399886369705\n",
      "Epoch: 33 Train loss: 0.046384348909681045 test accuracy: 0.8865 time: 3738.1266207695007\n",
      "Epoch: 34 Train loss: 0.041786006243589024 test accuracy: 0.89025 time: 3850.6123933792114\n",
      "Epoch: 35 Train loss: 0.040164793534204365 test accuracy: 0.889 time: 3964.0374937057495\n",
      "Epoch: 36 Train loss: 0.03988033502673109 test accuracy: 0.8815 time: 4076.7825899124146\n",
      "Epoch: 37 Train loss: 0.03783278436244776 test accuracy: 0.88375 time: 4189.508939027786\n",
      "Epoch: 38 Train loss: 0.03798561956927491 test accuracy: 0.8785 time: 4302.368656635284\n",
      "Epoch: 39 Train loss: 0.035570529949230455 test accuracy: 0.89375 time: 4415.230140447617\n",
      "Epoch: 40 Train loss: 0.03403311832730348 test accuracy: 0.88675 time: 4528.118764638901\n",
      "Epoch: 41 Train loss: 0.03616142015516137 test accuracy: 0.88475 time: 4641.051800251007\n",
      "Epoch: 42 Train loss: 0.03281389222635577 test accuracy: 0.89325 time: 4753.881341934204\n",
      "Epoch: 43 Train loss: 0.033634859023150054 test accuracy: 0.88825 time: 4866.757977724075\n",
      "Epoch: 44 Train loss: 0.03363438677585994 test accuracy: 0.8865 time: 4979.605416297913\n",
      "Epoch: 45 Train loss: 0.029375233640894293 test accuracy: 0.8895 time: 5092.44521021843\n",
      "Epoch: 46 Train loss: 0.034082181453704834 test accuracy: 0.8875 time: 5205.392844438553\n",
      "Epoch: 47 Train loss: 0.028988826895365492 test accuracy: 0.89525 time: 5318.239276170731\n",
      "Epoch: 48 Train loss: 0.029785965617823724 test accuracy: 0.887 time: 5430.91193318367\n",
      "Epoch: 49 Train loss: 0.027570698241858434 test accuracy: 0.883 time: 5543.843546152115\n",
      "Epoch: 50 Train loss: 0.028526406526410333 test accuracy: 0.895 time: 5656.689850091934\n",
      "Epoch: 51 Train loss: 0.02606607856772219 test accuracy: 0.8945 time: 5769.710969209671\n",
      "Epoch: 52 Train loss: 0.02783453342349579 test accuracy: 0.897 time: 5882.831241130829\n",
      "Epoch: 53 Train loss: 0.02712527823479225 test accuracy: 0.88825 time: 5995.414010047913\n",
      "Epoch: 54 Train loss: 0.024658760578604416 test accuracy: 0.896 time: 6108.461093187332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.897"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class fused_block(nn.Module):\n",
    "    def __init__(self,i):\n",
    "        super(fused_block,self).__init__()\n",
    "        self.c1=nn.Conv2d(i,4*i,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(4*i)\n",
    "        self.c2=nn.Conv2d(4*i,i,1,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(i)\n",
    "    def __call__(self,X):\n",
    "        return F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X))))))\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,64,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.fb1=fused_block(64)\n",
    "        self.p1=nn.MaxPool2d(2,2)\n",
    "        self.c2=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(128)\n",
    "        self.fb2=fused_block(128)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "        self.c3=nn.Conv2d(128,256,3,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(256)\n",
    "        self.p3=nn.MaxPool2d(2,2)\n",
    "        self.p4=nn.MaxPool2d(2,2)\n",
    "        self.c4=nn.Conv2d(256,512,3,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(512)\n",
    "        self.fc0=nn.Linear(2048,256)\n",
    "        self.fc1=nn.Linear(256,128)\n",
    "        self.fc2=nn.Linear(128,10)\n",
    "    def forward(self,X):\n",
    "        X=F.relu(self.bn1(self.c1(X)))\n",
    "        X=self.p1(self.fb1(X))\n",
    "        X=F.relu(self.bn2(self.c2(X)))\n",
    "        X=self.p2(self.fb2(X))\n",
    "        X=self.p4(F.relu(self.bn3(self.c3(X))))\n",
    "        X=self.p4(F.relu(self.bn4(self.c4(X))))\n",
    "        X=X.view(-1,2048)\n",
    "        X=F.relu(self.fc1(F.relu(self.fc0(X))))\n",
    "        X=self.fc2(X)\n",
    "        return X\n",
    "    \n",
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,100,10)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.933706\n",
      "Epoch: 1 Train loss: 1.3016689265767734 test accuracy: 0.681 time: 117.93196868896484\n",
      "Epoch: 2 Train loss: 0.7701983705163002 test accuracy: 0.766 time: 225.98340272903442\n",
      "Epoch: 3 Train loss: 0.5807673605779807 test accuracy: 0.7995 time: 334.30927300453186\n",
      "Epoch: 4 Train loss: 0.474008629967769 test accuracy: 0.8145 time: 442.149010181427\n",
      "Epoch: 5 Train loss: 0.4002903940776984 test accuracy: 0.8345 time: 550.6497392654419\n",
      "Epoch: 6 Train loss: 0.34590201526880265 test accuracy: 0.8505 time: 659.7726557254791\n",
      "Epoch: 7 Train loss: 0.3051791110386451 test accuracy: 0.85925 time: 768.2181706428528\n",
      "Epoch: 8 Train loss: 0.2703090442965428 test accuracy: 0.85525 time: 877.2850024700165\n",
      "Epoch: 9 Train loss: 0.23680540435016156 test accuracy: 0.85925 time: 986.1607208251953\n",
      "Epoch: 10 Train loss: 0.21191833366950352 test accuracy: 0.8645 time: 1094.7298257350922\n",
      "Epoch: 11 Train loss: 0.19438071760038536 test accuracy: 0.8695 time: 1203.1873099803925\n",
      "Epoch: 12 Train loss: 0.1705857475598653 test accuracy: 0.8685 time: 1312.3868503570557\n",
      "Epoch: 13 Train loss: 0.15834285244345664 test accuracy: 0.8775 time: 1421.5218577384949\n",
      "Epoch: 14 Train loss: 0.14935593058665594 test accuracy: 0.86775 time: 1530.6927282810211\n",
      "Epoch: 15 Train loss: 0.13404041156172752 test accuracy: 0.87975 time: 1640.0979359149933\n",
      "Epoch: 16 Train loss: 0.11817252536614736 test accuracy: 0.876 time: 1749.0930693149567\n",
      "Epoch: 17 Train loss: 0.10755340804656346 test accuracy: 0.878 time: 1857.0795149803162\n",
      "Epoch: 18 Train loss: 0.10406367930894096 test accuracy: 0.8665 time: 1964.1893064975739\n",
      "Epoch: 19 Train loss: 0.09884312059730291 test accuracy: 0.8735 time: 2071.1157155036926\n",
      "Epoch: 20 Train loss: 0.0960041493177414 test accuracy: 0.86 time: 2177.955773830414\n",
      "Epoch: 21 Train loss: 0.09307046877220274 test accuracy: 0.87125 time: 2284.8986308574677\n",
      "Epoch: 22 Train loss: 0.08086438318714499 test accuracy: 0.87875 time: 2391.9561631679535\n",
      "Epoch: 23 Train loss: 0.08170468729610245 test accuracy: 0.87825 time: 2498.7730844020844\n",
      "Epoch: 24 Train loss: 0.07854509921744465 test accuracy: 0.87675 time: 2605.7818558216095\n",
      "Epoch: 25 Train loss: 0.07163955676369368 test accuracy: 0.885 time: 2712.481735944748\n",
      "Epoch: 26 Train loss: 0.06445821390176813 test accuracy: 0.87175 time: 2819.4522728919983\n",
      "Epoch: 27 Train loss: 0.06019410329560439 test accuracy: 0.8795 time: 2926.2595267295837\n",
      "Epoch: 28 Train loss: 0.05683606791620453 test accuracy: 0.88325 time: 3033.0874671936035\n",
      "Epoch: 29 Train loss: 0.05624827605982621 test accuracy: 0.884 time: 3139.859271287918\n",
      "Epoch: 30 Train loss: 0.05546212714786331 test accuracy: 0.8865 time: 3246.788746356964\n",
      "Epoch: 31 Train loss: 0.053113451475898424 test accuracy: 0.8775 time: 3353.670032978058\n",
      "Epoch: 32 Train loss: 0.05011806702241302 test accuracy: 0.87775 time: 3460.5669350624084\n",
      "Epoch: 33 Train loss: 0.050331902938584486 test accuracy: 0.8895 time: 3567.3462665081024\n",
      "Epoch: 34 Train loss: 0.04646600515892108 test accuracy: 0.88825 time: 3674.393778324127\n",
      "Epoch: 35 Train loss: 0.040954680756355326 test accuracy: 0.8825 time: 3781.3692529201508\n",
      "Epoch: 36 Train loss: 0.04521667632895211 test accuracy: 0.88825 time: 3888.2086277008057\n",
      "Epoch: 37 Train loss: 0.039228356637371085 test accuracy: 0.88625 time: 3995.0370218753815\n",
      "Epoch: 38 Train loss: 0.044238709922259055 test accuracy: 0.89 time: 4102.036440372467\n",
      "Epoch: 39 Train loss: 0.04028511870031556 test accuracy: 0.88275 time: 4209.028688907623\n",
      "Epoch: 40 Train loss: 0.04507880061864853 test accuracy: 0.88175 time: 4315.761839389801\n",
      "Epoch: 41 Train loss: 0.037893487125014266 test accuracy: 0.8915 time: 4422.474644899368\n",
      "Epoch: 42 Train loss: 0.041641417782132824 test accuracy: 0.8935 time: 4529.157190561295\n",
      "Epoch: 43 Train loss: 0.03684398543167238 test accuracy: 0.891 time: 4636.014139175415\n",
      "Epoch: 44 Train loss: 0.03877462566985438 test accuracy: 0.89025 time: 4742.9493861198425\n",
      "Epoch: 45 Train loss: 0.038970652610684435 test accuracy: 0.88925 time: 4849.915556907654\n",
      "Epoch: 46 Train loss: 0.03557574475028862 test accuracy: 0.89075 time: 4956.775075912476\n",
      "Epoch: 47 Train loss: 0.03901201863773167 test accuracy: 0.8915 time: 5063.626272439957\n",
      "Epoch: 48 Train loss: 0.03552884495972345 test accuracy: 0.8855 time: 5170.34526014328\n",
      "Epoch: 49 Train loss: 0.03664433472634603 test accuracy: 0.88875 time: 5277.305565595627\n",
      "Epoch: 50 Train loss: 0.032375054674533506 test accuracy: 0.89025 time: 5384.422267913818\n",
      "Epoch: 51 Train loss: 0.03286965588728587 test accuracy: 0.88275 time: 5491.429298877716\n",
      "Epoch: 52 Train loss: 0.029019834566861392 test accuracy: 0.8875 time: 5598.412566184998\n",
      "Epoch: 53 Train loss: 0.034474835242144765 test accuracy: 0.88825 time: 5705.346543073654\n",
      "Epoch: 54 Train loss: 0.027564354609542836 test accuracy: 0.88875 time: 5812.306931734085\n",
      "Epoch: 55 Train loss: 0.031302751395075275 test accuracy: 0.88575 time: 5919.157603263855\n",
      "Epoch: 56 Train loss: 0.028120239459288616 test accuracy: 0.8865 time: 6026.144711017609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8935"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=500\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(10),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,100,10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet style fused block (skip connection added)\n",
    "class fused_block(nn.Module):\n",
    "    def __init__(self,i):\n",
    "        super(fused_block,self).__init__()\n",
    "        self.c1=nn.Conv2d(i,4*i,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(4*i)\n",
    "        self.c2=nn.Conv2d(4*i,i,1,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(i)\n",
    "        \n",
    "    def __call__(self,X):\n",
    "        temp=self.bn2(self.c2(F.relu(self.bn1(self.c1(X)))))\n",
    "        temp+=X\n",
    "        return F.relu(temp)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,64,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.fb1=fused_block(64)\n",
    "        self.p1=nn.MaxPool2d(2,2)\n",
    "        self.c2=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(128)\n",
    "        self.fb2=fused_block(128)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "        self.c3=nn.Conv2d(128,256,3,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(256)\n",
    "        self.p3=nn.MaxPool2d(2,2)\n",
    "        self.p4=nn.MaxPool2d(2,2)\n",
    "        self.c4=nn.Conv2d(256,512,3,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(512)\n",
    "        self.fc0=nn.Linear(2048,256)\n",
    "        self.fc1=nn.Linear(256,128)\n",
    "        self.fc2=nn.Linear(128,10)\n",
    "    def forward(self,X):\n",
    "        X=F.relu(self.bn1(self.c1(X)))\n",
    "        X=self.p1(self.fb1(X))\n",
    "        X=F.relu(self.bn2(self.c2(X)))\n",
    "        X=self.p2(self.fb2(X))\n",
    "        X=self.p4(F.relu(self.bn3(self.c3(X))))\n",
    "        X=self.p4(F.relu(self.bn4(self.c4(X))))\n",
    "        X=X.view(-1,2048)\n",
    "        X=F.relu(self.fc1(F.relu(self.fc0(X))))\n",
    "        X=self.fc2(X)\n",
    "        return X\n",
    "\n",
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,90,10)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 0.03051372542977333 test accuracy: 0.8935 time: 116.74633836746216\n",
      "Epoch: 2 Train loss: 0.0295064664989089 test accuracy: 0.88825 time: 223.6542718410492\n",
      "Epoch: 3 Train loss: 0.02616366548851753 test accuracy: 0.88475 time: 330.4164342880249\n",
      "Epoch: 4 Train loss: 0.030895102862268688 test accuracy: 0.8915 time: 437.206645488739\n",
      "Epoch: 5 Train loss: 0.02815421421158438 test accuracy: 0.89175 time: 544.2268781661987\n",
      "Epoch: 6 Train loss: 0.027090135977293053 test accuracy: 0.883 time: 651.4237592220306\n",
      "Epoch: 7 Train loss: 0.025261733665441474 test accuracy: 0.891 time: 758.3973379135132\n",
      "Epoch: 8 Train loss: 0.022791942488402127 test accuracy: 0.894 time: 865.0422923564911\n",
      "Epoch: 9 Train loss: 0.022945009152560186 test accuracy: 0.89325 time: 972.0949218273163\n",
      "Epoch: 10 Train loss: 0.025096950974936288 test accuracy: 0.894 time: 1078.9495260715485\n",
      "Epoch: 11 Train loss: 0.029411631364685793 test accuracy: 0.88875 time: 1185.8070557117462\n",
      "Epoch: 12 Train loss: 0.028368107633044322 test accuracy: 0.88625 time: 1292.7742216587067\n",
      "Epoch: 13 Train loss: 0.023504085982373604 test accuracy: 0.892 time: 1399.658347606659\n",
      "Epoch: 14 Train loss: 0.02453794553099821 test accuracy: 0.8905 time: 1506.5420560836792\n",
      "Epoch: 15 Train loss: 0.024626870837528257 test accuracy: 0.8905 time: 1613.653820514679\n",
      "Epoch: 16 Train loss: 0.02578377472818829 test accuracy: 0.89 time: 1720.4513113498688\n",
      "Epoch: 17 Train loss: 0.021606844446311394 test accuracy: 0.8965 time: 1827.2519569396973\n",
      "Epoch: 18 Train loss: 0.025135875008224198 test accuracy: 0.899 time: 1934.012080192566\n",
      "Epoch: 19 Train loss: 0.023215424052129188 test accuracy: 0.889 time: 2041.0079126358032\n",
      "Epoch: 20 Train loss: 0.02332872567543139 test accuracy: 0.88925 time: 2147.968754053116\n",
      "Epoch: 21 Train loss: 0.021008598724923406 test accuracy: 0.89125 time: 2255.0015943050385\n",
      "Epoch: 22 Train loss: 0.021356768940070953 test accuracy: 0.893 time: 2361.768649816513\n",
      "Epoch: 23 Train loss: 0.022507423243951052 test accuracy: 0.883 time: 2468.7723038196564\n",
      "Epoch: 24 Train loss: 0.022606665660471967 test accuracy: 0.89075 time: 2575.7819039821625\n",
      "Epoch: 25 Train loss: 0.01918665076373145 test accuracy: 0.88375 time: 2682.86469912529\n",
      "Epoch: 26 Train loss: 0.020190789243982484 test accuracy: 0.893 time: 2789.843314886093\n",
      "Epoch: 27 Train loss: 0.020168795640347525 test accuracy: 0.8945 time: 2896.806313276291\n",
      "Epoch: 28 Train loss: 0.017429631263560928 test accuracy: 0.89125 time: 3003.769719839096\n",
      "Epoch: 29 Train loss: 0.022269581033227345 test accuracy: 0.88275 time: 3111.0661401748657\n",
      "Epoch: 30 Train loss: 0.018164563357519606 test accuracy: 0.8855 time: 3218.0966670513153\n",
      "Epoch: 31 Train loss: 0.02001037672162056 test accuracy: 0.889 time: 3324.9888837337494\n",
      "Epoch: 32 Train loss: 0.020604197178424027 test accuracy: 0.89525 time: 3431.8941876888275\n",
      "Epoch: 33 Train loss: 0.018186607031384482 test accuracy: 0.896 time: 3538.8852124214172\n",
      "Epoch: 34 Train loss: 0.016611319302076783 test accuracy: 0.89175 time: 3645.627596616745\n",
      "Epoch: 35 Train loss: 0.019248055616238467 test accuracy: 0.88175 time: 3752.606067419052\n",
      "Epoch: 36 Train loss: 0.020107742688075327 test accuracy: 0.89525 time: 3859.7898185253143\n",
      "Epoch: 37 Train loss: 0.018128223882134382 test accuracy: 0.89 time: 3966.686897754669\n",
      "Epoch: 38 Train loss: 0.01719244468161681 test accuracy: 0.9005 time: 4073.6420345306396\n",
      "Epoch: 39 Train loss: 0.017324044782435523 test accuracy: 0.88875 time: 4180.494729042053\n",
      "Epoch: 40 Train loss: 0.017883988060445215 test accuracy: 0.8955 time: 4287.377097606659\n",
      "Epoch: 41 Train loss: 0.016407269769115374 test accuracy: 0.8935 time: 4394.256569623947\n",
      "Epoch: 42 Train loss: 0.01808127624099143 test accuracy: 0.89075 time: 4501.381846189499\n",
      "Epoch: 43 Train loss: 0.01669380843328933 test accuracy: 0.89425 time: 4608.380388975143\n",
      "Epoch: 44 Train loss: 0.016362960606541795 test accuracy: 0.89425 time: 4715.4087870121\n",
      "Epoch: 45 Train loss: 0.016168260077635447 test accuracy: 0.9015 time: 4822.909960508347\n",
      "Epoch: 46 Train loss: 0.014270702431288858 test accuracy: 0.8915 time: 4930.00812959671\n",
      "Epoch: 47 Train loss: 0.015401624845496068 test accuracy: 0.89575 time: 5036.9888734817505\n",
      "Epoch: 48 Train loss: 0.01575888753286563 test accuracy: 0.8955 time: 5143.945284843445\n",
      "Epoch: 49 Train loss: 0.013748654740629718 test accuracy: 0.89225 time: 5250.899761915207\n",
      "Epoch: 50 Train loss: 0.016447008872637524 test accuracy: 0.88925 time: 5357.7545828819275\n",
      "Epoch: 51 Train loss: 0.01833391421435711 test accuracy: 0.89225 time: 5464.6816210746765\n",
      "Epoch: 52 Train loss: 0.01697331838659011 test accuracy: 0.89225 time: 5571.781190633774\n",
      "Epoch: 53 Train loss: 0.014337805791486365 test accuracy: 0.895 time: 5678.655101299286\n",
      "Epoch: 54 Train loss: 0.013096694407674173 test accuracy: 0.8885 time: 5785.396570682526\n",
      "Epoch: 55 Train loss: 0.01787414444067205 test accuracy: 0.8895 time: 5892.47624373436\n",
      "Epoch: 56 Train loss: 0.01696520936093293 test accuracy: 0.89275 time: 5999.5090508461\n",
      "Epoch: 57 Train loss: 0.013248857868408475 test accuracy: 0.8905 time: 6106.492501974106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9015"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=500\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,100,10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 0.01594566713126066 test accuracy: 0.8925 time: 118.27213764190674\n",
      "Epoch: 2 Train loss: 0.013841352158730539 test accuracy: 0.895 time: 224.94381403923035\n",
      "Epoch: 3 Train loss: 0.014042485718770573 test accuracy: 0.89975 time: 331.9372224807739\n",
      "Epoch: 4 Train loss: 0.012461598541509982 test accuracy: 0.89675 time: 438.84532380104065\n",
      "Epoch: 5 Train loss: 0.013081887797064458 test accuracy: 0.89925 time: 545.7662198543549\n",
      "Epoch: 6 Train loss: 0.013503988966112957 test accuracy: 0.8915 time: 652.7046809196472\n",
      "Epoch: 7 Train loss: 0.013877387915272266 test accuracy: 0.89775 time: 759.7042717933655\n",
      "Epoch: 8 Train loss: 0.013315222303693494 test accuracy: 0.8895 time: 866.8131761550903\n",
      "Epoch: 9 Train loss: 0.014268294289164866 test accuracy: 0.8965 time: 973.90580701828\n",
      "Epoch: 10 Train loss: 0.012646718670536454 test accuracy: 0.8905 time: 1082.2039334774017\n",
      "Epoch: 11 Train loss: 0.010666097490563213 test accuracy: 0.891 time: 1189.1738274097443\n",
      "Epoch: 12 Train loss: 0.013168196711922065 test accuracy: 0.8975 time: 1296.1099553108215\n",
      "Epoch: 13 Train loss: 0.013462438886441911 test accuracy: 0.89775 time: 1403.011091709137\n",
      "Epoch: 14 Train loss: 0.013217720825438543 test accuracy: 0.89575 time: 1510.1800491809845\n",
      "Epoch: 15 Train loss: 0.015801251355636245 test accuracy: 0.8875 time: 1617.4157071113586\n",
      "Epoch: 16 Train loss: 0.012446125084534288 test accuracy: 0.88975 time: 1726.6142709255219\n",
      "Epoch: 17 Train loss: 0.013214260287350043 test accuracy: 0.8965 time: 1834.020048379898\n",
      "Epoch: 18 Train loss: 0.012239501808653585 test accuracy: 0.8945 time: 1940.7249312400818\n",
      "Epoch: 19 Train loss: 0.014913799556476684 test accuracy: 0.89725 time: 2047.4405047893524\n",
      "Epoch: 20 Train loss: 0.013638722076332972 test accuracy: 0.897 time: 2154.196120738983\n",
      "Epoch: 21 Train loss: 0.016015294912115983 test accuracy: 0.8945 time: 2261.1848776340485\n",
      "Epoch: 22 Train loss: 0.012252415367402136 test accuracy: 0.90275 time: 2368.0714299678802\n",
      "Epoch: 23 Train loss: 0.009026473758179538 test accuracy: 0.89825 time: 2475.096184015274\n",
      "Epoch: 24 Train loss: 0.010412832205959906 test accuracy: 0.8975 time: 2582.0836889743805\n",
      "Epoch: 25 Train loss: 0.01198445523865909 test accuracy: 0.90075 time: 2688.860711336136\n",
      "Epoch: 26 Train loss: 0.011237209333921782 test accuracy: 0.897 time: 2795.7561509609222\n",
      "Epoch: 27 Train loss: 0.011890053980459924 test accuracy: 0.89625 time: 2902.713924407959\n",
      "Epoch: 28 Train loss: 0.010129993620406215 test accuracy: 0.89525 time: 3009.504248857498\n",
      "Epoch: 29 Train loss: 0.011890540270057197 test accuracy: 0.8975 time: 3116.61754488945\n",
      "Epoch: 30 Train loss: 0.01352563339023618 test accuracy: 0.892 time: 3223.4706654548645\n",
      "Epoch: 31 Train loss: 0.0132154443495286 test accuracy: 0.89325 time: 3330.4276700019836\n",
      "Epoch: 32 Train loss: 0.011489701774553395 test accuracy: 0.89525 time: 3437.5515530109406\n",
      "Epoch: 33 Train loss: 0.011170816340018064 test accuracy: 0.89675 time: 3544.4898688793182\n",
      "Epoch: 34 Train loss: 0.010466365596706358 test accuracy: 0.903 time: 3651.325459957123\n",
      "Epoch: 35 Train loss: 0.010299250234190064 test accuracy: 0.895 time: 3758.483398914337\n",
      "Epoch: 36 Train loss: 0.009376810001655637 test accuracy: 0.8975 time: 3865.34952044487\n",
      "Epoch: 37 Train loss: 0.009916343613682935 test accuracy: 0.89675 time: 3972.4371070861816\n",
      "Epoch: 38 Train loss: 0.008844978033691102 test accuracy: 0.89875 time: 4079.1699085235596\n",
      "Epoch: 39 Train loss: 0.012731470655611095 test accuracy: 0.89525 time: 4185.915100336075\n",
      "Epoch: 40 Train loss: 0.009766819099119554 test accuracy: 0.89825 time: 4292.679238080978\n",
      "Epoch: 41 Train loss: 0.010375988476638062 test accuracy: 0.90175 time: 4399.571925640106\n",
      "Epoch: 42 Train loss: 0.011994563020319522 test accuracy: 0.9005 time: 4506.510584354401\n",
      "Epoch: 43 Train loss: 0.010689050915728634 test accuracy: 0.898 time: 4613.425137519836\n",
      "Epoch: 44 Train loss: 0.010749624032177963 test accuracy: 0.894 time: 4720.368383407593\n",
      "Epoch: 45 Train loss: 0.011538214498432352 test accuracy: 0.8925 time: 4827.282642126083\n",
      "Epoch: 46 Train loss: 0.010602153261424973 test accuracy: 0.899 time: 4934.131338834763\n",
      "Epoch: 47 Train loss: 0.00908101822521227 test accuracy: 0.8985 time: 5040.9853637218475\n",
      "Epoch: 48 Train loss: 0.011834266382599405 test accuracy: 0.89675 time: 5147.75471162796\n",
      "Epoch: 49 Train loss: 0.010309970266340921 test accuracy: 0.8925 time: 5254.815126180649\n",
      "Epoch: 50 Train loss: 0.010413617331990584 test accuracy: 0.887 time: 5361.723827600479\n",
      "Epoch: 51 Train loss: 0.011842960233722503 test accuracy: 0.89875 time: 5468.613452672958\n",
      "Epoch: 52 Train loss: 0.008595525656225315 test accuracy: 0.88975 time: 5575.656581401825\n",
      "Epoch: 53 Train loss: 0.008165430983353872 test accuracy: 0.8885 time: 5682.633568048477\n",
      "Epoch: 54 Train loss: 0.011797873398366694 test accuracy: 0.89275 time: 5789.836090803146\n",
      "Epoch: 55 Train loss: 0.007667881624850755 test accuracy: 0.89 time: 5896.78338098526\n",
      "Epoch: 56 Train loss: 0.010921698338643182 test accuracy: 0.8955 time: 6004.006058692932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.903"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=500\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=500\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layered fused block\n",
    "class fused_block(nn.Module):\n",
    "    def __init__(self,i):\n",
    "        super(fused_block,self).__init__()\n",
    "        self.c1=nn.Conv2d(i,4*i,1,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(4*i)\n",
    "        self.c2=nn.Conv2d(4*i,i,3,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(i)\n",
    "        self.c3=nn.Conv2d(i,i,1,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(i)\n",
    "        \n",
    "    def __call__(self,X):\n",
    "        temp=self.bn3(self.c3(F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X))))))))\n",
    "        return F.relu(temp)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,64,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.fb1=fused_block(64)\n",
    "        self.p1=nn.MaxPool2d(2,2)\n",
    "        self.c2=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(128)\n",
    "        self.fb2=fused_block(128)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "        self.c3=nn.Conv2d(128,256,3,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(256)\n",
    "        self.p3=nn.MaxPool2d(2,2)\n",
    "        self.p4=nn.MaxPool2d(2,2)\n",
    "        self.c4=nn.Conv2d(256,512,3,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(512)\n",
    "        self.fc0=nn.Linear(2048,256)\n",
    "        self.fc1=nn.Linear(256,128)\n",
    "        self.fc2=nn.Linear(128,10)\n",
    "    def forward(self,X):\n",
    "        X=F.relu(self.bn1(self.c1(X)))\n",
    "        X=self.p1(self.fb1(X))\n",
    "        X=F.relu(self.bn2(self.c2(X)))\n",
    "        X=self.p2(self.fb2(X))\n",
    "        X=self.p4(F.relu(self.bn3(self.c3(X))))\n",
    "        X=self.p4(F.relu(self.bn4(self.c4(X))))\n",
    "        X=X.view(-1,2048)\n",
    "        X=F.relu(self.fc1(F.relu(self.fc0(X))))\n",
    "        X=self.fc2(X)\n",
    "        return X\n",
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomChoice([transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1))]),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=200\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cifar10_dataset(Dataset):    \n",
    "    def __init__(self,data,train = True,img_transform=None):\n",
    "        self.img_transform = img_transform\n",
    "        self.is_train = train   \n",
    "#         data = pd.read_csv(data_csv, header=None)\n",
    "        if self.is_train:\n",
    "            self.images,self.labels=data[0],data[1]            \n",
    "#             images = data.iloc[:,1:].to_numpy()\n",
    "#             labels = data.iloc[:,0].astype(int)\n",
    "        else:\n",
    "            self.images=data\n",
    "#             images = data.iloc[:,:]\n",
    "#             labels = None  \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        image = self.images[i]\n",
    "        #image = np.array(image).astype(np.uint8).reshape((32, 32, 3),order='F')\n",
    "        if self.is_train:\n",
    "            label = self.labels[i]\n",
    "        else:\n",
    "            label = -1\n",
    "        image = self.img_transform(image)\n",
    "        return image,label\n",
    "    \n",
    "X_train=pd.read_csv('cifar10_data/train_data.csv',header=None)\n",
    "X_test=pd.read_csv('cifar10_data/public_test.csv',header=None)\n",
    "X_train,y_train=np.array(X_train.iloc[:,1:],dtype=np.uint8),np.array(X_train.iloc[:,0],dtype=int)\n",
    "X_test,y_test=np.array(X_test.iloc[:,1:],dtype=np.uint8),np.array(X_test.iloc[:,0],dtype=int)\n",
    "X_train,X_test=X_train.reshape((-1,3,32,32)).transpose(0,2,3,1),X_test.reshape((-1,3,32,32)).transpose(0,2,3,1)\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape\n",
    "\n",
    "def train(cnn,train_data,epochs,opt,loss,test_data,n,t):\n",
    "\n",
    "    th=time()\n",
    "#     losses=[]\n",
    "#     accuracies=[]\n",
    "    a=0\n",
    "    amax=0\n",
    "    t+=time()-th\n",
    "    for i in range(epochs):\n",
    "        th=time()\n",
    "        l=0\n",
    "        for j,(X,y) in enumerate(train_data):\n",
    "                \n",
    "            #print(X.shape,y.shape,type(X),type(y))\n",
    "            yh=cnn(X.cuda())\n",
    "            train_loss=loss(yh,y.type(torch.LongTensor).cuda())\n",
    "            opt.zero_grad()\n",
    "            l+=train_loss.item()\n",
    "            train_loss.backward()\n",
    "            opt.step()\n",
    "        t+=time()-th\n",
    "        th=time()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "#             losses.append(l)\n",
    "            l/=len(train_data) \n",
    "            a=0\n",
    "            for k,(X,y) in enumerate(test_data):\n",
    "                y_preds=cnn(X.cuda())\n",
    "                y_preds=torch.argmax(y_preds,dim=1).squeeze()\n",
    "                a+=(y.cuda()==y_preds).sum().item()\n",
    "            a/=n\n",
    "#             ac=0\n",
    "#             for k,(X,y) in enumerate(test):\n",
    "#                 y_preds=cnn(X)\n",
    "#                 y_preds=torch.argmax(y_preds,dim=1).squeeze()\n",
    "#                 ac+=(y==y_preds).sum().item()\n",
    "#             ac/=n    \n",
    "#            accuracies.append()\n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            print(\"Epoch: \"+str(i+1)+\" Train loss: \"+str(l)+\" test accuracy: \" +str(a)+\" time: \"+str(t))  \n",
    "            if(a>amax):\n",
    "                amax=a\n",
    "                torch.save(cnn.state_dict(),'C/model1.pth')\n",
    "            t+=time()-th\n",
    "        \n",
    "            \n",
    "    return amax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.933706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/textile/btech/tt1180958/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 1.2499797348181407 test accuracy: 0.6825 time: 132.95144701004028\n",
      "Epoch: 2 Train loss: 0.7831301792462667 test accuracy: 0.7765 time: 246.37721490859985\n",
      "Epoch: 3 Train loss: 0.605864942073822 test accuracy: 0.81225 time: 359.60923886299133\n",
      "Epoch: 4 Train loss: 0.5024707367022833 test accuracy: 0.828 time: 472.8800919055939\n",
      "Epoch: 5 Train loss: 0.4299016054471334 test accuracy: 0.839 time: 586.3695151805878\n",
      "Epoch: 6 Train loss: 0.3755283152560393 test accuracy: 0.847 time: 699.5546405315399\n",
      "Epoch: 7 Train loss: 0.33113459904988607 test accuracy: 0.857 time: 812.7818505764008\n",
      "Epoch: 8 Train loss: 0.2940612540145715 test accuracy: 0.8535 time: 926.0037081241608\n",
      "Epoch: 9 Train loss: 0.26213649064302447 test accuracy: 0.8595 time: 1039.216032743454\n",
      "Epoch: 10 Train loss: 0.2388439542800188 test accuracy: 0.862 time: 1152.4727206230164\n",
      "Epoch: 11 Train loss: 0.21842611735065778 test accuracy: 0.8645 time: 1265.7574326992035\n",
      "Epoch: 12 Train loss: 0.19640116882820924 test accuracy: 0.87225 time: 1378.905611038208\n",
      "Epoch: 13 Train loss: 0.1763388238598903 test accuracy: 0.876 time: 1492.1533727645874\n",
      "Epoch: 14 Train loss: 0.1675171715517839 test accuracy: 0.8565 time: 1605.4744956493378\n",
      "Epoch: 15 Train loss: 0.15334368067483106 test accuracy: 0.87225 time: 1718.6614165306091\n",
      "Epoch: 16 Train loss: 0.13881185779968896 test accuracy: 0.868 time: 1832.0363280773163\n",
      "Epoch: 17 Train loss: 0.12843517176806926 test accuracy: 0.8695 time: 1945.847708940506\n",
      "Epoch: 18 Train loss: 0.1215296382829547 test accuracy: 0.8735 time: 2059.7181248664856\n",
      "Epoch: 19 Train loss: 0.11173952985554933 test accuracy: 0.883 time: 2173.6606724262238\n",
      "Epoch: 20 Train loss: 0.10302608078966538 test accuracy: 0.873 time: 2287.6842930316925\n",
      "Epoch: 21 Train loss: 0.0965987936531504 test accuracy: 0.873 time: 2401.6233196258545\n",
      "Epoch: 22 Train loss: 0.08975621605912844 test accuracy: 0.8785 time: 2515.4221284389496\n",
      "Epoch: 23 Train loss: 0.08714581492667396 test accuracy: 0.87875 time: 2629.1622025966644\n",
      "Epoch: 24 Train loss: 0.08470130657156308 test accuracy: 0.87825 time: 2743.0109004974365\n",
      "Epoch: 25 Train loss: 0.07893829889285067 test accuracy: 0.88025 time: 2856.7584459781647\n",
      "Epoch: 26 Train loss: 0.07212550594160955 test accuracy: 0.882 time: 2970.951910495758\n",
      "Epoch: 27 Train loss: 0.07073675158123176 test accuracy: 0.883 time: 3084.3008110523224\n",
      "Epoch: 28 Train loss: 0.06654267347728213 test accuracy: 0.87625 time: 3197.344347715378\n",
      "Epoch: 29 Train loss: 0.06655034240024785 test accuracy: 0.886 time: 3310.537593603134\n",
      "Epoch: 30 Train loss: 0.06279566631341973 test accuracy: 0.88025 time: 3424.272162914276\n",
      "Epoch: 31 Train loss: 0.05906790903458992 test accuracy: 0.8785 time: 3538.1643481254578\n",
      "Epoch: 32 Train loss: 0.055579063473269345 test accuracy: 0.8865 time: 3651.9723932743073\n",
      "Epoch: 33 Train loss: 0.053336524326975145 test accuracy: 0.884 time: 3765.813488006592\n",
      "Epoch: 34 Train loss: 0.05203139556882282 test accuracy: 0.8875 time: 3879.7681612968445\n",
      "Epoch: 35 Train loss: 0.05185245112205545 test accuracy: 0.886 time: 3993.3644802570343\n",
      "Epoch: 36 Train loss: 0.050452625410010415 test accuracy: 0.8865 time: 4107.0254917144775\n",
      "Epoch: 37 Train loss: 0.048277097043270864 test accuracy: 0.8785 time: 4220.754345417023\n",
      "Epoch: 38 Train loss: 0.045119636887684465 test accuracy: 0.89175 time: 4334.498733758926\n",
      "Epoch: 39 Train loss: 0.04702511176622162 test accuracy: 0.883 time: 4448.183494567871\n",
      "Epoch: 40 Train loss: 0.043118244151895246 test accuracy: 0.884 time: 4561.855664253235\n",
      "Epoch: 41 Train loss: 0.041464534130257864 test accuracy: 0.8835 time: 4675.048645973206\n",
      "Epoch: 42 Train loss: 0.04296195829908053 test accuracy: 0.88575 time: 4788.343818902969\n",
      "Epoch: 43 Train loss: 0.03904638501194616 test accuracy: 0.88625 time: 4902.051355838776\n",
      "Epoch: 44 Train loss: 0.03825239175154517 test accuracy: 0.89175 time: 5015.799667835236\n",
      "Epoch: 45 Train loss: 0.03886866490317819 test accuracy: 0.8815 time: 5129.407410860062\n",
      "Epoch: 46 Train loss: 0.037680375104149184 test accuracy: 0.887 time: 5243.245564937592\n"
     ]
    }
   ],
   "source": [
    "class fused_block(nn.Module):\n",
    "    def __init__(self,i):\n",
    "        super(fused_block,self).__init__()\n",
    "        self.c1=nn.Conv2d(i,4*i,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(4*i)\n",
    "        self.c2=nn.Conv2d(4*i,i,1,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(i)\n",
    "    def __call__(self,X):\n",
    "        return F.relu(self.bn2(self.c2(F.relu(self.bn1(self.c1(X))))))\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.c1=nn.Conv2d(3,64,3,padding='same')\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.fb1=fused_block(64)\n",
    "        self.p1=nn.MaxPool2d(2,2)\n",
    "        self.c2=nn.Conv2d(64,128,3,padding='same')\n",
    "        self.bn2=nn.BatchNorm2d(128)\n",
    "        self.fb2=fused_block(128)\n",
    "        self.p2=nn.MaxPool2d(2,2)\n",
    "        self.c3=nn.Conv2d(128,256,3,padding='same')\n",
    "        self.bn3=nn.BatchNorm2d(256)\n",
    "        self.p3=nn.MaxPool2d(2,2)\n",
    "        self.p4=nn.MaxPool2d(2,2)\n",
    "        self.c4=nn.Conv2d(256,512,3,padding='same')\n",
    "        self.bn4=nn.BatchNorm2d(512)\n",
    "        self.fc0=nn.Linear(2048,256)\n",
    "        self.fc1=nn.Linear(256,128)\n",
    "        self.fc2=nn.Linear(128,10)\n",
    "    def forward(self,X):\n",
    "        X=F.relu(self.bn1(self.c1(X)))\n",
    "        X=self.p1(self.fb1(X))\n",
    "        X=F.relu(self.bn2(self.c2(X)))\n",
    "        X=self.p2(self.fb2(X))\n",
    "        X=self.p4(F.relu(self.bn3(self.c3(X))))\n",
    "        X=self.p4(F.relu(self.bn4(self.c4(X))))\n",
    "        X=X.view(-1,2048)\n",
    "        X=F.relu(self.fc1(F.relu(self.fc0(X))))\n",
    "        X=self.fc2(X)\n",
    "        return X\n",
    "    \n",
    "print(sum(p.numel() for p in CNN().parameters())/10**6) \n",
    "bs=200\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                   transforms.RandomRotation(5),\n",
    "                                    transforms.RandomAffine(0,translate=(.1,.1)),\n",
    "                                    transforms.ToTensor()])\n",
    "train_data=DataLoader(cifar10_dataset((X_train,y_train),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "n=X_test.shape[0]\n",
    "img_transform = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])                                 \n",
    "test_data=DataLoader(cifar10_dataset((X_test,y_test),True,img_transform),batch_size=bs,shuffle=False,num_workers=0)\n",
    "cnn=CNN()\n",
    "cnn=cnn.cuda()\n",
    "opt=optim.Adam(cnn.parameters(),lr=1e-3)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "epochs=200\n",
    "train(cnn,train_data,epochs,opt,loss,test_data,n,10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shubham)",
   "language": "python",
   "name": "shubham"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

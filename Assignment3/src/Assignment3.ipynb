{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91cef96",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-30T08:23:28.994837Z",
     "iopub.status.busy": "2021-11-30T08:23:28.993293Z",
     "iopub.status.idle": "2021-11-30T08:23:28.997884Z",
     "shell.execute_reply": "2021-11-30T08:23:28.997373Z"
    },
    "papermill": {
     "duration": 0.039026,
     "end_time": "2021-11-30T08:23:28.998011",
     "exception": false,
     "start_time": "2021-11-30T08:23:28.958985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3867b4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:23:29.064972Z",
     "iopub.status.busy": "2021-11-30T08:23:29.064234Z",
     "iopub.status.idle": "2021-11-30T08:23:29.066508Z",
     "shell.execute_reply": "2021-11-30T08:23:29.066080Z"
    },
    "papermill": {
     "duration": 0.038242,
     "end_time": "2021-11-30T08:23:29.066620",
     "exception": false,
     "start_time": "2021-11-30T08:23:29.028378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/kaggle/input/col341-a3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c51358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:23:29.132671Z",
     "iopub.status.busy": "2021-11-30T08:23:29.131965Z",
     "iopub.status.idle": "2021-11-30T08:23:35.374112Z",
     "shell.execute_reply": "2021-11-30T08:23:35.374567Z"
    },
    "papermill": {
     "duration": 6.277141,
     "end_time": "2021-11-30T08:23:35.374768",
     "exception": false,
     "start_time": "2021-11-30T08:23:29.097627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from time import time\n",
    "# Import TF and TF Hub libraries.\n",
    "import tensorflow as tf\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# import torchvision\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "np.random.seed(46)\n",
    "# torch.manual_seed(46)\n",
    "# from torchvision import transforms, utils,models\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "# from pytorch_pretrained_vit import ViT\n",
    "import keras\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96274314",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:23:35.439579Z",
     "iopub.status.busy": "2021-11-30T08:23:35.438806Z",
     "iopub.status.idle": "2021-11-30T08:23:35.506379Z",
     "shell.execute_reply": "2021-11-30T08:23:35.505941Z"
    },
    "papermill": {
     "duration": 0.101012,
     "end_time": "2021-11-30T08:23:35.506522",
     "exception": false,
     "start_time": "2021-11-30T08:23:35.405510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./training/450030N425231.jpg</td>\n",
       "      <td>Virabhadrasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./training/2634j01014741.jpg</td>\n",
       "      <td>Vrikshasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./training/440023N423072.jpg</td>\n",
       "      <td>Utkatasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./training/2845016N420103.jpg</td>\n",
       "      <td>Padahastasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./training/100024N423211.jpg</td>\n",
       "      <td>Katichakrasana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name        category\n",
       "0   ./training/450030N425231.jpg  Virabhadrasana\n",
       "1   ./training/2634j01014741.jpg     Vrikshasana\n",
       "2   ./training/440023N423072.jpg      Utkatasana\n",
       "3  ./training/2845016N420103.jpg   Padahastasana\n",
       "4   ./training/100024N423211.jpg  Katichakrasana"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.read_csv('training.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c920322c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:23:35.576550Z",
     "iopub.status.busy": "2021-11-30T08:23:35.575849Z",
     "iopub.status.idle": "2021-11-30T08:23:35.585626Z",
     "shell.execute_reply": "2021-11-30T08:23:35.585185Z"
    },
    "papermill": {
     "duration": 0.048931,
     "end_time": "2021-11-30T08:23:35.585747",
     "exception": false,
     "start_time": "2021-11-30T08:23:35.536816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./training/450030N425231.jpg</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./training/2634j01014741.jpg</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./training/440023N423072.jpg</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./training/2845016N420103.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./training/100024N423211.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  category\n",
       "0   ./training/450030N425231.jpg        17\n",
       "1   ./training/2634j01014741.jpg        18\n",
       "2   ./training/440023N423072.jpg        16\n",
       "3  ./training/2845016N420103.jpg         7\n",
       "4   ./training/100024N423211.jpg         3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['category']=train_data[\"category\"].astype('category').cat.codes\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "233d5642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:23:35.652074Z",
     "iopub.status.busy": "2021-11-30T08:23:35.651448Z",
     "iopub.status.idle": "2021-11-30T08:23:35.661040Z",
     "shell.execute_reply": "2021-11-30T08:23:35.660614Z"
    },
    "papermill": {
     "duration": 0.045215,
     "end_time": "2021-11-30T08:23:35.661153",
     "exception": false,
     "start_time": "2021-11-30T08:23:35.615938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29000, 2), (11, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=train_data.sample(frac=1.,random_state=46)\n",
    "train_data,test_data=train_data.iloc[:29000],train_data.iloc[29000:]\n",
    "train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea1c2093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:23:35.731397Z",
     "iopub.status.busy": "2021-11-30T08:23:35.730674Z",
     "iopub.status.idle": "2021-11-30T08:23:35.733098Z",
     "shell.execute_reply": "2021-11-30T08:23:35.732685Z"
    },
    "papermill": {
     "duration": 0.037603,
     "end_time": "2021-11-30T08:23:35.733204",
     "exception": false,
     "start_time": "2021-11-30T08:23:35.695601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow, gc\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e6cf5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:23:35.798820Z",
     "iopub.status.busy": "2021-11-30T08:23:35.797976Z",
     "iopub.status.idle": "2021-11-30T08:23:36.102163Z",
     "shell.execute_reply": "2021-11-30T08:23:36.103178Z"
    },
    "papermill": {
     "duration": 0.338677,
     "end_time": "2021-11-30T08:23:36.103358",
     "exception": false,
     "start_time": "2021-11-30T08:23:35.764681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataGenerator(tensorflow.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data,train=True,val=False, batch_size=32, n_channels=3,\n",
    "                 n_classes=19, shuffle=True):\n",
    "        'Initialization'\n",
    "        #self.dim = dim\n",
    "        self.train=train\n",
    "        self.val=val\n",
    "        self.batch_size = batch_size\n",
    "        if(self.train):\n",
    "            self.labels = data.iloc[:,1].to_numpy()\n",
    "            self.list_IDs = data.iloc[:,0].to_numpy()\n",
    "        else:\n",
    "            self.labels = data.to_numpy().squeeze()\n",
    "            self.list_IDs = data.to_numpy().squeeze()\n",
    "        self.total=self.labels.shape[0] \n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.augmentor = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.15,\n",
    "            height_shift_range=0.15,\n",
    "            shear_range=0.15,\n",
    "            zoom_range=0.15,\n",
    "            fill_mode='nearest',\n",
    "            horizontal_flip=True,\n",
    "        )\n",
    "        #Image.fromarray(numpy_image.astype('uint8'), 'RGB')\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        if (self.train==False):\n",
    "            return int(np.floor(len(self.list_IDs) / self.batch_size))+1\n",
    "        else:\n",
    "            return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "    \n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "       \n",
    "        # Find list of IDs\n",
    "        image_names = [self.list_IDs[k] for k in indexes]\n",
    "        if(self.train):\n",
    "            y=np.array([self.labels[i] for i in indexes],dtype=int)\n",
    "        # Generate data\n",
    "        X = self.__data_generation(image_names)\n",
    "        if(self.train):\n",
    "            return X, tensorflow.keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        else:\n",
    "            return X,np.array(image_names)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        gc.collect()\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        os.chdir(\"/kaggle/input/col341-a3\")\n",
    "        \n",
    "        X = np.empty((self.batch_size, 256,256, self.n_channels))\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            X[i,] = cv2.imread(ID)[-256:,128:128+256,:]\n",
    "        if(self.train==True and self.val==False):\n",
    "            X = self.augmentor.flow(X, batch_size=self.batch_size, shuffle=False)[0]\n",
    "#         X=np.array(transforms.Compose([transforms.ToPILImage(),transforms.RandomPerspective()])(X))\n",
    "        gc.collect()\n",
    "        os.chdir(\"/kaggle/working\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37d9094b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:23:36.179521Z",
     "iopub.status.busy": "2021-11-30T08:23:36.178623Z",
     "iopub.status.idle": "2021-11-30T08:23:36.182345Z",
     "shell.execute_reply": "2021-11-30T08:23:36.181922Z"
    },
    "papermill": {
     "duration": 0.046732,
     "end_time": "2021-11-30T08:23:36.182580",
     "exception": false,
     "start_time": "2021-11-30T08:23:36.135848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import keras as keras\n",
    "\n",
    "\n",
    "# Generators\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import keras as keras\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    training_generator = DataGenerator(train_data,True,False,24,3,19,True)\n",
    "    validation_generator = DataGenerator(test_data,True,True,24,3,19,True)\n",
    "\n",
    "\n",
    "    base_model = tf.keras.applications.EfficientNetB5(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        classes=19,\n",
    "    )\n",
    "\n",
    "    inputs = keras.Input(shape=(256, 256, 3))\n",
    "\n",
    "    x = base_model(inputs, training=True)\n",
    "    # x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.GlobalMaxPool2D()(x)\n",
    "    x = keras.layers.Dense(1024,activation='relu')(x)\n",
    "    #x = keras.layers.Dense(128,activation='relu')(x)\n",
    "    outputs = keras.layers.Dense(19,activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    def scheduler(epoch, lr):\n",
    "        return lr*((.9)**(epoch-1))\n",
    "    modelcheckpoint=tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"model.h5\",\n",
    "        monitor=\"val_acc\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        mode=\"auto\",\n",
    "        save_freq=\"epoch\",\n",
    "        options=None,\n",
    "    )\n",
    "    #tf.config.get_visible_devices()\n",
    "    lrs = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=6e-4),\n",
    "              loss='categorical_crossentropy',metrics=[\"acc\"])\n",
    "    # Train model on dataset\n",
    "    model.fit_generator(epochs=5,generator=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        use_multiprocessing=True,callbacks=[lrs],\n",
    "                        workers=6)\n",
    "\n",
    "    os.chdir('/kaggle/working')\n",
    "    model.save('effb5')\n",
    "\n",
    "    import shutil\n",
    "    shutil.make_archive('effb5', 'zip', 'effb5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a77f332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:23:36.249941Z",
     "iopub.status.busy": "2021-11-30T08:23:36.247615Z",
     "iopub.status.idle": "2021-11-30T09:47:34.891900Z",
     "shell.execute_reply": "2021-11-30T09:47:34.891355Z"
    },
    "papermill": {
     "duration": 5038.678106,
     "end_time": "2021-11-30T09:47:34.892042",
     "exception": false,
     "start_time": "2021-11-30T08:23:36.213936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 08:23:36.766130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 08:23:36.767748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 08:23:36.768843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 08:23:36.770125: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-30 08:23:36.771488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 08:23:36.772673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 08:23:36.773803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 08:23:41.570294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 08:23:41.571676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 08:23:41.572957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 08:23:41.573924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14959 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n",
      "115269632/115263384 [==============================] - 1s 0us/step\n",
      "115277824/115263384 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 08:23:49.621498: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-30 08:24:14.852967: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208/1208 [==============================] - 980s 785ms/step - loss: 0.8668 - acc: 0.7590\n",
      "Epoch 2/5\n",
      "1208/1208 [==============================] - 957s 787ms/step - loss: 0.4486 - acc: 0.8611\n",
      "Epoch 3/5\n",
      "1208/1208 [==============================] - 948s 780ms/step - loss: 0.3687 - acc: 0.8795\n",
      "Epoch 4/5\n",
      "1208/1208 [==============================] - 960s 791ms/step - loss: 0.3086 - acc: 0.8964\n",
      "Epoch 5/5\n",
      "1208/1208 [==============================] - 964s 794ms/step - loss: 0.2556 - acc: 0.9108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 09:46:16.981660: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "p = multiprocessing.Process(target=train)\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ef9a268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T09:47:47.812860Z",
     "iopub.status.busy": "2021-11-30T09:47:47.812130Z",
     "iopub.status.idle": "2021-11-30T09:47:47.816157Z",
     "shell.execute_reply": "2021-11-30T09:47:47.815754Z",
     "shell.execute_reply.started": "2021-11-16T20:45:04.125003Z"
    },
    "papermill": {
     "duration": 6.521046,
     "end_time": "2021-11-30T09:47:47.816282",
     "exception": false,
     "start_time": "2021-11-30T09:47:41.295236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/kaggle/input/col341-a3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b08061c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T09:48:00.649157Z",
     "iopub.status.busy": "2021-11-30T09:48:00.648196Z",
     "iopub.status.idle": "2021-11-30T09:48:00.652054Z",
     "shell.execute_reply": "2021-11-30T09:48:00.651577Z",
     "shell.execute_reply.started": "2021-11-16T20:45:04.732756Z"
    },
    "papermill": {
     "duration": 6.169685,
     "end_time": "2021-11-30T09:48:00.652173",
     "exception": false,
     "start_time": "2021-11-30T09:47:54.482488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from time import time\n",
    "# Import TF and TF Hub libraries.\n",
    "import tensorflow as tf\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# import torchvision\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "np.random.seed(46)\n",
    "# torch.manual_seed(46)\n",
    "# from torchvision import transforms, utils,models\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "# from pytorch_pretrained_vit import ViT\n",
    "import keras\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(46)\n",
    "import random\n",
    "random.seed(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db584755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T09:48:14.043299Z",
     "iopub.status.busy": "2021-11-30T09:48:14.042756Z",
     "iopub.status.idle": "2021-11-30T09:48:14.079919Z",
     "shell.execute_reply": "2021-11-30T09:48:14.080325Z",
     "shell.execute_reply.started": "2021-11-16T20:45:11.469530Z"
    },
    "papermill": {
     "duration": 6.52242,
     "end_time": "2021-11-30T09:48:14.080498",
     "exception": false,
     "start_time": "2021-11-30T09:48:07.558078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./training/450030N425231.jpg</td>\n",
       "      <td>Virabhadrasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./training/2634j01014741.jpg</td>\n",
       "      <td>Vrikshasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./training/440023N423072.jpg</td>\n",
       "      <td>Utkatasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./training/2845016N420103.jpg</td>\n",
       "      <td>Padahastasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./training/100024N423211.jpg</td>\n",
       "      <td>Katichakrasana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name        category\n",
       "0   ./training/450030N425231.jpg  Virabhadrasana\n",
       "1   ./training/2634j01014741.jpg     Vrikshasana\n",
       "2   ./training/440023N423072.jpg      Utkatasana\n",
       "3  ./training/2845016N420103.jpg   Padahastasana\n",
       "4   ./training/100024N423211.jpg  Katichakrasana"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.read_csv('training.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "754a78a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T09:48:26.803314Z",
     "iopub.status.busy": "2021-11-30T09:48:26.801813Z",
     "iopub.status.idle": "2021-11-30T09:48:26.811992Z",
     "shell.execute_reply": "2021-11-30T09:48:26.812481Z",
     "shell.execute_reply.started": "2021-11-16T20:45:11.539259Z"
    },
    "papermill": {
     "duration": 6.512155,
     "end_time": "2021-11-30T09:48:26.812643",
     "exception": false,
     "start_time": "2021-11-30T09:48:20.300488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./training/450030N425231.jpg</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./training/2634j01014741.jpg</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./training/440023N423072.jpg</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./training/2845016N420103.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./training/100024N423211.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  category\n",
       "0   ./training/450030N425231.jpg        17\n",
       "1   ./training/2634j01014741.jpg        18\n",
       "2   ./training/440023N423072.jpg        16\n",
       "3  ./training/2845016N420103.jpg         7\n",
       "4   ./training/100024N423211.jpg         3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['category']=train_data[\"category\"].astype('category').cat.codes\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dbcc017",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T09:48:39.917389Z",
     "iopub.status.busy": "2021-11-30T09:48:39.916606Z",
     "iopub.status.idle": "2021-11-30T09:48:39.924701Z",
     "shell.execute_reply": "2021-11-30T09:48:39.925112Z",
     "shell.execute_reply.started": "2021-11-16T20:45:11.559180Z"
    },
    "papermill": {
     "duration": 6.827243,
     "end_time": "2021-11-30T09:48:39.925246",
     "exception": false,
     "start_time": "2021-11-30T09:48:33.098003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29000, 2), (11, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=train_data.sample(frac=1.,random_state=46)\n",
    "train_data,test_data=train_data.iloc[:29000],train_data.iloc[29000:]\n",
    "train_data.shape,test_data.shape\n",
    "# train_data=train_data.to_numpy()\n",
    "# train_data.shape\n",
    "# np.random.shuffle(train_data)\n",
    "# train_data,test_data=train_data[:26000],train_data[26000:]\n",
    "# train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63a91966",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T09:48:52.578254Z",
     "iopub.status.busy": "2021-11-30T09:48:52.577451Z",
     "iopub.status.idle": "2021-11-30T09:48:52.579956Z",
     "shell.execute_reply": "2021-11-30T09:48:52.579551Z",
     "shell.execute_reply.started": "2021-11-16T20:45:11.574170Z"
    },
    "papermill": {
     "duration": 6.514542,
     "end_time": "2021-11-30T09:48:52.580069",
     "exception": false,
     "start_time": "2021-11-30T09:48:46.065527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow, gc\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f95ec73f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T09:49:05.126847Z",
     "iopub.status.busy": "2021-11-30T09:49:05.125973Z",
     "iopub.status.idle": "2021-11-30T09:49:05.127818Z",
     "shell.execute_reply": "2021-11-30T09:49:05.128313Z",
     "shell.execute_reply.started": "2021-11-16T20:45:11.580829Z"
    },
    "papermill": {
     "duration": 6.168634,
     "end_time": "2021-11-30T09:49:05.128471",
     "exception": false,
     "start_time": "2021-11-30T09:48:58.959837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataGenerator(tensorflow.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data,train=True,val=False, batch_size=32, n_channels=3,\n",
    "                 n_classes=19, shuffle=True):\n",
    "        'Initialization'\n",
    "        #self.dim = dim\n",
    "        self.train=train\n",
    "        self.val=val\n",
    "        self.batch_size = batch_size\n",
    "        if(self.train):\n",
    "            self.labels = data.iloc[:,1].to_numpy()\n",
    "            self.list_IDs = data.iloc[:,0].to_numpy()\n",
    "        else:\n",
    "            self.labels = data.to_numpy().squeeze()\n",
    "            self.list_IDs = data.to_numpy().squeeze()\n",
    "        self.total=self.labels.shape[0] \n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.augmentor = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.15,\n",
    "            height_shift_range=0.15,\n",
    "            shear_range=0.15,\n",
    "            zoom_range=0.15,\n",
    "            fill_mode='nearest',\n",
    "            horizontal_flip=True,\n",
    "        )\n",
    "        #Image.fromarray(numpy_image.astype('uint8'), 'RGB')\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        if (self.train==False):\n",
    "            return int(np.floor(len(self.list_IDs) / self.batch_size))+1\n",
    "        else:\n",
    "            return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "    \n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "       \n",
    "        # Find list of IDs\n",
    "        image_names = [self.list_IDs[k] for k in indexes]\n",
    "        if(self.train):\n",
    "            y=np.array([self.labels[i] for i in indexes],dtype=int)\n",
    "        # Generate data\n",
    "        X = self.__data_generation(image_names)\n",
    "        if(self.train):\n",
    "            return X, tensorflow.keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        else:\n",
    "            return X,np.array(image_names)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        gc.collect()\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        os.chdir(\"/kaggle/input/col341-a3\")\n",
    "        \n",
    "        X = np.empty((self.batch_size, 256,256, self.n_channels))\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            X[i,] = cv2.imread(ID)[-256:,128:128+256,:]\n",
    "        if(self.train==True and self.val==False):\n",
    "            X = self.augmentor.flow(X, batch_size=self.batch_size, shuffle=False)[0]\n",
    "        gc.collect()\n",
    "        os.chdir(\"/kaggle/working\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fc69abe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T09:49:18.148015Z",
     "iopub.status.busy": "2021-11-30T09:49:18.147001Z",
     "iopub.status.idle": "2021-11-30T09:49:18.148770Z",
     "shell.execute_reply": "2021-11-30T09:49:18.149186Z",
     "shell.execute_reply.started": "2021-11-16T20:45:11.898277Z"
    },
    "papermill": {
     "duration": 6.151302,
     "end_time": "2021-11-30T09:49:18.149326",
     "exception": false,
     "start_time": "2021-11-30T09:49:11.998024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import keras as keras\n",
    "\n",
    "\n",
    "# Generators\n",
    "\n",
    "\n",
    "def train():\n",
    "    training_generator = DataGenerator(train_data,True,False,40,3,19,True)\n",
    "    validation_generator = DataGenerator(test_data,True,True,40,3,19,True)\n",
    "\n",
    "    base_model = tf.keras.applications.Xception(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        classes=19,\n",
    "    )\n",
    "\n",
    "    inputs = keras.Input(shape=(256, 256, 3))\n",
    "\n",
    "    x = base_model(inputs, training=True)\n",
    "    # x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.GlobalMaxPool2D()(x)\n",
    "    x = keras.layers.Dense(1024,activation='relu')(x)\n",
    "    #x = keras.layers.Dense(128,activation='relu')(x)\n",
    "    outputs = keras.layers.Dense(19,activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    gc.collect()\n",
    "\n",
    "    def scheduler(epoch, lr):\n",
    "        return lr*((.95)**(epoch-1))\n",
    "    modelcheckpoint=tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"model.h5\",\n",
    "        monitor=\"val_acc\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        mode=\"auto\",\n",
    "        save_freq=\"epoch\",\n",
    "        options=None,\n",
    "    )\n",
    "    #tf.config.get_visible_devices()\n",
    "    lrs = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=5.5e-4),\n",
    "              loss='categorical_crossentropy',metrics=[\"acc\"])\n",
    "    # Train model on dataset\n",
    "    model.fit_generator(epochs=5,generator=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        use_multiprocessing=True,callbacks=[lrs],\n",
    "                        workers=6)\n",
    "\n",
    "    os.chdir('/kaggle/working')\n",
    "    model.save('xception')\n",
    "\n",
    "    import shutil\n",
    "    shutil.make_archive('xception', 'zip', 'xception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8c35943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T09:49:30.981049Z",
     "iopub.status.busy": "2021-11-30T09:49:30.979836Z",
     "iopub.status.idle": "2021-11-30T10:43:04.256857Z",
     "shell.execute_reply": "2021-11-30T10:43:04.256185Z",
     "shell.execute_reply.started": "2021-11-16T20:45:19.254408Z"
    },
    "papermill": {
     "duration": 3219.702482,
     "end_time": "2021-11-30T10:43:04.257019",
     "exception": false,
     "start_time": "2021-11-30T09:49:24.554537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 09:49:31.465771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 09:49:31.467459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 09:49:31.468347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 09:49:31.469591: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-30 09:49:31.469962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 09:49:31.471004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 09:49:31.471863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 09:49:33.584466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 09:49:33.585616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 09:49:33.586516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 09:49:33.587272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14959 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 0s 0us/step\n",
      "83697664/83683744 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 09:49:36.788207: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-30 09:49:47.917805: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725/725 [==============================] - 642s 864ms/step - loss: 1.2593 - acc: 0.6005\n",
      "Epoch 2/5\n",
      "725/725 [==============================] - 595s 804ms/step - loss: 0.4842 - acc: 0.8483\n",
      "Epoch 3/5\n",
      "725/725 [==============================] - 602s 822ms/step - loss: 0.3917 - acc: 0.8735\n",
      "Epoch 4/5\n",
      "725/725 [==============================] - 616s 834ms/step - loss: 0.3347 - acc: 0.8889\n",
      "Epoch 5/5\n",
      "725/725 [==============================] - 621s 842ms/step - loss: 0.2835 - acc: 0.9019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 10:42:34.464671: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "p = multiprocessing.Process(target=train)\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1c3ec8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T10:43:24.855542Z",
     "iopub.status.busy": "2021-11-30T10:43:24.852679Z",
     "iopub.status.idle": "2021-11-30T10:43:24.862776Z",
     "shell.execute_reply": "2021-11-30T10:43:24.861921Z"
    },
    "papermill": {
     "duration": 10.305354,
     "end_time": "2021-11-30T10:43:24.862944",
     "exception": false,
     "start_time": "2021-11-30T10:43:14.557590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/kaggle/input/col341-a3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b3a4dd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T10:43:45.864524Z",
     "iopub.status.busy": "2021-11-30T10:43:45.863696Z",
     "iopub.status.idle": "2021-11-30T10:43:45.867389Z",
     "shell.execute_reply": "2021-11-30T10:43:45.867796Z"
    },
    "papermill": {
     "duration": 10.241199,
     "end_time": "2021-11-30T10:43:45.867930",
     "exception": false,
     "start_time": "2021-11-30T10:43:35.626731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from time import time\n",
    "# Import TF and TF Hub libraries.\n",
    "import tensorflow as tf\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# import torchvision\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "np.random.seed(46)\n",
    "# torch.manual_seed(46)\n",
    "# from torchvision import transforms, utils,models\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "# from pytorch_pretrained_vit import ViT\n",
    "import keras\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(46)\n",
    "# import random\n",
    "# random.seed(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c40b5419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T10:44:07.057160Z",
     "iopub.status.busy": "2021-11-30T10:44:07.056499Z",
     "iopub.status.idle": "2021-11-30T10:44:07.100253Z",
     "shell.execute_reply": "2021-11-30T10:44:07.099804Z"
    },
    "papermill": {
     "duration": 10.901501,
     "end_time": "2021-11-30T10:44:07.100378",
     "exception": false,
     "start_time": "2021-11-30T10:43:56.198877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29000, 2), (11, 2))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.read_csv('training.csv')\n",
    "train_data.head()\n",
    "train_data['category']=train_data[\"category\"].astype('category').cat.codes\n",
    "train_data.head()\n",
    "train_data=train_data.sample(frac=1.,random_state=46)\n",
    "train_data,test_data=train_data.iloc[:29000],train_data.iloc[29000:]\n",
    "train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "755b7019",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T10:44:27.729427Z",
     "iopub.status.busy": "2021-11-30T10:44:27.728774Z",
     "iopub.status.idle": "2021-11-30T10:44:27.731632Z",
     "shell.execute_reply": "2021-11-30T10:44:27.731169Z"
    },
    "papermill": {
     "duration": 10.310672,
     "end_time": "2021-11-30T10:44:27.731754",
     "exception": false,
     "start_time": "2021-11-30T10:44:17.421082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow, gc\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "class DataGenerator(tensorflow.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data,train=True,val=False, batch_size=32, n_channels=3,\n",
    "                 n_classes=19, shuffle=True):\n",
    "        'Initialization'\n",
    "        #self.dim = dim\n",
    "        self.train=train\n",
    "        self.val=val\n",
    "        self.batch_size = batch_size\n",
    "        if(self.train):\n",
    "            self.labels = data.iloc[:,1].to_numpy()\n",
    "            self.list_IDs = data.iloc[:,0].to_numpy()\n",
    "        else:\n",
    "            self.labels = data.to_numpy().squeeze()\n",
    "            self.list_IDs = data.to_numpy().squeeze()\n",
    "        self.total=self.labels.shape[0] \n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.augmentor = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.15,\n",
    "            height_shift_range=0.15,\n",
    "            shear_range=0.15,\n",
    "            zoom_range=0.15,\n",
    "            fill_mode='nearest',\n",
    "            horizontal_flip=True,\n",
    "        )\n",
    "        #Image.fromarray(numpy_image.astype('uint8'), 'RGB')\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        if (self.train==False):\n",
    "            return int(np.floor(len(self.list_IDs) / self.batch_size))+1\n",
    "        else:\n",
    "            return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "    \n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "       \n",
    "        # Find list of IDs\n",
    "        image_names = [self.list_IDs[k] for k in indexes]\n",
    "        if(self.train):\n",
    "            y=np.array([self.labels[i] for i in indexes],dtype=int)\n",
    "        # Generate data\n",
    "        X = self.__data_generation(image_names)\n",
    "        if(self.train):\n",
    "            return X, tensorflow.keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        else:\n",
    "            return X,np.array(image_names)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        gc.collect()\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        os.chdir(\"/kaggle/input/col341-a3\")\n",
    "        \n",
    "        X = np.empty((self.batch_size, 256,256, self.n_channels))\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            X[i,] = cv2.imread(ID)[-256:,128:128+256,:]\n",
    "        if(self.train==True and self.val==False):\n",
    "            X = self.augmentor.flow(X, batch_size=self.batch_size, shuffle=False)[0]\n",
    "        gc.collect()\n",
    "        os.chdir(\"/kaggle/working\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a7e76dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T10:44:49.179011Z",
     "iopub.status.busy": "2021-11-30T10:44:49.177438Z",
     "iopub.status.idle": "2021-11-30T10:44:49.179609Z",
     "shell.execute_reply": "2021-11-30T10:44:49.180020Z"
    },
    "papermill": {
     "duration": 10.318166,
     "end_time": "2021-11-30T10:44:49.180156",
     "exception": false,
     "start_time": "2021-11-30T10:44:38.861990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import keras as keras\n",
    "\n",
    "\n",
    "# Generators\n",
    "def train():\n",
    "    training_generator = DataGenerator(train_data,True,False,40,3,19,True)\n",
    "    validation_generator = DataGenerator(test_data,True,True,40,3,19,True)\n",
    "\n",
    "\n",
    "    base_model = tf.keras.applications.ResNet50V2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        classes=19,\n",
    "    )\n",
    "\n",
    "    inputs = keras.Input(shape=(256, 256, 3))\n",
    "\n",
    "    x = base_model(inputs, training=True)\n",
    "    # x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.GlobalMaxPool2D()(x)\n",
    "    x = keras.layers.Dense(1024,activation='relu')(x)\n",
    "    #x = keras.layers.Dense(128,activation='relu')(x)\n",
    "    outputs = keras.layers.Dense(19,activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    gc.collect()\n",
    "\n",
    "    def scheduler(epoch, lr):\n",
    "        return lr*((.95)**(epoch-1))\n",
    "    modelcheckpoint=tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"model.h5\",\n",
    "        monitor=\"val_acc\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        mode=\"auto\",\n",
    "        save_freq=\"epoch\",\n",
    "        options=None,\n",
    "    )\n",
    "    #tf.config.get_visible_devices()\n",
    "    lrs = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=5e-4),\n",
    "              loss=\"categorical_crossentropy\",metrics=[\"acc\"])\n",
    "\n",
    "    # Train model on dataset\n",
    "    model.fit_generator(epochs=5,generator=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        use_multiprocessing=True,callbacks=[lrs],\n",
    "                        workers=6)\n",
    "\n",
    "    os.chdir('/kaggle/working')\n",
    "    model.save('resnet50v2')\n",
    "\n",
    "    import shutil\n",
    "    shutil.make_archive('resnet50v2', 'zip', 'resnet50v2')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7653983d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T10:45:10.338111Z",
     "iopub.status.busy": "2021-11-30T10:45:10.337206Z",
     "iopub.status.idle": "2021-11-30T11:36:20.412876Z",
     "shell.execute_reply": "2021-11-30T11:36:20.412329Z"
    },
    "papermill": {
     "duration": 3080.85909,
     "end_time": "2021-11-30T11:36:20.413023",
     "exception": false,
     "start_time": "2021-11-30T10:44:59.553933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 10:45:10.819250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 10:45:10.821131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 10:45:10.822218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 10:45:10.823663: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-30 10:45:10.824151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 10:45:10.825498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 10:45:10.826658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 10:45:12.970224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 10:45:12.971425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 10:45:12.972630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 10:45:12.973648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14959 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94674944/94668760 [==============================] - 1s 0us/step\n",
      "94683136/94668760 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 10:45:16.822982: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-30 10:45:28.068176: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725/725 [==============================] - 613s 824ms/step - loss: 1.1550 - acc: 0.6978\n",
      "Epoch 2/5\n",
      "725/725 [==============================] - 577s 778ms/step - loss: 0.5633 - acc: 0.8241\n",
      "Epoch 3/5\n",
      "725/725 [==============================] - 573s 782ms/step - loss: 0.4781 - acc: 0.8500\n",
      "Epoch 4/5\n",
      "725/725 [==============================] - 573s 784ms/step - loss: 0.4219 - acc: 0.8635\n",
      "Epoch 5/5\n",
      "725/725 [==============================] - 576s 777ms/step - loss: 0.3775 - acc: 0.8739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 11:35:45.780705: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "p = multiprocessing.Process(target=train)\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7808853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T11:36:49.219984Z",
     "iopub.status.busy": "2021-11-30T11:36:49.219243Z",
     "iopub.status.idle": "2021-11-30T11:36:49.225017Z",
     "shell.execute_reply": "2021-11-30T11:36:49.224555Z"
    },
    "papermill": {
     "duration": 14.839293,
     "end_time": "2021-11-30T11:36:49.225137",
     "exception": false,
     "start_time": "2021-11-30T11:36:34.385844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/kaggle/input/col341-a3\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from time import time\n",
    "# Import TF and TF Hub libraries.\n",
    "import tensorflow as tf\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# import torchvision\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "np.random.seed(46)\n",
    "# torch.manual_seed(46)\n",
    "# from torchvision import transforms, utils,models\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "# from pytorch_pretrained_vit import ViT\n",
    "import keras\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(46)\n",
    "import random\n",
    "random.seed(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74a6c865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T11:37:17.627260Z",
     "iopub.status.busy": "2021-11-30T11:37:17.626708Z",
     "iopub.status.idle": "2021-11-30T11:37:17.668862Z",
     "shell.execute_reply": "2021-11-30T11:37:17.668353Z"
    },
    "papermill": {
     "duration": 14.555302,
     "end_time": "2021-11-30T11:37:17.668982",
     "exception": false,
     "start_time": "2021-11-30T11:37:03.113680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29000, 2), (11, 2))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.read_csv('training.csv')\n",
    "train_data.head()\n",
    "train_data['category']=train_data[\"category\"].astype('category').cat.codes\n",
    "train_data.head()\n",
    "train_data=train_data.sample(frac=1.,random_state=46)\n",
    "train_data,test_data=train_data.iloc[:29000],train_data.iloc[29000:]\n",
    "train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51de8c5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T11:37:45.833898Z",
     "iopub.status.busy": "2021-11-30T11:37:45.832996Z",
     "iopub.status.idle": "2021-11-30T11:37:45.835526Z",
     "shell.execute_reply": "2021-11-30T11:37:45.835100Z"
    },
    "papermill": {
     "duration": 13.926552,
     "end_time": "2021-11-30T11:37:45.835647",
     "exception": false,
     "start_time": "2021-11-30T11:37:31.909095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow, gc\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "class DataGenerator(tensorflow.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data,train=True,val=False, batch_size=32, n_channels=3,\n",
    "                 n_classes=19, shuffle=True):\n",
    "        'Initialization'\n",
    "        #self.dim = dim\n",
    "        self.train=train\n",
    "        self.val=val\n",
    "        self.batch_size = batch_size\n",
    "        if(self.train):\n",
    "            self.labels = data.iloc[:,1].to_numpy()\n",
    "            self.list_IDs = data.iloc[:,0].to_numpy()\n",
    "        else:\n",
    "            self.labels = data.to_numpy().squeeze()\n",
    "            self.list_IDs = data.to_numpy().squeeze()\n",
    "        self.total=self.labels.shape[0] \n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.augmentor = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.15,\n",
    "            height_shift_range=0.15,\n",
    "            shear_range=0.15,\n",
    "            zoom_range=0.15,\n",
    "            fill_mode='nearest',\n",
    "            horizontal_flip=True,\n",
    "        )\n",
    "        #Image.fromarray(numpy_image.astype('uint8'), 'RGB')\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        if (self.train==False):\n",
    "            return int(np.floor(len(self.list_IDs) / self.batch_size))+1\n",
    "        else:\n",
    "            return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "    \n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "       \n",
    "        # Find list of IDs\n",
    "        image_names = [self.list_IDs[k] for k in indexes]\n",
    "        if(self.train):\n",
    "            y=np.array([self.labels[i] for i in indexes],dtype=int)\n",
    "        # Generate data\n",
    "        X = self.__data_generation(image_names)\n",
    "        if(self.train):\n",
    "            return X, tensorflow.keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        else:\n",
    "            return X,np.array(image_names)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        gc.collect()\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        os.chdir(\"/kaggle/input/col341-a3\")\n",
    "        \n",
    "        X = np.empty((self.batch_size, 256,256, self.n_channels))\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            X[i,] = cv2.imread(ID)[-256:,128:128+256,:]\n",
    "        if(self.train==True and self.val==False):\n",
    "            X = self.augmentor.flow(X, batch_size=self.batch_size, shuffle=False)[0]\n",
    "        gc.collect()\n",
    "        os.chdir(\"/kaggle/working\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc82d4d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T11:38:14.464661Z",
     "iopub.status.busy": "2021-11-30T11:38:14.463745Z",
     "iopub.status.idle": "2021-11-30T11:38:14.465661Z",
     "shell.execute_reply": "2021-11-30T11:38:14.466073Z"
    },
    "papermill": {
     "duration": 14.196071,
     "end_time": "2021-11-30T11:38:14.466209",
     "exception": false,
     "start_time": "2021-11-30T11:38:00.270138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import keras as keras\n",
    "\n",
    "\n",
    "# Generators\n",
    "def train():\n",
    "    training_generator = DataGenerator(train_data,True,False,40,3,19,True)\n",
    "    validation_generator = DataGenerator(test_data,True,True,40,3,19,True)\n",
    "\n",
    "\n",
    "    base_model = tf.keras.applications.EfficientNetB4(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        classes=19,\n",
    "    )\n",
    "\n",
    "    inputs = keras.Input(shape=(256, 256, 3))\n",
    "\n",
    "    x = base_model(inputs, training=True)\n",
    "    # x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.GlobalMaxPool2D()(x)\n",
    "    x = keras.layers.Dense(1024,activation='relu')(x)\n",
    "    #x = keras.layers.Dense(128,activation='relu')(x)\n",
    "    outputs = keras.layers.Dense(19,activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    gc.collect()\n",
    "\n",
    "    def scheduler(epoch, lr):\n",
    "        return lr*((.95)**(epoch-1))\n",
    "    modelcheckpoint=tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"model.h5\",\n",
    "        monitor=\"val_acc\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        mode=\"auto\",\n",
    "        save_freq=\"epoch\",\n",
    "        options=None,\n",
    "    )\n",
    "    #tf.config.get_visible_devices()\n",
    "    lrs = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=5e-4),\n",
    "              loss='categorical_crossentropy',metrics=[\"acc\"])\n",
    "\n",
    "    # Train model on dataset\n",
    "    model.fit_generator(epochs=5,generator=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        use_multiprocessing=True,callbacks=[lrs],\n",
    "                        workers=6)\n",
    "\n",
    "    os.chdir('/kaggle/working')\n",
    "    model.save('effb4')\n",
    "\n",
    "    import shutil\n",
    "    shutil.make_archive('effb4', 'zip', 'effb4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24c1b82f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T11:38:42.876199Z",
     "iopub.status.busy": "2021-11-30T11:38:42.875377Z",
     "iopub.status.idle": "2021-11-30T12:42:12.630861Z",
     "shell.execute_reply": "2021-11-30T12:42:12.632085Z"
    },
    "papermill": {
     "duration": 3823.802431,
     "end_time": "2021-11-30T12:42:12.632469",
     "exception": false,
     "start_time": "2021-11-30T11:38:28.830038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 11:38:43.365796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 11:38:43.367513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 11:38:43.368367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 11:38:43.369515: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-30 11:38:43.369907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 11:38:43.370745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 11:38:43.371621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 11:38:45.520705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 11:38:45.521838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 11:38:45.522773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 11:38:45.523545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14959 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
      "71688192/71686520 [==============================] - 0s 0us/step\n",
      "71696384/71686520 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 11:38:52.120695: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-30 11:39:15.431616: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725/725 [==============================] - 756s 1s/step - loss: 0.8749 - acc: 0.7694\n",
      "Epoch 2/5\n",
      "725/725 [==============================] - 705s 963ms/step - loss: 0.3797 - acc: 0.8761\n",
      "Epoch 3/5\n",
      "725/725 [==============================] - 717s 968ms/step - loss: 0.3232 - acc: 0.8915\n",
      "Epoch 4/5\n",
      "725/725 [==============================] - 726s 984ms/step - loss: 0.2756 - acc: 0.9043\n",
      "Epoch 5/5\n",
      "725/725 [==============================] - 716s 978ms/step - loss: 0.2310 - acc: 0.9181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 12:41:10.032906: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "p = multiprocessing.Process(target=train)\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5493517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:42:50.614944Z",
     "iopub.status.busy": "2021-11-30T12:42:50.614117Z",
     "iopub.status.idle": "2021-11-30T12:42:50.618346Z",
     "shell.execute_reply": "2021-11-30T12:42:50.617887Z"
    },
    "papermill": {
     "duration": 18.753855,
     "end_time": "2021-11-30T12:42:50.618481",
     "exception": false,
     "start_time": "2021-11-30T12:42:31.864626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from time import time\n",
    "# Import TF and TF Hub libraries.\n",
    "import tensorflow as tf\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# import torchvision\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "np.random.seed(46)\n",
    "# torch.manual_seed(46)\n",
    "# from torchvision import transforms, utils,models\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "# from pytorch_pretrained_vit import ViT\n",
    "import keras\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(46)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e5ddae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:43:27.554388Z",
     "iopub.status.busy": "2021-11-30T12:43:27.553444Z",
     "iopub.status.idle": "2021-11-30T12:43:27.560989Z",
     "shell.execute_reply": "2021-11-30T12:43:27.560540Z"
    },
    "papermill": {
     "duration": 18.647088,
     "end_time": "2021-11-30T12:43:27.561109",
     "exception": false,
     "start_time": "2021-11-30T12:43:08.914021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataGenerator(tensorflow.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data,train=True,val=False, batch_size=32, n_channels=3,\n",
    "                 n_classes=19, shuffle=True):\n",
    "        'Initialization'\n",
    "        #self.dim = dim\n",
    "        self.train=train\n",
    "        self.val=val\n",
    "        self.batch_size = batch_size\n",
    "        if(self.train):\n",
    "            self.labels = data.iloc[:,1].to_numpy()\n",
    "            self.list_IDs = data.iloc[:,0].to_numpy()\n",
    "        else:\n",
    "            self.labels = data.to_numpy().squeeze()\n",
    "            self.list_IDs = data.to_numpy().squeeze()\n",
    "        self.total=self.labels.shape[0] \n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.augmentor = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.15,\n",
    "            height_shift_range=0.15,\n",
    "            shear_range=0.15,\n",
    "            zoom_range=0.15,\n",
    "            fill_mode='nearest',\n",
    "            horizontal_flip=True,\n",
    "        )\n",
    "        #Image.fromarray(numpy_image.astype('uint8'), 'RGB')\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        if (self.train==False):\n",
    "            return int(np.floor(len(self.list_IDs) / self.batch_size))+1\n",
    "        else:\n",
    "            return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "    \n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "       \n",
    "        # Find list of IDs\n",
    "        image_names = [self.list_IDs[k] for k in indexes]\n",
    "        if(self.train):\n",
    "            y=np.array([self.labels[i] for i in indexes],dtype=int)\n",
    "        # Generate data\n",
    "        X = self.__data_generation(image_names)\n",
    "        if(self.train):\n",
    "            return X, tensorflow.keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        else:\n",
    "            return X,np.array(image_names)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        gc.collect()\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        os.chdir(\"/kaggle/input/col341-a3\")\n",
    "        \n",
    "        X = np.empty((self.batch_size, 256,256, self.n_channels))\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            X[i,] = cv2.imread(ID)[-256:,128:128+256,:]\n",
    "        if(self.train==True and self.val==False):\n",
    "            X = self.augmentor.flow(X, batch_size=self.batch_size, shuffle=False)[0]\n",
    "        gc.collect()\n",
    "        os.chdir(\"/kaggle/working\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94d867b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:44:04.800463Z",
     "iopub.status.busy": "2021-11-30T12:44:04.799900Z",
     "iopub.status.idle": "2021-11-30T12:44:04.825292Z",
     "shell.execute_reply": "2021-11-30T12:44:04.824321Z"
    },
    "papermill": {
     "duration": 19.048554,
     "end_time": "2021-11-30T12:44:04.825423",
     "exception": false,
     "start_time": "2021-11-30T12:43:45.776869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/kaggle/input/col341-a3\")\n",
    "private_test_data=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b90c8f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:44:41.306366Z",
     "iopub.status.busy": "2021-11-30T12:44:41.305750Z",
     "iopub.status.idle": "2021-11-30T12:44:41.308446Z",
     "shell.execute_reply": "2021-11-30T12:44:41.308876Z"
    },
    "papermill": {
     "duration": 18.684421,
     "end_time": "2021-11-30T12:44:41.309013",
     "exception": false,
     "start_time": "2021-11-30T12:44:22.624592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8800, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e18c13bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:45:17.988720Z",
     "iopub.status.busy": "2021-11-30T12:45:17.987630Z",
     "iopub.status.idle": "2021-11-30T12:45:17.989545Z",
     "shell.execute_reply": "2021-11-30T12:45:17.990016Z"
    },
    "papermill": {
     "duration": 18.189108,
     "end_time": "2021-11-30T12:45:17.990168",
     "exception": false,
     "start_time": "2021-11-30T12:44:59.801060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d={0:'Ardhachakrasana', 1:'Garudasana', 2:'Gorakshasana', 3:'Katichakrasana',\n",
    "       4:'Natarajasana', 5:'Natavarasana', 6:'Naukasana', 7:'Padahastasana',\n",
    "       8:'ParivrittaTrikonasana', 9:'Pranamasana', 10:'Santolanasana',11: 'Still',\n",
    "       12:'Tadasana', 13:'Trikonasana', 14:'TriyakTadasana', 15:'Tuladandasana',\n",
    "       16:'Utkatasana', 17:'Virabhadrasana',18: 'Vrikshasana'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f664321",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:45:55.614680Z",
     "iopub.status.busy": "2021-11-30T12:45:55.613917Z",
     "iopub.status.idle": "2021-11-30T12:45:55.616681Z",
     "shell.execute_reply": "2021-11-30T12:45:55.617175Z"
    },
    "papermill": {
     "duration": 18.461694,
     "end_time": "2021-11-30T12:45:55.617318",
     "exception": false,
     "start_time": "2021-11-30T12:45:37.155624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./testing/100032N39150.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./testing/1156016N33502.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./testing/1283038N310628.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./testing/2232023N36263.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./testing/2404020N34858.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name\n",
       "0    ./testing/100032N39150.jpg\n",
       "1   ./testing/1156016N33502.jpg\n",
       "2  ./testing/1283038N310628.jpg\n",
       "3   ./testing/2232023N36263.jpg\n",
       "4   ./testing/2404020N34858.jpg"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "badee530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:46:32.759546Z",
     "iopub.status.busy": "2021-11-30T12:46:32.757625Z",
     "iopub.status.idle": "2021-11-30T12:46:32.760213Z",
     "shell.execute_reply": "2021-11-30T12:46:32.760748Z"
    },
    "papermill": {
     "duration": 18.607561,
     "end_time": "2021-11-30T12:46:32.760921",
     "exception": false,
     "start_time": "2021-11-30T12:46:14.153360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "private_test=DataGenerator(private_test_data,False,False,39,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d74b75e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:47:10.255724Z",
     "iopub.status.busy": "2021-11-30T12:47:10.255143Z",
     "iopub.status.idle": "2021-11-30T12:48:36.908801Z",
     "shell.execute_reply": "2021-11-30T12:48:36.907870Z"
    },
    "papermill": {
     "duration": 105.145485,
     "end_time": "2021-11-30T12:48:36.908952",
     "exception": false,
     "start_time": "2021-11-30T12:46:51.763467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 12:47:10.753356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 12:47:10.754365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 12:47:10.755050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 12:47:10.755994: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-30 12:47:10.756341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 12:47:10.757022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 12:47:10.757661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 12:47:12.887624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 12:47:12.888344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 12:47:12.889013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-30 12:47:12.889639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14959 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/kaggle/working')\n",
    "model1=tf.keras.models.load_model('effb4')\n",
    "model2=tf.keras.models.load_model('resnet50v2')\n",
    "model3=tf.keras.models.load_model('xception')\n",
    "model4=tf.keras.models.load_model('effb5')\n",
    "os.chdir(\"/kaggle/input/col341-a3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51109086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:49:13.890092Z",
     "iopub.status.busy": "2021-11-30T12:49:13.889217Z",
     "iopub.status.idle": "2021-11-30T13:12:28.057399Z",
     "shell.execute_reply": "2021-11-30T13:12:28.056917Z"
    },
    "papermill": {
     "duration": 1412.219648,
     "end_time": "2021-11-30T13:12:28.057580",
     "exception": false,
     "start_time": "2021-11-30T12:48:55.837932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n",
      "2021-11-30 12:49:15.625577: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-30 12:49:20.839023: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    }
   ],
   "source": [
    "preds1=model1.predict_generator(private_test)\n",
    "preds2=model2.predict_generator(private_test)\n",
    "preds3=model3.predict_generator(private_test)\n",
    "preds4=model4.predict_generator(private_test)\n",
    "# preds5=model5.predict_generator(private_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4a4cf32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:13:05.289333Z",
     "iopub.status.busy": "2021-11-30T13:13:05.288391Z",
     "iopub.status.idle": "2021-11-30T13:13:05.290289Z",
     "shell.execute_reply": "2021-11-30T13:13:05.290715Z"
    },
    "papermill": {
     "duration": 18.964108,
     "end_time": "2021-11-30T13:13:05.290862",
     "exception": false,
     "start_time": "2021-11-30T13:12:46.326754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds1=preds1[:private_test_data.shape[0]]\n",
    "preds2=preds2[:private_test_data.shape[0]]\n",
    "preds3=preds3[:private_test_data.shape[0]]\n",
    "preds4=preds4[:private_test_data.shape[0]]\n",
    "# preds5=preds5[:private_test_data.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77c8813c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:13:42.305686Z",
     "iopub.status.busy": "2021-11-30T13:13:42.304801Z",
     "iopub.status.idle": "2021-11-30T13:13:42.312471Z",
     "shell.execute_reply": "2021-11-30T13:13:42.312018Z"
    },
    "papermill": {
     "duration": 17.937215,
     "end_time": "2021-11-30T13:13:42.312591",
     "exception": false,
     "start_time": "2021-11-30T13:13:24.375376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir('/kaggle/working')\n",
    "np.save('ens_f2-effb4.npy',preds1)\n",
    "np.save('ens_f2-resnet50v2.npy',preds2)\n",
    "np.save('ens_f2-xception.npy',preds3)\n",
    "np.save('ens_f2-effb5.npy',preds4)\n",
    "os.chdir(\"/kaggle/input/col341-a3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0a4f7ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:14:19.293950Z",
     "iopub.status.busy": "2021-11-30T13:14:19.293257Z",
     "iopub.status.idle": "2021-11-30T13:14:19.302041Z",
     "shell.execute_reply": "2021-11-30T13:14:19.301580Z"
    },
    "papermill": {
     "duration": 18.306545,
     "end_time": "2021-11-30T13:14:19.302157",
     "exception": false,
     "start_time": "2021-11-30T13:14:00.995612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8800, 19)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=preds1*6.3+preds2*6.3+preds3*6.3+preds4*6\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12f56d8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:14:56.487171Z",
     "iopub.status.busy": "2021-11-30T13:14:56.486317Z",
     "iopub.status.idle": "2021-11-30T13:14:56.489594Z",
     "shell.execute_reply": "2021-11-30T13:14:56.490233Z"
    },
    "papermill": {
     "duration": 18.674012,
     "end_time": "2021-11-30T13:14:56.490456",
     "exception": false,
     "start_time": "2021-11-30T13:14:37.816444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8800,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=np.argmax(preds,axis=1)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f26c442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:15:33.772251Z",
     "iopub.status.busy": "2021-11-30T13:15:33.770522Z",
     "iopub.status.idle": "2021-11-30T13:15:33.772920Z",
     "shell.execute_reply": "2021-11-30T13:15:33.773318Z"
    },
    "papermill": {
     "duration": 18.728667,
     "end_time": "2021-11-30T13:15:33.773474",
     "exception": false,
     "start_time": "2021-11-30T13:15:15.044807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission=[]\n",
    "names=private_test_data['name'].to_numpy().squeeze()\n",
    "for i in range(preds.shape[0]):\n",
    "    submission.append([names[i],d[preds[i]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c087d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:16:11.220830Z",
     "iopub.status.busy": "2021-11-30T13:16:11.219925Z",
     "iopub.status.idle": "2021-11-30T13:16:11.231881Z",
     "shell.execute_reply": "2021-11-30T13:16:11.231363Z"
    },
    "papermill": {
     "duration": 19.065595,
     "end_time": "2021-11-30T13:16:11.232005",
     "exception": false,
     "start_time": "2021-11-30T13:15:52.166410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8800, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=np.array(submission)\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c00bb477",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:16:48.164055Z",
     "iopub.status.busy": "2021-11-30T13:16:48.163091Z",
     "iopub.status.idle": "2021-11-30T13:16:48.169074Z",
     "shell.execute_reply": "2021-11-30T13:16:48.168623Z"
    },
    "papermill": {
     "duration": 18.825022,
     "end_time": "2021-11-30T13:16:48.169192",
     "exception": false,
     "start_time": "2021-11-30T13:16:29.344170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(submission, columns = ['name','category']).iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7c6157b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:17:25.145283Z",
     "iopub.status.busy": "2021-11-30T13:17:25.144588Z",
     "iopub.status.idle": "2021-11-30T13:17:25.178183Z",
     "shell.execute_reply": "2021-11-30T13:17:25.177675Z"
    },
    "papermill": {
     "duration": 18.307623,
     "end_time": "2021-11-30T13:17:25.178303",
     "exception": false,
     "start_time": "2021-11-30T13:17:06.870680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8799, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/kaggle/working')\n",
    "submission.to_csv('submission.csv',index=False)\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "394ab4f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T13:18:01.762943Z",
     "iopub.status.busy": "2021-11-30T13:18:01.762187Z",
     "iopub.status.idle": "2021-11-30T13:18:01.766023Z",
     "shell.execute_reply": "2021-11-30T13:18:01.766386Z"
    },
    "papermill": {
     "duration": 18.119037,
     "end_time": "2021-11-30T13:18:01.766551",
     "exception": false,
     "start_time": "2021-11-30T13:17:43.647514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./testing/100032N39150.jpg</td>\n",
       "      <td>Still</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./testing/1156016N33502.jpg</td>\n",
       "      <td>Natarajasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./testing/1283038N310628.jpg</td>\n",
       "      <td>Katichakrasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./testing/2232023N36263.jpg</td>\n",
       "      <td>Padahastasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./testing/2404020N34858.jpg</td>\n",
       "      <td>Padahastasana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name        category\n",
       "0    ./testing/100032N39150.jpg           Still\n",
       "1   ./testing/1156016N33502.jpg    Natarajasana\n",
       "2  ./testing/1283038N310628.jpg  Katichakrasana\n",
       "3   ./testing/2232023N36263.jpg   Padahastasana\n",
       "4   ./testing/2404020N34858.jpg   Padahastasana"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bfe25d",
   "metadata": {
    "papermill": {
     "duration": 17.942085,
     "end_time": "2021-11-30T13:18:38.390553",
     "exception": false,
     "start_time": "2021-11-30T13:18:20.448468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692cf29",
   "metadata": {
    "papermill": {
     "duration": 17.968255,
     "end_time": "2021-11-30T13:19:14.990255",
     "exception": false,
     "start_time": "2021-11-30T13:18:57.022000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17774.837147,
   "end_time": "2021-11-30T13:19:36.374372",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-30T08:23:21.537225",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

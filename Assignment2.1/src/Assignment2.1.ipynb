{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc50b4fa",
   "metadata": {},
   "source": [
    "# PART A and B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc729194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995f16d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10db6076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 200), (3000, 2), (300, 200), (300, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data=pd.read_csv('toy_dataset_train.csv',header=None)\n",
    "# X_test=pd.read_csv('toy_dataset_test.csv',header=None).iloc[:,1:].to_numpy()/255.\n",
    "# y_test=pd.read_csv('toy_dataset_test_labels.csv',header=None)\n",
    "# y_test=pd.get_dummies(y_test,columns=y_test.columns).to_numpy()\n",
    "# X,y=data.iloc[:,1:].to_numpy()/255.,pd.get_dummies(data.iloc[:,0],columns=data.columns[0]).to_numpy()\n",
    "# X.shape,y.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7daf5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78200, 1024), (78200, 46), (4600, 1024), (4600, 46))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('train_data_shuffled.csv',header=None)\n",
    "test=pd.read_csv('public_test.csv',header=None)\n",
    "X_test,y_test=test.iloc[:,:-1].to_numpy()/255.,pd.get_dummies(test.iloc[:,-1:],columns=test.columns[-1:]).to_numpy()\n",
    "X,y=data.iloc[:,:-1].to_numpy()/255.,pd.get_dummies(data.iloc[:,-1:],columns=data.columns[-1:]).to_numpy()\n",
    "X.shape,y.shape,X_test.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2951e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b2f4df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    m=np.max(a,axis=1).reshape(-1,1)\n",
    "    #gamma=1e-15\n",
    "    a=np.exp(a-m)\n",
    "    #return a/(a.sum(axis=a.ndim-1).reshape(-1,1))\n",
    "    return np.nan_to_num(a/(a.sum(axis=a.ndim-1).reshape(-1,1)),False)\n",
    "def relu(a):\n",
    "    return np.where(a>0,a,0)\n",
    "def drelu(a):\n",
    "    return np.where(a>0,1,0)\n",
    "def tanh(a):\n",
    "    return np.tanh(a)  \n",
    "def dtanh(a):\n",
    "    return 1-np.square(a)\n",
    "def sigmoid(a):\n",
    "    return 1/(1+np.exp(-a))\n",
    "    #return expit(a)\n",
    "def dsig(a):\n",
    "    #return sigmoid(a)*(1-sigmoid(a))\n",
    "    return a*(1-a)\n",
    "    #return (1-expit(a))*expit(a)\n",
    "def CE_loss(y_true,y_preds):\n",
    "    gamma=1e-15\n",
    "    return -np.sum(np.multiply(y_true,np.log(np.clip(y_preds,gamma,1-gamma))))/y_true.shape[0]\n",
    "\n",
    "def mse(y_true,y_preds):  \n",
    "    return np.sum(np.square(y_true.reshape(-1,1)-y_preds.reshape(-1,1)))/y_preds.shape[0]\n",
    "\n",
    "\n",
    "def acc(y_true,y_preds):\n",
    "    y_preds=np.argmax(y_preds,axis=1).squeeze()\n",
    "    y_true=np.argmax(y_true,axis=1).squeeze()\n",
    "    return np.count_nonzero(y_true-y_preds==0)/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3180b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    hidden_units=daf=af=l=W=Z=0\n",
    "    \n",
    "    def __init__(self,hidden_units,af,num_features,loss):\n",
    "        \n",
    "        self.hidden_units=hidden_units\n",
    "        self.l=loss\n",
    "        if(af==0):\n",
    "            self.af=sigmoid\n",
    "            self.daf=dsig\n",
    "        elif(af==1):\n",
    "            self.af=tanh\n",
    "            self.daf=dtanh\n",
    "        else:\n",
    "            self.af=relu\n",
    "            self.daf=drelu\n",
    "        if(loss==0):\n",
    "            self.loss=CE_loss\n",
    "        else:\n",
    "            self.loss=mse \n",
    "        self.W=[]\n",
    "        self.b=[]\n",
    "        temp=np.float32(np.random.normal(0,1,(num_features+1,hidden_units[0])))*(np.sqrt(2/(num_features+1+hidden_units[0])))\n",
    "        self.W.append(temp[1:,:])\n",
    "        self.b.append(temp[0])\n",
    "        for i in range(1,len(hidden_units)):\n",
    "            temp=np.float32(np.random.normal(0,1,(hidden_units[i-1]+1,hidden_units[i])))*(np.sqrt(2/(hidden_units[i-1]+1+hidden_units[i])))\n",
    "            self.W.append(temp[1:,:])\n",
    "            self.b.append(temp[0])\n",
    "        self.Z=[]    \n",
    "    def fp(self,X):\n",
    "        self.Z=[]\n",
    "        \n",
    "        self.Z.append(X)\n",
    "        \n",
    "#         for i in range(len(self.W)):\n",
    "#             self.Z.append(self.af(np.matmul(self.Z[i],self.W[i])+self.b[i]))\n",
    "            \n",
    "#         if(self.l==0):\n",
    "#             return softmax(self.Z[-1]) \n",
    "        for i in range(len(self.W)-1):\n",
    "            self.Z.append(self.af(np.matmul(self.Z[i],self.W[i])+self.b[i]))\n",
    "            \n",
    "        if(self.l==0):\n",
    "            #print(self.Z[-1].shape,self.W[-1].shape,self.b[-1].shape)\n",
    "            self.Z.append(np.matmul(self.Z[-1],self.W[-1])+self.b[-1])\n",
    "            # In case of Cross Entropy loss, softmax is the final activation\n",
    "            return softmax(self.Z[-1])\n",
    "            \n",
    "        else:\n",
    "            self.Z.append(self.af(np.matmul(self.Z[-1],self.W[-1])+self.b[-1]))\n",
    "        return self.Z[-1]\n",
    "    def bp(self,X,y,lr):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        # Note:  In case of MSE:Y_h=Z_l ---> dL/dZ_l=Y_h-Y\n",
    "        #        In case of CE Loss:Y_h=Softmax(Z_l) --->dL/dZ_l= (dL/dY_h)*(dY_h/dZ_l)= Y_h-Y\n",
    "        # Since its same in both the cases, no need for different functions\n",
    "        \n",
    "        #print(g)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                # if loss== mse (l=1) ---> we multiply with deriv of af always,\n",
    "                # but if loss==CE ---> last layer has softmax activation, whose derivative is already incorporated in yh-y \n",
    "                #so no need\n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #print(dw[0])\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            \n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            self.W[i]-=dw*lr\n",
    "            self.b[i]-=db*lr\n",
    "#     def bp(self,X,y,lr):\n",
    "#         yh=self.fp(X)\n",
    "#         g=yh-y\n",
    "#         #print(g)\n",
    "#         dummy=np.ones(yh.shape[0])\n",
    "#         for i in reversed(range(len(self.W))):\n",
    "#             deriv_af=self.daf(self.Z[i+1])\n",
    "#             g=np.multiply(deriv_af,g)\n",
    "#             dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "#             #print(dw[0])\n",
    "#             #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "#             db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            \n",
    "#             g=np.dot(g,self.W[i].T)\n",
    "#             self.W[i]-=dw*lr\n",
    "#             self.b[i]-=db*lr\n",
    "    def bp_mom(self,X,y,lr,wt,bt,gamma=.9):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        \n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            change=gamma*wt[i]+dw*lr\n",
    "            self.W[i]-=change\n",
    "            wt[i]=change\n",
    "            #print(wt[i])\n",
    "            change=gamma*bt[i]+db*lr\n",
    "            self.b[i]-=change\n",
    "            bt[i]=change\n",
    "    \n",
    "    def bp_rmsprop(self,X,y,lr,wt,bt,gamma=.9):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        e=1e-8\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            temp=gamma*wt[i]+0.1*(dw**2)\n",
    "            self.W[i]-=lr*dw/(np.sqrt(temp+e))\n",
    "            wt[i]=temp\n",
    "            #print(wt[i])\n",
    "            temp=gamma*bt[i]+.1*(db**2)\n",
    "            self.b[i]-=lr*db/(np.sqrt(temp+e))\n",
    "            bt[i]=temp\n",
    "    def bp_adam(self,X,y,lr,vwt,vbt,mwt,mbt,b1=.9,b2=.999):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        e=1e-8\n",
    "        b1t=1\n",
    "        b2t=1\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            vwt[i]=b2*vwt[i]+(1-b2)*(dw**2)\n",
    "            vbt[i]=b2*vbt[i]+(1-b2)*(db**2)\n",
    "            mwt[i]=b1*mwt[i]+(1-b1)*(dw)\n",
    "            mbt[i]=b1*mbt[i]+(1-b1)*(db)\n",
    "            #print(mbt[i])\n",
    "            b1t*=b1\n",
    "            b2t*=b2\n",
    "            self.W[i]-=lr*(mwt[i]/(1-b1t))/(np.sqrt(vwt[i]/(1-b2t))+e)\n",
    "            self.b[i]-=lr*(mbt[i]/(1-b1t))/(np.sqrt(vbt[i]/(1-b2t))+e)\n",
    "            \n",
    "    def bp_nag(self,X,y,lr,wt,bt,gamma=.9):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        e=1e-8\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            \n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            temp=gamma*wt[i]+lr*(dw**2)\n",
    "            self.W[i]-=temp\n",
    "            wt[i]=temp\n",
    "            #print(wt[i])\n",
    "            temp=gamma*bt[i]+.1*(db**2)\n",
    "            self.b[i]-=temp\n",
    "            bt[i]=temp\n",
    "    def fit(self,bs,epochs,X,y,lr,adaptive=False):\n",
    "        for i in range(len(self.W)):\n",
    "            self.W[i]=np.float64(self.W[i])\n",
    "            self.b[i]=np.float64(self.b[i])\n",
    "        l=[]    \n",
    "        for i in range(epochs):\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "#                 if(j==5 and i==0):\n",
    "#                     for k in range(len(a.W)):\n",
    "#                         temp=np.concatenate((a.b[k].reshape(1,-1),a.W[k]),axis=0)\n",
    "#                         np.save('essentials/part_a_and_b/multiclass_dataset/tc_3/w_'+str(k+1)+'_iter.npy',temp)\n",
    "#                         print(np.max(np.load('essentials/part_a_and_b/multiclass_dataset/tc_3/ac_w_'+str(k+1)+'_iter.npy')-temp))\n",
    "                    \n",
    "                self.bp(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr)\n",
    "            y_pred=self.fp(X_test)\n",
    "            l.append(self.loss(y,self.fp(X)))\n",
    "            print(i,l[-1],acc(y,self.fp(X)))\n",
    "            #print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))\n",
    "        return l    \n",
    "    def fit_mom(self,bs,epochs,X,y,lr,adaptive=False):\n",
    "        l=[]\n",
    "        wt=[0]*len(self.W)\n",
    "        bt=[0]*len(self.W)\n",
    "        for i in range(epochs):\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                self.bp_mom(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,wt,bt)\n",
    "            y_pred=self.fp(X_test)\n",
    "            l.append(self.loss(y,self.fp(X)))\n",
    "            print(i,l[-1],acc(y,self.fp(X)))\n",
    "            #print(i,self.loss(y_test,y_pred),acc(y_test,y_pred)) \n",
    "        return l\n",
    "    def fit_adam(self,bs,epochs,X,y,lr,adaptive=False):\n",
    "        mwt=[0]*len(self.W)\n",
    "        mbt=[0]*len(self.W)\n",
    "        vwt=[0]*len(self.W)\n",
    "        vbt=[0]*len(self.W)\n",
    "        l=[]\n",
    "        for i in range(epochs):\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                self.bp_adam(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,vwt,vbt,mwt,mbt)\n",
    "            y_pred=self.fp(X_test) \n",
    "            l.append(self.loss(y,self.fp(X)))\n",
    "            print(i,l[-1],acc(y,self.fp(X)))\n",
    "            #print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))    \n",
    "        return l\n",
    "    def fit_rmsprop(self,bs,epochs,X,y,lr,adaptive=False):\n",
    "        wt=[0]*len(self.W)\n",
    "        bt=[0]*len(self.W)\n",
    "        l=[]\n",
    "        for i in range(epochs):\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                self.bp_rmsprop(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,wt,bt)\n",
    "            y_pred=self.fp(X_test)\n",
    "            l.append(self.loss(y,self.fp(X)))\n",
    "            print(i,l[-1],acc(y,self.fp(X)))\n",
    "            #print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))             \n",
    "        return l    \n",
    "    def pred(X):\n",
    "        return fp(X)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c95c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=ANN([512,256,128,46],2,1024,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6f4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.fit(1700,5,X,y,.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a.W)):\n",
    "    temp=np.concatenate((a.b[i].reshape(1,-1),a.W[i]),axis=0)\n",
    "    np.save('essentials/part_a_and_b/multiclass_dataset/tc_3/w_'+str(i+1)+'.npy',temp)\n",
    "    print(np.max((np.load('essentials/part_a_and_b/multiclass_dataset/tc_3/ac_w_'+str(i+1)+'.npy')-temp)))\n",
    "    #print(np.max((np.load('essentials/part_a_and_b/multiclass_dataset/tc_3/ac_w_'+str(i+1)+'.npy')-temp)/np.load('essentials/part_a_and_b/multiclass_dataset/tc_3/ac_w_'+str(i+1)+'.npy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=ANN([100,50,20,10,2],2,200,0)\n",
    "#a.fp(X)\n",
    "a.W[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f9acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.fit(100,5,X,y,.001)\n",
    "a.W[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a.W)):\n",
    "    temp=np.concatenate((a.b[i].reshape(1,-1),a.W[i]),axis=0)\n",
    "    np.save('essentials/part_a_and_b/toy_dataset/tc_3/w_'+str(i+1)+'.npy',temp)\n",
    "    print(np.max((np.load('essentials/part_a_and_b/toy_dataset/tc_3/ac_w_'+str(i+1)+'.npy')-temp)))\n",
    "    #print(np.max((np.load('essentials/part_a_and_b/toy_dataset/tc_3/ac_w_'+str(i+1)+'.npy')-temp)/np.load('essentials/part_a_and_b/toy_dataset/tc_3/ac_w_'+str(i+1)+'.npy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da754b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a8f59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf3a5e6d",
   "metadata": {},
   "source": [
    "# PART C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f836a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from scipy.special import expit\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f03546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78200, 1024), (78200, 46), (4600, 1024), (4600, 46))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(146)\n",
    "\n",
    "\n",
    "data=pd.read_csv('data/train_data_shuffled.csv',header=None)\n",
    "test=pd.read_csv('data/public_test.csv',header=None)\n",
    "X_test,y_test=test.iloc[:,:-1].to_numpy()/255.,pd.get_dummies(test.iloc[:,-1:],columns=test.columns[-1:]).to_numpy()\n",
    "X,y=data.iloc[:,:-1].to_numpy()/255.,pd.get_dummies(data.iloc[:,-1:],columns=data.columns[-1:]).to_numpy()\n",
    "X.shape,y.shape,X_test.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77aa5638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    m=np.max(a,axis=1).reshape(-1,1)\n",
    "    #gamma=1e-15\n",
    "    a=np.exp(a-m)\n",
    "    #return a/(a.sum(axis=a.ndim-1).reshape(-1,1))\n",
    "    return np.nan_to_num(a/(a.sum(axis=a.ndim-1).reshape(-1,1)),False)\n",
    "def relu(a):\n",
    "    return np.where(a>0,a,0)\n",
    "def drelu(a):\n",
    "    return np.where(a>0,1,0)\n",
    "def tanh(a):\n",
    "    return np.tanh(a)  \n",
    "def dtanh(a):\n",
    "    return 1-np.square(a)\n",
    "def sigmoid(a):\n",
    "    return 1/(1+np.exp(-a))\n",
    "    #return expit(a)\n",
    "def dsig(a):\n",
    "    #return sigmoid(a)*(1-sigmoid(a))\n",
    "    return a*(1-a)\n",
    "    #return (1-expit(a))*expit(a)\n",
    "def CE_loss(y_true,y_preds):\n",
    "    gamma=1e-15\n",
    "    return -np.sum(np.multiply(y_true,np.log(np.clip(y_preds,gamma,1-gamma))))/y_true.shape[0]\n",
    "\n",
    "def mse(y_true,y_preds):  \n",
    "    return np.sum(np.square(y_true.reshape(-1,1)-y_preds.reshape(-1,1)))/y_preds.shape[0]\n",
    "\n",
    "\n",
    "def acc(y_true,y_preds):\n",
    "    y_preds=np.argmax(y_preds,axis=1).squeeze()\n",
    "    y_true=np.argmax(y_true,axis=1).squeeze()\n",
    "    return np.count_nonzero(y_true-y_preds==0)/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ad77ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    hidden_units=daf=af=l=W=Z=0\n",
    "    \n",
    "    def __init__(self,hidden_units,af,num_features,loss):\n",
    "        \n",
    "        self.hidden_units=hidden_units\n",
    "        self.l=loss\n",
    "        if(af==0):\n",
    "            self.af=sigmoid\n",
    "            self.daf=dsig\n",
    "        elif(af==1):\n",
    "            self.af=tanh\n",
    "            self.daf=dtanh\n",
    "        else:\n",
    "            self.af=relu\n",
    "            self.daf=drelu\n",
    "        if(loss==0):\n",
    "            self.loss=CE_loss\n",
    "        else:\n",
    "            self.loss=mse \n",
    "        self.W=[]\n",
    "        self.b=[]\n",
    "        temp=np.float32(np.random.normal(0,1,(num_features+1,hidden_units[0])))*(np.sqrt(2/(num_features+1+hidden_units[0])))\n",
    "        self.W.append(temp[1:,:])\n",
    "        self.b.append(temp[0])\n",
    "        for i in range(1,len(hidden_units)):\n",
    "            temp=np.float32(np.random.normal(0,1,(hidden_units[i-1]+1,hidden_units[i])))*(np.sqrt(2/(hidden_units[i-1]+1+hidden_units[i])))\n",
    "            self.W.append(temp[1:,:])\n",
    "            self.b.append(temp[0])\n",
    "        self.Z=[]    \n",
    "    def fp(self,X):\n",
    "        self.Z=[]\n",
    "        \n",
    "        self.Z.append(X)\n",
    "        \n",
    "#         for i in range(len(self.W)):\n",
    "#             self.Z.append(self.af(np.matmul(self.Z[i],self.W[i])+self.b[i]))\n",
    "            \n",
    "#         if(self.l==0):\n",
    "#             return softmax(self.Z[-1]) \n",
    "        for i in range(len(self.W)-1):\n",
    "            self.Z.append(self.af(np.matmul(self.Z[i],self.W[i])+self.b[i]))\n",
    "            \n",
    "        if(self.l==0):\n",
    "            #print(self.Z[-1].shape,self.W[-1].shape,self.b[-1].shape)\n",
    "            self.Z.append(np.matmul(self.Z[-1],self.W[-1])+self.b[-1])\n",
    "            return softmax(self.Z[-1])\n",
    "            \n",
    "        else:\n",
    "            self.Z.append(self.af(np.matmul(self.Z[-1],self.W[-1])+self.b[-1]))\n",
    "        return self.Z[-1]\n",
    "    def bp(self,X,y,lr):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #print(dw[0])\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            \n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            self.W[i]-=dw*lr\n",
    "            self.b[i]-=db*lr\n",
    "#     def bp(self,X,y,lr):\n",
    "#         yh=self.fp(X)\n",
    "#         g=yh-y\n",
    "#         #print(g)\n",
    "#         dummy=np.ones(yh.shape[0])\n",
    "#         for i in reversed(range(len(self.W))):\n",
    "#             deriv_af=self.daf(self.Z[i+1])\n",
    "#             g=np.multiply(deriv_af,g)\n",
    "#             dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "#             #print(dw[0])\n",
    "#             #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "#             db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            \n",
    "#             g=np.dot(g,self.W[i].T)\n",
    "#             self.W[i]-=dw*lr\n",
    "#             self.b[i]-=db*lr\n",
    "    def bp_mom(self,X,y,lr,wt,bt,gamma=.9):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        \n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            change=gamma*wt[i]+dw*lr\n",
    "            self.W[i]-=change\n",
    "            wt[i]=change\n",
    "            #print(wt[i])\n",
    "            change=gamma*bt[i]+db*lr\n",
    "            self.b[i]-=change\n",
    "            bt[i]=change\n",
    "            \n",
    "    \n",
    "    def bp_rmsprop(self,X,y,lr,wt,bt,gamma=.9):\n",
    "        \n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        \n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        e=1e-8\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            temp=gamma*wt[i]+0.1*(dw**2)\n",
    "            self.W[i]-=lr*dw/(np.sqrt(temp+e))\n",
    "            wt[i]=temp\n",
    "            #print(wt[i])\n",
    "            temp=gamma*bt[i]+.1*(db**2)\n",
    "            self.b[i]-=lr*db/(np.sqrt(temp+e))\n",
    "            bt[i]=temp\n",
    "    def bp_adam(self,X,y,lr,vwt,vbt,mwt,mbt,b1=.9,b2=.999):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        e=1e-8\n",
    "        b1t=1\n",
    "        b2t=1\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            vwt[i]=b2*vwt[i]+(1-b2)*(dw**2)\n",
    "            vbt[i]=b2*vbt[i]+(1-b2)*(db**2)\n",
    "            mwt[i]=b1*mwt[i]+(1-b1)*(dw)\n",
    "            mbt[i]=b1*mbt[i]+(1-b1)*(db)\n",
    "            #print(mbt[i])\n",
    "            b1t*=b1\n",
    "            b2t*=b2\n",
    "            self.W[i]-=lr*(mwt[i]/(1-b1t))/(np.sqrt(vwt[i]/(1-b2t)+e))\n",
    "            self.b[i]-=lr*(mbt[i]/(1-b1t))/(np.sqrt(vbt[i]/(1-b2t)+e))\n",
    "            \n",
    "            \n",
    "    def bp_nadam(self,X,y,lr,vwt,vbt,mwt,mbt,b1=.9,b2=.999):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        e=1e-8\n",
    "        b1t=1\n",
    "        b2t=1\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            vwt[i]=b2*vwt[i]+(1-b2)*(dw**2)\n",
    "            vbt[i]=b2*vbt[i]+(1-b2)*(db**2)\n",
    "            mwt[i]=b1*mwt[i]+(1-b1)*(dw)\n",
    "            mbt[i]=b1*mbt[i]+(1-b1)*(db)\n",
    "            #print(mbt[i])\n",
    "            b1t*=b1\n",
    "            b2t*=b2\n",
    "            self.W[i]-=lr*(b1*mwt[i]/(1-b1t)+(1-b1)*dw/(1-b1t))/(np.sqrt(vwt[i]/(1-b2t)+e))\n",
    "            self.b[i]-=lr*(b1*mbt[i]/(1-b1t)+(1-b1)*db/(1-b1t))/(np.sqrt(vbt[i]/(1-b2t)+e))\n",
    "    \n",
    "    def bp_nag(self,X,y,lr,wt,bt,gamma=.9):\n",
    "        W_temp=self.W\n",
    "        b_temp=self.b\n",
    "        for i in range(len(self.W)):\n",
    "            self.W[i]-=gamma*wt[i]\n",
    "            self.b[i]-=gamma*bt[i]\n",
    "            \n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        \n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        \n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "               \n",
    "            g=np.dot(g,self.W[i].T)\n",
    "           \n",
    "            temp=gamma*wt[i]+lr*dw\n",
    "            \n",
    "            W_temp[i]-=temp\n",
    "            wt[i]=temp\n",
    "            #print(wt[i])\n",
    "            temp=gamma*bt[i]+lr*db\n",
    "            b_temp[i]-=temp\n",
    "            bt[i]=temp\n",
    "        self.W=W_temp\n",
    "        self.b=b_temp\n",
    "    \n",
    "    def fit(self,bs,epochs,X,y,lr,adaptive=False):\n",
    "        for i in range(len(self.W)):\n",
    "            self.W[i]=np.float64(self.W[i])\n",
    "            self.b[i]=np.float64(self.b[i])\n",
    "        l=[]    \n",
    "        for i in range(epochs):\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "#                 if(j==5 and i==0):\n",
    "#                     for k in range(len(a.W)):\n",
    "#                         temp=np.concatenate((a.b[k].reshape(1,-1),a.W[k]),axis=0)\n",
    "#                         np.save('essentials/part_a_and_b/multiclass_dataset/tc_3/w_'+str(k+1)+'_iter.npy',temp)\n",
    "#                         print(np.max(np.load('essentials/part_a_and_b/multiclass_dataset/tc_3/ac_w_'+str(k+1)+'_iter.npy')-temp))\n",
    "                    \n",
    "                self.bp(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr)\n",
    "            y_pred=self.fp(X_test)\n",
    "            l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "            print(i,l[-1])\n",
    "            print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))\n",
    "        return l    \n",
    "    def fit_mom(self,bs,epochs,X,y,lr,adaptive=False):\n",
    "        l=[]\n",
    "        wt=[0]*len(self.W)\n",
    "        bt=[0]*len(self.W)\n",
    "        for i in range(epochs):\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                self.bp_mom(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,wt,bt)\n",
    "            y_pred=self.fp(X_test)\n",
    "            l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "            print(i,l[-1])\n",
    "            print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))\n",
    "        return l\n",
    "    def fit_nag(self,bs,epochs,X,y,lr,adaptive=False):\n",
    "        l=[]\n",
    "        wt=[0]*len(self.W)\n",
    "        bt=[0]*len(self.W)\n",
    "        for i in range(epochs):\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                self.bp_nag(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,wt,bt)\n",
    "            y_pred=self.fp(X_test)\n",
    "            l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "            print(i,l[-1])\n",
    "            print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))\n",
    "        return l\n",
    "    def fit_adam(self,bs,epochs,X,y,lr,adaptive=False):\n",
    "        mwt=[0]*len(self.W)\n",
    "        mbt=[0]*len(self.W)\n",
    "        vwt=[0]*len(self.W)\n",
    "        vbt=[0]*len(self.W)\n",
    "        l=[]\n",
    "        for i in range(epochs):\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                self.bp_adam(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,vwt,vbt,mwt,mbt)\n",
    "            y_pred=self.fp(X_test)\n",
    "            l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "            print(i,l[-1])\n",
    "            print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))    \n",
    "        return l\n",
    "    def fit_nadam(self,bs,epochs,X,y,lr,adaptive=False):\n",
    "        mwt=[0]*len(self.W)\n",
    "        mbt=[0]*len(self.W)\n",
    "        vwt=[0]*len(self.W)\n",
    "        vbt=[0]*len(self.W)\n",
    "        l=[]\n",
    "        for i in range(epochs):\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                self.bp_nadam(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,vwt,vbt,mwt,mbt)\n",
    "            y_pred=self.fp(X_test)\n",
    "            l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "            print(i,l[-1])\n",
    "            print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))    \n",
    "        return l\n",
    "    def fit_rmsprop(self,bs,epochs,X,y,lr,adaptive=False):\n",
    "        wt=[0]*len(self.W)\n",
    "        bt=[0]*len(self.W)\n",
    "        l=[]\n",
    "        for i in range(epochs):\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                self.bp_rmsprop(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,wt,bt)\n",
    "            y_pred=self.fp(X_test)\n",
    "            l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "            print(i,l[-1])\n",
    "            print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))             \n",
    "        return l    \n",
    "    def pred(self,X):\n",
    "        return self.fp(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fadda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e30aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c44ff6",
   "metadata": {},
   "source": [
    "# Gradient Decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [5,10,25,50,100,150,500,1000]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit(bs,8,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "#plt.savefig('best_batchsize_arc1.png')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45cfacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [5,10,25,50,100,150,500,1000]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit(bs,8,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "#plt.savefig('best_batchsize_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8795fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51015b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 342.3061590194702\n",
    "# [(0.06582774118697778, 0.9819948849104859)], bs=50, 20 epochs\n",
    "# 246.69421291351318\n",
    "# [(0.18625646011060976, 0.9508312020460358)] bs=100 epoch=20\n",
    "# 436.7336814403534\n",
    "# [(0.02960007737225836, 0.9919437340153453)] bs=25 epoch=15\n",
    "# 298.78515434265137\n",
    "# [(0.061727844479410494, 0.9822634271099744)] bs=25 epoch=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee269f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out activation function\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for af in [('sigmoid',0),('tanh',1),('relu',2)]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],af[1],1024,0)\n",
    "    losses=a.fit(100,5,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=af[0])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_af_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49593d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141aeb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [1e-4,1e-3,1e-2,.1,1]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit(100,10,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr_arc1.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a61f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95727d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [1e-4,1e-3,1e-2,.1,1]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit(100,10,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03964d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e51254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [5e-2,.07,.1,.15,.2,.3,.4,.5,.7]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit(100,10,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr1_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a48836",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [5e-2,.07,.1,.15,.2,.3,.4,.5,.7]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit(100,10,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr1_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff78ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd5270",
   "metadata": {},
   "source": [
    "# MOMENTUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22c8ed83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.703111713095217, 0.814923273657289)\n",
      "0 0.7442710984439754 0.8023913043478261\n",
      "1 (0.43189943249061347, 0.8867774936061381)\n",
      "1 0.5042542749871772 0.8658695652173913\n",
      "2 (0.31839017085575333, 0.9173401534526854)\n",
      "2 0.41316990254030916 0.8910869565217391\n",
      "3 (0.2517303522078707, 0.9348209718670076)\n",
      "3 0.36316266331038266 0.9010869565217391\n",
      "4 (0.2083904523452574, 0.9455882352941176)\n",
      "4 0.33563160081379095 0.9082608695652173\n",
      "5 (0.17854783216064216, 0.9531457800511509)\n",
      "5 0.31847236087659125 0.9128260869565218\n",
      "6 (0.1549254728566791, 0.9593606138107417)\n",
      "6 0.30641624388092975 0.9165217391304348\n",
      "7 (0.1363063889962506, 0.9642966751918158)\n",
      "7 0.2971213907360447 0.9191304347826087\n",
      "8 (0.11986398822461922, 0.9683375959079283)\n",
      "8 0.2888560498968966 0.9219565217391305\n",
      "9 (0.10531913195925711, 0.9724424552429668)\n",
      "9 0.28218378222924506 0.926304347826087\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2467d5d0880>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [5,10,25,50,100,150,500,1000]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit_mom(bs,10,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize_mom_arc1.png')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8382e4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.87185025215149\n",
      "[(0.10531913195925711, 0.9724424552429668)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad45257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52633977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dcae11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.8307514997935778, 0.7684271099744245)\n",
      "0 0.8622091040763213 0.7613043478260869\n",
      "1 (0.44948504530161426, 0.8700127877237852)\n",
      "1 0.5227694773535877 0.85\n",
      "2 (0.3084963261162603, 0.9091943734015345)\n",
      "2 0.4140709889274521 0.8817391304347826\n",
      "3 (0.221591067000425, 0.9343989769820972)\n",
      "3 0.3529281014905998 0.8967391304347826\n",
      "4 (0.18748333279561027, 0.9416879795396419)\n",
      "4 0.33552008140656175 0.9026086956521739\n",
      "5 (0.14301938538831388, 0.9554092071611253)\n",
      "5 0.3020154002633157 0.9132608695652173\n",
      "6 (0.1468000690294204, 0.9532225063938619)\n",
      "6 0.3231981299660416 0.9117391304347826\n",
      "7 (0.13014833761879022, 0.9579795396419437)\n",
      "7 0.3318332892423893 0.9117391304347826\n",
      "8 (0.08829692459612515, 0.9714066496163682)\n",
      "8 0.30071235866390833 0.9206521739130434\n",
      "9 (0.06176018110688603, 0.9800895140664961)\n",
      "9 0.2894690625903368 0.9267391304347826\n",
      "\n",
      "0 (1.1377225403825943, 0.6876854219948849)\n",
      "0 1.1509441120397232 0.6867391304347826\n",
      "1 (0.7016512398310195, 0.8007800511508951)\n",
      "1 0.7395311727457375 0.7917391304347826\n",
      "2 (0.46105699350148355, 0.8686061381074168)\n",
      "2 0.5299568390546758 0.8480434782608696\n",
      "3 (0.35470985289650475, 0.8984782608695652)\n",
      "3 0.4481826643959449 0.8773913043478261\n",
      "4 (0.2990442766396248, 0.9117135549872123)\n",
      "4 0.4207663936183812 0.8815217391304347\n",
      "5 (0.257619869803007, 0.9222378516624041)\n",
      "5 0.409403862178558 0.8867391304347826\n",
      "6 (0.19186729779009493, 0.9435038363171355)\n",
      "6 0.3628037505547785 0.8980434782608696\n",
      "7 (0.16065844415168204, 0.9523529411764706)\n",
      "7 0.3483509460370022 0.9060869565217391\n",
      "8 (0.1556297064789057, 0.9523529411764706)\n",
      "8 0.3630130033991443 0.9021739130434783\n",
      "9 (0.13335333220827242, 0.9586061381074169)\n",
      "9 0.3520263396187041 0.9065217391304348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24622e6f0d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [5,10,25,50,100,150,500,1000]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit_mom(bs,10,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize_mom_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "655bff76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.93885087966919 63.98290205001831\n",
      "[(0.10682739068660597, 0.9720076726342711), (0.1877940438856365, 0.9532736572890026)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2282b896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f7c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06597e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3.831245816409815, 0.021739130434782608)\n",
      "0 3.8312787282985705 0.021739130434782608\n",
      "1 (3.828992319477445, 0.021739130434782608)\n",
      "1 3.829047224861386 0.021739130434782608\n",
      "2 (3.8261239112810244, 0.026956521739130435)\n",
      "2 3.8262153339056035 0.025652173913043478\n",
      "3 (3.8210587699604637, 0.04352941176470588)\n",
      "3 3.821235688492051 0.044130434782608696\n",
      "4 (3.804293467257725, 0.06584398976982098)\n",
      "4 3.80484614000601 0.0632608695652174\n",
      "\n",
      "0 (0.8871761844149905, 0.7749488491048593)\n",
      "0 0.9142638873342163 0.7676086956521739\n",
      "1 (0.4998826578644193, 0.8726982097186701)\n",
      "1 0.5523786177811885 0.8489130434782609\n",
      "2 (0.3343413025685625, 0.9153196930946291)\n",
      "2 0.40648082720038625 0.8897826086956522\n",
      "3 (0.2506279252907179, 0.9354475703324808)\n",
      "3 0.34134543783481985 0.9054347826086957\n",
      "4 (0.188875560277995, 0.9521739130434783)\n",
      "4 0.2960587210244129 0.9193478260869565\n",
      "\n",
      "0 (0.6257073135126576, 0.821611253196931)\n",
      "0 0.6739249944898758 0.8184782608695652\n",
      "1 (0.32055093053183054, 0.9068925831202046)\n",
      "1 0.4135088247374831 0.8819565217391304\n",
      "2 (0.2204914599770712, 0.9347058823529412)\n",
      "2 0.3438994685881203 0.8993478260869565\n",
      "3 (0.18464555119227608, 0.9417774936061382)\n",
      "3 0.3390223422375893 0.9054347826086957\n",
      "4 (0.15479302837368872, 0.9504347826086956)\n",
      "4 0.3228789738080031 0.9115217391304348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out activation function\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for af in [('sigmoid',0),('tanh',1),('relu',2)]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],af[1],1024,0)\n",
    "    losses=a.fit_mom(100,5,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=af[0])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_af_mom_arc2.png') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "293dc155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.27585625648499 97.29585123062134 81.47588014602661\n",
      "[(3.804293467257725, 0.06584398976982098), (0.188875560277995, 0.9521739130434783), (0.15479302837368872, 0.9504347826086956)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d932cc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1.6636151385733948, 0.6163938618925832)\n",
      "0 1.6554553400596457 0.6156521739130435\n",
      "1 (1.2960257507151987, 0.6750895140664962)\n",
      "1 1.2921549612925112 0.6797826086956522\n",
      "2 (1.155399232808624, 0.7042966751918158)\n",
      "2 1.1588814378509151 0.7067391304347826\n",
      "3 (1.0682304111942726, 0.7241687979539642)\n",
      "3 1.0782501982775443 0.7247826086956521\n",
      "4 (1.002247871743516, 0.7388874680306905)\n",
      "4 1.017674327437366 0.7354347826086957\n",
      "\n",
      "0 (1.0265693191250564, 0.7331457800511509)\n",
      "0 1.040827035338164 0.7376086956521739\n",
      "1 (0.8267634120179892, 0.7845140664961637)\n",
      "1 0.8600905946613566 0.7769565217391304\n",
      "2 (0.6800460286535398, 0.8260102301790281)\n",
      "2 0.7265659268095965 0.8067391304347826\n",
      "3 (0.5671470244491539, 0.858158567774936)\n",
      "3 0.6247760770972628 0.8360869565217391\n",
      "4 (0.48178846645491036, 0.8809590792838875)\n",
      "4 0.5492666956608298 0.8578260869565217\n",
      "\n",
      "0 (0.9741126051662078, 0.7401278772378517)\n",
      "0 0.9992920098274485 0.7334782608695652\n",
      "1 (0.706394473861463, 0.8133759590792838)\n",
      "1 0.7515622230925292 0.7965217391304348\n",
      "2 (0.5379955847951359, 0.8598976982097186)\n",
      "2 0.599044411501496 0.8406521739130435\n",
      "3 (0.43087472107641334, 0.8888363171355499)\n",
      "3 0.5034694866931151 0.8660869565217392\n",
      "4 (0.36048668554300783, 0.9080690537084399)\n",
      "4 0.4426625974267101 0.8784782608695653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out activation function\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for af in [('sigmoid',0),('tanh',1),('relu',2)]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],af[1],1024,0)\n",
    "    losses=a.fit_mom(100,5,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=af[0])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_af_mom_arc1.png') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9060ef53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.17193961143494 37.695943117141724 32.671950340270996\n",
      "[(1.002247871743516, 0.7388874680306905), (0.48178846645491036, 0.8809590792838875), (0.36048668554300783, 0.9080690537084399)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f7a2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [1e-4,1e-3,1e-2,.1,1]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit_mom(100,7,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr_mom_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad7d7ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.479918479919434 45.92392826080322 48.64792776107788 44.95193099975586 45.57193040847778\n",
      "[(2.3744167174807624, 0.49404092071611255), (1.03576554771077, 0.7315601023017902), (0.2643730371360236, 0.9328132992327366), (0.22836529371940992, 0.9373145780051151), (3.8555128499864417, 0.02176470588235294)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27252543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3.8096758343887496, 0.03524296675191816)\n",
      "0 3.808893876854413 0.030434782608695653\n",
      "1 (3.7646437561615063, 0.05516624040920716)\n",
      "1 3.764039586461608 0.050869565217391305\n",
      "2 (3.7021612343071397, 0.08588235294117647)\n",
      "2 3.7015211307311295 0.08369565217391305\n",
      "3 (3.606335123064112, 0.1373017902813299)\n",
      "3 3.6058243791955427 0.1323913043478261\n",
      "4 (3.463723377927448, 0.1889002557544757)\n",
      "4 3.463517053305036 0.19195652173913044\n",
      "5 (3.254226672015963, 0.24881074168797954)\n",
      "5 3.2543756858320827 0.24717391304347827\n",
      "6 (2.9553359575704756, 0.31516624040920715)\n",
      "6 2.9551629496588863 0.3154347826086957\n",
      "\n",
      "0 (2.2733449512447423, 0.42164961636828646)\n",
      "0 2.256400277036458 0.43021739130434783\n",
      "1 (1.4088435736021219, 0.6244757033248082)\n",
      "1 1.410726562221631 0.6204347826086957\n",
      "2 (1.153913620372559, 0.6909718670076727)\n",
      "2 1.1647175278813475 0.683695652173913\n",
      "3 (0.9861938306070243, 0.7341304347826086)\n",
      "3 1.0050860980378191 0.7260869565217392\n",
      "4 (0.8475872359230491, 0.7698721227621483)\n",
      "4 0.8732815023526872 0.7621739130434783\n",
      "5 (0.731716787520555, 0.8014578005115089)\n",
      "5 0.7650521282155227 0.7908695652173913\n",
      "6 (0.635874491747902, 0.825997442455243)\n",
      "6 0.6784854849597747 0.8139130434782609\n",
      "\n",
      "0 (0.616900669554188, 0.8236061381074169)\n",
      "0 0.674972305157492 0.8084782608695652\n",
      "1 (0.3431172163474367, 0.8999104859335039)\n",
      "1 0.4285162634502339 0.8739130434782608\n",
      "2 (0.2242460175537517, 0.9329156010230178)\n",
      "2 0.3417371724453448 0.8973913043478261\n",
      "3 (0.18358435376316887, 0.943542199488491)\n",
      "3 0.32982471254170626 0.9069565217391304\n",
      "4 (0.14333876382377778, 0.9543606138107417)\n",
      "4 0.30444107920133234 0.913695652173913\n",
      "5 (0.10528122790180525, 0.9661892583120205)\n",
      "5 0.29549166933713394 0.921304347826087\n",
      "6 (0.1076983477087977, 0.9641432225063938)\n",
      "6 0.3183346832271526 0.9165217391304348\n",
      "\n",
      "0 (0.7625945028181583, 0.7799872122762148)\n",
      "0 0.8317351727984199 0.7654347826086957\n",
      "1 (0.5821708779414633, 0.8412404092071611)\n",
      "1 0.7012809776246721 0.8208695652173913\n",
      "2 (0.4821640870181915, 0.870843989769821)\n",
      "2 0.6032980909373281 0.8467391304347827\n",
      "3 (0.448800451365911, 0.8845524296675192)\n",
      "3 0.6082624734185542 0.8582608695652174\n",
      "4 (0.4519942590362919, 0.8858951406649617)\n",
      "4 0.6429268345516804 0.8641304347826086\n",
      "5 (0.35021646915887794, 0.9110230179028133)\n",
      "5 0.5634182864187051 0.8797826086956522\n",
      "6 (0.3710570570968945, 0.9124424552429667)\n",
      "6 0.5920912977938732 0.8765217391304347\n",
      "\n",
      "0 (3.855616423189475, 0.021739130434782608)\n",
      "0 3.8556164231894843 0.021739130434782608\n",
      "1 (3.8556164241298307, 0.021739130434782608)\n",
      "1 3.855616424129838 0.021739130434782608\n",
      "2 (3.8556164240184607, 0.021739130434782608)\n",
      "2 3.8556164240184745 0.021739130434782608\n",
      "3 (3.8556164238508464, 0.021739130434782608)\n",
      "3 3.855616423850823 0.021739130434782608\n",
      "4 (3.8556164230402006, 0.021739130434782608)\n",
      "4 3.8556164230401664 0.021739130434782608\n",
      "5 (3.855616423927467, 0.021739130434782608)\n",
      "5 3.8556164239274633 0.021739130434782608\n",
      "6 (3.8556164238344683, 0.021739130434782608)\n",
      "6 3.8556164238344546 0.021739130434782608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [1e-4,1e-3,1e-2,.1,1]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit_mom(100,7,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr_mom_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ebe57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7b06a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110.47183132171631 113.0998318195343 114.50782465934753 115.9518256187439 115.52459669113159\n",
      "[(2.9553359575704756, 0.31516624040920715), (0.635874491747902, 0.825997442455243), (0.1076983477087977, 0.9641432225063938), (0.3710570570968945, 0.9124424552429667), (3.8556164238344683, 0.021739130434782608)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b50e5b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.7859398704447106, 0.7834910485933504)\n",
      "0 0.8276567622580836 0.7676086956521739\n",
      "1 (0.4090405198688935, 0.8840664961636828)\n",
      "1 0.4730769484516586 0.8673913043478261\n",
      "2 (0.2913138539947819, 0.9148081841432225)\n",
      "2 0.3904651088569843 0.8904347826086957\n",
      "3 (0.22271064750153782, 0.9339386189258312)\n",
      "3 0.35484310334184854 0.8982608695652174\n",
      "4 (0.18073447750911828, 0.9456393861892584)\n",
      "4 0.33942114091680153 0.9026086956521739\n",
      "5 (0.13580919926100596, 0.9577749360613811)\n",
      "5 0.3123901879904835 0.9141304347826087\n",
      "6 (0.1231882703859728, 0.960613810741688)\n",
      "6 0.325827248272183 0.9128260869565218\n",
      "\n",
      "0 (0.5912126266593093, 0.8340920716112532)\n",
      "0 0.6415927483840842 0.8184782608695652\n",
      "1 (0.3409473683181891, 0.8990920716112532)\n",
      "1 0.4379916898024736 0.8719565217391304\n",
      "2 (0.24617118810345112, 0.9257416879795396)\n",
      "2 0.3758591840800076 0.8876086956521739\n",
      "3 (0.1872005476663068, 0.9416496163682865)\n",
      "3 0.33738753982938047 0.9034782608695652\n",
      "4 (0.15677898844440546, 0.9495268542199489)\n",
      "4 0.3269624287746522 0.9093478260869565\n",
      "5 (0.1316173628765838, 0.958005115089514)\n",
      "5 0.3184535433928379 0.9128260869565218\n",
      "6 (0.09061251715379383, 0.9702685421994884)\n",
      "6 0.2902442610869725 0.9245652173913044\n",
      "\n",
      "0 (0.46019174767292764, 0.861611253196931)\n",
      "0 0.5185621635839067 0.8426086956521739\n",
      "1 (0.2555232441036127, 0.9216368286445012)\n",
      "1 0.35418393136195225 0.8982608695652174\n",
      "2 (0.20668590128478717, 0.9351278772378516)\n",
      "2 0.3526430363958139 0.9002173913043479\n",
      "3 (0.23968903144414158, 0.9261636828644502)\n",
      "3 0.41828773092127625 0.8884782608695653\n",
      "4 (0.15096334922614235, 0.9525191815856777)\n",
      "4 0.34072417662686066 0.9141304347826087\n",
      "5 (0.09986384575589914, 0.9672122762148337)\n",
      "5 0.31378416616865956 0.9182608695652174\n",
      "6 (0.13023704710655043, 0.9593478260869566)\n",
      "6 0.3490739576592881 0.9154347826086957\n",
      "\n",
      "0 (0.43647641005141424, 0.8681329923273657)\n",
      "0 0.5178719995486808 0.8489130434782609\n",
      "1 (0.29953917351602105, 0.9078900255754476)\n",
      "1 0.41653171766823227 0.8736956521739131\n",
      "2 (0.30108673557436244, 0.9072378516624041)\n",
      "2 0.44879741184126426 0.8793478260869565\n",
      "3 (0.18052401630654613, 0.944386189258312)\n",
      "3 0.3240575834909375 0.91\n",
      "4 (0.1815982013725969, 0.9444501278772378)\n",
      "4 0.36629242655254696 0.9082608695652173\n",
      "5 (0.1650912675980499, 0.949693094629156)\n",
      "5 0.36833053856101133 0.9104347826086957\n",
      "6 (0.1492914807807535, 0.9554219948849105)\n",
      "6 0.3666705501369222 0.9104347826086957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [7e-3,1e-2,2e-2,4e-2]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit_mom(100,7,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr1_mom_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "932a15ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.78380370140076 112.13856887817383 114.64382719993591 108.46434998512268\n",
      "[(0.1231882703859728, 0.960613810741688), (0.09061251715379383, 0.9702685421994884), (0.13023704710655043, 0.9593478260869566), (0.1492914807807535, 0.9554219948849105)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58d3ea67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.9669095909496254, 0.7422762148337596)\n",
      "0 0.9885938079038199 0.7356521739130435\n",
      "1 (0.6937300802134747, 0.8177109974424552)\n",
      "1 0.7376885178685075 0.8069565217391305\n",
      "2 (0.526582390377922, 0.8637468030690537)\n",
      "2 0.5870958073618877 0.8460869565217392\n",
      "3 (0.42369763853322207, 0.8916624040920716)\n",
      "3 0.496302860473202 0.8665217391304347\n",
      "4 (0.3558671250109262, 0.9094757033248082)\n",
      "4 0.43934928565270154 0.8806521739130435\n",
      "5 (0.30682888818721243, 0.9220460358056266)\n",
      "5 0.39943499425715107 0.893695652173913\n",
      "6 (0.2688946794990988, 0.9318670076726343)\n",
      "6 0.3697446057205439 0.9019565217391304\n",
      "7 (0.2381316884207255, 0.9396291560102302)\n",
      "7 0.34739916108271707 0.9089130434782609\n",
      "8 (0.21291928196090704, 0.9462915601023018)\n",
      "8 0.3297783791218987 0.9130434782608695\n",
      "9 (0.1920087048921828, 0.9518797953964194)\n",
      "9 0.3160817359857038 0.9139130434782609\n",
      "\n",
      "0 (0.5663846651600581, 0.8460613810741688)\n",
      "0 0.625387153391489 0.8293478260869566\n",
      "1 (0.3362775204207301, 0.9091687979539642)\n",
      "1 0.42349173000181456 0.8858695652173914\n",
      "2 (0.2515036152101511, 0.9301790281329924)\n",
      "2 0.36061815518305523 0.9019565217391304\n",
      "3 (0.202064552609647, 0.9436317135549872)\n",
      "3 0.331013854458778 0.9073913043478261\n",
      "4 (0.17083673914207448, 0.9514322250639387)\n",
      "4 0.31535466224910014 0.9108695652173913\n",
      "5 (0.14541612033354198, 0.9579283887468031)\n",
      "5 0.30384233481526 0.9145652173913044\n",
      "6 (0.12507018222777416, 0.9637212276214834)\n",
      "6 0.2973152681344744 0.917608695652174\n",
      "7 (0.10880962822956121, 0.968312020460358)\n",
      "7 0.2924518374941954 0.92\n",
      "8 (0.0952980903619503, 0.9720971867007673)\n",
      "8 0.28848018400980646 0.9219565217391305\n",
      "9 (0.08293891178580774, 0.9754987212276215)\n",
      "9 0.2856263850571714 0.9241304347826087\n",
      "\n",
      "0 (0.42917628282062353, 0.87423273657289)\n",
      "0 0.5102367682629076 0.8530434782608696\n",
      "1 (0.2880779512896337, 0.9129795396419438)\n",
      "1 0.4165852807202196 0.8806521739130435\n",
      "2 (0.22276130883989695, 0.9318286445012788)\n",
      "2 0.3869430054765617 0.8919565217391304\n",
      "3 (0.1816197712424156, 0.943542199488491)\n",
      "3 0.37197720611438995 0.8976086956521739\n",
      "4 (0.158009681809743, 0.9497953964194373)\n",
      "4 0.37735811027130467 0.9060869565217391\n",
      "5 (0.13298016786609598, 0.9566879795396419)\n",
      "5 0.3699128253240223 0.9065217391304348\n",
      "6 (0.12229379084106812, 0.9603196930946292)\n",
      "6 0.37880784137613116 0.9069565217391304\n",
      "7 (0.09981160535869521, 0.9671867007672634)\n",
      "7 0.373401263715263 0.9158695652173913\n",
      "8 (0.10147831054152456, 0.9667774936061381)\n",
      "8 0.3970146768341588 0.9134782608695652\n",
      "9 (0.07910935260557285, 0.9741432225063938)\n",
      "9 0.3862142591592595 0.917608695652174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24617bad160>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [1e-2,3e-2,7e-2,.1,.11,.12,.14]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit_mom(100,7,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr1_mom_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62a3909d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.28393745422363 43.81192088127136 43.95993399620056 44.135934352874756 43.867934703826904 43.73193359375 43.47993731498718\n",
      "[(0.2623428209878484, 0.9341304347826087), (0.12353589842539049, 0.9644373401534527), (0.11176657990835927, 0.9641943734015346), (0.21685401387251252, 0.9387340153452686), (0.22174802779651323, 0.9379539641943734), (0.253777272799641, 0.929923273657289), (0.4002061421680739, 0.9067391304347826)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b783a6e",
   "metadata": {},
   "source": [
    "# NAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c617491b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.8892528665544023, 0.7632480818414322)\n",
      "0 0.9127648638652258 0.7545652173913043\n",
      "1 (0.6018024515761946, 0.8432225063938619)\n",
      "1 0.6463649964130466 0.8302173913043478\n",
      "2 (0.4475256501831831, 0.8853452685421995)\n",
      "2 0.5097464284064797 0.8660869565217392\n",
      "3 (0.3566547508732969, 0.9094373401534527)\n",
      "3 0.43518191516017746 0.8867391304347826\n",
      "4 (0.2980284719299274, 0.9239258312020461)\n",
      "4 0.39103608132730094 0.8971739130434783\n",
      "5 (0.2556010075123842, 0.9345524296675192)\n",
      "5 0.36105047525094425 0.9030434782608696\n",
      "6 (0.22211388221328388, 0.9434398976982097)\n",
      "6 0.3371896810344859 0.9067391304347826\n",
      "7 (0.1953260262148944, 0.9509590792838875)\n",
      "7 0.31906568478926994 0.9104347826086957\n",
      "8 (0.17351929809688593, 0.957084398976982)\n",
      "8 0.30554238509103815 0.9143478260869565\n",
      "9 (0.15455477628335337, 0.9624424552429668)\n",
      "9 0.2948053430656257 0.9184782608695652\n",
      "10 (0.1387344431207014, 0.9668925831202047)\n",
      "10 0.28639152723489786 0.9202173913043479\n",
      "11 (0.12482192146471359, 0.9708312020460358)\n",
      "11 0.2793571677097383 0.9210869565217391\n",
      "12 (0.1128056173189721, 0.9744501278772378)\n",
      "12 0.2744875535133666 0.9241304347826087\n",
      "13 (0.10208853943077238, 0.9773273657289002)\n",
      "13 0.27036480119440237 0.9254347826086956\n",
      "14 (0.09276535495965574, 0.979616368286445)\n",
      "14 0.2672281832229343 0.9265217391304348\n",
      "15 (0.08453289553363472, 0.9819053708439898)\n",
      "15 0.2652512555421178 0.9280434782608695\n",
      "16 (0.0770693231642339, 0.9839769820971866)\n",
      "16 0.26377455419612544 0.928695652173913\n",
      "17 (0.07058595847776346, 0.985843989769821)\n",
      "17 0.26337819041018207 0.9304347826086956\n",
      "18 (0.06479415205684765, 0.9874040920716113)\n",
      "18 0.2626970178545146 0.9289130434782609\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2461cc9dbe0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [25,50,100,150,500,1000]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit_nag(bs,10,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize_nag_arc1.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "048b039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205.81445813179016 118.77981734275818 72.29989051818848 59.13191294670105 37.940460205078125 34.49594569206238\n",
      "[(0.09118178796073186, 0.9714961636828644), (0.0572566450892252, 0.9837979539641943), (0.11644426449839615, 0.9687851662404092), (0.1530439684552261, 0.9627493606138108), (0.4485570167023755, 0.886994884910486), (0.739027379982765, 0.8070204603580563)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4ebae8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.5402990262403794, 0.838618925831202)\n",
      "0 0.5892725208662442 0.8297826086956521\n",
      "1 (0.36519343856001074, 0.8941687979539642)\n",
      "1 0.4751472642762232 0.8702173913043478\n",
      "2 (0.3308998350095716, 0.9097570332480819)\n",
      "2 0.4671499621611311 0.8832608695652174\n",
      "3 (0.23150551012572762, 0.9332097186700767)\n",
      "3 0.37140104570307697 0.9015217391304348\n",
      "4 (0.2181437470752625, 0.9369820971867008)\n",
      "4 0.3511570428919252 0.905\n",
      "5 (0.23938742033455676, 0.9340281329923273)\n",
      "5 0.41444225007032093 0.8963043478260869\n",
      "6 (0.16866843183543362, 0.9527365728900256)\n",
      "6 0.35154073536606567 0.918695652173913\n",
      "7 (0.1823785558495994, 0.9483887468030691)\n",
      "7 0.36896377705543826 0.9123913043478261\n",
      "8 (0.19437695646770595, 0.9477621483375959)\n",
      "8 0.42239052586249815 0.9032608695652173\n",
      "9 (0.11869241961292115, 0.9659718670076727)\n",
      "9 0.3341694586688771 0.923695652173913\n",
      "\n",
      "0 (0.44193662158304553, 0.8660358056265984)\n",
      "0 0.540248575146037 0.8441304347826087\n",
      "1 (0.26768234964572973, 0.9187851662404092)\n",
      "1 0.40191772586535746 0.8860869565217391\n",
      "2 (0.22494937374021245, 0.9297953964194373)\n",
      "2 0.384361633995349 0.8954347826086957\n",
      "3 (0.21954523185267183, 0.9317902813299233)\n",
      "3 0.40718884934732946 0.8939130434782608\n",
      "4 (0.15689525423041303, 0.9506649616368287)\n",
      "4 0.3628492656467757 0.908695652173913\n",
      "5 (0.15876793009138881, 0.949462915601023)\n",
      "5 0.36021690933503264 0.9082608695652173\n",
      "6 (0.14499448486592573, 0.9570204603580562)\n",
      "6 0.3800339576908334 0.9095652173913044\n",
      "7 (0.09842588509484669, 0.9688874680306906)\n",
      "7 0.31255737164674274 0.9317391304347826\n",
      "8 (0.09297631031239108, 0.971611253196931)\n",
      "8 0.3059246438768809 0.9284782608695652\n",
      "9 (0.07931926784697643, 0.9751790281329923)\n",
      "9 0.337655249088823 0.9256521739130434\n",
      "\n",
      "0 (0.45865360755836726, 0.8665601023017903)\n",
      "0 0.5277814741610923 0.8445652173913043\n",
      "1 (0.2796323775676414, 0.915153452685422)\n",
      "1 0.3811585639145927 0.8876086956521739\n",
      "2 (0.19012649792321168, 0.941150895140665)\n",
      "2 0.32955876896550684 0.9056521739130434\n",
      "3 (0.13378874315580871, 0.9581841432225064)\n",
      "3 0.28659746472017666 0.9195652173913044\n",
      "4 (0.14495701126478558, 0.9528260869565217)\n",
      "4 0.3291499067131698 0.9165217391304348\n",
      "5 (0.12661003684590827, 0.9586572890025575)\n",
      "5 0.3324149924466488 0.9195652173913044\n",
      "6 (0.11712325453313309, 0.9651918158567775)\n",
      "6 0.341419084434543 0.9173913043478261\n",
      "7 (0.06307877279722414, 0.9793478260869565)\n",
      "7 0.2905288046466397 0.9339130434782609\n",
      "8 (0.07437284013779646, 0.9754731457800512)\n",
      "8 0.3286505302418898 0.9273913043478261\n",
      "9 (0.08237930956727905, 0.9723273657289002)\n",
      "9 0.35266778086631423 0.9221739130434783\n",
      "\n",
      "0 (0.5763610835194608, 0.8303324808184144)\n",
      "0 0.618646845259328 0.8143478260869565\n",
      "1 (0.30571050240073183, 0.9079156010230179)\n",
      "1 0.40064277111328883 0.8852173913043478\n",
      "2 (0.21426955270135922, 0.9343222506393862)\n",
      "2 0.339890431940696 0.9039130434782608\n",
      "3 (0.15605641298315376, 0.9512404092071611)\n",
      "3 0.30400174482899417 0.912608695652174\n",
      "4 (0.1513138157617295, 0.9507672634271099)\n",
      "4 0.3370450988807782 0.9091304347826087\n",
      "5 (0.11467594975768279, 0.9617263427109974)\n",
      "5 0.33506234635884374 0.9132608695652173\n",
      "6 (0.10832450954294437, 0.964769820971867)\n",
      "6 0.32960723635389105 0.9191304347826087\n",
      "7 (0.07393579905885195, 0.9756393861892583)\n",
      "7 0.31215225307835803 0.9260869565217391\n",
      "8 (0.07052078811893889, 0.9765984654731458)\n",
      "8 0.32765895800979283 0.9239130434782609\n",
      "9 (0.07107518448254102, 0.975997442455243)\n",
      "9 0.3395125186234026 0.9232608695652174\n",
      "\n",
      "0 (1.1831413482422626, 0.6768797953964194)\n",
      "0 1.1913727833718089 0.6723913043478261\n",
      "1 (0.7065746496073136, 0.805537084398977)\n",
      "1 0.7452411664740928 0.7856521739130434\n",
      "2 (0.47562869128185503, 0.8659846547314578)\n",
      "2 0.5365875718187173 0.8517391304347826\n",
      "3 (0.3641622960932401, 0.8955882352941177)\n",
      "3 0.45091165462730004 0.871304347826087\n",
      "4 (0.29625808911362694, 0.9140409207161125)\n",
      "4 0.3993253643294879 0.8845652173913043\n",
      "5 (0.20704990281392754, 0.9427109974424552)\n",
      "5 0.3251437588704244 0.9065217391304348\n",
      "6 (0.1718961385959785, 0.9517007672634271)\n",
      "6 0.31104833695451833 0.9115217391304348\n",
      "7 (0.16043245255217167, 0.9532992327365729)\n",
      "7 0.3182407914039049 0.9080434782608696\n",
      "8 (0.14304182224507975, 0.9565984654731458)\n",
      "8 0.3084222054903452 0.9139130434782609\n",
      "9 (0.1300982400828952, 0.9605626598465473)\n",
      "9 0.3030169406688886 0.9163043478260869\n",
      "\n",
      "0 (2.0402162982052996, 0.4489769820971867)\n",
      "0 2.0227785397813673 0.45760869565217394\n",
      "1 (1.190047077792175, 0.6730434782608695)\n",
      "1 1.1964600060413608 0.677608695652174\n",
      "2 (0.8990386211119799, 0.7541048593350383)\n",
      "2 0.9263075972611381 0.7510869565217392\n",
      "3 (0.712625444038662, 0.8019693094629156)\n",
      "3 0.7527852438507289 0.796304347826087\n",
      "4 (0.5684739071260634, 0.8416496163682864)\n",
      "4 0.6223504023839358 0.8297826086956521\n",
      "5 (0.4636969134152926, 0.8712915601023018)\n",
      "5 0.5324301848529294 0.8532608695652174\n",
      "6 (0.4044170104343393, 0.8872250639386189)\n",
      "6 0.4846341907041126 0.8639130434782609\n",
      "7 (0.37308560173822586, 0.8940409207161125)\n",
      "7 0.46925233493256535 0.8682608695652174\n",
      "8 (0.3062406063730495, 0.9145012787723785)\n",
      "8 0.4134995494043375 0.8865217391304347\n",
      "9 (0.2868496535411937, 0.9166240409207161)\n",
      "9 0.4048430825306395 0.8860869565217391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [25,50,100,150,500,1000]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit_nag(bs,10,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize_nag_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d053470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538.4816226959229 296.74824500083923 177.28170561790466 138.11179089546204 88.92386865615845 77.87987899780273\n",
      "[(0.11869241961292115, 0.9659718670076727), (0.07931926784697643, 0.9751790281329923), (0.08237930956727905, 0.9723273657289002), (0.07107518448254102, 0.975997442455243), (0.1300982400828952, 0.9605626598465473), (0.2868496535411937, 0.9166240409207161)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "09074032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.5409029592342997, 0.8419948849104859)\n",
      "0 0.5887375133672926 0.8269565217391305\n",
      "1 (0.33149603831303576, 0.8986445012787724)\n",
      "1 0.437382079535038 0.871304347826087\n",
      "2 (0.20829739886179247, 0.9368414322250639)\n",
      "2 0.3282696538512705 0.9041304347826087\n",
      "3 (0.1809501462233266, 0.9432992327365729)\n",
      "3 0.33489710803530415 0.9039130434782608\n",
      "4 (0.14239853596963223, 0.9544245524296675)\n",
      "4 0.31439163529673697 0.9128260869565218\n",
      "5 (0.11601867581768495, 0.9626854219948849)\n",
      "5 0.30813750078626295 0.9191304347826087\n",
      "6 (0.08778814412833517, 0.9713682864450128)\n",
      "6 0.2918371028931767 0.9221739130434783\n",
      "7 (0.07310819040872599, 0.9757800511508952)\n",
      "7 0.3165105121960034 0.9197826086956522\n",
      "8 (0.061732141167816286, 0.9787084398976982)\n",
      "8 0.31172797807374164 0.9278260869565217\n",
      "9 (0.08708251333463617, 0.9715856777493607)\n",
      "9 0.34887629549139915 0.9189130434782609\n",
      "\n",
      "0 (0.8489255980289327, 0.7598081841432225)\n",
      "0 0.8673329173197574 0.7571739130434783\n",
      "1 (0.4234094871942923, 0.8769437340153453)\n",
      "1 0.49799556864334005 0.8606521739130435\n",
      "2 (0.2946396137149108, 0.9122378516624041)\n",
      "2 0.40084316959507743 0.8854347826086957\n",
      "3 (0.23714822438191158, 0.9271355498721228)\n",
      "3 0.3634377418665508 0.8984782608695652\n",
      "4 (0.16051521802860086, 0.9506649616368287)\n",
      "4 0.3032925699708298 0.9180434782608695\n",
      "5 (0.14144604932620855, 0.9560869565217391)\n",
      "5 0.30096009596567735 0.9145652173913044\n",
      "6 (0.11404248639632222, 0.9642071611253197)\n",
      "6 0.28775883067678937 0.9215217391304348\n",
      "7 (0.09347773992155076, 0.9698721227621483)\n",
      "7 0.2808620904232642 0.9269565217391305\n",
      "8 (0.07546510634095373, 0.9762915601023018)\n",
      "8 0.2840312708429274 0.9284782608695652\n",
      "9 (0.06725019268537831, 0.9779923273657289)\n",
      "9 0.2934683056900035 0.9252173913043479\n",
      "\n",
      "0 (0.9223489130527941, 0.7439002557544757)\n",
      "0 0.9324844607125293 0.7369565217391304\n",
      "1 (0.5076449940289374, 0.8566751918158568)\n",
      "1 0.5631390499588406 0.8434782608695652\n",
      "2 (0.3440739182776378, 0.9017647058823529)\n",
      "2 0.4282077990351908 0.8841304347826087\n",
      "3 (0.2550713157995509, 0.9260997442455243)\n",
      "3 0.3656261403707742 0.8956521739130435\n",
      "4 (0.2155751113445627, 0.9353196930946291)\n",
      "4 0.35538993339489716 0.8993478260869565\n",
      "5 (0.1843117099258739, 0.9456138107416879)\n",
      "5 0.34531801840173126 0.9063043478260869\n",
      "6 (0.1343211390861815, 0.9606265984654732)\n",
      "6 0.3060135304494423 0.917608695652174\n",
      "7 (0.09941482925411588, 0.9710613810741688)\n",
      "7 0.2777966813396168 0.9282608695652174\n",
      "8 (0.08653853762265953, 0.9747314578005115)\n",
      "8 0.28161294455576796 0.9293478260869565\n",
      "9 (0.07212199615010918, 0.9786061381074169)\n",
      "9 0.2798357036774352 0.9289130434782609\n",
      "\n",
      "0 (1.0956720077088824, 0.6915473145780051)\n",
      "0 1.1057684450497038 0.6873913043478261\n",
      "1 (0.5987775355043378, 0.8307161125319693)\n",
      "1 0.6396957205709077 0.82\n",
      "2 (0.4096791665137418, 0.8809974424552429)\n",
      "2 0.48134320813369563 0.8676086956521739\n",
      "3 (0.31488157881433265, 0.9078644501278772)\n",
      "3 0.4111528798335927 0.8880434782608696\n",
      "4 (0.26012804335913015, 0.9211636828644502)\n",
      "4 0.37906756649872386 0.8941304347826087\n",
      "5 (0.20215444675521457, 0.9396035805626598)\n",
      "5 0.3365904307650915 0.9063043478260869\n",
      "6 (0.15634206869162282, 0.9534910485933504)\n",
      "6 0.3008299485434947 0.9171739130434783\n",
      "7 (0.1410765447110711, 0.9567519181585677)\n",
      "7 0.30898880114116634 0.9169565217391304\n",
      "8 (0.16416234214129133, 0.9466240409207161)\n",
      "8 0.3529924586077172 0.9073913043478261\n",
      "9 (0.10920724360782022, 0.9659207161125319)\n",
      "9 0.29790340307300517 0.9217391304347826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [150,250,350,400]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit_nag(bs,10,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize1_nag_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b2c686a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138.89579010009766 111.02382969856262 101.3718478679657 102.66088891029358\n",
      "[(0.08708251333463617, 0.9715856777493607), (0.06725019268537831, 0.9779923273657289), (0.07212199615010918, 0.9786061381074169), (0.10920724360782022, 0.9659207161125319)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "43aaf77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3.8306184440270785, 0.0220460358056266)\n",
      "0 3.8306514592178105 0.021739130434782608\n",
      "1 (3.8290706627783657, 0.02176470588235294)\n",
      "1 3.8290968725808243 0.021739130434782608\n",
      "2 (3.8272036348870926, 0.021918158567774935)\n",
      "2 3.827222483772888 0.021739130434782608\n",
      "3 (3.824557821175228, 0.023734015345268544)\n",
      "3 3.824566724686806 0.02391304347826087\n",
      "4 (3.819706397508451, 0.03014066496163683)\n",
      "4 3.819696128246374 0.030869565217391304\n",
      "\n",
      "0 (1.0432134549721797, 0.7348721227621483)\n",
      "0 1.0559211253961345 0.7276086956521739\n",
      "1 (0.6223455006971291, 0.8420588235294117)\n",
      "1 0.6596419764252669 0.8304347826086956\n",
      "2 (0.41129964141908637, 0.8966624040920717)\n",
      "2 0.47109204019253964 0.8741304347826087\n",
      "3 (0.29547845361215963, 0.9262020460358056)\n",
      "3 0.37737828813123536 0.9004347826086957\n",
      "4 (0.22806274225173115, 0.9432225063938618)\n",
      "4 0.3299876729514856 0.9130434782608695\n",
      "\n",
      "0 (0.7898920475251596, 0.7772506393861892)\n",
      "0 0.820395410279014 0.7721739130434783\n",
      "1 (0.40785915508688153, 0.8824040920716113)\n",
      "1 0.4816494515387814 0.8636956521739131\n",
      "2 (0.2898938884194522, 0.9119693094629157)\n",
      "2 0.3944557701078271 0.8843478260869565\n",
      "3 (0.2395686340529586, 0.9257289002557545)\n",
      "3 0.373953212489232 0.8902173913043478\n",
      "4 (0.19082921759357815, 0.9398081841432225)\n",
      "4 0.35634006914268357 0.8928260869565218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out activation function\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for af in [('sigmoid',0),('tanh',1),('relu',2)]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],af[1],1024,0)\n",
    "    losses=a.fit_nag(250,5,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=af[0])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_af_nag_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5bb26785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.71188044548035 70.50542831420898 53.83092474937439\n",
      "[(3.819706397508451, 0.03014066496163683), (0.22806274225173115, 0.9432225063938618), (0.19082921759357815, 0.9398081841432225)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd4e2f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1.5116203921522668, 0.6364833759590793)\n",
      "0 1.5070115026050879 0.6363043478260869\n",
      "1 (1.2111541327238933, 0.6907800511508951)\n",
      "1 1.212044836870097 0.697391304347826\n",
      "2 (1.0843158497825192, 0.7184015345268542)\n",
      "2 1.0921991267117457 0.721304347826087\n",
      "3 (0.9986463666760234, 0.7388746803069054)\n",
      "3 1.0121919805329376 0.736304347826087\n",
      "4 (0.9293019615798321, 0.7556905370843989)\n",
      "4 0.947620612851895 0.7513043478260869\n",
      "\n",
      "0 (0.9818770155188488, 0.743158567774936)\n",
      "0 1.002534684354445 0.7386956521739131\n",
      "1 (0.7631598664217837, 0.8013171355498722)\n",
      "1 0.8081299514083614 0.7860869565217391\n",
      "2 (0.605710248764647, 0.845306905370844)\n",
      "2 0.6678781555513154 0.8247826086956521\n",
      "3 (0.49487307287942056, 0.8764450127877238)\n",
      "3 0.5700801302778675 0.8504347826086956\n",
      "4 (0.4153934017507939, 0.8976598465473146)\n",
      "4 0.5016873446785907 0.8691304347826087\n",
      "\n",
      "0 (0.8901885539223628, 0.7617263427109975)\n",
      "0 0.9156717245314214 0.7539130434782608\n",
      "1 (0.5975909372033003, 0.8452685421994884)\n",
      "1 0.651460166732781 0.831304347826087\n",
      "2 (0.43879406833548057, 0.8878516624040921)\n",
      "2 0.5134157220005934 0.8671739130434782\n",
      "3 (0.34857887018733297, 0.9116496163682865)\n",
      "3 0.43800495249386723 0.8856521739130435\n",
      "4 (0.2908013762424991, 0.9264066496163683)\n",
      "4 0.3926606603735124 0.8967391304347826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out activation function\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for af in [('sigmoid',0),('tanh',1),('relu',2)]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],af[1],1024,0)\n",
    "    losses=a.fit_nag(150,5,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=af[0])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_af_nag_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1bdac0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.81995177268982 32.041951417922974 28.169959545135498\n",
      "[(0.9293019615798321, 0.7556905370843989), (0.4153934017507939, 0.8976598465473146), (0.2908013762424991, 0.9264066496163683)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "86629d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3.4206826446822833, 0.1932992327365729)\n",
      "0 3.426116250063099 0.19260869565217392\n",
      "1 (2.9574556960117, 0.3560613810741688)\n",
      "1 2.960214428702895 0.35630434782608694\n",
      "2 (2.5517324252683355, 0.4507416879795396)\n",
      "2 2.5521555175388206 0.4591304347826087\n",
      "3 (2.240604625577449, 0.5089641943734016)\n",
      "3 2.239733692702475 0.5089130434782608\n",
      "4 (2.013619929190276, 0.5474296675191815)\n",
      "4 2.0122070440456516 0.547608695652174\n",
      "5 (1.847781584557551, 0.5745780051150895)\n",
      "5 1.846312787683177 0.571304347826087\n",
      "6 (1.7241177500151572, 0.5944245524296675)\n",
      "6 1.7227726983719058 0.592391304347826\n",
      "\n",
      "0 (1.4970284975619015, 0.6325703324808184)\n",
      "0 1.4953631663329523 0.6341304347826087\n",
      "1 (1.209382398825134, 0.6902173913043478)\n",
      "1 1.2129260004211078 0.6895652173913044\n",
      "2 (1.0922226085349407, 0.717391304347826)\n",
      "2 1.1025961398681312 0.715\n",
      "3 (1.0141132945810227, 0.7360485933503836)\n",
      "3 1.0310711493655007 0.7341304347826086\n",
      "4 (0.9504430155558317, 0.7521099744245524)\n",
      "4 0.9729712553728607 0.7484782608695653\n",
      "5 (0.8939609303855782, 0.766687979539642)\n",
      "5 0.9207057813915432 0.7630434782608696\n",
      "6 (0.8419139520301482, 0.781074168797954)\n",
      "6 0.8726523641659892 0.7752173913043479\n",
      "\n",
      "0 (0.7267368829663811, 0.8046547314578005)\n",
      "0 0.7663494748763935 0.796304347826087\n",
      "1 (0.45993551632821994, 0.8768414322250639)\n",
      "1 0.5230100948470404 0.8602173913043478\n",
      "2 (0.3409568313065597, 0.9087851662404092)\n",
      "2 0.42325772280987956 0.8843478260869565\n",
      "3 (0.2693867148194177, 0.9276214833759591)\n",
      "3 0.36745528041291076 0.8973913043478261\n",
      "4 (0.2270616626678402, 0.9387979539641944)\n",
      "4 0.33853674236720716 0.905\n",
      "5 (0.1934268284166806, 0.9482864450127877)\n",
      "5 0.3168970092722132 0.913695652173913\n",
      "6 (0.16510895494649372, 0.9558567774936061)\n",
      "6 0.3010072441719774 0.9193478260869565\n",
      "\n",
      "0 (0.919591494605169, 0.7510869565217392)\n",
      "0 1.0109499207172812 0.735\n",
      "1 (0.7336853875976814, 0.7992838874680307)\n",
      "1 0.8689705060652176 0.7817391304347826\n",
      "2 (0.68268504855198, 0.8149360613810742)\n",
      "2 0.8376603151027486 0.792608695652174\n",
      "3 (0.7050337978016082, 0.8218670076726343)\n",
      "3 0.891923236925419 0.7943478260869565\n",
      "4 (0.6689974436535945, 0.835613810741688)\n",
      "4 0.9170258821872035 0.8015217391304348\n",
      "5 (0.7639850619105004, 0.8283248081841432)\n",
      "5 1.0457324204398424 0.7991304347826087\n",
      "6 (0.6520767571130279, 0.8480434782608696)\n",
      "6 0.9863130598168263 0.8126086956521739\n",
      "\n",
      "0 (3.8850311573992236, 0.021739130434782608)\n",
      "0 3.8842744464691368 0.021739130434782608\n",
      "1 (3.884272732019637, 0.021739130434782608)\n",
      "1 3.884274407815176 0.021739130434782608\n",
      "2 (3.884274407203803, 0.021739130434782608)\n",
      "2 3.884274407203807 0.021739130434782608\n",
      "3 (3.8842744074852207, 0.021739130434782608)\n",
      "3 3.8842744074852025 0.021739130434782608\n",
      "4 (3.88427440843556, 0.021739130434782608)\n",
      "4 3.884274408435581 0.021739130434782608\n",
      "5 (3.8842744065398063, 0.021739130434782608)\n",
      "5 3.884274406539809 0.021739130434782608\n",
      "6 (3.8842744062667536, 0.021739130434782608)\n",
      "6 3.884274406266752 0.021739130434782608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [1e-4,1e-3,1e-2,.1,1]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit_nag(100,7,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr_nag_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5f42f3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.5749249458313 47.66492772102356 47.602927923202515 47.75493025779724 47.11392593383789\n",
      "[(1.7241177500151572, 0.5944245524296675), (0.8419139520301482, 0.781074168797954), (0.16510895494649372, 0.9558567774936061), (0.6520767571130279, 0.8480434782608696), (3.8842744062667536, 0.021739130434782608)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dc3ceaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3.7475973856340654, 0.07237851662404092)\n",
      "0 3.749028552885513 0.07326086956521739\n",
      "1 (3.603754695594871, 0.1298849104859335)\n",
      "1 3.606523684496087 0.12760869565217392\n",
      "2 (3.337107723799012, 0.20717391304347826)\n",
      "2 3.341058915561855 0.19956521739130434\n",
      "3 (2.8592244174452013, 0.32864450127877237)\n",
      "3 2.863365888810268 0.3241304347826087\n",
      "4 (2.303240132168837, 0.4364450127877238)\n",
      "4 2.3064188757412 0.435\n",
      "5 (1.9285531762793071, 0.509539641943734)\n",
      "5 1.9305610539932498 0.5097826086956522\n",
      "6 (1.7020411017078092, 0.5593734015345269)\n",
      "6 1.7047721152052835 0.5591304347826087\n",
      "\n",
      "0 (1.4864652648398116, 0.594616368286445)\n",
      "0 1.5009072015296687 0.5904347826086956\n",
      "1 (1.0474118790893878, 0.7156265984654732)\n",
      "1 1.073381075235962 0.7126086956521739\n",
      "2 (0.7925746956527572, 0.7842838874680307)\n",
      "2 0.8271159461275879 0.7795652173913044\n",
      "3 (0.605791480848001, 0.8357289002557545)\n",
      "3 0.6515617744377443 0.8178260869565217\n",
      "4 (0.4884267816504994, 0.8676086956521739)\n",
      "4 0.5493060646055815 0.8476086956521739\n",
      "5 (0.40761375235329345, 0.8881329923273658)\n",
      "5 0.48703138966558795 0.8667391304347826\n",
      "6 (0.34577532420290585, 0.9051278772378517)\n",
      "6 0.44170116258637737 0.88\n",
      "\n",
      "0 (0.4627819192600367, 0.8644629156010231)\n",
      "0 0.5333879707983283 0.8452173913043478\n",
      "1 (0.2562289036025735, 0.9217902813299232)\n",
      "1 0.35901610947948587 0.8928260869565218\n",
      "2 (0.20410021707201742, 0.9359207161125319)\n",
      "2 0.33598688516653985 0.9039130434782608\n",
      "3 (0.1614247619794838, 0.94923273657289)\n",
      "3 0.323470113209487 0.9067391304347826\n",
      "4 (0.11881004103555215, 0.9616240409207161)\n",
      "4 0.28895468191358925 0.9271739130434783\n",
      "5 (0.13328494720914572, 0.9574168797953965)\n",
      "5 0.317339766214634 0.9193478260869565\n",
      "6 (0.08292424184450631, 0.9724296675191816)\n",
      "6 0.2724869719064766 0.9310869565217391\n",
      "\n",
      "0 (2.033430868231712, 0.48553708439897697)\n",
      "0 2.0581591548126577 0.485\n",
      "1 (2.332712161991597, 0.4242071611253197)\n",
      "1 2.390296449338602 0.42369565217391303\n",
      "2 (3.7779687219348332, 0.10534526854219949)\n",
      "2 3.7733950806143484 0.1041304347826087\n",
      "3 (3.8332382831047953, 0.021739130434782608)\n",
      "3 3.83323828310478 0.021739130434782608\n",
      "4 (3.8332382831047953, 0.021739130434782608)\n",
      "4 3.83323828310478 0.021739130434782608\n",
      "5 (3.8332382831047953, 0.021739130434782608)\n",
      "5 3.83323828310478 0.021739130434782608\n",
      "6 (3.8332382831047953, 0.021739130434782608)\n",
      "6 3.83323828310478 0.021739130434782608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-66-f3ff4b4cd6ba>:233: RuntimeWarning: overflow encountered in subtract\n",
      "  W_temp[i]-=temp\n",
      "<ipython-input-66-f3ff4b4cd6ba>:237: RuntimeWarning: overflow encountered in subtract\n",
      "  b_temp[i]-=temp\n",
      "<ipython-input-66-f3ff4b4cd6ba>:209: RuntimeWarning: overflow encountered in subtract\n",
      "  self.W[i]-=gamma*wt[i]\n",
      "<ipython-input-66-f3ff4b4cd6ba>:42: RuntimeWarning: invalid value encountered in matmul\n",
      "  self.Z.append(self.af(np.matmul(self.Z[i],self.W[i])+self.b[i]))\n",
      "<ipython-input-66-f3ff4b4cd6ba>:46: RuntimeWarning: invalid value encountered in matmul\n",
      "  self.Z.append(np.matmul(self.Z[-1],self.W[-1])+self.b[-1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (34.53877639491091, 0.021739130434782608)\n",
      "0 34.538776394910684 0.021739130434782608\n",
      "1 (34.53877639491091, 0.021739130434782608)\n",
      "1 34.538776394910684 0.021739130434782608\n",
      "2 (34.53877639491091, 0.021739130434782608)\n",
      "2 34.538776394910684 0.021739130434782608\n",
      "3 (34.53877639491091, 0.021739130434782608)\n",
      "3 34.538776394910684 0.021739130434782608\n",
      "4 (34.53877639491091, 0.021739130434782608)\n",
      "4 34.538776394910684 0.021739130434782608\n",
      "5 (34.53877639491091, 0.021739130434782608)\n",
      "5 34.538776394910684 0.021739130434782608\n",
      "6 (34.53877639491091, 0.021739130434782608)\n",
      "6 34.538776394910684 0.021739130434782608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [1e-4,1e-3,1e-2,.1,1]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit_nag(100,7,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr_nag_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a0a12f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.68681693077087 124.17227458953857 130.03273057937622 124.95044612884521 130.4781723022461\n",
      "[(1.7020411017078092, 0.5593734015345269), (0.34577532420290585, 0.9051278772378517), (0.08292424184450631, 0.9724296675191816), (3.8332382831047953, 0.021739130434782608), (34.53877639491091, 0.021739130434782608)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6476f7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1.0509985193167064, 0.7208823529411764)\n",
      "0 1.062355943670425 0.7154347826086956\n",
      "1 (0.8116086824281655, 0.7876598465473146)\n",
      "1 0.8458439770915799 0.7782608695652173\n",
      "2 (0.6393836705223986, 0.8357289002557545)\n",
      "2 0.6875008362522647 0.8239130434782609\n",
      "3 (0.5203962286967911, 0.8670460358056266)\n",
      "3 0.5801233058855958 0.8558695652173913\n",
      "4 (0.4374273683870985, 0.889616368286445)\n",
      "4 0.5080068999332066 0.8730434782608696\n",
      "5 (0.3767021906616101, 0.9054987212276214)\n",
      "5 0.4573074347265866 0.8821739130434783\n",
      "6 (0.33060368492113046, 0.9171994884910486)\n",
      "6 0.41988176519986486 0.8895652173913043\n",
      "\n",
      "0 (0.9667410645283614, 0.7433248081841433)\n",
      "0 0.9777547463734414 0.7369565217391304\n",
      "1 (0.7038052003367068, 0.8150255754475704)\n",
      "1 0.7359138013601052 0.8089130434782609\n",
      "2 (0.5352042184945077, 0.8618286445012787)\n",
      "2 0.5875803959787151 0.8452173913043478\n",
      "3 (0.42828027777081457, 0.8906777493606138)\n",
      "3 0.4966356102207889 0.8706521739130435\n",
      "4 (0.35743285324235763, 0.9090792838874681)\n",
      "4 0.43808887255645096 0.8834782608695653\n",
      "5 (0.306403073464125, 0.9222634271099744)\n",
      "5 0.39874994711468636 0.8932608695652174\n",
      "6 (0.26741029406286554, 0.9325063938618926)\n",
      "6 0.3691750852122161 0.8993478260869565\n",
      "\n",
      "0 (0.8923706800645834, 0.7599488491048594)\n",
      "0 0.9138642363499189 0.7558695652173913\n",
      "1 (0.6031889700858888, 0.8408695652173913)\n",
      "1 0.6508762328402132 0.8278260869565217\n",
      "2 (0.4452641294413446, 0.884309462915601)\n",
      "2 0.5103775863861454 0.8639130434782609\n",
      "3 (0.3541711354898237, 0.9082992327365729)\n",
      "3 0.4323572980681113 0.8858695652173914\n",
      "4 (0.2945553060081216, 0.9244373401534527)\n",
      "4 0.38362493601696274 0.8967391304347826\n",
      "5 (0.25178132361222155, 0.9355242966751918)\n",
      "5 0.3507368250841106 0.9056521739130434\n",
      "6 (0.2190328473302691, 0.9438235294117647)\n",
      "6 0.3276898992999962 0.9132608695652173\n",
      "\n",
      "0 (0.6343205745929394, 0.8290537084398977)\n",
      "0 0.6778772711770271 0.8141304347826087\n",
      "1 (0.3898437484428426, 0.8951150895140665)\n",
      "1 0.46016394762328394 0.8765217391304347\n",
      "2 (0.28505055866475254, 0.9226342710997443)\n",
      "2 0.37724199002778824 0.8945652173913043\n",
      "3 (0.22716085703681613, 0.9379028132992328)\n",
      "3 0.33569058535891616 0.9043478260869565\n",
      "4 (0.18941790880241635, 0.9473017902813299)\n",
      "4 0.313839899063892 0.9134782608695652\n",
      "5 (0.15771015529721988, 0.9554475703324808)\n",
      "5 0.29545502063030826 0.9169565217391304\n",
      "6 (0.13464646897733734, 0.9620204603580562)\n",
      "6 0.28627777588850906 0.9206521739130434\n",
      "\n",
      "0 (0.4534683361081284, 0.870843989769821)\n",
      "0 0.5296420511806135 0.8545652173913043\n",
      "1 (0.2968503257653338, 0.9134398976982098)\n",
      "1 0.4036015375189804 0.8843478260869565\n",
      "2 (0.22742296970485046, 0.9312148337595908)\n",
      "2 0.3634843778271298 0.8973913043478261\n",
      "3 (0.18386976382191225, 0.94269820971867)\n",
      "3 0.353472902813991 0.9039130434782608\n",
      "4 (0.16935830864089702, 0.9453452685421995)\n",
      "4 0.36863033883436097 0.8989130434782608\n",
      "5 (0.15305396550823652, 0.9500255754475704)\n",
      "5 0.36935213899731967 0.9039130434782608\n",
      "6 (0.11747498754473083, 0.9620076726342711)\n",
      "6 0.34426923394435666 0.9132608695652173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [6e-3,8e-3,1e-2,2e-2,4e-2]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit_nag(150,7,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr_nag_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f718803a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.22088861465454 43.29163694381714 42.625967025756836 43.1541063785553 41.59028196334839\n",
      "[(0.33060368492113046, 0.9171994884910486), (0.26741029406286554, 0.9325063938618926), (0.2190328473302691, 0.9438235294117647), (0.13464646897733734, 0.9620204603580562), (0.11747498754473083, 0.9620076726342711)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "168bb3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1.0308708216326743, 0.7127365728900256)\n",
      "0 1.0534354437020508 0.705\n",
      "1 (0.5899607712132241, 0.8342710997442455)\n",
      "1 0.6364674300635028 0.8217391304347826\n",
      "2 (0.39930945507511184, 0.885306905370844)\n",
      "2 0.4759237145987761 0.8678260869565217\n",
      "3 (0.3429283559867467, 0.8951790281329923)\n",
      "3 0.4544249792186756 0.8708695652173913\n",
      "4 (0.24469796275189326, 0.92730179028133)\n",
      "4 0.3752943022093357 0.8939130434782608\n",
      "5 (0.18785984826308785, 0.9454475703324808)\n",
      "5 0.34144852979951335 0.9052173913043479\n",
      "6 (0.15748084801227463, 0.9534398976982097)\n",
      "6 0.3254742905523667 0.9080434782608696\n",
      "\n",
      "0 (0.8745885396051553, 0.7536445012787724)\n",
      "0 0.8970759469805039 0.7484782608695653\n",
      "1 (0.4640246735555552, 0.8668925831202046)\n",
      "1 0.5295665618396951 0.8523913043478261\n",
      "2 (0.30975482972198065, 0.9093734015345268)\n",
      "2 0.40624361406107806 0.8815217391304347\n",
      "3 (0.25307649423155193, 0.9237340153452686)\n",
      "3 0.37040124509034533 0.8910869565217391\n",
      "4 (0.21769493403929824, 0.9325319693094629)\n",
      "4 0.35676122377812564 0.8973913043478261\n",
      "5 (0.1552066206610437, 0.9523273657289003)\n",
      "5 0.30834705436975124 0.91\n",
      "6 (0.13374956732816845, 0.9575319693094629)\n",
      "6 0.31297995777290893 0.913695652173913\n",
      "\n",
      "0 (0.8142874301605177, 0.769386189258312)\n",
      "0 0.8517868723929206 0.7578260869565218\n",
      "1 (0.42216163678255614, 0.8789386189258312)\n",
      "1 0.5074622799514864 0.8554347826086957\n",
      "2 (0.28866519032450333, 0.9158184143222506)\n",
      "2 0.3954269495486491 0.8871739130434783\n",
      "3 (0.22253243673567802, 0.9333503836317135)\n",
      "3 0.34611345709803837 0.8976086956521739\n",
      "4 (0.21217445165130489, 0.9336061381074169)\n",
      "4 0.36584149619143574 0.8956521739130435\n",
      "5 (0.1411025940051606, 0.9562659846547314)\n",
      "5 0.30484708118078296 0.9184782608695652\n",
      "6 (0.10781635232842064, 0.9667007672634271)\n",
      "6 0.2796035725340677 0.9223913043478261\n",
      "\n",
      "0 (0.5487351003289234, 0.8388107416879795)\n",
      "0 0.6011626165651477 0.8232608695652174\n",
      "1 (0.2906141625446354, 0.9133120204603581)\n",
      "1 0.3750484628395254 0.8908695652173914\n",
      "2 (0.21215441916920347, 0.9351918158567775)\n",
      "2 0.33158103560148106 0.9030434782608696\n",
      "3 (0.167048070380357, 0.947237851662404)\n",
      "3 0.3275576475173029 0.9073913043478261\n",
      "4 (0.1377566058242362, 0.9551150895140665)\n",
      "4 0.3061444697170841 0.9147826086956522\n",
      "5 (0.12348503425135293, 0.9600383631713555)\n",
      "5 0.3108058195189791 0.912608695652174\n",
      "6 (0.11393570974326171, 0.9624040920716113)\n",
      "6 0.31160116640788404 0.9163043478260869\n",
      "\n",
      "0 (0.503878110276493, 0.8490920716112532)\n",
      "0 0.572608202294506 0.8304347826086956\n",
      "1 (0.2866463784593453, 0.9110358056265985)\n",
      "1 0.3891724390737483 0.8804347826086957\n",
      "2 (0.21926382150161644, 0.9313682864450128)\n",
      "2 0.3563571210333441 0.8958695652173913\n",
      "3 (0.17632850480971096, 0.944309462915601)\n",
      "3 0.34991499144672905 0.9078260869565218\n",
      "4 (0.13903612091732964, 0.9550639386189258)\n",
      "4 0.3199764847481973 0.9167391304347826\n",
      "5 (0.1386595560948306, 0.9562915601023018)\n",
      "5 0.343466278084462 0.9139130434782609\n",
      "6 (0.10577301480100233, 0.9662659846547315)\n",
      "6 0.3335893959510591 0.9202173913043479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [6e-3,8e-3,1e-2,2e-2,4e-2]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit_nag(250,7,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr_nag_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "04176b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.89712953567505 82.07650947570801 79.93774175643921 82.12377691268921 86.41462206840515\n",
      "[(0.15748084801227463, 0.9534398976982097), (0.13374956732816845, 0.9575319693094629), (0.10781635232842064, 0.9667007672634271), (0.11393570974326171, 0.9624040920716113), (0.10577301480100233, 0.9662659846547315)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06dca33",
   "metadata": {},
   "source": [
    "# NADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "29a3e40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.7622132503483016, 0.7792199488491048)\n",
      "0 0.8268055964909327 0.7708695652173913\n",
      "1 (0.633571507703032, 0.8146547314578005)\n",
      "1 0.7340588678483406 0.7917391304347826\n",
      "2 (0.5726640675461543, 0.8322634271099745)\n",
      "2 0.7000221814032557 0.7997826086956522\n",
      "3 (0.522944474757352, 0.8451278772378517)\n",
      "3 0.666489718902961 0.818695652173913\n",
      "4 (0.5083629792874579, 0.8505882352941176)\n",
      "4 0.6662001849094671 0.8254347826086956\n",
      "5 (0.488202694803359, 0.8555626598465473)\n",
      "5 0.6481979533036338 0.8260869565217391\n",
      "6 (0.48054414598858675, 0.8571994884910485)\n",
      "6 0.6589701655096067 0.8228260869565217\n",
      "7 (0.4746851093218905, 0.8591304347826086)\n",
      "7 0.6770885062102837 0.8271739130434783\n",
      "8 (0.4614481363744848, 0.8638107416879796)\n",
      "8 0.6801832335687042 0.8245652173913044\n",
      "9 (0.4472369493445251, 0.8667519181585678)\n",
      "9 0.6853913760127921 0.8232608695652174\n",
      "\n",
      "0 (0.6816233418682469, 0.8023785166240409)\n",
      "0 0.753269684123649 0.7871739130434783\n",
      "1 (0.5705295483422922, 0.8332736572890026)\n",
      "1 0.6639637556293706 0.8097826086956522\n",
      "2 (0.5042390307315171, 0.8525575447570333)\n",
      "2 0.6171512440615109 0.8308695652173913\n",
      "3 (0.45649427272237025, 0.8654731457800512)\n",
      "3 0.5862040362826695 0.8415217391304348\n",
      "4 (0.42140750206396654, 0.8747442455242966)\n",
      "4 0.5705984280175391 0.846304347826087\n",
      "5 (0.4012230711896283, 0.8800127877237852)\n",
      "5 0.579740815685473 0.8480434782608696\n",
      "6 (0.3804489039867118, 0.8860102301790281)\n",
      "6 0.5751845068234863 0.8508695652173913\n",
      "7 (0.36487918686739096, 0.8900639386189259)\n",
      "7 0.5748835203480258 0.8493478260869565\n",
      "8 (0.3497600426304601, 0.8948337595907928)\n",
      "8 0.5699242022167724 0.8552173913043478\n",
      "9 (0.3339285932147802, 0.9004219948849105)\n",
      "9 0.5743308146547992 0.861304347826087\n",
      "\n",
      "0 (0.6886721918038241, 0.8006265984654731)\n",
      "0 0.7552207850764364 0.7915217391304348\n",
      "1 (0.5311889712122793, 0.8461764705882353)\n",
      "1 0.6273963721759227 0.828695652173913\n",
      "2 (0.45694929852823046, 0.8664961636828644)\n",
      "2 0.5828731197942733 0.8432608695652174\n",
      "3 (0.4205098072466919, 0.8762787723785166)\n",
      "3 0.5672518276851476 0.8489130434782609\n",
      "4 (0.38686217060786465, 0.8845524296675192)\n",
      "4 0.5460729011353621 0.8497826086956521\n",
      "5 (0.36343741579215505, 0.8908056265984655)\n",
      "5 0.5399148447713437 0.8521739130434782\n",
      "6 (0.3481392780827788, 0.895460358056266)\n",
      "6 0.5381259514600152 0.8539130434782609\n",
      "7 (0.3356814759861059, 0.8988746803069053)\n",
      "7 0.5328547947666644 0.8582608695652174\n",
      "8 (0.3240041614123561, 0.9027621483375959)\n",
      "8 0.5364070039246834 0.8582608695652174\n",
      "9 (0.3143671699916029, 0.905460358056266)\n",
      "9 0.5437634998633987 0.8604347826086957\n",
      "\n",
      "0 (0.5309231683505993, 0.8459590792838875)\n",
      "0 0.6154065268996424 0.8232608695652174\n",
      "1 (0.4085102527432627, 0.8805882352941177)\n",
      "1 0.508940812176556 0.8556521739130435\n",
      "2 (0.3459195651687806, 0.899156010230179)\n",
      "2 0.46388140615504664 0.8706521739130435\n",
      "3 (0.3099745436505216, 0.9079795396419438)\n",
      "3 0.4547302985806922 0.875\n",
      "4 (0.2857561988289398, 0.9135677749360613)\n",
      "4 0.4498201796937801 0.8834782608695653\n",
      "5 (0.264837287031498, 0.9198209718670076)\n",
      "5 0.45096685891868793 0.8808695652173913\n",
      "6 (0.25629511057582294, 0.9213554987212276)\n",
      "6 0.4607826661419022 0.8817391304347826\n",
      "7 (0.23991051810452413, 0.9265856777493606)\n",
      "7 0.4624812717631027 0.8830434782608696\n",
      "8 (0.22719409111251274, 0.9300127877237852)\n",
      "8 0.4693204698727706 0.8810869565217392\n",
      "9 (0.2169580148742381, 0.9324936061381074)\n",
      "9 0.4797726958738899 0.8802173913043478\n",
      "\n",
      "0 (0.699844165780339, 0.8064833759590793)\n",
      "0 0.7361006467137591 0.7993478260869565\n",
      "1 (0.5280209477096646, 0.851150895140665)\n",
      "1 0.6039117579163205 0.8334782608695652\n",
      "2 (0.4485494575135978, 0.8726470588235294)\n",
      "2 0.5465178337412171 0.8476086956521739\n",
      "3 (0.40047026404250363, 0.8864705882352941)\n",
      "3 0.5141069908153687 0.8558695652173913\n",
      "4 (0.3671334687518671, 0.896074168797954)\n",
      "4 0.4930748538962079 0.8608695652173913\n",
      "5 (0.34204399734555685, 0.902621483375959)\n",
      "5 0.4812112258806713 0.8654347826086957\n",
      "6 (0.3215310470766248, 0.9079795396419438)\n",
      "6 0.4726755598218299 0.8706521739130435\n",
      "7 (0.30451685647494176, 0.9122634271099744)\n",
      "7 0.46568382424923366 0.8734782608695653\n",
      "8 (0.2897403782965088, 0.9165217391304348)\n",
      "8 0.4598229362051624 0.875\n",
      "9 (0.2779619220122635, 0.9200127877237851)\n",
      "9 0.456517295195092 0.8763043478260869\n",
      "\n",
      "0 (0.8572887010109609, 0.7614066496163683)\n",
      "0 0.8937280104443535 0.7478260869565218\n",
      "1 (0.632077203862371, 0.8221355498721228)\n",
      "1 0.6874269590300307 0.8069565217391305\n",
      "2 (0.5245917543939902, 0.8514705882352941)\n",
      "2 0.5902719785322745 0.832391304347826\n",
      "3 (0.46451715603127697, 0.8690409207161125)\n",
      "3 0.5436370179958903 0.8467391304347827\n",
      "4 (0.42274443516360644, 0.8795268542199488)\n",
      "4 0.514678917153166 0.8565217391304348\n",
      "5 (0.39157202787762313, 0.8890920716112531)\n",
      "5 0.4944810625613466 0.8610869565217392\n",
      "6 (0.36663128308894277, 0.8963427109974424)\n",
      "6 0.4803596161401518 0.8676086956521739\n",
      "7 (0.3469080722864308, 0.9014578005115089)\n",
      "7 0.46952778307622506 0.8717391304347826\n",
      "8 (0.3292294758147895, 0.906841432225064)\n",
      "8 0.4595833771292378 0.875\n",
      "9 (0.31520356074866485, 0.9107800511508951)\n",
      "9 0.45410065353991413 0.8754347826086957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [25,50,100,150,500,1000]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit_nadam(bs,10,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize_nadam_arc1.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2def30df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725.5183036327362 338.3878335952759 141.14829349517822 96.77441310882568 49.73471474647522 38.00297546386719\n",
      "[(0.4472369493445251, 0.8667519181585678), (0.3339285932147802, 0.9004219948849105), (0.3143671699916029, 0.905460358056266), (0.2169580148742381, 0.9324936061381074), (0.2779619220122635, 0.9200127877237851), (0.31520356074866485, 0.9107800511508951)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "736510fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.5273550304449102, 0.8642071611253197)\n",
      "0 0.5917640757724169 0.8454347826086956\n",
      "1 (0.36027466854307955, 0.908695652173913)\n",
      "1 0.4573821986910076 0.8797826086956522\n",
      "2 (0.27589117574336713, 0.9299616368286445)\n",
      "2 0.39383349739848583 0.8941304347826087\n",
      "3 (0.22076814356430935, 0.9444373401534527)\n",
      "3 0.35529517621647927 0.9045652173913044\n",
      "4 (0.18178969456371577, 0.9545140664961637)\n",
      "4 0.332114823362653 0.9113043478260869\n",
      "5 (0.15203208725484244, 0.9629923273657289)\n",
      "5 0.31769105191450175 0.9154347826086957\n",
      "6 (0.13085119859885602, 0.9682352941176471)\n",
      "6 0.3099577106365717 0.915\n",
      "7 (0.11420562481916606, 0.9729156010230179)\n",
      "7 0.30661168119609766 0.9152173913043479\n",
      "8 (0.10123324299350596, 0.9758184143222507)\n",
      "8 0.30661637648936085 0.9141304347826087\n",
      "9 (0.09044528230730337, 0.9779411764705882)\n",
      "9 0.30942839234964187 0.9147826086956522\n",
      "\n",
      "0 (0.5493981480486714, 0.8582992327365729)\n",
      "0 0.6008122256166595 0.8417391304347827\n",
      "1 (0.3751610555050468, 0.9048721227621483)\n",
      "1 0.45704975383155094 0.8747826086956522\n",
      "2 (0.28645604310173717, 0.9293606138107416)\n",
      "2 0.39460856563044877 0.8917391304347826\n",
      "3 (0.2303769253964629, 0.944846547314578)\n",
      "3 0.3573970448177129 0.8993478260869565\n",
      "4 (0.19121583123820537, 0.9551150895140665)\n",
      "4 0.3330754723445509 0.9052173913043479\n",
      "5 (0.16234289481765027, 0.9633503836317135)\n",
      "5 0.316860168737574 0.9104347826086957\n",
      "6 (0.13942507841682472, 0.9693734015345269)\n",
      "6 0.30505168040679587 0.9130434782608695\n",
      "7 (0.12149510295222804, 0.9742583120204603)\n",
      "7 0.29848561947775853 0.9134782608695652\n",
      "8 (0.10698062025594944, 0.9779283887468031)\n",
      "8 0.2939396362026376 0.9156521739130434\n",
      "9 (0.09482290860245471, 0.9808695652173913)\n",
      "9 0.29160490920745064 0.9160869565217391\n",
      "\n",
      "0 (0.5958721565794165, 0.8453580562659847)\n",
      "0 0.6488174444291518 0.8291304347826087\n",
      "1 (0.41002262568743775, 0.8955882352941177)\n",
      "1 0.4924313447990736 0.8693478260869565\n",
      "2 (0.3163306785545379, 0.9225319693094629)\n",
      "2 0.4166206209570609 0.8902173913043478\n",
      "3 (0.25797597441759795, 0.9385038363171355)\n",
      "3 0.37460727046416903 0.8991304347826087\n",
      "4 (0.21706697185373794, 0.9497826086956521)\n",
      "4 0.34718430782351634 0.9067391304347826\n",
      "5 (0.18612756741980657, 0.9581074168797954)\n",
      "5 0.32863914195920685 0.9108695652173913\n",
      "6 (0.161098546785324, 0.9647058823529412)\n",
      "6 0.31565261492274904 0.9132608695652173\n",
      "7 (0.14071224570927654, 0.9700895140664961)\n",
      "7 0.3064427559674701 0.9165217391304348\n",
      "8 (0.12401280760390522, 0.9743989769820972)\n",
      "8 0.30110168438739343 0.9165217391304348\n",
      "9 (0.11026750844552347, 0.9780562659846548)\n",
      "9 0.299050879027549 0.9154347826086957\n",
      "\n",
      "0 (0.6430597434129767, 0.832237851662404)\n",
      "0 0.6850973903291669 0.8202173913043478\n",
      "1 (0.44713966912187686, 0.8869820971867007)\n",
      "1 0.5164341796029811 0.8665217391304347\n",
      "2 (0.3493419907691902, 0.9135677749360613)\n",
      "2 0.44020967892936635 0.885\n",
      "3 (0.28727980972552225, 0.9300127877237852)\n",
      "3 0.3963817409427191 0.8923913043478261\n",
      "4 (0.24404970603748777, 0.9420204603580563)\n",
      "4 0.36849234324236346 0.8993478260869565\n",
      "5 (0.21160517253106972, 0.9514194373401534)\n",
      "5 0.35005878382333383 0.9045652173913044\n",
      "6 (0.18590018913148362, 0.9583248081841432)\n",
      "6 0.33684099174715204 0.9073913043478261\n",
      "7 (0.16484525180625378, 0.9639514066496163)\n",
      "7 0.3269984486155469 0.9093478260869565\n",
      "8 (0.14711250760325953, 0.968772378516624)\n",
      "8 0.3193693545862211 0.9119565217391304\n",
      "9 (0.1320817814183061, 0.972851662404092)\n",
      "9 0.3135604244243925 0.9123913043478261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [150,250,350,450]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],0,1024,0)\n",
    "    losses=a.fit_nadam(bs,10,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize1_nadam_arc1.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "195adeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.5038378238678 75.35188674926758 61.50730586051941 54.28791809082031\n",
      "[(0.09044528230730337, 0.9779411764705882), (0.09482290860245471, 0.9808695652173913), (0.11026750844552347, 0.9780562659846548), (0.1320817814183061, 0.972851662404092)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "31652fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.6993207490342821, 0.794309462915601)\n",
      "0 0.7766548129470706 0.7810869565217391\n",
      "1 (0.5424268551698372, 0.8401790281329923)\n",
      "1 0.6732173073896538 0.8132608695652174\n",
      "2 (0.45462138157491117, 0.865153452685422)\n",
      "2 0.6079024655068885 0.836304347826087\n",
      "3 (0.3895545266318499, 0.8870204603580563)\n",
      "3 0.5761518492455961 0.8456521739130435\n",
      "4 (0.3679501320733689, 0.892148337595908)\n",
      "4 0.5848712245794467 0.8519565217391304\n",
      "\n",
      "0 (0.6323673405250042, 0.8130562659846547)\n",
      "0 0.7093433930080766 0.7928260869565218\n",
      "1 (0.43113231761816107, 0.8695268542199488)\n",
      "1 0.5500403447025572 0.8465217391304348\n",
      "2 (0.34998318478134705, 0.8928900255754476)\n",
      "2 0.5110107813615968 0.8619565217391304\n",
      "3 (0.31392780734096865, 0.9030434782608696)\n",
      "3 0.4866362991746399 0.8717391304347826\n",
      "4 (0.31221141281311726, 0.9049744245524297)\n",
      "4 0.5157052469968687 0.8665217391304347\n",
      "\n",
      "0 (0.711853102923568, 0.7893606138107417)\n",
      "0 0.790681204687983 0.7808695652173913\n",
      "1 (0.4851881107095232, 0.855383631713555)\n",
      "1 0.5956620033033576 0.8304347826086956\n",
      "2 (0.39150404038885606, 0.8829923273657289)\n",
      "2 0.5293166276211965 0.8560869565217392\n",
      "3 (0.340746343423717, 0.8976982097186701)\n",
      "3 0.5013379397312868 0.861304347826087\n",
      "4 (0.29370750442773225, 0.9113171355498721)\n",
      "4 0.4797574993904627 0.8697826086956522\n",
      "\n",
      "0 (0.6290523053470604, 0.8138746803069054)\n",
      "0 0.7177628757454657 0.7856521739130434\n",
      "1 (0.4248840804537298, 0.8714194373401535)\n",
      "1 0.5539468617362889 0.8395652173913043\n",
      "2 (0.3410047207678855, 0.8957544757033248)\n",
      "2 0.49126344068850425 0.8691304347826087\n",
      "3 (0.2996693282980098, 0.9068158567774937)\n",
      "3 0.48723354005678127 0.8680434782608696\n",
      "4 (0.2617981469251226, 0.9183631713554987)\n",
      "4 0.4565808066132051 0.8795652173913043\n",
      "\n",
      "0 (1.1462733949636454, 0.6648976982097187)\n",
      "0 1.1894576291899541 0.6656521739130434\n",
      "1 (0.6428430826240665, 0.8103708439897698)\n",
      "1 0.7206259057138636 0.8002173913043479\n",
      "2 (0.4873650161860241, 0.8542071611253197)\n",
      "2 0.5903310717552835 0.8347826086956521\n",
      "3 (0.4079456217454042, 0.8782608695652174)\n",
      "3 0.5332700092774779 0.8473913043478261\n",
      "4 (0.3625067312547533, 0.89153452685422)\n",
      "4 0.5037208754622453 0.8576086956521739\n",
      "\n",
      "0 (1.317728557040313, 0.6133248081841433)\n",
      "0 1.3333516333623376 0.6158695652173913\n",
      "1 (0.7056250586188486, 0.7922506393861892)\n",
      "1 0.8004204255244346 0.7689130434782608\n",
      "2 (0.48275801462400764, 0.8591432225063939)\n",
      "2 0.6046758435331321 0.8243478260869566\n",
      "3 (0.36565605524856826, 0.891687979539642)\n",
      "3 0.5128138960936333 0.856304347826087\n",
      "4 (0.3009267341933239, 0.9100639386189259)\n",
      "4 0.46904492548031157 0.8680434782608696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [25,50,100,150,500,1000]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit_nadam(bs,5,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize_nadam_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7f493080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "831.5702362060547 317.18752241134644 153.61977672576904 114.01582717895508 58.60391163825989 46.251932859420776\n",
      "[(0.3679501320733689, 0.892148337595908), (0.31221141281311726, 0.9049744245524297), (0.29370750442773225, 0.9113171355498721), (0.2617981469251226, 0.9183631713554987), (0.3625067312547533, 0.89153452685422), (0.3009267341933239, 0.9100639386189259)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6a1d5874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.6880738307364977, 0.7963682864450128)\n",
      "0 0.7807755448710127 0.7726086956521739\n",
      "1 (0.4550611816852702, 0.8632480818414322)\n",
      "1 0.5623097747552629 0.842391304347826\n",
      "2 (0.37974944747121436, 0.885460358056266)\n",
      "2 0.5178129075383251 0.8552173913043478\n",
      "3 (0.32253925087949314, 0.9018542199488491)\n",
      "3 0.4857069873735875 0.8706521739130435\n",
      "4 (0.2798681175824529, 0.9140153452685422)\n",
      "4 0.4675991780483964 0.8756521739130435\n",
      "\n",
      "0 (0.7521528555075488, 0.775230179028133)\n",
      "0 0.81151742605401 0.7578260869565218\n",
      "1 (0.47993742759720254, 0.8563299232736573)\n",
      "1 0.5913465350179248 0.827391304347826\n",
      "2 (0.38201257947375516, 0.884846547314578)\n",
      "2 0.5232218399491894 0.8523913043478261\n",
      "3 (0.32843477242576763, 0.8991048593350384)\n",
      "3 0.498101778766168 0.8610869565217392\n",
      "4 (0.30857383893458384, 0.9043606138107417)\n",
      "4 0.49742692851152065 0.8665217391304347\n",
      "\n",
      "0 (0.9239545005695035, 0.7310102301790281)\n",
      "0 0.9715276851047397 0.7160869565217391\n",
      "1 (0.5816203721478038, 0.8287979539641944)\n",
      "1 0.6548835890510927 0.8147826086956522\n",
      "2 (0.4567428295774081, 0.8641176470588235)\n",
      "2 0.5596237619785527 0.8419565217391304\n",
      "3 (0.3793016455110772, 0.8873401534526855)\n",
      "3 0.5073581060936463 0.8539130434782609\n",
      "4 (0.33202962664895475, 0.9006649616368286)\n",
      "4 0.4814604369403587 0.8626086956521739\n",
      "\n",
      "0 (1.0247652165597907, 0.6990920716112532)\n",
      "0 1.056383808099204 0.6947826086956522\n",
      "1 (0.6015957319001438, 0.8224552429667519)\n",
      "1 0.678230160737788 0.8047826086956522\n",
      "2 (0.45046196497973084, 0.8663427109974424)\n",
      "2 0.5490833685409625 0.8408695652173913\n",
      "3 (0.38287973658881036, 0.8861636828644501)\n",
      "3 0.5090346051277008 0.8556521739130435\n",
      "4 (0.34203560565640634, 0.8976598465473146)\n",
      "4 0.4877858674959996 0.8639130434782609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [150,250,350,450]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],0,1024,0)\n",
    "    losses=a.fit_nadam(bs,5,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize1_nadam_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4a8baf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.80381321907043 82.82387447357178 69.68789410591125 62.331907987594604\n",
      "[(0.2798681175824529, 0.9140153452685422), (0.30857383893458384, 0.9043606138107417), (0.33202962664895475, 0.9006649616368286), (0.34203560565640634, 0.8976598465473146)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a5e999a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3.1995453370312728, 0.0808312020460358)\n",
      "0 3.2003986326407783 0.08130434782608696\n",
      "1 (0.6551497569898646, 0.8119437340153453)\n",
      "1 0.729566011555629 0.7828260869565218\n",
      "2 (0.3209350958665301, 0.9082992327365729)\n",
      "2 0.437756457651325 0.8760869565217392\n",
      "3 (0.22529331576192432, 0.9344245524296675)\n",
      "3 0.3793844489153522 0.8906521739130435\n",
      "4 (0.16727651801811175, 0.9506777493606138)\n",
      "4 0.3553137644270358 0.9043478260869565\n",
      "\n",
      "0 (2.764803585455344, 0.14370843989769821)\n",
      "0 2.7830712396582795 0.1443478260869565\n",
      "1 (2.0947908656373198, 0.30792838874680306)\n",
      "1 2.133736730034326 0.29934782608695654\n",
      "2 (1.788534971995919, 0.3676854219948849)\n",
      "2 1.8576742202616527 0.36478260869565216\n",
      "3 (1.6904190301000206, 0.4171739130434783)\n",
      "3 1.7914080254847522 0.4091304347826087\n",
      "4 (1.440089689331602, 0.5040664961636828)\n",
      "4 1.549331718749769 0.4880434782608696\n",
      "\n",
      "0 (0.6297117649805463, 0.8162787723785166)\n",
      "0 0.7104941914194769 0.7967391304347826\n",
      "1 (0.4325573354102026, 0.870537084398977)\n",
      "1 0.5575884836629657 0.8410869565217391\n",
      "2 (0.3481599262845717, 0.8959718670076726)\n",
      "2 0.505881856579609 0.8604347826086957\n",
      "3 (0.31014323168801694, 0.9056777493606138)\n",
      "3 0.49817949190614647 0.8628260869565217\n",
      "4 (0.2654249439706307, 0.9178644501278772)\n",
      "4 0.4780257356263245 0.8754347826086957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out activation function\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for af in [('sigmoid',0),('tanh',1),('relu',2)]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],af[1],1024,0)\n",
    "    losses=a.fit_nadam(100,5,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=af[0])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_af_nadam_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "59098806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162.3677535057068 170.95573925971985 153.0557713508606\n",
      "[(0.16727651801811175, 0.9506777493606138), (1.440089689331602, 0.5040664961636828), (0.2654249439706307, 0.9178644501278772)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "02da18b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.5331808537031673, 0.8616624040920716)\n",
      "0 0.5984999810587708 0.8397826086956521\n",
      "1 (0.36261273904030683, 0.906381074168798)\n",
      "1 0.45505332666411336 0.8782608695652174\n",
      "2 (0.2783394319507596, 0.928222506393862)\n",
      "2 0.39182205947858023 0.8928260869565218\n",
      "3 (0.22522867615714792, 0.9412787723785166)\n",
      "3 0.355854048175032 0.9023913043478261\n",
      "4 (0.18341753597990765, 0.95269820971867)\n",
      "4 0.33114159818421535 0.9065217391304348\n",
      "\n",
      "0 (0.6420216536370802, 0.8217263427109974)\n",
      "0 0.7089424534417788 0.8078260869565217\n",
      "1 (0.4720105373194459, 0.8674680306905371)\n",
      "1 0.5666338937392855 0.8406521739130435\n",
      "2 (0.39784698946823066, 0.8852685421994885)\n",
      "2 0.515212955638595 0.8580434782608696\n",
      "3 (0.34940844351089, 0.8983759590792839)\n",
      "3 0.48814803600218404 0.8621739130434782\n",
      "4 (0.31160340495710326, 0.9070716112531969)\n",
      "4 0.4764475861279314 0.8665217391304347\n",
      "\n",
      "0 (0.6411647604551968, 0.8161892583120205)\n",
      "0 0.7010549372341397 0.7978260869565217\n",
      "1 (0.48400154153247704, 0.8597442455242966)\n",
      "1 0.5652862752826046 0.8391304347826087\n",
      "2 (0.4179696191889716, 0.8780690537084399)\n",
      "2 0.5175318321634487 0.8526086956521739\n",
      "3 (0.37991447303690046, 0.8864833759590793)\n",
      "3 0.497413433753828 0.8615217391304347\n",
      "4 (0.3512773926545463, 0.8941432225063939)\n",
      "4 0.4907285791930672 0.8632608695652174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out activation function\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for af in [('sigmoid',0),('tanh',1),('relu',2)]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],af[1],1024,0)\n",
    "    losses=a.fit_nadam(100,5,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=af[0])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_af_nadam_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ad1601cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.01590251922607 65.60790205001831 61.04390549659729\n",
      "[(0.18341753597990765, 0.95269820971867), (0.31160340495710326, 0.9070716112531969), (0.3512773926545463, 0.8941432225063939)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "40a774a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2.910621833890904, 0.4863682864450128)\n",
      "0 2.9065009786404308 0.48891304347826087\n",
      "1 (2.560633131089382, 0.5343478260869565)\n",
      "1 2.556064598301219 0.5323913043478261\n",
      "2 (2.323152035294736, 0.5617263427109974)\n",
      "2 2.3184520092698144 0.5595652173913044\n",
      "3 (2.1433902187765996, 0.5811892583120205)\n",
      "3 2.138596345076375 0.5791304347826087\n",
      "4 (2.0004258047363113, 0.5971227621483376)\n",
      "4 1.9955504210437973 0.5908695652173913\n",
      "5 (1.8834279668414045, 0.610843989769821)\n",
      "5 1.8785160704405257 0.6041304347826087\n",
      "6 (1.785842949524149, 0.6231457800511508)\n",
      "6 1.7809712644872684 0.6191304347826087\n",
      "\n",
      "0 (1.2233366738647455, 0.6992966751918158)\n",
      "0 1.2219482955419263 0.7019565217391305\n",
      "1 (1.0509071959777607, 0.7343989769820972)\n",
      "1 1.0583001385010231 0.7306521739130435\n",
      "2 (0.9541377988035941, 0.7570971867007673)\n",
      "2 0.9683678022785556 0.753695652173913\n",
      "3 (0.8821827210683142, 0.7745780051150896)\n",
      "3 0.9020513534116849 0.7704347826086957\n",
      "4 (0.8225842405257703, 0.7900127877237851)\n",
      "4 0.8473885503152908 0.7828260869565218\n",
      "5 (0.7706344904000035, 0.8035933503836317)\n",
      "5 0.7999941961294068 0.7947826086956522\n",
      "6 (0.7241347944649428, 0.8156777493606138)\n",
      "6 0.7578915589825411 0.8043478260869565\n",
      "\n",
      "0 (0.5908512202496546, 0.8443350383631714)\n",
      "0 0.6546541295516525 0.827391304347826\n",
      "1 (0.40756803200232333, 0.8952429667519182)\n",
      "1 0.5097860097492998 0.8608695652173913\n",
      "2 (0.3147712600145814, 0.9196803069053708)\n",
      "2 0.43962757904065003 0.8756521739130435\n",
      "3 (0.2576301960523264, 0.9353196930946291)\n",
      "3 0.40204823643256127 0.885\n",
      "4 (0.21770463450615232, 0.945383631713555)\n",
      "4 0.37849494616117046 0.8945652173913043\n",
      "5 (0.18784347183118028, 0.9524168797953965)\n",
      "5 0.3641223024762558 0.8976086956521739\n",
      "6 (0.16461909740537867, 0.9580818414322251)\n",
      "6 0.35433844719036983 0.9008695652173913\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-9a4801ec2207>:16: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2.2809855707250626, 0.3490153452685422)\n",
      "0 2.26750979643925 0.35934782608695653\n",
      "1 (1.9617073544757304, 0.43833759590792837)\n",
      "1 1.9259703368886252 0.44804347826086954\n",
      "2 (1.7998219477239783, 0.4922762148337596)\n",
      "2 1.7990923572707083 0.4960869565217391\n",
      "3 (1.6863004502372647, 0.5226086956521739)\n",
      "3 1.6997718650331357 0.5232608695652174\n",
      "4 (1.5540861145730251, 0.5560358056265985)\n",
      "4 1.5673630425216432 0.5506521739130434\n",
      "5 (1.5365977868853757, 0.5696547314578005)\n",
      "5 1.5433693261893684 0.5693478260869566\n",
      "6 (1.5181055644172043, 0.5697953964194373)\n",
      "6 1.5517651105593664 0.5619565217391305\n",
      "\n",
      "0 (6.026386546208456, 0.05592071611253197)\n",
      "0 6.034201359852479 0.05478260869565217\n",
      "1 (6.679176725432725, 0.07157289002557544)\n",
      "1 6.674116419856551 0.07152173913043479\n",
      "2 (6.209291505050971, 0.06506393861892583)\n",
      "2 6.239348390494304 0.065\n",
      "3 (5.58685334820596, 0.09759590792838875)\n",
      "3 5.613581567823005 0.09717391304347826\n",
      "4 (7.068567188814136, 0.06648337595907929)\n",
      "4 7.083686280309709 0.0667391304347826\n",
      "5 (7.20015040079093, 0.08838874680306906)\n",
      "5 7.219220202676431 0.08673913043478261\n",
      "6 (9.759133639699403, 0.11452685421994885)\n",
      "6 9.7882754397124 0.11565217391304349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [1e-4,1e-3,1e-2,.1,1]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],0,1024,0)\n",
    "    losses=a.fit_nadam(150,7,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr_nadam_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "70539e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.65189480781555 68.86260151863098 67.46389770507812 67.31189799308777 89.71586561203003\n",
      "[(1.785842949524149, 0.6231457800511508), (0.7241347944649428, 0.8156777493606138), (0.16461909740537867, 0.9580818414322251), (1.5181055644172043, 0.5697953964194373), (9.759133639699403, 0.11452685421994885)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5cdc4920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.5428061093471547, 0.8631841432225064)\n",
      "0 0.5962847134882752 0.846304347826087\n",
      "1 (0.3688840347818986, 0.9103964194373402)\n",
      "1 0.447602921889797 0.8832608695652174\n",
      "2 (0.2822017378717448, 0.9330690537084398)\n",
      "2 0.3789329575916901 0.8995652173913044\n",
      "3 (0.22685744378144918, 0.9482352941176471)\n",
      "3 0.337513236805319 0.9095652173913044\n",
      "4 (0.18739368327714795, 0.9583759590792839)\n",
      "4 0.3109362573125843 0.9158695652173913\n",
      "5 (0.15742621431048937, 0.9658567774936061)\n",
      "5 0.2933095176877753 0.9217391304347826\n",
      "6 (0.13385196654145953, 0.9722634271099744)\n",
      "6 0.2814349030064443 0.9247826086956522\n",
      "\n",
      "0 (0.5168838735337161, 0.8679283887468031)\n",
      "0 0.5691069625410332 0.8482608695652174\n",
      "1 (0.346785408617731, 0.9141048593350384)\n",
      "1 0.42991492632690237 0.8856521739130435\n",
      "2 (0.260064883913055, 0.9376470588235294)\n",
      "2 0.36450812436896085 0.9056521739130434\n",
      "3 (0.20629079919758395, 0.9521355498721228)\n",
      "3 0.32783751616626544 0.912608695652174\n",
      "4 (0.1686576169579983, 0.9619437340153453)\n",
      "4 0.30559083683726435 0.9152173913043479\n",
      "5 (0.14004078547043733, 0.969539641943734)\n",
      "5 0.2911882703676924 0.92\n",
      "6 (0.11691649234015754, 0.9754475703324809)\n",
      "6 0.2810629273551268 0.9221739130434783\n",
      "\n",
      "0 (0.5272254821185166, 0.8623273657289002)\n",
      "0 0.5814037868115545 0.8434782608695652\n",
      "1 (0.362557898008219, 0.9068670076726343)\n",
      "1 0.45393985158016015 0.8758695652173913\n",
      "2 (0.2766904528846512, 0.9292199488491049)\n",
      "2 0.39491901641030247 0.8921739130434783\n",
      "3 (0.22446668928136046, 0.9428900255754475)\n",
      "3 0.3608592147216862 0.8984782608695652\n",
      "4 (0.18755068263526423, 0.9524808184143223)\n",
      "4 0.3387530544425403 0.9023913043478261\n",
      "5 (0.15931393546010636, 0.9601150895140665)\n",
      "5 0.3247376043159297 0.9073913043478261\n",
      "6 (0.13579712725915197, 0.9669693094629156)\n",
      "6 0.3142309909269223 0.9102173913043479\n",
      "\n",
      "0 (0.8646428331494073, 0.7611253196930946)\n",
      "0 0.9098800159034813 0.75\n",
      "1 (0.6930044843630135, 0.806150895140665)\n",
      "1 0.7692952288234989 0.7854347826086957\n",
      "2 (0.5968187111772053, 0.8314066496163682)\n",
      "2 0.7018501878329296 0.8019565217391305\n",
      "3 (0.5370608532666266, 0.8464961636828644)\n",
      "3 0.6673268955562881 0.8102173913043478\n",
      "4 (0.4959726511280508, 0.8573401534526854)\n",
      "4 0.6465503034387137 0.8145652173913044\n",
      "5 (0.4675200476747526, 0.8647442455242966)\n",
      "5 0.6336209378379293 0.8184782608695652\n",
      "6 (0.4352874061637624, 0.8740920716112532)\n",
      "6 0.6165902088425598 0.8258695652173913\n",
      "\n",
      "0 (1.5721225223967958, 0.561304347826087)\n",
      "0 1.587338051316663 0.5615217391304348\n",
      "1 (1.3452254754443773, 0.6237468030690537)\n",
      "1 1.385264265309468 0.6130434782608696\n",
      "2 (1.2388815887549105, 0.6496547314578005)\n",
      "2 1.3087778193436999 0.6330434782608696\n",
      "3 (1.1499528451013685, 0.676381074168798)\n",
      "3 1.2466625190240666 0.6528260869565218\n",
      "4 (1.0784292878984876, 0.6932736572890026)\n",
      "4 1.190217292004181 0.6715217391304348\n",
      "5 (1.0307456230330765, 0.7064450127877238)\n",
      "5 1.1560974485132545 0.678695652173913\n",
      "6 (0.9884072537579212, 0.7160869565217391)\n",
      "6 1.102983387251536 0.6904347826086956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [6e-3,8e-3,1e-2,2e-2,4e-2]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],0,1024,0)\n",
    "    losses=a.fit_nadam(150,7,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr1_nadam_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "83222712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.90389585494995 67.77189493179321 68.2919111251831 67.90705609321594 68.02790021896362\n",
      "[(0.13385196654145953, 0.9722634271099744), (0.11691649234015754, 0.9754475703324809), (0.13579712725915197, 0.9669693094629156), (0.4352874061637624, 0.8740920716112532), (0.9884072537579212, 0.7160869565217391)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0a9c68e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3.8217695915335193, 0.022621483375959078)\n",
      "0 3.821674659042616 0.019782608695652175\n",
      "1 (3.7981380083822023, 0.09667519181585678)\n",
      "1 3.797737535884224 0.10173913043478261\n",
      "2 (3.7468978835003455, 0.09969309462915601)\n",
      "2 3.7460849162814527 0.09891304347826087\n",
      "3 (3.669857746204064, 0.10548593350383632)\n",
      "3 3.6689977014102895 0.10521739130434783\n",
      "4 (3.583145279001694, 0.11428388746803068)\n",
      "4 3.5823853598691326 0.11130434782608696\n",
      "5 (3.4964593195265676, 0.12240409207161125)\n",
      "5 3.495683628323738 0.12130434782608696\n",
      "6 (3.4133977058600617, 0.13465473145780052)\n",
      "6 3.4126074492319165 0.13217391304347825\n",
      "\n",
      "0 (2.538583705508458, 0.3726086956521739)\n",
      "0 2.5434757451420036 0.37521739130434784\n",
      "1 (1.9320158792872835, 0.5204475703324808)\n",
      "1 1.9397055699368806 0.5265217391304348\n",
      "2 (1.5584941249162012, 0.609616368286445)\n",
      "2 1.5712292138002917 0.6058695652173913\n",
      "3 (1.2883559443447683, 0.6759718670076726)\n",
      "3 1.3083282785610604 0.6739130434782609\n",
      "4 (1.088044908217584, 0.7263171355498721)\n",
      "4 1.1167476928211566 0.7167391304347827\n",
      "5 (0.9366672771965593, 0.764079283887468)\n",
      "5 0.9754266049653152 0.7497826086956522\n",
      "6 (0.8190885454857658, 0.7926854219948849)\n",
      "6 0.8689213095959236 0.7773913043478261\n",
      "\n",
      "0 (3.829105898530781, 0.021739130434782608)\n",
      "0 3.829105951672632 0.021739130434782608\n",
      "1 (3.8289271777336253, 0.021739130434782608)\n",
      "1 3.8289280319030103 0.021739130434782608\n",
      "2 (2.3818231343994674, 0.2620332480818414)\n",
      "2 2.389663785860688 0.2530434782608696\n",
      "3 (0.6018054355776696, 0.8300383631713555)\n",
      "3 0.7071449620948006 0.8015217391304348\n",
      "4 (0.2971732999494803, 0.9158823529411765)\n",
      "4 0.4408608947212776 0.8758695652173913\n",
      "5 (0.20015942515672663, 0.9431074168797954)\n",
      "5 0.3621903097890319 0.8989130434782608\n",
      "6 (0.15093054513241877, 0.9553196930946292)\n",
      "6 0.34777010642599165 0.9047826086956522\n",
      "\n",
      "0 (3.887704954740761, 0.021739130434782608)\n",
      "0 3.8877049547407565 0.021739130434782608\n",
      "1 (3.88316474320597, 0.021739130434782608)\n",
      "1 3.883164743205972 0.021739130434782608\n",
      "2 (3.880613646552237, 0.021739130434782608)\n",
      "2 3.8806136465522374 0.021739130434782608\n",
      "3 (3.8792091410280527, 0.021739130434782608)\n",
      "3 3.8792091410280527 0.021739130434782608\n",
      "4 (3.8784284449811905, 0.021739130434782608)\n",
      "4 3.878428444981187 0.021739130434782608\n",
      "5 (3.8779887465578047, 0.021739130434782608)\n",
      "5 3.8779887465578065 0.021739130434782608\n",
      "6 (3.877738745792845, 0.021739130434782608)\n",
      "6 3.877738745792845 0.021739130434782608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-9a4801ec2207>:16: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (4.003378877033226, 0.021739130434782608)\n",
      "0 4.003378877033242 0.021739130434782608\n",
      "1 (4.085362790403102, 0.021739130434782608)\n",
      "1 4.085362790403096 0.021739130434782608\n",
      "2 (4.1783507508437285, 0.021739130434782608)\n",
      "2 4.178350750843751 0.021739130434782608\n",
      "3 (4.267477401073073, 0.021739130434782608)\n",
      "3 4.267477401073087 0.021739130434782608\n",
      "4 (4.313806717375414, 0.021739130434782608)\n",
      "4 4.31380671737543 0.021739130434782608\n",
      "5 (4.336123596305221, 0.021739130434782608)\n",
      "5 4.336123596305206 0.021739130434782608\n",
      "6 (4.343491470053158, 0.021739130434782608)\n",
      "6 4.34349147005318 0.021739130434782608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [1e-4,1e-3,1e-2,.1,1]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],0,1024,0)\n",
    "    losses=a.fit_nadam(150,7,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr_nadam_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "70343071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183.64297485351562 171.17574286460876 170.80774092674255 171.29174089431763 231.79192781448364\n",
      "[(3.4133977058600617, 0.13465473145780052), (0.8190885454857658, 0.7926854219948849), (0.15093054513241877, 0.9553196930946292), (3.877738745792845, 0.021739130434782608), (4.343491470053158, 0.021739130434782608)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5140006a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2.589252913294305, 0.24773657289002557)\n",
      "0 2.5898611081685714 0.24304347826086956\n",
      "1 (0.7466549547180386, 0.7964961636828645)\n",
      "1 0.8318013407038205 0.7726086956521739\n",
      "2 (0.3955211269323563, 0.8936828644501279)\n",
      "2 0.5333045862088469 0.8552173913043478\n",
      "3 (0.2536035062624571, 0.9318797953964194)\n",
      "3 0.41916913070070744 0.8817391304347826\n",
      "4 (0.18596709472794637, 0.9491432225063938)\n",
      "4 0.37993194288890275 0.8939130434782608\n",
      "5 (0.15211507481730804, 0.9567263427109974)\n",
      "5 0.3830339778403969 0.8965217391304348\n",
      "6 (0.12948506197250045, 0.9619693094629156)\n",
      "6 0.39556215733289707 0.8945652173913043\n",
      "\n",
      "0 (2.0376107983915692, 0.4169309462915601)\n",
      "0 2.0599640668181594 0.4132608695652174\n",
      "1 (0.5116943593409996, 0.856611253196931)\n",
      "1 0.6091786640351763 0.832391304347826\n",
      "2 (0.27777478436476166, 0.9239769820971867)\n",
      "2 0.4144707843487754 0.8884782608695653\n",
      "3 (0.17833361170785744, 0.9512148337595908)\n",
      "3 0.34567634478459597 0.9082608695652173\n",
      "4 (0.13201284029119276, 0.962851662404092)\n",
      "4 0.3274318493131972 0.9095652173913044\n",
      "5 (0.1009693055764347, 0.9715601023017902)\n",
      "5 0.3304047836637423 0.9143478260869565\n",
      "6 (0.08657385755024487, 0.9745524296675192)\n",
      "6 0.3294955516703676 0.9139130434782609\n",
      "\n",
      "0 (3.4853210655755698, 0.05219948849104859)\n",
      "0 3.4815359711107283 0.05\n",
      "1 (0.9324415973142908, 0.7368286445012787)\n",
      "1 1.0005510507699045 0.715\n",
      "2 (0.3884342075534247, 0.8926342710997442)\n",
      "2 0.5129376095235989 0.8495652173913043\n",
      "3 (0.23830513268331605, 0.9322506393861892)\n",
      "3 0.4029440621602217 0.8845652173913043\n",
      "4 (0.16213378325894057, 0.9537084398976982)\n",
      "4 0.3544224324746062 0.8971739130434783\n",
      "5 (0.1364333194249365, 0.9598976982097187)\n",
      "5 0.3552625779503064 0.9032608695652173\n",
      "6 (0.104520176233498, 0.968312020460358)\n",
      "6 0.3443878602024966 0.9121739130434783\n",
      "\n",
      "0 (3.8297433764866233, 0.021739130434782608)\n",
      "0 3.829743375500801 0.021739130434782608\n",
      "1 (3.8294612321496513, 0.021739130434782608)\n",
      "1 3.82946123107845 0.021739130434782608\n",
      "2 (3.8293579709931227, 0.021739130434782608)\n",
      "2 3.8293579698148736 0.021739130434782608\n",
      "3 (3.8293090990880128, 0.021739130434782608)\n",
      "3 3.8293090977985216 0.021739130434782608\n",
      "4 (3.829283386094743, 0.021739130434782608)\n",
      "4 3.829283384723854 0.021739130434782608\n",
      "5 (3.8292691240171663, 0.021739130434782608)\n",
      "5 3.8292691226389337 0.021739130434782608\n",
      "6 (3.8292609836825977, 0.021739130434782608)\n",
      "6 3.829260982390008 0.021739130434782608\n",
      "\n",
      "0 (3.8336493609165063, 0.021739130434782608)\n",
      "0 3.8336493609162448 0.021739130434782608\n",
      "1 (3.832443086154221, 0.021739130434782608)\n",
      "1 3.832443086153759 0.021739130434782608\n",
      "2 (3.832032558618966, 0.021739130434782608)\n",
      "2 3.83203255861295 0.021739130434782608\n",
      "3 (3.831856005532055, 0.021739130434782608)\n",
      "3 3.831856005511593 0.021739130434782608\n",
      "4 (3.831743392699424, 0.021739130434782608)\n",
      "4 3.831743392216763 0.021739130434782608\n",
      "5 (3.8300924755993564, 0.021739130434782608)\n",
      "5 3.830092475599356 0.021739130434782608\n",
      "6 (3.8300816047922277, 0.021739130434782608)\n",
      "6 3.830081604792231 0.021739130434782608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [6e-3,8e-3,1e-2,2e-2,4e-2]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],0,1024,0)\n",
    "    losses=a.fit_nadam(150,7,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr1_nadam_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2baa1b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175.36503219604492 174.34424448013306 173.9557363986969 176.57364225387573 173.73250102996826\n",
      "[(0.12948506197250045, 0.9619693094629156), (0.08657385755024487, 0.9745524296675192), (0.104520176233498, 0.968312020460358), (3.8292609836825977, 0.021739130434782608), (3.8300816047922277, 0.021739130434782608)]\n"
     ]
    }
   ],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eedccea",
   "metadata": {},
   "source": [
    "# ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc864326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [25,50,100,150,500,1000]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit_adam(bs,6,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize_adam_arc1.png')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a2e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6e4aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [750,1000,1200,1500,2000,3000]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit_adam(bs,6,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize_adam1_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4107bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f419c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [25,50,100,150,500,1000]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit_adam(bs,6,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize_adam_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dda5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [750,1000,1200,1500,2000,3000]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit_adam(bs,6,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize_adam1_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a1dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a49eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out activation function\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for af in [('sigmoid',0),('tanh',1),('relu',2)]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],af[1],1024,0)\n",
    "    losses=a.fit_adam(500,10,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=af[0])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_af_adam_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe0cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out activation function\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for af in [0,1,2]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],af,1024,0)\n",
    "    losses=a.fit_adam(500,5,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(af))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_af_adam_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a591544d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d333aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [1e-4,1e-3,1e-2,.1,1]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit_adam(1000,10,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr_adam_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfefa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [1e-4,1e-3,1e-2,.1]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit_adam(750,10,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr_adam_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116df14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [8e-3,1e-2,2e-2,4e-2]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit_adam(1000,10,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr1_adam_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [8e-3,1e-2,2e-2,4e-2]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit_adam(750,10,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr1_adam_arc2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b407bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee79b395",
   "metadata": {},
   "source": [
    "# RMSPROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2e17ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [10,25,50,100,150,500,1000]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit_rmsprop(bs,6,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize_rmsprop_arc1.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caeb7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [150,250,400,500,600,750,850]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],2,1024,0)\n",
    "    losses=a.fit_rmsprop(bs,6,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize_rmsprop1_arc1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1fae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [10,25,50,100,150,500,1000]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit_rmsprop(bs,6,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize_rmsprop_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d20317",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da6fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out batch size\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for bs in [150,250,400,500,600,750,850]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],2,1024,0)\n",
    "    losses=a.fit_rmsprop(bs,6,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(bs))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_batchsize_rmsprop1_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd7ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b28d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out activation function\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for af in [('sigmoid',0),('tanh',1),('relu',2)]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],af[1],1024,0)\n",
    "    losses=a.fit_rmsprop(500,5,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=af[0])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_af_rmsprop_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d753c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out activation function\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for af in [0,1,2]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],af,1024,0)\n",
    "    losses=a.fit_rmsprop(500,5,X,y,.01)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(af))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_af_rmsprop_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce1a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [1e-4,1e-3,1e-2,.1,1]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],0,1024,0)\n",
    "    losses=a.fit_rmsprop(500,10,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr_rmsprop_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7039d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f125fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [1e-4,1e-3,1e-2,.1,1]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],0,1024,0)\n",
    "    losses=a.fit_rmsprop(500,10,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr_rmsprop_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3706ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca5716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [8e-3,1e-2,2e-2,4e-2]:\n",
    "    t=time()\n",
    "    a=ANN([256,46],0,1024,0)\n",
    "    losses=a.fit_rmsprop(500,10,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr1_rmsprop_arc1.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92474f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77497043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out lr\n",
    "plt.clf()\n",
    "best_metrics=[]\n",
    "times=[]\n",
    "for lr in [8e-3,1e-2,2e-2,4e-2]:\n",
    "    t=time()\n",
    "    a=ANN([512,256,128,64,46],0,1024,0)\n",
    "    losses=a.fit_rmsprop(500,10,X,y,lr)\n",
    "    plt.plot(range(1,len(losses)+1),[a[0] for a in losses],label=str(lr))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    best_metrics.append(losses[-1])\n",
    "    times.append(time()-t)\n",
    "    print()\n",
    "plt.legend()\n",
    "plt.savefig('best_lr1_rmsprop_arc2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1dcbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*times)\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d7cc8",
   "metadata": {},
   "source": [
    "# Final Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ce915045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    hidden_units=daf=af=l=W=Z=0\n",
    "    \n",
    "    def __init__(self,hidden_units,af,num_features,loss):\n",
    "        \n",
    "        self.hidden_units=hidden_units\n",
    "        self.l=loss\n",
    "        if(af==0):\n",
    "            self.af=sigmoid\n",
    "            self.daf=dsig\n",
    "        elif(af==1):\n",
    "            self.af=tanh\n",
    "            self.daf=dtanh\n",
    "        else:\n",
    "            self.af=relu\n",
    "            self.daf=drelu\n",
    "        if(loss==0):\n",
    "            self.loss=CE_loss\n",
    "        else:\n",
    "            self.loss=mse \n",
    "        self.W=[]\n",
    "        self.b=[]\n",
    "        \n",
    "        \n",
    "        temp=np.float32(np.random.normal(0,1,(num_features+1,hidden_units[0])))*(np.sqrt(2/(num_features+1+hidden_units[0])))\n",
    "        self.W.append(temp[1:,:])\n",
    "        self.b.append(temp[0])\n",
    "        for i in range(1,len(hidden_units)):\n",
    "            temp=np.float32(np.random.normal(0,1,(hidden_units[i-1]+1,hidden_units[i])))*(np.sqrt(2/(hidden_units[i-1]+1+hidden_units[i])))\n",
    "            self.W.append(temp[1:,:])\n",
    "            self.b.append(temp[0])\n",
    "        self.final_W=self.W\n",
    "        self.final_b=self.b\n",
    "        self.Z=[]    \n",
    "    def fp(self,X):\n",
    "        self.Z=[]\n",
    "        \n",
    "        self.Z.append(X)\n",
    "        \n",
    "#         for i in range(len(self.W)):\n",
    "#             self.Z.append(self.af(np.matmul(self.Z[i],self.W[i])+self.b[i]))\n",
    "            \n",
    "#         if(self.l==0):\n",
    "#             return softmax(self.Z[-1]) \n",
    "        for i in range(len(self.W)-1):\n",
    "            self.Z.append(self.af(np.matmul(self.Z[i],self.W[i])+self.b[i]))\n",
    "            \n",
    "        if(self.l==0):\n",
    "            #print(self.Z[-1].shape,self.W[-1].shape,self.b[-1].shape)\n",
    "            self.Z.append(np.matmul(self.Z[-1],self.W[-1])+self.b[-1])\n",
    "            return softmax(self.Z[-1])\n",
    "            \n",
    "        else:\n",
    "            self.Z.append(self.af(np.matmul(self.Z[-1],self.W[-1])+self.b[-1]))\n",
    "        return self.Z[-1]\n",
    "    def bp(self,X,y,lr):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #print(dw[0])\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            \n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            self.W[i]-=dw*lr\n",
    "            self.b[i]-=db*lr\n",
    "#     def bp(self,X,y,lr):\n",
    "#         yh=self.fp(X)\n",
    "#         g=yh-y\n",
    "#         #print(g)\n",
    "#         dummy=np.ones(yh.shape[0])\n",
    "#         for i in reversed(range(len(self.W))):\n",
    "#             deriv_af=self.daf(self.Z[i+1])\n",
    "#             g=np.multiply(deriv_af,g)\n",
    "#             dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "#             #print(dw[0])\n",
    "#             #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "#             db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            \n",
    "#             g=np.dot(g,self.W[i].T)\n",
    "#             self.W[i]-=dw*lr\n",
    "#             self.b[i]-=db*lr\n",
    "    def bp_mom(self,X,y,lr,wt,bt,gamma=.9):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        \n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            change=gamma*wt[i]+dw*lr\n",
    "            self.W[i]-=change\n",
    "            wt[i]=change\n",
    "            #print(wt[i])\n",
    "            change=gamma*bt[i]+db*lr\n",
    "            self.b[i]-=change\n",
    "            bt[i]=change\n",
    "            \n",
    "    \n",
    "    def bp_rmsprop(self,X,y,lr,wt,bt,gamma=.9):\n",
    "        \n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        \n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        e=1e-8\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            temp=gamma*wt[i]+0.1*(dw**2)\n",
    "            self.W[i]-=lr*dw/(np.sqrt(temp+e))\n",
    "            wt[i]=temp\n",
    "            #print(wt[i])\n",
    "            temp=gamma*bt[i]+.1*(db**2)\n",
    "            self.b[i]-=lr*db/(np.sqrt(temp+e))\n",
    "            bt[i]=temp\n",
    "    def bp_adam(self,X,y,lr,vwt,vbt,mwt,mbt,b1=.9,b2=.999):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        e=1e-8\n",
    "        b1t=1\n",
    "        b2t=1\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            vwt[i]=b2*vwt[i]+(1-b2)*(dw**2)\n",
    "            vbt[i]=b2*vbt[i]+(1-b2)*(db**2)\n",
    "            mwt[i]=b1*mwt[i]+(1-b1)*(dw)\n",
    "            mbt[i]=b1*mbt[i]+(1-b1)*(db)\n",
    "            #print(mbt[i])\n",
    "            b1t*=b1\n",
    "            b2t*=b2\n",
    "            self.W[i]-=lr*(mwt[i]/(1-b1t))/(np.sqrt(vwt[i]/(1-b2t)+e))\n",
    "            self.b[i]-=lr*(mbt[i]/(1-b1t))/(np.sqrt(vbt[i]/(1-b2t)+e))\n",
    "            \n",
    "            \n",
    "    def bp_nadam(self,X,y,lr,vwt,vbt,mwt,mbt,b1=.9,b2=.999):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        e=1e-8\n",
    "        b1t=1\n",
    "        b2t=1\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            vwt[i]=b2*vwt[i]+(1-b2)*(dw**2)\n",
    "            vbt[i]=b2*vbt[i]+(1-b2)*(db**2)\n",
    "            mwt[i]=b1*mwt[i]+(1-b1)*(dw)\n",
    "            mbt[i]=b1*mbt[i]+(1-b1)*(db)\n",
    "            #print(mbt[i])\n",
    "            b1t*=b1\n",
    "            b2t*=b2\n",
    "            self.W[i]-=lr*(b1*mwt[i]/(1-b1t)+(1-b1)*dw/(1-b1t))/(np.sqrt(vwt[i]/(1-b2t)+e))\n",
    "            self.b[i]-=lr*(b1*mbt[i]/(1-b1t)+(1-b1)*db/(1-b1t))/(np.sqrt(vbt[i]/(1-b2t)+e))\n",
    "    \n",
    "    def bp_nag(self,X,y,lr,wt,bt,gamma=.9):\n",
    "        W_temp=self.W\n",
    "        b_temp=self.b\n",
    "        for i in range(len(self.W)):\n",
    "            self.W[i]-=gamma*wt[i]\n",
    "            self.b[i]-=gamma*bt[i]\n",
    "            \n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        \n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        \n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "               \n",
    "            g=np.dot(g,self.W[i].T)\n",
    "           \n",
    "            temp=gamma*wt[i]+lr*dw\n",
    "            \n",
    "            W_temp[i]-=temp\n",
    "            wt[i]=temp\n",
    "            #print(wt[i])\n",
    "            temp=gamma*bt[i]+lr*db\n",
    "            b_temp[i]-=temp\n",
    "            bt[i]=temp\n",
    "        self.W=W_temp\n",
    "        self.b=b_temp\n",
    "    \n",
    "    def fit(self,bs,epochs,X,y,lr,t,adaptive=False):\n",
    "        t_counter=time()\n",
    "        th=time()\n",
    "        for i in range(len(self.W)):\n",
    "            \n",
    "            \n",
    "            self.W[i]=np.float64(self.W[i])\n",
    "            self.b[i]=np.float64(self.b[i])\n",
    "#         l=[]\n",
    "        lmin=float('inf')\n",
    "        t+=time()-th\n",
    "        for i in range(epochs):\n",
    "            th=time()\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                th=time()\n",
    "#                 if(j==5 and i==0):\n",
    "#                     for k in range(len(a.W)):\n",
    "#                         temp=np.concatenate((a.b[k].reshape(1,-1),a.W[k]),axis=0)\n",
    "#                         np.save('essentials/part_a_and_b/multiclass_dataset/tc_3/w_'+str(k+1)+'_iter.npy',temp)\n",
    "#                         print(np.max(np.load('essentials/part_a_and_b/multiclass_dataset/tc_3/ac_w_'+str(k+1)+'_iter.npy')-temp))\n",
    "                    \n",
    "                self.bp(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr)\n",
    "                t+=time()-th\n",
    "                th=time()\n",
    "                if(4.92*60>t>4.8*60):\n",
    "                    l=self.loss(y,self.fp(X))\n",
    "                    if(l<lmin):\n",
    "                        lmin=l\n",
    "                        self.final_W=self.W\n",
    "                        self.final_b=self.b\n",
    "#                         for k in range(len(self.final_W)):\n",
    "#                             temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                             np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                        print(str(t)+': saved:'+str(lmin))\n",
    "                        \n",
    "                t+=time()-th\n",
    "            \n",
    "            \n",
    "            th=time()    \n",
    "            l=self.loss(y,self.fp(X))\n",
    "            if(l<lmin):\n",
    "                lmin=l\n",
    "                self.final_W=self.W\n",
    "                self.final_b=self.b\n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            if(time()-t_counter>30 or t>4.4*60):\n",
    "                t_counter=time()\n",
    "#                 for k in range(len(self.final_W)):\n",
    "#                     temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                     np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                print(str(t)+': saved:'+str(lmin))\n",
    "            t+=time()-th\n",
    "           \n",
    "            if(t>300):\n",
    "                return lmin\n",
    "#             y_pred=self.fp(X_test)\n",
    "#             l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "#             print(i,l[-1])\n",
    "#             print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))\n",
    "        return lmin    \n",
    "    def fit_mom(self,bs,epochs,X,y,lr,t,adaptive=False):\n",
    "        t_counter=time()\n",
    "        th=time()\n",
    "        for i in range(len(self.W)):\n",
    "            \n",
    "            \n",
    "            self.W[i]=np.float64(self.W[i])\n",
    "            self.b[i]=np.float64(self.b[i])\n",
    "#         l=[]\n",
    "        lmin=float('inf')\n",
    "       \n",
    "        wt=[0]*len(self.W)\n",
    "        bt=[0]*len(self.W)\n",
    "        t+=time()-th\n",
    "        for i in range(epochs):\n",
    "            th=time()\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                th=time()\n",
    "                self.bp_mom(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,wt,bt)\n",
    "                t+=time()-th\n",
    "                th=time()\n",
    "                if(4.92*60>t>4.8*60):\n",
    "                    l=self.loss(y,self.fp(X))\n",
    "                    if(l<lmin):\n",
    "                        lmin=l\n",
    "                        self.final_W=self.W\n",
    "                        self.final_b=self.b\n",
    "#                         for k in range(len(self.final_W)):\n",
    "#                             temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                             np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                        print(str(t)+': saved:'+str(lmin))\n",
    "                        \n",
    "                t+=time()-th\n",
    "            th=time()    \n",
    "            l=self.loss(y,self.fp(X))\n",
    "            if(l<lmin):\n",
    "                lmin=l\n",
    "                self.final_W=self.W\n",
    "                self.final_b=self.b\n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            if(time()-t_counter>30 or t>4.4*60):\n",
    "                t_counter=time()\n",
    "#                 for k in range(len(self.final_W)):\n",
    "#                     temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                     np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                print(str(t)+': saved:'+str(lmin))\n",
    "            t+=time()-th\n",
    "            if(t>300):\n",
    "                return lmin\n",
    "#             y_pred=self.fp(X_test)\n",
    "#             l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "#             print(i,l[-1])\n",
    "#             print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))\n",
    "        return lmin\n",
    "    def fit_nag(self,bs,epochs,X,y,lr,t,adaptive=False):\n",
    "        t_counter=time()\n",
    "        th=time()\n",
    "        for i in range(len(self.W)):\n",
    "            \n",
    "            \n",
    "            self.W[i]=np.float64(self.W[i])\n",
    "            self.b[i]=np.float64(self.b[i])\n",
    "#         l=[]\n",
    "        lmin=float('inf')\n",
    "        wt=[0]*len(self.W)\n",
    "        bt=[0]*len(self.W)\n",
    "        t+=time()-th\n",
    "        for i in range(epochs):\n",
    "            th=time()\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                th=time()\n",
    "                self.bp_nag(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,wt,bt)\n",
    "                t+=time()-th\n",
    "                th=time()\n",
    "                if(4.92*60>t>4.8*60):\n",
    "                    l=self.loss(y,self.fp(X))\n",
    "                    if(l<lmin):\n",
    "                        lmin=l\n",
    "                        self.final_W=self.W\n",
    "                        self.final_b=self.b\n",
    "#                         for k in range(len(self.final_W)):\n",
    "#                             temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                             np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                        print(str(t)+': saved:'+str(lmin))\n",
    "                        \n",
    "                t+=time()-th\n",
    "            th=time()    \n",
    "            l=self.loss(y,self.fp(X))\n",
    "            if(l<lmin):\n",
    "                lmin=l\n",
    "                self.final_W=self.W\n",
    "                self.final_b=self.b\n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            if(time()-t_counter>30 or t>4.4*60):\n",
    "                t_counter=time()\n",
    "#                 for k in range(len(self.final_W)):\n",
    "#                     temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                     np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                print(str(t)+': saved:'+str(lmin))\n",
    "            t+=time()-th\n",
    "            if(t>300):\n",
    "                return lmin\n",
    "#             y_pred=self.fp(X_test)\n",
    "#             l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "#             print(i,l[-1])\n",
    "#             print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))\n",
    "        return lmin\n",
    "    def fit_adam(self,bs,epochs,X,y,lr,t,adaptive=False):\n",
    "        t_counter=time()\n",
    "        th=time()\n",
    "        for i in range(len(self.W)):\n",
    "            \n",
    "            \n",
    "            self.W[i]=np.float64(self.W[i])\n",
    "            self.b[i]=np.float64(self.b[i])\n",
    "#         l=[]\n",
    "        lmin=float('inf')\n",
    "        mwt=[0]*len(self.W)\n",
    "        mbt=[0]*len(self.W)\n",
    "        vwt=[0]*len(self.W)\n",
    "        vbt=[0]*len(self.W)\n",
    "        t+=time()-th\n",
    "        for i in range(epochs):\n",
    "            th=time()\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                th=time()\n",
    "                self.bp_adam(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,vwt,vbt,mwt,mbt)\n",
    "                t+=time()-th\n",
    "                th=time()\n",
    "                if(4.92*60>t>4.8*60):\n",
    "                    l=self.loss(y,self.fp(X))\n",
    "                    if(l<lmin):\n",
    "                        lmin=l\n",
    "                        self.final_W=self.W\n",
    "                        self.final_b=self.b\n",
    "#                         for k in range(len(self.final_W)):\n",
    "#                             temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                             np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                        print(str(t)+': saved:'+str(lmin))\n",
    "                        \n",
    "                t+=time()-th\n",
    "            th=time()    \n",
    "            l=self.loss(y,self.fp(X))\n",
    "            if(l<lmin):\n",
    "                lmin=l\n",
    "                self.final_W=self.W\n",
    "                self.final_b=self.b\n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            if(time()-t_counter>30 or t>4.4*60):\n",
    "                t_counter=time()\n",
    "#                 for k in range(len(self.final_W)):\n",
    "#                     temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                     np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                print(str(t)+': saved:'+str(lmin))\n",
    "            t+=time()-th\n",
    "            if(t>300):\n",
    "                return lmin\n",
    "#             y_pred=self.fp(X_test)\n",
    "#             l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "#             print(i,l[-1])\n",
    "#             print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))    \n",
    "        return lmin\n",
    "    def fit_nadam(self,bs,epochs,X,y,lr,t,adaptive=False):\n",
    "        t_counter=time()\n",
    "        th=time()\n",
    "        for i in range(len(self.W)):\n",
    "            \n",
    "            \n",
    "            self.W[i]=np.float64(self.W[i])\n",
    "            self.b[i]=np.float64(self.b[i])\n",
    "#         l=[]\n",
    "        lmin=float('inf')\n",
    "        \n",
    "        mwt=[0]*len(self.W)\n",
    "        mbt=[0]*len(self.W)\n",
    "        vwt=[0]*len(self.W)\n",
    "        vbt=[0]*len(self.W)\n",
    "        t+=time()-th\n",
    "        for i in range(epochs):\n",
    "            th=time()\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                th=time()\n",
    "                self.bp_nadam(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,vwt,vbt,mwt,mbt)\n",
    "                t+=time()-th\n",
    "                th=time()\n",
    "                if(4.92*60>t>4.8*60):\n",
    "                    l=self.loss(y,self.fp(X))\n",
    "                    if(l<lmin):\n",
    "                        lmin=l\n",
    "                        self.final_W=self.W\n",
    "                        self.final_b=self.b\n",
    "#                         for k in range(len(self.final_W)):\n",
    "#                             temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                             np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                        print(str(t)+': saved:'+str(lmin))\n",
    "                        \n",
    "                t+=time()-th\n",
    "            th=time()    \n",
    "            l=self.loss(y,self.fp(X))\n",
    "            if(l<lmin):\n",
    "                lmin=l\n",
    "                self.final_W=self.W\n",
    "                self.final_b=self.b\n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            if(time()-t_counter>30 or t>4.4*60):\n",
    "                t_counter=time()\n",
    "#                 for k in range(len(self.final_W)):\n",
    "#                     temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                     np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                print(str(t)+': saved:'+str(lmin))\n",
    "            t+=time()-th\n",
    "            if(t>300):\n",
    "                return lmin\n",
    "#             y_pred=self.fp(X_test)\n",
    "#             l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "#             print(i,l[-1])\n",
    "#             print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))    \n",
    "        return lmin\n",
    "    def fit_rmsprop(self,bs,epochs,X,y,lr,t,adaptive=False):\n",
    "        t_counter=time()\n",
    "        th=time()\n",
    "        for i in range(len(self.W)):\n",
    "            \n",
    "            \n",
    "            self.W[i]=np.float64(self.W[i])\n",
    "            self.b[i]=np.float64(self.b[i])\n",
    "#         l=[]\n",
    "        lmin=float('inf')\n",
    "        \n",
    "        wt=[0]*len(self.W)\n",
    "        bt=[0]*len(self.W)\n",
    "        t+=time()-th\n",
    "        for i in range(epochs):\n",
    "            th=time()\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                th=time()\n",
    "                self.bp_rmsprop(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,wt,bt)\n",
    "                t+=time()-th\n",
    "                th=time()\n",
    "                if(4.92*60>t>4.8*60):\n",
    "                    l=self.loss(y,self.fp(X))\n",
    "                    if(l<lmin):\n",
    "                        lmin=l\n",
    "                        self.final_W=self.W\n",
    "                        self.final_b=self.b\n",
    "#                         for k in range(len(self.final_W)):\n",
    "#                             temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                             np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                        print(str(t)+': saved:'+str(lmin))\n",
    "                        \n",
    "                t+=time()-th\n",
    "            th=time()    \n",
    "            l=self.loss(y,self.fp(X))\n",
    "            if(l<lmin):\n",
    "                lmin=l\n",
    "                self.final_W=self.W\n",
    "                self.final_b=self.b\n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            if(time()-t_counter>30 or t>4.4*60):\n",
    "                t_counter=time()\n",
    "#                 for k in range(len(self.final_W)):\n",
    "#                     temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                     np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                print(str(t)+': saved:'+str(lmin))\n",
    "            t+=time()-th\n",
    "            if(t>300):\n",
    "                return lmin\n",
    "#             y_pred=self.fp(X_test)\n",
    "#             l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "#             print(i,l[-1])\n",
    "#             print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))             \n",
    "        return lmin    \n",
    "    def pred(X):\n",
    "        return fp(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9589227b",
   "metadata": {},
   "source": [
    "# Architecture 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f2df63c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.32071661949158: saved:0.12797411423976807\n",
      "73.32387375831604: saved:0.07027356416544742\n",
      "103.6833426952362: saved:0.05504735456063214\n",
      "139.03887939453125: saved:0.021270111887961924\n",
      "173.8141074180603: saved:0.00017494197113149831\n",
      "204.0316677093506: saved:0.0001108212985047658\n",
      "238.1155378818512: saved:8.736161010640652e-05\n",
      "268.86664485931396: saved:7.584576209434174e-05\n",
      "274.0070159435272: saved:7.431216657007477e-05\n",
      "278.96747517585754: saved:7.286542980889305e-05\n",
      "284.28012108802795: saved:7.149089873203478e-05\n",
      "288.0011155605316: saved:7.035017011193176e-05\n",
      "289.2041132450104: saved:7.034872089993565e-05\n",
      "290.39062309265137: saved:7.034788642504598e-05\n",
      "290.9436228275299: saved:7.034136261343404e-05\n",
      "291.50262117385864: saved:7.034045641102987e-05\n",
      "292.0766203403473: saved:7.034032840463493e-05\n",
      "296.1106140613556: saved:7.01854951613793e-05\n",
      "300.4596073627472: saved:6.894863688066795e-05\n",
      "6.894863688066795e-05\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit(50,100,X,y,.4,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37089a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=ANN([256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit(50,100,X,y,.4,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7de945db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.654956340789795: saved:0.09703423464693788\n",
      "73.32191133499146: saved:0.037492628910760356\n",
      "106.49486422538757: saved:0.0021108621700548728\n",
      "140.47281193733215: saved:0.0006271814128793796\n",
      "174.98076176643372: saved:0.0004581858223084695\n",
      "205.0827362537384: saved:0.0003805464109991747\n",
      "238.90568685531616: saved:0.00032168883124949544\n",
      "265.6586434841156: saved:0.00028591043445511734\n",
      "270.14663791656494: saved:0.0002808158818167856\n",
      "274.70562863349915: saved:0.000276008136203134\n",
      "279.0646216869354: saved:0.00027125153318918944\n",
      "283.4306149482727: saved:0.0002666988367700959\n",
      "287.7686085700989: saved:0.00026236648726842547\n",
      "288.0016086101532: saved:0.00026149835883794437\n",
      "288.5986077785492: saved:0.00026149606546131525\n",
      "289.1876084804535: saved:0.00026112132162253726\n",
      "289.7596061229706: saved:0.00026110341154071735\n",
      "290.31560492515564: saved:0.00026092082131281506\n",
      "290.87560415267944: saved:0.0002609161059662264\n",
      "291.4456031322479: saved:0.00026087644700339545\n",
      "292.0086033344269: saved:0.000260868212232297\n",
      "300.04258966445923: saved:0.00025816039567198824\n",
      "0.00025816039567198824\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit(50,100,X,y,.35,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac08d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2469b4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "86bb1b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.36794924736023: saved:0.10391741052848788\n",
      "73.18089747428894: saved:0.027093435540840507\n",
      "104.1708471775055: saved:0.003019167796886527\n",
      "134.9477939605713: saved:0.0017070545284267515\n",
      "166.51874613761902: saved:0.0012439329661831499\n",
      "198.00570011138916: saved:0.000985622917816816\n",
      "229.7176501750946: saved:0.0008171650783001632\n",
      "263.4245991706848: saved:0.0006840371143262208\n",
      "267.6345911026001: saved:0.0006704490805206594\n",
      "271.8125834465027: saved:0.0006577553746658887\n",
      "276.02157735824585: saved:0.0006447589434031394\n",
      "280.2115697860718: saved:0.000632713945751054\n",
      "284.7315630912781: saved:0.0006211128894572326\n",
      "288.00055718421936: saved:0.0006129897233264396\n",
      "288.59655714035034: saved:0.0006127368365698264\n",
      "289.24255657196045: saved:0.0006124623341601627\n",
      "289.8565535545349: saved:0.000612185301356519\n",
      "290.46055340766907: saved:0.0006119165136848907\n",
      "291.04255294799805: saved:0.0006116203451544764\n",
      "291.63455176353455: saved:0.0006112726232059867\n",
      "292.30655169487: saved:0.0006108922261968546\n",
      "292.94454979896545: saved:0.000610544729939666\n",
      "293.5825481414795: saved:0.0006101832553035261\n",
      "294.16554713249207: saved:0.000609940204619597\n",
      "294.76454734802246: saved:0.0006097108220727438\n",
      "296.6265435218811: saved:0.0006097108220727438\n",
      "302.38653683662415: saved:0.0005989680131602233\n",
      "0.0005989680131602233\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(100,100,X,y,.05,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab591ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87a9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1ee4d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.88261604309082: saved:0.11905815183808706\n",
      "74.70530700683594: saved:0.06015486065135422\n",
      "106.76371121406555: saved:0.03462704952614278\n",
      "139.03086924552917: saved:0.021779691090854588\n",
      "171.53801488876343: saved:0.015705342491201424\n",
      "204.25313544273376: saved:0.004794366822594597\n",
      "237.19999861717224: saved:0.0034991839028428724\n",
      "265.95128655433655: saved:0.0027220486343607774\n",
      "269.0392801761627: saved:0.002665416017322769\n",
      "272.05951023101807: saved:0.0026055679386806367\n",
      "275.0118832588196: saved:0.0025602823329546297\n",
      "278.0318784713745: saved:0.002513729174474239\n",
      "281.1850538253784: saved:0.00247078180215711\n",
      "284.9134247303009: saved:0.002436337359032371\n",
      "288.0374176502228: saved:0.002403994532707785\n",
      "289.221657037735: saved:0.002403994532707785\n",
      "294.52594566345215: saved:0.0024010639082449664\n",
      "295.16194438934326: saved:0.0023785900389272367\n",
      "299.0139379501343: saved:0.0023713868870420467\n",
      "302.9548485279083: saved:0.0023452791722606307\n",
      "0.0023452791722606307\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_adam(1000,100,X,y,8e-3,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19838705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.082013845443726: saved:0.12332795023176055\n",
      "72.54975748062134: saved:0.02823347383653065\n",
      "103.60066413879395: saved:0.00369779949627232\n",
      "134.214679479599: saved:0.0019159525703624583\n",
      "164.7087323665619: saved:0.001449354468164846\n",
      "195.45958137512207: saved:0.0012512045293725429\n",
      "226.23848843574524: saved:0.0011450129717433337\n",
      "257.25273990631104: saved:0.0010803470852205354\n",
      "264.22115325927734: saved:0.0010693964864091291\n",
      "267.6936752796173: saved:0.0010642786470509455\n",
      "271.0616674423218: saved:0.0010593808166209223\n",
      "274.49792671203613: saved:0.001054690534860404\n",
      "277.9023344516754: saved:0.0010501962429505397\n",
      "281.35093808174133: saved:0.001045887203941671\n",
      "284.7469308376312: saved:0.0010417534314937002\n",
      "288.1671586036682: saved:0.001037785625926574\n",
      "288.2191627025604: saved:0.0010368675260882946\n",
      "299.0398027896881: saved:0.001033975116715574\n",
      "302.3440833091736: saved:0.0010303138106814182\n",
      "0.0010303138106814182\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,46],0,1024,0)\n",
    "t=10\n",
    "loss=a.fit_rmsprop(750,100,X,y,8e-3,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a166e7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3df15628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.879080057144165: saved:0.10758415115640874\n",
      "74.01815676689148: saved:0.043209396567702396\n",
      "104.23666262626648: saved:0.015381860895133615\n",
      "134.48392486572266: saved:0.007647287038125716\n",
      "167.35059690475464: saved:0.004869642868010666\n",
      "200.40246272087097: saved:0.0035740841928279393\n",
      "233.6527395248413: saved:0.0028018989195474457\n",
      "266.55492401123047: saved:0.0023040967325510006\n",
      "270.9352421760559: saved:0.0022473002704949266\n",
      "275.3676075935364: saved:0.0021923850117627937\n",
      "279.97220826148987: saved:0.0021414108977161886\n",
      "284.5765161514282: saved:0.002091324940934573\n",
      "288.00451254844666: saved:0.002066246915694852\n",
      "296.5227949619293: saved:0.0020434346269076853\n",
      "301.0587878227234: saved:0.001998465655169792\n",
      "0.001998465655169792\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_nag(150,100,X,y,2e-2,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a20f705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.67934823036194: saved:0.20795972976578908\n",
      "87.0498571395874: saved:0.09825353727164873\n",
      "117.47231888771057: saved:0.061639313179063376\n",
      "153.9161021709442: saved:0.03504091762916864\n",
      "189.98120379447937: saved:0.01931894488943356\n",
      "226.4648265838623: saved:0.01109597351872415\n",
      "263.3484139442444: saved:0.006725226908388872\n",
      "273.23713970184326: saved:0.0059975198086723415\n",
      "283.18737030029297: saved:0.0052810397817105335\n",
      "288.0083956718445: saved:0.0038609093531581894\n",
      "299.92470693588257: saved:0.0038609093531581894\n",
      "309.35941672325134: saved:0.0038609093531581894\n",
      "0.0038609093531581894\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,46],0,1024,0)\n",
    "t=10\n",
    "loss=a.fit_nadam(150,100,X,y,8e-3,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb698759",
   "metadata": {},
   "source": [
    "# Architecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "046fa1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.448058128356934: saved:0.10471136575974462\n",
      "94.45933961868286: saved:0.022718815072883352\n",
      "135.11355328559875: saved:0.020879694450728854\n",
      "175.1303837299347: saved:0.02082787937899941\n",
      "213.86919569969177: saved:0.020826687344057127\n",
      "252.7358114719391: saved:0.020826667349356832\n",
      "265.72941637039185: saved:0.02082666714759808\n",
      "278.59058237075806: saved:0.020826667102483494\n",
      "288.00738644599915: saved:0.020826667092779808\n",
      "289.49539947509766: saved:0.020826667092778448\n",
      "294.03138184547424: saved:0.020826667092778195\n",
      "299.2007246017456: saved:0.02082666709263871\n",
      "312.57374119758606: saved:0.020826667090539822\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,64,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit(50,100,X,y,.3,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba542ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=ANN([512,256,128,64,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit(50,100,X,y,.3,t,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ce91085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.10695552825928: saved:0.31392902907407383\n",
      "78.85891103744507: saved:0.1522993439375868\n",
      "112.6389753818512: saved:0.09350404349209757\n",
      "150.51981902122498: saved:0.05428237077112218\n",
      "185.24399399757385: saved:0.03978696961527502\n",
      "220.18794012069702: saved:0.01602000214263224\n",
      "253.70988988876343: saved:0.004727858148767623\n",
      "266.56182384490967: saved:0.0022736294231141332\n",
      "281.415052652359: saved:0.0007337633649778262\n",
      "288.0108013153076: saved:0.0006673938907146987\n",
      "289.8357963562012: saved:0.0006664443808572475\n",
      "292.0337920188904: saved:0.0006656827677705265\n",
      "294.255788564682: saved:0.000662630966533914\n",
      "302.86955165863037: saved:0.0006082029050242926\n",
      "0.0006082029050242926\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,64,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X,y,.01,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc21e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "154aa66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.448949337005615: saved:0.25111272978184007\n",
      "67.46989727020264: saved:0.1081185689595886\n",
      "101.12484812736511: saved:0.054789599004107944\n",
      "134.3647973537445: saved:0.054789599004107944\n",
      "167.4107472896576: saved:0.03013228660070909\n",
      "200.3586974143982: saved:0.0260242732341453\n",
      "233.5976483821869: saved:0.023744490968175623\n",
      "266.4396002292633: saved:0.023744490968175623\n",
      "274.6875858306885: saved:0.01363690760512086\n",
      "283.06759333610535: saved:0.01363690760512086\n",
      "298.36537861824036: saved:0.01363690760512086\n",
      "306.6503870487213: saved:0.01363690760512086\n",
      "0.01363690760512086\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,64,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_adam(750,100,X,y,8e-3,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6b34f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.356956958770752: saved:1.1361408806583408\n",
      "60.52393817901611: saved:0.3010104295319888\n",
      "99.9718508720398: saved:0.10162258497606037\n",
      "139.39279174804688: saved:0.07712867820591945\n",
      "169.59074592590332: saved:0.04877729865090138\n",
      "209.1266839504242: saved:0.04762702472396235\n",
      "240.40763974189758: saved:0.028826459191550927\n",
      "270.68659234046936: saved:0.028826459191550927\n",
      "281.59557461738586: saved:0.028173661834546337\n",
      "301.22854709625244: saved:0.028173661834546337\n",
      "0.028173661834546337\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,64,46],0,1024,0)\n",
    "t=10\n",
    "loss=a.fit_rmsprop(450,100,X,y,8e-3,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fada8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.64595985412598: saved:0.19448453856199543\n",
      "73.03190279006958: saved:0.08478366594675804\n",
      "110.9818480014801: saved:0.07312738459739919\n",
      "146.22979545593262: saved:0.05469768371758282\n",
      "182.2627410888672: saved:0.0377501736379212\n",
      "218.0496699810028: saved:0.036721588888194316\n",
      "254.15461587905884: saved:0.027445313030928252\n",
      "272.0875895023346: saved:0.02048549828432247\n",
      "281.2185871601105: saved:0.0184695873433179\n",
      "298.7915606498718: saved:0.0184695873433179\n",
      "307.97154664993286: saved:0.0184695873433179\n",
      "0.0184695873433179\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,64,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_nag(250,100,X,y,4e-2,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4336a6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.158923387527466: saved:0.47719411824933244\n",
      "96.81585383415222: saved:0.1970304408131215\n",
      "142.7967836856842: saved:0.12071752417255614\n",
      "188.6857144832611: saved:0.08986706060715001\n",
      "240.2697286605835: saved:0.06227296387977846\n",
      "264.38571071624756: saved:0.05178309337406109\n",
      "287.9476749897003: saved:0.05118085114559342\n",
      "288.05769324302673: saved:0.0497114881124312\n",
      "290.5626699924469: saved:0.047405501152649916\n",
      "293.1574490070343: saved:0.045785215039322875\n",
      "320.01240849494934: saved:0.045785215039322875\n",
      "0.045785215039322875\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,64,46],0,1024,0)\n",
    "t=10\n",
    "loss=a.fit_nadam(150,100,X,y,8e-3,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee24eb",
   "metadata": {},
   "source": [
    "# PART D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed3d7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from scipy.special import expit\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "from time import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4b7e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc143936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78200, 1024), (78200, 46), (4600, 1024), (4600, 46))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data=pd.read_csv('data/train_data_shuffled.csv',header=None)\n",
    "test=pd.read_csv('data/public_test.csv',header=None)\n",
    "X_test,y_test=test.iloc[:,:-1].to_numpy()/255.,pd.get_dummies(test.iloc[:,-1:],columns=test.columns[-1:]).to_numpy()\n",
    "X,y=data.iloc[:,:-1].to_numpy()/255.,pd.get_dummies(data.iloc[:,-1:],columns=data.columns[-1:]).to_numpy()\n",
    "X.shape,y.shape,X_test.shape,y_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7dd29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb6cdf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    m=np.max(a,axis=1).reshape(-1,1)\n",
    "    #gamma=1e-15\n",
    "    a=np.exp(a-m)\n",
    "    #return a/(a.sum(axis=a.ndim-1).reshape(-1,1))\n",
    "    return np.nan_to_num(a/(a.sum(axis=a.ndim-1).reshape(-1,1)),False)\n",
    "def relu(a):\n",
    "    return np.where(a>0,a,0)\n",
    "def drelu(a):\n",
    "    return np.where(a>0,1,0)\n",
    "def tanh(a):\n",
    "    return np.tanh(a)  \n",
    "def dtanh(a):\n",
    "    return 1-np.square(a)\n",
    "def sigmoid(a):\n",
    "    return 1/(1+np.exp(-a))\n",
    "\n",
    "    #return expit(a)\n",
    "def dsig(a):\n",
    "    #return sigmoid(a)*(1-sigmoid(a))\n",
    "    return a*(1-a)\n",
    "    #return (1-expit(a))*expit(a)\n",
    "def CE_loss(y_true,y_preds):\n",
    "    gamma=1e-15\n",
    "    return -np.sum(np.multiply(y_true,np.log(np.clip(y_preds,gamma,1-gamma))))/y_true.shape[0]\n",
    "\n",
    "def mse(y_true,y_preds):  \n",
    "    return np.sum(np.square(y_true.reshape(-1,1)-y_preds.reshape(-1,1)))/y_preds.shape[0]\n",
    "\n",
    "\n",
    "def acc(y_true,y_preds):\n",
    "    y_preds=np.argmax(y_preds,axis=1).squeeze()\n",
    "    y_true=np.argmax(y_true,axis=1).squeeze()\n",
    "    return np.count_nonzero(y_true-y_preds==0)/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e7b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa70fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    hidden_units=daf=af=l=W=Z=0\n",
    "    \n",
    "    def __init__(self,hidden_units,af,num_features,loss):\n",
    "        \n",
    "        self.hidden_units=hidden_units\n",
    "        self.l=loss\n",
    "        if(af==0):\n",
    "            self.af=sigmoid\n",
    "            self.daf=dsig\n",
    "        elif(af==1):\n",
    "            self.af=tanh\n",
    "            self.daf=dtanh\n",
    "        else:\n",
    "            self.af=relu\n",
    "            self.daf=drelu\n",
    "        if(loss==0):\n",
    "            self.loss=CE_loss\n",
    "        else:\n",
    "            self.loss=mse \n",
    "        self.W=[]\n",
    "        self.b=[]\n",
    "        \n",
    "        \n",
    "        temp=np.float32(np.random.normal(0,1,(num_features+1,hidden_units[0])))*(np.sqrt(2/(num_features+1+hidden_units[0])))\n",
    "        self.W.append(temp[1:,:])\n",
    "        self.b.append(temp[0])\n",
    "        for i in range(1,len(hidden_units)):\n",
    "            temp=np.float32(np.random.normal(0,1,(hidden_units[i-1]+1,hidden_units[i])))*(np.sqrt(2/(hidden_units[i-1]+1+hidden_units[i])))\n",
    "            self.W.append(temp[1:,:])\n",
    "            self.b.append(temp[0])\n",
    "        self.final_W=self.W\n",
    "        self.final_b=self.b\n",
    "        self.Z=[]    \n",
    "    def fp(self,X):\n",
    "        self.Z=[]\n",
    "        \n",
    "        self.Z.append(X)\n",
    "        \n",
    "#         for i in range(len(self.W)):\n",
    "#             self.Z.append(self.af(np.matmul(self.Z[i],self.W[i])+self.b[i]))\n",
    "            \n",
    "#         if(self.l==0):\n",
    "#             return softmax(self.Z[-1]) \n",
    "        for i in range(len(self.W)-1):\n",
    "            self.Z.append(self.af(np.matmul(self.Z[i],self.W[i])+self.b[i]))\n",
    "            \n",
    "        if(self.l==0):\n",
    "            #print(self.Z[-1].shape,self.W[-1].shape,self.b[-1].shape)\n",
    "            self.Z.append(np.matmul(self.Z[-1],self.W[-1])+self.b[-1])\n",
    "            return softmax(self.Z[-1])\n",
    "            \n",
    "        else:\n",
    "            self.Z.append(self.af(np.matmul(self.Z[-1],self.W[-1])+self.b[-1]))\n",
    "        return self.Z[-1]\n",
    "    def bp(self,X,y,lr):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #print(dw[0])\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            \n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            self.W[i]-=dw*lr\n",
    "            self.b[i]-=db*lr\n",
    "#     def bp(self,X,y,lr):\n",
    "#         yh=self.fp(X)\n",
    "#         g=yh-y\n",
    "#         #print(g)\n",
    "#         dummy=np.ones(yh.shape[0])\n",
    "#         for i in reversed(range(len(self.W))):\n",
    "#             deriv_af=self.daf(self.Z[i+1])\n",
    "#             g=np.multiply(deriv_af,g)\n",
    "#             dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "#             #print(dw[0])\n",
    "#             #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "#             db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            \n",
    "#             g=np.dot(g,self.W[i].T)\n",
    "#             self.W[i]-=dw*lr\n",
    "#             self.b[i]-=db*lr\n",
    "    def bp_mom(self,X,y,lr,wt,bt,gamma=.9):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        \n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            change=gamma*wt[i]+dw*lr\n",
    "            self.W[i]-=change\n",
    "            wt[i]=change\n",
    "            #print(wt[i])\n",
    "            change=gamma*bt[i]+db*lr\n",
    "            self.b[i]-=change\n",
    "            bt[i]=change\n",
    "            \n",
    "    \n",
    "    def bp_rmsprop(self,X,y,lr,wt,bt,gamma=.9):\n",
    "        \n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        \n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        e=1e-8\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            temp=gamma*wt[i]+0.1*(dw**2)\n",
    "            self.W[i]-=lr*dw/(np.sqrt(temp+e))\n",
    "            wt[i]=temp\n",
    "            #print(wt[i])\n",
    "            temp=gamma*bt[i]+.1*(db**2)\n",
    "            self.b[i]-=lr*db/(np.sqrt(temp+e))\n",
    "            bt[i]=temp\n",
    "    def bp_adam(self,X,y,lr,vwt,vbt,mwt,mbt,b1=.9,b2=.999):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        e=1e-8\n",
    "        b1t=1\n",
    "        b2t=1\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            vwt[i]=b2*vwt[i]+(1-b2)*(dw**2)\n",
    "            vbt[i]=b2*vbt[i]+(1-b2)*(db**2)\n",
    "            mwt[i]=b1*mwt[i]+(1-b1)*(dw)\n",
    "            mbt[i]=b1*mbt[i]+(1-b1)*(db)\n",
    "            #print(mbt[i])\n",
    "            b1t*=b1\n",
    "            b2t*=b2\n",
    "            self.W[i]-=lr*(mwt[i]/(1-b1t))/(np.sqrt(vwt[i]/(1-b2t)+e))\n",
    "            self.b[i]-=lr*(mbt[i]/(1-b1t))/(np.sqrt(vbt[i]/(1-b2t)+e))\n",
    "            \n",
    "            \n",
    "    def bp_nadam(self,X,y,lr,vwt,vbt,mwt,mbt,b1=.9,b2=.999):\n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        dummy=np.ones(yh.shape[0])\n",
    "        e=1e-8\n",
    "        b1t=1\n",
    "        b2t=1\n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "            g=np.dot(g,self.W[i].T)\n",
    "            #print(gamma*wt[i])\n",
    "            vwt[i]=b2*vwt[i]+(1-b2)*(dw**2)\n",
    "            vbt[i]=b2*vbt[i]+(1-b2)*(db**2)\n",
    "            mwt[i]=b1*mwt[i]+(1-b1)*(dw)\n",
    "            mbt[i]=b1*mbt[i]+(1-b1)*(db)\n",
    "            #print(mbt[i])\n",
    "            b1t*=b1\n",
    "            b2t*=b2\n",
    "            self.W[i]-=lr*(b1*mwt[i]/(1-b1t)+(1-b1)*dw/(1-b1t))/(np.sqrt(vwt[i]/(1-b2t)+e))\n",
    "            self.b[i]-=lr*(b1*mbt[i]/(1-b1t)+(1-b1)*db/(1-b1t))/(np.sqrt(vbt[i]/(1-b2t)+e))\n",
    "    \n",
    "    def bp_nag(self,X,y,lr,wt,bt,gamma=.9):\n",
    "        W_temp=self.W\n",
    "        b_temp=self.b\n",
    "        for i in range(len(self.W)):\n",
    "            self.W[i]-=gamma*wt[i]\n",
    "            self.b[i]-=gamma*bt[i]\n",
    "            \n",
    "        yh=self.fp(X)\n",
    "        g=yh-y\n",
    "        \n",
    "        #print(g)\n",
    "        #print(gamma)\n",
    "        \n",
    "        for i in reversed(range(len(self.W))):\n",
    "            \n",
    "            deriv_af=self.daf(self.Z[i+1])\n",
    "            \n",
    "            if(i<len(self.W)-1 or self.l==1):\n",
    "                \n",
    "                g=np.multiply(g,deriv_af)\n",
    "            dw=np.matmul(self.Z[i].T,g)/yh.shape[0]\n",
    "            #db=np.matmul(dummy,g)/yh.shape[0]\n",
    "            db=np.sum(g,axis=0)/yh.shape[0]\n",
    "               \n",
    "            g=np.dot(g,self.W[i].T)\n",
    "           \n",
    "            temp=gamma*wt[i]+lr*dw\n",
    "            \n",
    "            W_temp[i]-=temp\n",
    "            wt[i]=temp\n",
    "            #print(wt[i])\n",
    "            temp=gamma*bt[i]+lr*db\n",
    "            b_temp[i]-=temp\n",
    "            bt[i]=temp\n",
    "        self.W=W_temp\n",
    "        self.b=b_temp\n",
    "    \n",
    "    def fit(self,bs,epochs,X,y,x_t,y_t,lr,t,adaptive=False):\n",
    "        t_counter=time()\n",
    "        th=time()\n",
    "        for i in range(len(self.W)):\n",
    "            \n",
    "            \n",
    "            self.W[i]=np.float64(self.W[i])\n",
    "            self.b[i]=np.float64(self.b[i])\n",
    "#         l=[]\n",
    "        lmin=float('inf')\n",
    "        amax=float('-inf')\n",
    "        t+=time()-th\n",
    "        for i in range(epochs):\n",
    "            th=time()\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                th=time()\n",
    "#                 if(j==5 and i==0):\n",
    "#                     for k in range(len(a.W)):\n",
    "#                         temp=np.concatenate((a.b[k].reshape(1,-1),a.W[k]),axis=0)\n",
    "#                         np.save('essentials/part_a_and_b/multiclass_dataset/tc_3/w_'+str(k+1)+'_iter.npy',temp)\n",
    "#                         print(np.max(np.load('essentials/part_a_and_b/multiclass_dataset/tc_3/ac_w_'+str(k+1)+'_iter.npy')-temp))\n",
    "                    \n",
    "                self.bp(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr)\n",
    "                t+=time()-th\n",
    "                th=time()\n",
    "                if(4.92*60>t>4.8*60):\n",
    "                    l=self.loss(y_t,self.fp(x_t))\n",
    "                    a=acc(y_t,self.fp(x_t))\n",
    "                    if(a>amax):\n",
    "                        amax=a\n",
    "                        lmin=l\n",
    "                        self.final_W=self.W\n",
    "                        self.final_b=self.b\n",
    "#                         for k in range(len(self.final_W)):\n",
    "#                             temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                             np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                        yh=self.fp(X_test)\n",
    "                        print(str(t)+': train_loss:'+ str(self.loss(y,self.fp(X))) +' test_acc:'+str(amax)+\" val loss:\" +str(self.loss(y_test,yh))+\" acc:\"+str(acc(y_test,yh)))\n",
    "    \n",
    "                t+=time()-th\n",
    "            th=time()    \n",
    "            l=self.loss(y_t,self.fp(x_t))\n",
    "            a=acc(y_t,self.fp(x_t))\n",
    "            if(a>amax):\n",
    "                amax=a\n",
    "                lmin=l\n",
    "                self.final_W=self.W\n",
    "                self.final_b=self.b\n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            if(time()-t_counter>30 or t>4.4*60):\n",
    "                t_counter=time()\n",
    "#                 for k in range(len(self.final_W)):\n",
    "#                     temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                     np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                yh=self.fp(X_test)\n",
    "                print(str(t)+': train_loss:' +str(self.loss(y,self.fp(X))) +' test_acc:'+str(amax)+\" val loss:\" +str(self.loss(y_test,yh))+\" acc:\"+str(acc(y_test,yh)))\n",
    "    \n",
    "            t+=time()-th\n",
    "            if(t>300):\n",
    "                return lmin\n",
    "                \n",
    "#             y_pred=self.fp(X_test)\n",
    "#             l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "#             print(i,l[-1])\n",
    "#             print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))\n",
    "        return lmin    \n",
    "    def fit_mom(self,bs,epochs,X,y,x_t,y_t,lr,t,adaptive=False):\n",
    "        t_counter=time()\n",
    "        th=time()\n",
    "        for i in range(len(self.W)):\n",
    "            \n",
    "            \n",
    "            self.W[i]=np.float64(self.W[i])\n",
    "            self.b[i]=np.float64(self.b[i])\n",
    "#         l=[]\n",
    "        lmin=float('inf')\n",
    "        amax=float('-inf')\n",
    "       \n",
    "        wt=[0]*len(self.W)\n",
    "        bt=[0]*len(self.W)\n",
    "        t+=time()-th\n",
    "        for i in range(epochs):\n",
    "            th=time()\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                th=time()\n",
    "                self.bp_mom(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,wt,bt)\n",
    "                t+=time()-th\n",
    "                th=time()\n",
    "                if(4.92*60>t>4.8*60):\n",
    "                    l=self.loss(y_t,self.fp(x_t))\n",
    "                    a=acc(y_t,self.fp(x_t))\n",
    "                    if(a>amax):\n",
    "                        amax=a\n",
    "                        lmin=l\n",
    "                        self.final_W=self.W\n",
    "                        self.final_b=self.b\n",
    "#                         for k in range(len(self.final_W)):\n",
    "#                             temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                             np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                        yh=self.fp(X_test)\n",
    "                        print(str(t)+': train_loss:'+ str(self.loss(y,self.fp(X))) +' test_acc:'+str(amax)+\" val loss:\" +str(self.loss(y_test,yh))+\" acc:\"+str(acc(y_test,yh)))\n",
    "    \n",
    "                t+=time()-th\n",
    "            th=time()    \n",
    "            l=self.loss(y_t,self.fp(x_t))\n",
    "            a=acc(y_t,self.fp(x_t))\n",
    "            if(a>amax):\n",
    "                amax=a\n",
    "                lmin=l\n",
    "                self.final_W=self.W\n",
    "                self.final_b=self.b\n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            if(time()-t_counter>30 or t>4.4*60):\n",
    "                t_counter=time()\n",
    "#                 for k in range(len(self.final_W)):\n",
    "#                     temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                     np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                yh=self.fp(X_test)\n",
    "                print(str(t)+': train_loss:' +str(self.loss(y,self.fp(X))) +' test_acc:'+str(amax)+\" val loss:\" +str(self.loss(y_test,yh))+\" acc:\"+str(acc(y_test,yh)))\n",
    "    \n",
    "            t+=time()-th\n",
    "            if(t>300):\n",
    "                return lmin\n",
    "            \n",
    "#             y_pred=self.fp(X_test)\n",
    "#             l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "#             print(i,l[-1])\n",
    "#             print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))\n",
    "        return lmin\n",
    "    def fit_nag(self,bs,epochs,X,y,x_t,y_t,lr,t,adaptive=False):\n",
    "        t_counter=time()\n",
    "        th=time()\n",
    "        for i in range(len(self.W)):\n",
    "            \n",
    "            \n",
    "            self.W[i]=np.float64(self.W[i])\n",
    "            self.b[i]=np.float64(self.b[i])\n",
    "#         l=[]\n",
    "        lmin=float('inf')\n",
    "        amax=float('-inf')\n",
    "        wt=[0]*len(self.W)\n",
    "        bt=[0]*len(self.W)\n",
    "        t+=time()-th\n",
    "        for i in range(epochs):\n",
    "            th=time()\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                th=time()\n",
    "                self.bp_nag(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,wt,bt)\n",
    "                t+=time()-th\n",
    "                th=time()\n",
    "                if(4.92*60>t>4.8*60):\n",
    "                    l=self.loss(y_t,self.fp(x_t))\n",
    "                    a=acc(y_t,self.fp(x_t))\n",
    "                    if(a>amax):\n",
    "                        amax=a\n",
    "                        lmin=l\n",
    "                        self.final_W=self.W\n",
    "                        self.final_b=self.b\n",
    "#                         for k in range(len(self.final_W)):\n",
    "#                             temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                             np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                        yh=self.fp(X_test)\n",
    "                        print(str(t)+': train_loss:'+ str(self.loss(y,self.fp(X))) +' test_acc:'+str(amax)+\" val loss:\" +str(self.loss(y_test,yh))+\" acc:\"+str(acc(y_test,yh)))\n",
    "    \n",
    "                t+=time()-th\n",
    "            th=time()    \n",
    "            l=self.loss(y_t,self.fp(x_t))\n",
    "            a=acc(y_t,self.fp(x_t))\n",
    "            if(a>amax):\n",
    "                amax=a\n",
    "                lmin=l\n",
    "                self.final_W=self.W\n",
    "                self.final_b=self.b\n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            if(time()-t_counter>30 or t>4.4*60):\n",
    "                t_counter=time()\n",
    "#                 for k in range(len(self.final_W)):\n",
    "#                     temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                     np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                yh=self.fp(X_test)\n",
    "                print(str(t)+': train_loss:' +str(self.loss(y,self.fp(X))) +' test_acc:'+str(amax)+\" val loss:\" +str(self.loss(y_test,yh))+\" acc:\"+str(acc(y_test,yh)))\n",
    "    \n",
    "            t+=time()-th\n",
    "            if(t>300):\n",
    "                return lmin\n",
    "        \n",
    "#             y_pred=self.fp(X_test)\n",
    "#             l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "#             print(i,l[-1])\n",
    "#             print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))\n",
    "        return lmin\n",
    "    def fit_adam(self,bs,epochs,X,y,x_t,y_t,lr,t,adaptive=False):\n",
    "        t_counter=time()\n",
    "        th=time()\n",
    "        for i in range(len(self.W)):\n",
    "            \n",
    "            \n",
    "            self.W[i]=np.float64(self.W[i])\n",
    "            self.b[i]=np.float64(self.b[i])\n",
    "#         l=[]\n",
    "        lmin=float('inf')\n",
    "        amax=float('-inf')\n",
    "    \n",
    "        mwt=[0]*len(self.W)\n",
    "        mbt=[0]*len(self.W)\n",
    "        vwt=[0]*len(self.W)\n",
    "        vbt=[0]*len(self.W)\n",
    "        t+=time()-th\n",
    "        for i in range(epochs):\n",
    "            th=time()\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                th=time()\n",
    "                self.bp_adam(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,vwt,vbt,mwt,mbt)\n",
    "                t+=time()-th\n",
    "                th=time()\n",
    "                if(4.92*60>t>4.8*60):\n",
    "                    l=self.loss(y_t,self.fp(x_t))\n",
    "                    a=acc(y_t,self.fp(x_t))\n",
    "                    if(a>amax):\n",
    "                        amax=a\n",
    "                        lmin=l\n",
    "                        self.final_W=self.W\n",
    "                        self.final_b=self.b\n",
    "#                         for k in range(len(self.final_W)):\n",
    "#                             temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                             np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                        yh=self.fp(X_test)\n",
    "                        print(str(t)+': train_loss:'+ str(self.loss(y,self.fp(X))) +' test_acc:'+str(amax)+\" val loss:\" +str(self.loss(y_test,yh))+\" acc:\"+str(acc(y_test,yh)))\n",
    "    \n",
    "                t+=time()-th\n",
    "            th=time()    \n",
    "            l=self.loss(y_t,self.fp(x_t))\n",
    "            a=acc(y_t,self.fp(x_t))\n",
    "            if(a>amax):\n",
    "                amax=a\n",
    "                lmin=l\n",
    "                self.final_W=self.W\n",
    "                self.final_b=self.b\n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            if(time()-t_counter>30 or t>4.4*60):\n",
    "                t_counter=time()\n",
    "#                 for k in range(len(self.final_W)):\n",
    "#                     temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                     np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                yh=self.fp(X_test)\n",
    "                print(str(t)+': train_loss:' +str(self.loss(y,self.fp(X))) +' test_acc:'+str(amax)+\" val loss:\" +str(self.loss(y_test,yh))+\" acc:\"+str(acc(y_test,yh)))\n",
    "    \n",
    "            t+=time()-th\n",
    "            if(t>300):\n",
    "                return lmin\n",
    "            \n",
    "#             y_pred=self.fp(X_test)\n",
    "#             l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "#             print(i,l[-1])\n",
    "#             print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))    \n",
    "        return lmin\n",
    "    def fit_nadam(self,bs,epochs,X,y,x_t,y_t,lr,t,adaptive=False):\n",
    "        t_counter=time()\n",
    "        th=time()\n",
    "        for i in range(len(self.W)):\n",
    "            \n",
    "            \n",
    "            self.W[i]=np.float64(self.W[i])\n",
    "            self.b[i]=np.float64(self.b[i])\n",
    "#         l=[]\n",
    "        lmin=float('inf')\n",
    "        amax=float('-inf')\n",
    "        \n",
    "        mwt=[0]*len(self.W)\n",
    "        mbt=[0]*len(self.W)\n",
    "        vwt=[0]*len(self.W)\n",
    "        vbt=[0]*len(self.W)\n",
    "        t+=time()-th\n",
    "        for i in range(epochs):\n",
    "            th=time()\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                th=time()\n",
    "                self.bp_nadam(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,vwt,vbt,mwt,mbt)\n",
    "                t+=time()-th\n",
    "                th=time()\n",
    "                if(4.92*60>t>4.8*60):\n",
    "                    l=self.loss(y_t,self.fp(x_t))\n",
    "                    a=acc(y_t,self.fp(x_t))\n",
    "                    if(a>amax):\n",
    "                        amax=a\n",
    "                        lmin=l\n",
    "                        self.final_W=self.W\n",
    "                        self.final_b=self.b\n",
    "#                         for k in range(len(self.final_W)):\n",
    "#                             temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                             np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                        yh=self.fp(X_test)\n",
    "                        print(str(t)+': train_loss:'+ str(self.loss(y,self.fp(X))) +' test_acc:'+str(amax)+\" val loss:\" +str(self.loss(y_test,yh))+\" acc:\"+str(acc(y_test,yh)))\n",
    "    \n",
    "                t+=time()-th\n",
    "            th=time()    \n",
    "            l=self.loss(y_t,self.fp(x_t))\n",
    "            a=acc(y_t,self.fp(x_t))\n",
    "            if(a>amax):\n",
    "                amax=a\n",
    "                lmin=l\n",
    "                self.final_W=self.W\n",
    "                self.final_b=self.b\n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            if(time()-t_counter>30 or t>4.4*60):\n",
    "                t_counter=time()\n",
    "#                 for k in range(len(self.final_W)):\n",
    "#                     temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                     np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                yh=self.fp(X_test)\n",
    "                print(str(t)+': train_loss:' +str(self.loss(y,self.fp(X))) +' test_acc:'+str(amax)+\" val loss:\" +str(self.loss(y_test,yh))+\" acc:\"+str(acc(y_test,yh)))\n",
    "    \n",
    "            t+=time()-th\n",
    "            if(t>300):\n",
    "                return lmin\n",
    "            \n",
    "#             y_pred=self.fp(X_test)\n",
    "#             l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "#             print(i,l[-1])\n",
    "#             print(i,self.loss(y_test,y_pred),acc(y_test,y_pred))\n",
    "\n",
    "\n",
    "        return lmin\n",
    "    def fit_rmsprop(self,bs,epochs,X,y,x_t,y_t,lr,t,adaptive=False):\n",
    "        t_counter=time()\n",
    "        th=time()\n",
    "        for i in range(len(self.W)):\n",
    "            \n",
    "            \n",
    "            self.W[i]=np.float64(self.W[i])\n",
    "            self.b[i]=np.float64(self.b[i])\n",
    "#         l=[]\n",
    "        lmin=float('inf')\n",
    "        amax=float('-inf')\n",
    "        \n",
    "        \n",
    "        wt=[0]*len(self.W)\n",
    "        bt=[0]*len(self.W)\n",
    "        t+=time()-th\n",
    "        for i in range(epochs):\n",
    "            th=time()\n",
    "            if(adaptive):\n",
    "                lr/=(i+1)**.5\n",
    "            for j in range(X.shape[0]//bs):\n",
    "                th=time()\n",
    "                self.bp_rmsprop(X[j*bs:(j+1)*bs,:],y[j*bs:(j+1)*bs,:],lr,wt,bt)\n",
    "                t+=time()-th\n",
    "                th=time()\n",
    "                if(4.92*60>t>4.8*60):\n",
    "                    l=self.loss(y_t,self.fp(x_t))\n",
    "                    a=acc(y_t,self.fp(x_t))\n",
    "                    if(a>amax):\n",
    "                        amax=a\n",
    "                        lmin=l\n",
    "                        self.final_W=self.W\n",
    "                        self.final_b=self.b\n",
    "#                         for k in range(len(self.final_W)):\n",
    "#                             temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                             np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                        yh=self.fp(X_test)\n",
    "                        print(str(t)+': train_loss:'+ str(self.loss(y,self.fp(X))) +' test_acc:'+str(amax)+\" val loss:\" +str(self.loss(y_test,yh))+\" acc:\"+str(acc(y_test,yh)))\n",
    "    \n",
    "                t+=time()-th\n",
    "            th=time()    \n",
    "            l=self.loss(y_t,self.fp(x_t))\n",
    "            a=acc(y_t,self.fp(x_t))\n",
    "            if(a>amax):\n",
    "                amax=a\n",
    "                lmin=l\n",
    "                self.final_W=self.W\n",
    "                self.final_b=self.b\n",
    "            t+=time()-th\n",
    "            th=time()\n",
    "            if(time()-t_counter>30 or t>4.4*60):\n",
    "                t_counter=time()\n",
    "#                 for k in range(len(self.final_W)):\n",
    "#                     temp=np.concatenate((self.final_b[k].reshape(1,-1),self.final_W[k]),axis=0)\n",
    "#                     np.save(output+'w_'+str(k+1)+'_.npy',temp)\n",
    "                yh=self.fp(X_test)\n",
    "                print(str(t)+': train_loss:' +str(self.loss(y,self.fp(X))) +' test_acc:'+str(amax)+\" val loss:\" +str(self.loss(y_test,yh))+\" acc:\"+str(acc(y_test,yh)))\n",
    "    \n",
    "            t+=time()-th\n",
    "            if(t>300):\n",
    "                return lmin\n",
    "#             y_pred=self.fp(X_test)\n",
    "#             l.append((self.loss(y,self.fp(X)),acc(y,self.fp(X))))\n",
    "#             print(i,l[-1])\n",
    "            \n",
    "        return lmin    \n",
    "    def pred(X):\n",
    "        return fp(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc635e38",
   "metadata": {},
   "source": [
    "# Experiments With Architecture 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20633cda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.262192249298096: train_loss:0.08266702214499312 test_acc:0.9149616368286445 val loss:0.38792946983895893 acc:0.9145652173913044\n",
      "72.63228297233582: train_loss:0.02552921895982873 test_acc:0.9254475703324808 val loss:0.4165266288488191 acc:0.927608695652174\n",
      "104.06613659858704: train_loss:0.0010182816194912537 test_acc:0.9414322250639386 val loss:0.37159762358082354 acc:0.941304347826087\n",
      "135.56419205665588: train_loss:0.0006106780468631648 test_acc:0.9423273657289003 val loss:0.3723652484839842 acc:0.9423913043478261\n",
      "167.34012484550476: train_loss:0.0005571264521559632 test_acc:0.9423273657289003 val loss:0.37446969389294493 acc:0.9419565217391305\n",
      "198.6105751991272: train_loss:0.0005292271927941024 test_acc:0.9425831202046036 val loss:0.37608795919496163 acc:0.9421739130434783\n",
      "230.08026099205017: train_loss:0.0005122029369257819 test_acc:0.9427109974424552 val loss:0.37745694377502587 acc:0.9423913043478261\n",
      "261.8625705242157: train_loss:0.0005008625643571648 test_acc:0.9427109974424552 val loss:0.37870807251393124 acc:0.9426086956521739\n",
      "266.38688468933105: train_loss:0.0004995910436007013 test_acc:0.9427109974424552 val loss:0.3788547264489519 acc:0.9426086956521739\n",
      "270.9751374721527: train_loss:0.0004987401728422276 test_acc:0.9427109974424552 val loss:0.37900336576364585 acc:0.9426086956521739\n",
      "275.40313363075256: train_loss:0.0004975190964342988 test_acc:0.9427109974424552 val loss:0.37916449049138823 acc:0.9426086956521739\n",
      "279.97944378852844: train_loss:0.0004967084552140085 test_acc:0.9427109974424552 val loss:0.3793093286593145 acc:0.9426086956521739\n",
      "284.4119086265564: train_loss:0.0004957320938485138 test_acc:0.9427109974424552 val loss:0.37946420303183104 acc:0.9426086956521739\n",
      "296.0414960384369: train_loss:0.0004947018013970489 test_acc:0.9427109974424552 val loss:0.3796059169948953 acc:0.9426086956521739\n",
      "300.493488073349: train_loss:0.0004938695138956853 test_acc:0.9427109974424552 val loss:0.3797581424111819 acc:0.9426086956521739\n",
      "0.3583100830516296\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit(50,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.4,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dc437ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.09081435203552: train_loss:0.09553805454174076 test_acc:0.9163682864450128 val loss:0.3434852961308703 acc:0.9119565217391304\n",
      "70.81776857376099: train_loss:0.011066131520207668 test_acc:0.9378516624040921 val loss:0.2889095003097324 acc:0.9332608695652174\n",
      "101.29762959480286: train_loss:0.0027267216056061066 test_acc:0.9414322250639386 val loss:0.28538812858878065 acc:0.941304347826087\n",
      "132.89635944366455: train_loss:0.0018710243952697382 test_acc:0.9419437340153453 val loss:0.2908431752469638 acc:0.9419565217391305\n",
      "163.4471263885498: train_loss:0.0014927759410966646 test_acc:0.9419437340153453 val loss:0.2954722209251515 acc:0.9419565217391305\n",
      "193.98150753974915: train_loss:0.0012763307823573835 test_acc:0.9423273657289003 val loss:0.299405674524126 acc:0.9419565217391305\n",
      "226.16499304771423: train_loss:0.0011349965877748827 test_acc:0.9423273657289003 val loss:0.30299046855250367 acc:0.9423913043478261\n",
      "258.57956290245056: train_loss:0.0010353454428433703 test_acc:0.9427109974424552 val loss:0.30616554467906454 acc:0.941304347826087\n",
      "267.4290974140167: train_loss:0.001014938306565049 test_acc:0.9427109974424552 val loss:0.3068900284841261 acc:0.9415217391304348\n",
      "272.05734157562256: train_loss:0.0010054991633872432 test_acc:0.9428388746803069 val loss:0.3072410653193668 acc:0.9415217391304348\n",
      "276.7259373664856: train_loss:0.0009962151621630258 test_acc:0.9428388746803069 val loss:0.3075940699759905 acc:0.9415217391304348\n",
      "281.3144636154175: train_loss:0.0009873734794608525 test_acc:0.9428388746803069 val loss:0.30794967685089475 acc:0.941304347826087\n",
      "285.8384518623352: train_loss:0.000978556030676052 test_acc:0.9428388746803069 val loss:0.30830666823438385 acc:0.941304347826087\n",
      "288.0066668987274: train_loss:0.0009635512169799455 test_acc:0.9434782608695652 val loss:0.30937199645340974 acc:0.9421739130434783\n",
      "288.7226629257202: train_loss:0.0009638567328271749 test_acc:0.9436061381074169 val loss:0.309369002434957 acc:0.9421739130434783\n",
      "289.43066453933716: train_loss:0.0009641322688798203 test_acc:0.9437340153452686 val loss:0.3093702268052406 acc:0.9423913043478261\n",
      "291.2271511554718: train_loss:0.000967905667192419 test_acc:0.9441176470588235 val loss:0.3093262009536961 acc:0.9419565217391305\n",
      "297.4318721294403: train_loss:0.0009701129116088877 test_acc:0.9441176470588235 val loss:0.3086455097957352 acc:0.9415217391304348\n",
      "302.11643385887146: train_loss:0.0009620317617242896 test_acc:0.9441176470588235 val loss:0.3089809699013568 acc:0.9415217391304348\n",
      "0.31084440739374863\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(100,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.05,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69034157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.347622871398926: train_loss:0.15520961572526473 test_acc:0.8904092071611254 val loss:0.5322703651949836 acc:0.8897826086956522\n",
      "71.10976314544678: train_loss:0.06673060024408951 test_acc:0.8994884910485933 val loss:0.6782378064601419 acc:0.8978260869565218\n",
      "103.04412889480591: train_loss:0.01652035610465319 test_acc:0.9090792838874681 val loss:0.7125660450932827 acc:0.9056521739130434\n",
      "133.18637251853943: train_loss:0.0011109855978471317 test_acc:0.9135549872122762 val loss:0.650013827449448 acc:0.9158695652173913\n",
      "164.24121165275574: train_loss:0.0010318196563880219 test_acc:0.9138107416879795 val loss:0.6511235507636801 acc:0.9173913043478261\n",
      "196.11633849143982: train_loss:0.000998657048981445 test_acc:0.9141943734015345 val loss:0.6528985867385492 acc:0.917608695652174\n",
      "0.6725228741577973\n"
     ]
    }
   ],
   "source": [
    "a=ANN([128,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(100,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.05,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1880f38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5:46.99563479423523: train_loss:0.08884899296369662 test_acc:0.9271099744245525 val loss:0.2647423444649119 acc:0.9243478260869565\n",
      "9:80.354576587677: train_loss:0.02517171927953997 test_acc:0.9392583120204604 val loss:0.23091899873189387 acc:0.9410869565217391\n",
      "13:114.04790234565735: train_loss:0.006379836430520092 test_acc:0.9465473145780051 val loss:0.22095986712183718 acc:0.9458695652173913\n",
      "17:147.79002165794373: train_loss:0.003671411449451637 test_acc:0.9482097186700768 val loss:0.22094406689348012 acc:0.9460869565217391\n",
      "21:179.59834694862366: train_loss:0.002724783554403161 test_acc:0.9482097186700768 val loss:0.2225635417780868 acc:0.9476086956521739\n",
      "25:210.26033091545105: train_loss:0.0022055723908933817 test_acc:0.9491048593350384 val loss:0.22425573581812006 acc:0.9469565217391305\n",
      "30:247.6072859764099: train_loss:0.001799531807372963 test_acc:0.9491048593350384 val loss:0.2262532332914022 acc:0.9484782608695652\n",
      "33:269.0992648601532: train_loss:0.0016249512225627396 test_acc:0.9491048593350384 val loss:0.22739813121266617 acc:0.9482608695652174\n",
      "34:276.8852529525757: train_loss:0.0015758161645847994 test_acc:0.9491048593350384 val loss:0.22774142980010148 acc:0.948695652173913\n",
      "35:284.7662401199341: train_loss:0.0015298662044742762 test_acc:0.9491048593350384 val loss:0.2280931045319151 acc:0.9482608695652174\n",
      "36:300.35521721839905: train_loss:0.001486601052594443 test_acc:0.9491048593350384 val loss:0.2284417770427136 acc:0.9482608695652174\n",
      "0.21429388118976633\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(100,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.05,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a757472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.30288052558899: train_loss:0.06963760580129334 test_acc:0.9296675191815856 val loss:0.254137256981233 acc:0.9321739130434783\n",
      "82.55191707611084: train_loss:0.01358105849361978 test_acc:0.9445012787723785 val loss:0.22806044770409728 acc:0.9434782608695652\n",
      "113.24575591087341: train_loss:0.003785048138990098 test_acc:0.9485933503836317 val loss:0.22832210684999657 acc:0.9480434782608695\n",
      "145.40468549728394: train_loss:0.002382815203149153 test_acc:0.9485933503836317 val loss:0.23227050400137242 acc:0.9482608695652174\n",
      "181.18163895606995: train_loss:0.0017275648658705276 test_acc:0.948849104859335 val loss:0.2355662916311726 acc:0.9478260869565217\n",
      "211.87357664108276: train_loss:0.0014406515159333287 test_acc:0.94923273657289 val loss:0.23760388478676625 acc:0.9489130434782609\n",
      "247.94447779655457: train_loss:0.0012077578518339344 test_acc:0.9494884910485933 val loss:0.23980710149189052 acc:0.9491304347826087\n",
      "264.07745337486267: train_loss:0.0011383412781555762 test_acc:0.949616368286445 val loss:0.24061513688394567 acc:0.9495652173913044\n",
      "271.96845293045044: train_loss:0.001107550325898676 test_acc:0.9498721227621484 val loss:0.24100251986335394 acc:0.9495652173913044\n",
      "280.1814022064209: train_loss:0.0010784628158273877 test_acc:0.9498721227621484 val loss:0.24136488937213402 acc:0.9495652173913044\n",
      "287.7824115753174: train_loss:0.001051140900183282 test_acc:0.9498721227621484 val loss:0.24174316057839973 acc:0.9495652173913044\n",
      "290.5684189796448: train_loss:0.0010454515815782946 test_acc:0.95 val loss:0.2414042947905167 acc:0.9502173913043478\n",
      "292.17340564727783: train_loss:0.0010446704860956597 test_acc:0.9501278772378516 val loss:0.24128245743868468 acc:0.9504347826086956\n",
      "294.56938099861145: train_loss:0.0010438066915189276 test_acc:0.9502557544757033 val loss:0.24106301021179868 acc:0.9508695652173913\n",
      "302.3654568195343: train_loss:0.0010255958807923547 test_acc:0.9502557544757033 val loss:0.2421035306358086 acc:0.9495652173913044\n",
      "0.2337198120057751\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(100,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.06,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eef55a8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.51695275306702: train_loss:0.07608854046887875 test_acc:0.9248081841432225 val loss:0.27165022827778573 acc:0.9252173913043479\n",
      "76.87988519668579: train_loss:0.01134816823154632 test_acc:0.9457800511508951 val loss:0.24485457747817987 acc:0.9421739130434783\n",
      "108.53381705284119: train_loss:0.002924155124502741 test_acc:0.950383631713555 val loss:0.23560230959822004 acc:0.947391304347826\n",
      "139.1097981929779: train_loss:0.0019930090080198183 test_acc:0.950383631713555 val loss:0.23832971933136926 acc:0.9491304347826087\n",
      "169.19277095794678: train_loss:0.0015288191628450968 test_acc:0.950383631713555 val loss:0.2407579939811907 acc:0.9489130434782609\n",
      "205.0137231349945: train_loss:0.0011997086113290083 test_acc:0.9507672634271099 val loss:0.24334854317898638 acc:0.9491304347826087\n",
      "235.73558592796326: train_loss:0.0010193290183852712 test_acc:0.951150895140665 val loss:0.24520035113197983 acc:0.9493478260869566\n",
      "267.1865301132202: train_loss:0.0008875172390670605 test_acc:0.9516624040920716 val loss:0.24679955405297135 acc:0.9491304347826087\n",
      "273.9195098876953: train_loss:0.0008655827221244346 test_acc:0.9516624040920716 val loss:0.2471180721695236 acc:0.9491304347826087\n",
      "280.69848799705505: train_loss:0.0008446592368801965 test_acc:0.9516624040920716 val loss:0.24744570789900525 acc:0.9491304347826087\n",
      "287.5484688282013: train_loss:0.000824614437949171 test_acc:0.9516624040920716 val loss:0.2477292188339516 acc:0.9491304347826087\n",
      "290.9724633693695: train_loss:0.0008268057630830343 test_acc:0.9517902813299233 val loss:0.24752715956757498 acc:0.9491304347826087\n",
      "300.63040018081665: train_loss:0.0008056316086162919 test_acc:0.9517902813299233 val loss:0.24802989265604428 acc:0.9491304347826087\n",
      "0.23027407719506982\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.08,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a513f16c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.46650981903076: train_loss:0.20816794744472017 test_acc:0.9099744245524297 val loss:0.32418478652049604 acc:0.9063043478260869\n",
      "77.50869083404541: train_loss:0.08940816995695972 test_acc:0.9313299232736573 val loss:0.25677534359627785 acc:0.9289130434782609\n",
      "110.24464154243469: train_loss:0.043227982005507704 test_acc:0.9396419437340153 val loss:0.2264443572779894 acc:0.9373913043478261\n",
      "144.71792554855347: train_loss:0.016360817431878328 test_acc:0.9497442455242967 val loss:0.20510072344360375 acc:0.9458695652173913\n",
      "177.17969465255737: train_loss:0.008275799309103922 test_acc:0.9497442455242967 val loss:0.1989772763261806 acc:0.9495652173913044\n",
      "209.79056549072266: train_loss:0.005462310000141867 test_acc:0.9501278772378516 val loss:0.19810480697777186 acc:0.9510869565217391\n",
      "242.65252804756165: train_loss:0.004127277694436684 test_acc:0.9502557544757033 val loss:0.19800656719537005 acc:0.9515217391304348\n",
      "275.52540159225464: train_loss:0.003362364377982156 test_acc:0.9507672634271099 val loss:0.19862058897335422 acc:0.951304347826087\n",
      "288.0133831501007: train_loss:0.003165587105025875 test_acc:0.9515345268542199 val loss:0.19652574343253626 acc:0.9504347826086956\n",
      "292.0593776702881: train_loss:0.0031823112647486836 test_acc:0.9516624040920716 val loss:0.19681084793490894 acc:0.9504347826086956\n",
      "294.804372549057: train_loss:0.0031854114479901987 test_acc:0.951918158567775 val loss:0.19694254970181757 acc:0.9506521739130435\n",
      "302.05436182022095: train_loss:0.0030960661604900594 test_acc:0.951918158567775 val loss:0.1991043592766725 acc:0.9515217391304348\n",
      "0.19393264864283746\n"
     ]
    }
   ],
   "source": [
    "a=ANN([1024,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(100,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.05,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7161bb39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.12390112876892: train_loss:0.10652899983206786 test_acc:0.9239130434782609 val loss:0.26683997341595017 acc:0.9239130434782609\n",
      "98.61893105506897: train_loss:0.03735469564772316 test_acc:0.9363171355498722 val loss:0.25654920037340995 acc:0.938695652173913\n",
      "130.57963228225708: train_loss:0.012030378035568412 test_acc:0.9489769820971867 val loss:0.21772665490029575 acc:0.9471739130434783\n",
      "166.2162139415741: train_loss:0.002819844201322849 test_acc:0.9510230179028133 val loss:0.21638401451213224 acc:0.9545652173913044\n",
      "200.3132610321045: train_loss:0.001337575497853241 test_acc:0.9526854219948849 val loss:0.21257135855642548 acc:0.9543478260869566\n",
      "234.62621688842773: train_loss:0.0010017348529206913 test_acc:0.9526854219948849 val loss:0.21638408546410837 acc:0.9547826086956521\n",
      "270.1179029941559: train_loss:0.00088133759547869 test_acc:0.9526854219948849 val loss:0.21779983069441688 acc:0.9547826086956521\n",
      "288.0098659992218: train_loss:0.0008588181586851214 test_acc:0.9528132992327366 val loss:0.21847469731468208 acc:0.955\n",
      "297.44885325431824: train_loss:0.0008384067370296649 test_acc:0.9528132992327366 val loss:0.21828761200344743 acc:0.9552173913043478\n",
      "315.9211483001709: train_loss:0.0008025695493193094 test_acc:0.9528132992327366 val loss:0.21869271750034774 acc:0.9554347826086956\n",
      "0.21265302690076734\n"
     ]
    }
   ],
   "source": [
    "a=ANN([1024,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(100,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.09,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d092805e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.2140839099884: train_loss:0.17499722053703234 test_acc:0.9176666666666666 val loss:0.3299338812855967 acc:0.9047826086956522\n",
      "72.74903774261475: train_loss:0.07310760319936425 test_acc:0.9316666666666666 val loss:0.26916663247348727 acc:0.9339130434782609\n",
      "103.0559914112091: train_loss:0.033452664225160335 test_acc:0.9423333333333334 val loss:0.25764685149821537 acc:0.9415217391304348\n",
      "134.18470191955566: train_loss:0.012637947859854656 test_acc:0.9526666666666667 val loss:0.2245291946895543 acc:0.9497826086956521\n",
      "164.35965657234192: train_loss:0.0035428793382821016 test_acc:0.956 val loss:0.21546437563962043 acc:0.9530434782608695\n",
      "195.87660789489746: train_loss:0.0012670203319164084 test_acc:0.957 val loss:0.20892065714698313 acc:0.9571739130434782\n",
      "226.8465621471405: train_loss:0.000740983410923291 test_acc:0.957 val loss:0.2098803162188857 acc:0.9576086956521739\n",
      "257.32551741600037: train_loss:0.0006163912826427537 test_acc:0.957 val loss:0.21107518639911094 acc:0.957391304347826\n",
      "273.35449051856995: train_loss:0.0005733257456572728 test_acc:0.957 val loss:0.21153970546330136 acc:0.9571739130434782\n",
      "296.11345505714417: train_loss:0.0005375463534506239 test_acc:0.957 val loss:0.21197000076815375 acc:0.9571739130434782\n",
      "312.4038043022156: train_loss:0.0005070458695246405 test_acc:0.957 val loss:0.21232036221913853 acc:0.9571739130434782\n",
      "0.21713982957072164\n"
     ]
    }
   ],
   "source": [
    "a=ANN([1024,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(100,100,X[:-3000],y[:-3000],X[-3000:],y[-3000:],.09,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b0cae533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.013225078582764: train_loss:0.09653931051393023 test_acc:0.9319565217391305 val loss:0.24443105178907118 acc:0.933695652173913\n",
      "84.03978967666626: train_loss:0.04726175231346494 test_acc:0.9376086956521739 val loss:0.24207150586876197 acc:0.9402173913043478\n",
      "116.80743312835693: train_loss:0.023331535634837967 test_acc:0.9447826086956522 val loss:0.228863264220836 acc:0.945\n",
      "149.162029504776: train_loss:0.005594485313718897 test_acc:0.952391304347826 val loss:0.20496404984660338 acc:0.9526086956521739\n",
      "181.17680978775024: train_loss:0.0017309473000619653 test_acc:0.953695652173913 val loss:0.20088699408326904 acc:0.9543478260869566\n",
      "214.41254377365112: train_loss:0.0008475438372312761 test_acc:0.955 val loss:0.20042922045437822 acc:0.9567391304347826\n",
      "247.7152373790741: train_loss:0.0006823866768170152 test_acc:0.9554347826086956 val loss:0.20272389381834865 acc:0.9569565217391305\n",
      "265.71294593811035: train_loss:0.0006284797120027301 test_acc:0.9554347826086956 val loss:0.20354322243736606 acc:0.9569565217391305\n",
      "284.0302357673645: train_loss:0.0005849442855941615 test_acc:0.9558695652173913 val loss:0.2042485019335687 acc:0.9569565217391305\n",
      "307.88568329811096: train_loss:0.0005486025507714038 test_acc:0.9558695652173913 val loss:0.20487568013414997 acc:0.9567391304347826\n",
      "0.22384728216524555\n"
     ]
    }
   ],
   "source": [
    "a=ANN([1024,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(100,100,X[:-4600],y[:-4600],X[-4600:],y[-4600:],.09,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c635376b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.48195576667786: train_loss:0.2793754464604033 test_acc:0.8929667519181586 val loss:0.3670539588475433 acc:0.8958695652173913\n",
      "131.96083736419678: train_loss:0.14320226450624285 test_acc:0.9236572890025575 val loss:0.27602814691581373 acc:0.92\n",
      "190.4877471923828: train_loss:0.07849507093362737 test_acc:0.9382352941176471 val loss:0.2321326617972155 acc:0.9328260869565217\n",
      "249.70969796180725: train_loss:0.05569279133561433 test_acc:0.9388746803069054 val loss:0.23117351738542055 acc:0.9378260869565217\n",
      "288.0546040534973: train_loss:0.04489325997350582 test_acc:0.9416879795396419 val loss:0.21585801503348812 acc:0.938695652173913\n",
      "314.7215449810028: train_loss:0.031897960492760356 test_acc:0.9441176470588235 val loss:0.2044953705263588 acc:0.948695652173913\n",
      "0.21121879281437775\n"
     ]
    }
   ],
   "source": [
    "a=ANN([4112,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(100,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.09,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97ccc14d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.16076397895813: train_loss:0.3610211596900865 test_acc:0.8772378516624041 val loss:0.4380539930832572 acc:0.8756521739130435\n",
      "76.46585297584534: train_loss:0.18818353181637534 test_acc:0.9164961636828645 val loss:0.3029515827340974 acc:0.9160869565217391\n",
      "109.5958948135376: train_loss:0.11245989134679582 test_acc:0.931457800511509 val loss:0.24983375247720652 acc:0.928695652173913\n",
      "142.86073684692383: train_loss:0.07419904303116276 test_acc:0.939002557544757 val loss:0.2243831285375406 acc:0.9389130434782609\n",
      "176.07668805122375: train_loss:0.05451811945852207 test_acc:0.9410485933503836 val loss:0.2175851731233941 acc:0.9408695652173913\n",
      "209.36673212051392: train_loss:0.03992116208457885 test_acc:0.9429667519181586 val loss:0.2115691445373178 acc:0.9423913043478261\n",
      "242.7466893196106: train_loss:0.022492660041832344 test_acc:0.948849104859335 val loss:0.19329625449756058 acc:0.9480434782608695\n",
      "275.8405261039734: train_loss:0.01291798225743894 test_acc:0.9514066496163683 val loss:0.18698710003598876 acc:0.95\n",
      "316.37396144866943: train_loss:0.009366462298998162 test_acc:0.9517902813299233 val loss:0.1850477328524821 acc:0.952391304347826\n",
      "0.17999817335831067\n"
     ]
    }
   ],
   "source": [
    "a=ANN([2056,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(100,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.05,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3f9518ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.475953578948975: train_loss:0.32567096806633383 test_acc:0.8873333333333333 val loss:0.40099215435908636 acc:0.8943478260869565\n",
      "76.9208984375: train_loss:0.16286261272132174 test_acc:0.926 val loss:0.2793116249187157 acc:0.9202173913043479\n",
      "108.5098512172699: train_loss:0.10218394900407163 test_acc:0.933 val loss:0.24081555569653681 acc:0.9339130434782609\n",
      "139.27780413627625: train_loss:0.06680309442398752 test_acc:0.9416666666666667 val loss:0.21826236954122769 acc:0.9421739130434783\n",
      "169.76875734329224: train_loss:0.04370842773337474 test_acc:0.9446666666666667 val loss:0.2043726374793081 acc:0.9447826086956522\n",
      "200.807710647583: train_loss:0.0294209301029503 test_acc:0.946 val loss:0.19485465370959154 acc:0.9508695652173913\n",
      "231.48666429519653: train_loss:0.01989515202269364 test_acc:0.9486666666666667 val loss:0.18887721734882904 acc:0.9528260869565217\n",
      "262.635617017746: train_loss:0.011477335484571699 test_acc:0.9503333333333334 val loss:0.17652412525267816 acc:0.9565217391304348\n",
      "288.0175795555115: train_loss:0.0088950812122465 test_acc:0.9513333333333334 val loss:0.17960451352391887 acc:0.9552173913043478\n",
      "291.5415732860565: train_loss:0.00891145130951204 test_acc:0.9516666666666667 val loss:0.17987560648869771 acc:0.955\n",
      "300.3765606880188: train_loss:0.00825782184342004 test_acc:0.9536666666666667 val loss:0.1745621483877855 acc:0.9580434782608696\n",
      "0.1888864028310198\n"
     ]
    }
   ],
   "source": [
    "a=ANN([2056,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(100,100,X[:-3000],y[:-3000],X[-3000:],y[-3000:],.05,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d616e852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.36271381378174: train_loss:0.31638916282488627 test_acc:0.8913043478260869 val loss:0.3957563851023779 acc:0.8930434782608696\n",
      "75.48057961463928: train_loss:0.15834353943793072 test_acc:0.923695652173913 val loss:0.27437673218523884 acc:0.9243478260869565\n",
      "110.17982697486877: train_loss:0.08963922121451945 test_acc:0.9360869565217391 val loss:0.22309822844051658 acc:0.9380434782608695\n",
      "144.69655299186707: train_loss:0.055856968845533476 test_acc:0.9415217391304348 val loss:0.20648595315026752 acc:0.9432608695652174\n",
      "178.37724113464355: train_loss:0.03491401148547181 test_acc:0.9467391304347826 val loss:0.19456294792526263 acc:0.9458695652173913\n",
      "213.31767463684082: train_loss:0.021340736971827794 test_acc:0.9476086956521739 val loss:0.18378407604409575 acc:0.9519565217391305\n",
      "248.07698965072632: train_loss:0.015977084402071916 test_acc:0.9476086956521739 val loss:0.186540600960453 acc:0.9497826086956521\n",
      "283.40035700798035: train_loss:0.011308817680099977 test_acc:0.9493478260869566 val loss:0.1860748320753687 acc:0.9510869565217391\n",
      "288.0289218425751: train_loss:0.009843727518598765 test_acc:0.9521739130434783 val loss:0.1840864348924921 acc:0.9510869565217391\n",
      "292.1813509464264: train_loss:0.009614589614299566 test_acc:0.9526086956521739 val loss:0.18358359561807736 acc:0.9508695652173913\n",
      "327.5231740474701: train_loss:0.005887218409829829 test_acc:0.9541304347826087 val loss:0.1767608275862225 acc:0.9552173913043478\n",
      "0.1836811306473706\n"
     ]
    }
   ],
   "source": [
    "a=ANN([2056,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(100,100,X[:-4600],y[:-4600],X[-4600:],y[-4600:],.06,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c79ca044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:69.24138593673706: train_loss:0.28507074199132143 test_acc:0.8881074168797954 val loss:0.3699993964614538 acc:0.8878260869565218\n",
      "2:135.0524618625641: train_loss:0.14745248405465233 test_acc:0.9251918158567775 val loss:0.2767719780751033 acc:0.9158695652173913\n",
      "3:203.11429905891418: train_loss:0.09038522043145687 test_acc:0.9347826086956522 val loss:0.23647526629260607 acc:0.9332608695652174\n",
      "4:269.9599668979645: train_loss:0.0476625784216795 test_acc:0.9415601023017903 val loss:0.2073131974355972 acc:0.9443478260869566\n",
      "5:342.4302337169647: train_loss:0.03522232466073427 test_acc:0.9470588235294117 val loss:0.21396611583366912 acc:0.9469565217391305\n",
      "0.21792264972152994\n"
     ]
    }
   ],
   "source": [
    "a=ANN([2056,1024,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(100,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.05,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "096fec07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.89926290512085: train_loss:0.10431818219809841 test_acc:0.9080562659846547 val loss:0.340794729671566 acc:0.9108695652173913\n",
      "72.3189685344696: train_loss:0.05966634921443277 test_acc:0.9139386189258312 val loss:0.379033161079445 acc:0.9095652173913044\n",
      "103.4020745754242: train_loss:0.02090885009035843 test_acc:0.9153452685421994 val loss:0.4022986507892415 acc:0.9189130434782609\n",
      "133.53558468818665: train_loss:0.008837360884718719 test_acc:0.9163682864450128 val loss:0.4159753248869036 acc:0.923695652173913\n",
      "163.64719605445862: train_loss:0.005724785595400709 test_acc:0.9187979539641944 val loss:0.43393230039009667 acc:0.9234782608695652\n",
      "194.06693625450134: train_loss:0.004565727839021777 test_acc:0.919309462915601 val loss:0.45636666850320207 acc:0.9247826086956522\n",
      "225.0540895462036: train_loss:0.0038983693465492225 test_acc:0.919309462915601 val loss:0.47677987267917477 acc:0.9254347826086956\n",
      "0.4672875783036417\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_adam(1000,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],8e-3,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a3489f8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.546563148498535: train_loss:0.11087464040553803 test_acc:0.9156010230179028 val loss:0.35497194032422613 acc:0.8958695652173913\n",
      "72.26303672790527: train_loss:0.007188024978275241 test_acc:0.9289002557544757 val loss:0.3153499131649393 acc:0.9247826086956522\n",
      "103.91778349876404: train_loss:0.0035108789652393015 test_acc:0.9289002557544757 val loss:0.333819259536786 acc:0.9291304347826087\n",
      "135.19662141799927: train_loss:0.0029852528640763173 test_acc:0.9289002557544757 val loss:0.34509091985214474 acc:0.93\n",
      "165.9431426525116: train_loss:0.002814976174917824 test_acc:0.9289002557544757 val loss:0.352702007028565 acc:0.9295652173913044\n",
      "197.35965251922607: train_loss:0.0027275233830706376 test_acc:0.9289002557544757 val loss:0.3592447546908421 acc:0.9282608695652174\n",
      "228.5703160762787: train_loss:0.002682261283034257 test_acc:0.9289002557544757 val loss:0.3646032115091804 acc:0.928695652173913\n",
      "259.92398262023926: train_loss:0.0026572408152392996 test_acc:0.9289002557544757 val loss:0.3691543847047892 acc:0.928695652173913\n",
      "265.7599754333496: train_loss:0.0026542925574009673 test_acc:0.9289002557544757 val loss:0.3698515003932225 acc:0.9284782608695652\n",
      "269.1173515319824: train_loss:0.0026529202497308866 test_acc:0.9289002557544757 val loss:0.3701942693603028 acc:0.9282608695652174\n",
      "272.4173471927643: train_loss:0.002651611789434174 test_acc:0.9289002557544757 val loss:0.3705332991709967 acc:0.9282608695652174\n",
      "275.6213421821594: train_loss:0.002650364358909227 test_acc:0.9289002557544757 val loss:0.3708686758466634 acc:0.9282608695652174\n",
      "0.30954070875193185\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,46],0,1024,0)\n",
    "t=10\n",
    "loss=a.fit_rmsprop(750,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],8e-3,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3ce11f46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.07457256317139: train_loss:0.1153549374133409 test_acc:0.9132992327365729 val loss:0.312848888155484 acc:0.9134782608695652\n",
      "75.18223237991333: train_loss:0.030654748434270143 test_acc:0.9269820971867008 val loss:0.2750560930870429 acc:0.9308695652173913\n",
      "107.52529430389404: train_loss:0.011544496406402793 test_acc:0.931841432225064 val loss:0.2726731542645378 acc:0.9317391304347826\n",
      "140.97376656532288: train_loss:0.006276327198359369 test_acc:0.9341432225063938 val loss:0.27408413289256484 acc:0.9358695652173913\n",
      "171.93313908576965: train_loss:0.004571346583124602 test_acc:0.9346547314578005 val loss:0.2794649125594886 acc:0.9371739130434783\n",
      "203.663227558136: train_loss:0.0035295594736820955 test_acc:0.9355498721227622 val loss:0.283557200475558 acc:0.9371739130434783\n",
      "235.1708209514618: train_loss:0.002826980791930811 test_acc:0.9355498721227622 val loss:0.28691427556483584 acc:0.9371739130434783\n",
      "264.51430201530457: train_loss:0.002357970785752178 test_acc:0.9355498721227622 val loss:0.2900543039661289 acc:0.9378260869565217\n",
      "268.810298204422: train_loss:0.0023118916095753207 test_acc:0.9355498721227622 val loss:0.2904253435232969 acc:0.9376086956521739\n",
      "273.39078974723816: train_loss:0.0022660091896677436 test_acc:0.9356777493606138 val loss:0.29077241552464766 acc:0.9378260869565217\n",
      "278.04751777648926: train_loss:0.0022222611370574384 test_acc:0.9361892583120205 val loss:0.2911598565025137 acc:0.9378260869565217\n",
      "282.1961305141449: train_loss:0.0021793638143120363 test_acc:0.9361892583120205 val loss:0.29147110783664054 acc:0.9378260869565217\n",
      "286.33676505088806: train_loss:0.0021410463371973397 test_acc:0.9363171355498722 val loss:0.2918074456712504 acc:0.9380434782608695\n",
      "288.004763841629: train_loss:0.0020406158277841524 test_acc:0.9378516624040921 val loss:0.2917705327887045 acc:0.9360869565217391\n",
      "289.22516560554504: train_loss:0.0020424844345982383 test_acc:0.9379795396419437 val loss:0.29194266952695164 acc:0.9356521739130435\n",
      "293.1971597671509: train_loss:0.00210069667241997 test_acc:0.9382352941176471 val loss:0.2924066809265891 acc:0.935\n",
      "294.29019379615784: train_loss:0.002096906656997698 test_acc:0.9384910485933504 val loss:0.2922283279930266 acc:0.9352173913043478\n",
      "295.0501925945282: train_loss:0.0020963396561557894 test_acc:0.9386189258312021 val loss:0.2921851452006269 acc:0.9352173913043478\n",
      "297.98618721961975: train_loss:0.0021025061205899895 test_acc:0.9386189258312021 val loss:0.2921417362147561 acc:0.9380434782608695\n",
      "302.16218304634094: train_loss:0.0020650406213405326 test_acc:0.9386189258312021 val loss:0.2925370626095714 acc:0.9380434782608695\n",
      "0.2997789970398577\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_nag(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],2e-2,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f297c7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.34117817878723: train_loss:0.27468045039991384 test_acc:0.8778772378516624 val loss:0.42536898729900546 acc:0.8823913043478261\n",
      "77.58846282958984: train_loss:0.19384948157524687 test_acc:0.8850383631713555 val loss:0.41309831713108053 acc:0.8910869565217391\n",
      "111.50620007514954: train_loss:0.15401172876076638 test_acc:0.8850383631713555 val loss:0.4503490034487381 acc:0.8915217391304348\n",
      "142.7453498840332: train_loss:0.13462461897046923 test_acc:0.8860613810741688 val loss:0.4879785365173288 acc:0.8917391304347826\n",
      "185.29615378379822: train_loss:0.12524161069998702 test_acc:0.8860613810741688 val loss:0.5330855258116973 acc:0.8871739130434783\n",
      "228.05610418319702: train_loss:0.11589378248594402 test_acc:0.8860613810741688 val loss:0.5823250053498805 acc:0.8869565217391304\n",
      "271.5781600475311: train_loss:0.11463531304662661 test_acc:0.8860613810741688 val loss:0.6322816296192193 acc:0.8865217391304347\n",
      "285.81313824653625: train_loss:0.11694737196695879 test_acc:0.8860613810741688 val loss:0.6444119640966385 acc:0.8867391304347826\n",
      "305.7645139694214: train_loss:0.11643032049091355 test_acc:0.8860613810741688 val loss:0.660266271182411 acc:0.8869565217391304\n",
      "0.497624749929797\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_nadam(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],8e-3,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7740cd2",
   "metadata": {},
   "source": [
    "# Experiments With Architecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8bbfab54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.47291088104248: train_loss:0.19176146738862815 test_acc:0.9044757033248082 val loss:0.34973870890445047 acc:0.9073913043478261\n",
      "79.65886425971985: train_loss:0.14193743008725376 test_acc:0.9108695652173913 val loss:0.32819198065333594 acc:0.9154347826086957\n",
      "119.16980171203613: train_loss:0.08495978606322958 test_acc:0.9290281329923273 val loss:0.29294482445536785 acc:0.9334782608695652\n",
      "158.70673823356628: train_loss:0.06862308152143834 test_acc:0.9336317135549872 val loss:0.317702261442539 acc:0.9330434782608695\n",
      "199.32466983795166: train_loss:0.054169859014960416 test_acc:0.9372122762148337 val loss:0.36656742336366627 acc:0.9360869565217391\n",
      "230.41061878204346: train_loss:0.07712629852436655 test_acc:0.9387468030690537 val loss:0.3902841925781242 acc:0.9280434782608695\n",
      "269.04755902290344: train_loss:0.09399990750990728 test_acc:0.9387468030690537 val loss:0.4006824232803993 acc:0.9269565217391305\n",
      "279.66954231262207: train_loss:0.04609923752822146 test_acc:0.9387468030690537 val loss:0.369105344437006 acc:0.9397826086956522\n",
      "297.415513753891: train_loss:0.05571540229714557 test_acc:0.9387468030690537 val loss:0.37865566512919513 acc:0.9384782608695652\n",
      "308.3744969367981: train_loss:0.04688004000131459 test_acc:0.9387468030690537 val loss:0.3850515674149817 acc:0.9367391304347826\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,64,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit(50,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.3,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d773d9d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.82794761657715: train_loss:0.19084719356580024 test_acc:0.9012787723785166 val loss:0.3450837435342641 acc:0.9054347826086957\n",
      "79.42789125442505: train_loss:0.06746372833268331 test_acc:0.9258312020460358 val loss:0.2837520133426393 acc:0.9278260869565217\n",
      "113.96383833885193: train_loss:0.02276970697391312 test_acc:0.9351662404092072 val loss:0.2903643661459689 acc:0.9391304347826087\n",
      "144.35479354858398: train_loss:0.004509106102090241 test_acc:0.9432225063938618 val loss:0.2742124044266747 acc:0.9471739130434783\n",
      "180.81573867797852: train_loss:0.0007430282572061838 test_acc:0.94769820971867 val loss:0.2751374498636 acc:0.9480434782608695\n",
      "216.92668223381042: train_loss:0.0005684626871931719 test_acc:0.94846547314578 val loss:0.2840306531984164 acc:0.9478260869565217\n",
      "252.12063121795654: train_loss:0.0004901584534738832 test_acc:0.94846547314578 val loss:0.2897596348081359 acc:0.9478260869565217\n",
      "266.9156084060669: train_loss:0.00046934723552896976 test_acc:0.94846547314578 val loss:0.29163370148450896 acc:0.9478260869565217\n",
      "274.8065960407257: train_loss:0.0004603111085629175 test_acc:0.94846547314578 val loss:0.2925495905253104 acc:0.9480434782608695\n",
      "282.6865882873535: train_loss:0.00045228622169336927 test_acc:0.94846547314578 val loss:0.2934220583126528 acc:0.9482608695652174\n",
      "297.66956543922424: train_loss:0.00044502492795985834 test_acc:0.94846547314578 val loss:0.2942968137126983 acc:0.9482608695652174\n",
      "305.54755330085754: train_loss:0.0004380920922320334 test_acc:0.94846547314578 val loss:0.29512380818822154 acc:0.9482608695652174\n",
      "0.2768073870313778\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,64,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.01,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "65823c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.917006731033325: train_loss:0.41127489231853065 test_acc:0.8687979539641943 val loss:0.4765130495301958 acc:0.8758695652173913\n",
      "88.18719172477722: train_loss:0.2355767709852649 test_acc:0.9099744245524297 val loss:0.3366383204362781 acc:0.9121739130434783\n",
      "120.20163059234619: train_loss:0.15599971345825708 test_acc:0.9210997442455243 val loss:0.2840180438044925 acc:0.9243478260869565\n",
      "150.724769115448: train_loss:0.1141485955558958 test_acc:0.9255754475703325 val loss:0.2637566555286072 acc:0.9280434782608695\n",
      "181.8798725605011: train_loss:0.08325465735359694 test_acc:0.9265984654731457 val loss:0.2490940379719092 acc:0.9315217391304348\n",
      "213.17160868644714: train_loss:0.05340766480489517 test_acc:0.9351662404092072 val loss:0.22841590448521554 acc:0.9397826086956522\n",
      "246.12781238555908: train_loss:0.03556430548184356 test_acc:0.939769820971867 val loss:0.2185281422904139 acc:0.9423913043478261\n",
      "264.1588439941406: train_loss:0.03024596505297454 test_acc:0.9415601023017903 val loss:0.21727651821861713 acc:0.9439130434782609\n",
      "281.53383111953735: train_loss:0.026160402694867694 test_acc:0.9434782608695652 val loss:0.2170871163704247 acc:0.945\n",
      "306.35993456840515: train_loss:0.022894650167864627 test_acc:0.9434782608695652 val loss:0.21713585222494733 acc:0.9460869565217391\n",
      "0.20662628036354672\n"
     ]
    }
   ],
   "source": [
    "a=ANN([1024,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.01,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a5bad4cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.49921631813049: train_loss:0.3105380245777005 test_acc:0.8831202046035805 val loss:0.40883912221665575 acc:0.8804347826086957\n",
      "80.31079959869385: train_loss:0.1657357182208851 test_acc:0.9104859335038363 val loss:0.3186552269744593 acc:0.9108695652173913\n",
      "114.08378386497498: train_loss:0.0805198854007733 test_acc:0.9286445012787724 val loss:0.270501190336825 acc:0.9282608695652174\n",
      "150.0311357975006: train_loss:0.05564888767637494 test_acc:0.9294117647058824 val loss:0.26318511307164916 acc:0.9321739130434783\n",
      "184.1056945323944: train_loss:0.046672214982333364 test_acc:0.9355498721227622 val loss:0.2998708789752177 acc:0.9343478260869565\n",
      "217.47676825523376: train_loss:0.006215849141663356 test_acc:0.948849104859335 val loss:0.24178839649717226 acc:0.9493478260869566\n",
      "250.28018021583557: train_loss:0.0019036663818992486 test_acc:0.9506393861892584 val loss:0.2443670044433574 acc:0.9506521739130435\n",
      "272.96229219436646: train_loss:0.0013526572814701672 test_acc:0.9510230179028133 val loss:0.2510708761821535 acc:0.9517391304347826\n",
      "285.2960066795349: train_loss:0.0012175185715194675 test_acc:0.9510230179028133 val loss:0.25370889634600696 acc:0.9517391304347826\n",
      "304.43254685401917: train_loss:0.0011151018810023916 test_acc:0.9510230179028133 val loss:0.2559552032561638 acc:0.9521739130434783\n",
      "0.25788845843049074\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,512,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.01,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97f07329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.92864441871643: train_loss:0.18263682245140028 test_acc:0.9021739130434783 val loss:0.39328123364959644 acc:0.8895652173913043\n",
      "74.5399100780487: train_loss:0.09335717390313365 test_acc:0.9171355498721228 val loss:0.39099295040064375 acc:0.9139130434782609\n",
      "105.13591432571411: train_loss:0.0355176794096262 test_acc:0.9292838874680307 val loss:0.3821457737530466 acc:0.926304347826087\n",
      "135.6523745059967: train_loss:0.017741777011358106 test_acc:0.9332480818414323 val loss:0.3812161186395822 acc:0.9356521739130435\n",
      "166.34570217132568: train_loss:0.00978720916073081 test_acc:0.9365728900255754 val loss:0.4200164081230529 acc:0.9360869565217391\n",
      "197.0086634159088: train_loss:0.017678937207059663 test_acc:0.9383631713554987 val loss:0.4531469524172703 acc:0.9302173913043478\n",
      "227.70532321929932: train_loss:0.023839650410977326 test_acc:0.9383631713554987 val loss:0.4844976224217421 acc:0.9271739130434783\n",
      "258.1768400669098: train_loss:0.0004290991357458417 test_acc:0.9452685421994885 val loss:0.40792060743254904 acc:0.9445652173913044\n",
      "267.57451915740967: train_loss:0.00034771873722518336 test_acc:0.9452685421994885 val loss:0.4078768817602858 acc:0.9456521739130435\n",
      "272.8465130329132: train_loss:0.0003406422245872124 test_acc:0.9452685421994885 val loss:0.40945129249477386 acc:0.9456521739130435\n",
      "278.0705029964447: train_loss:0.0003359197934072183 test_acc:0.9452685421994885 val loss:0.41098241882314757 acc:0.9456521739130435\n",
      "283.23049426078796: train_loss:0.0003326297828647584 test_acc:0.9452685421994885 val loss:0.41240177859242155 acc:0.9458695652173913\n",
      "292.4559416770935: train_loss:0.00033007803128400553 test_acc:0.9452685421994885 val loss:0.4137382351538448 acc:0.9458695652173913\n",
      "299.4759306907654: train_loss:0.0003280850669311091 test_acc:0.9452685421994885 val loss:0.4149649228302305 acc:0.9458695652173913\n",
      "0.41626801183193773\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,128,256,128,64,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.01,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "11a45ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.05595326423645: train_loss:0.13969006541728313 test_acc:0.9132992327365729 val loss:0.3289942777009638 acc:0.9110869565217391\n",
      "77.03307914733887: train_loss:0.059864478080335466 test_acc:0.9257033248081842 val loss:0.35930738821854163 acc:0.9232608695652174\n",
      "111.03222751617432: train_loss:0.017096907049738184 test_acc:0.9364450127877237 val loss:0.3716435099196049 acc:0.9330434782608695\n",
      "141.0550172328949: train_loss:0.0014214886576775576 test_acc:0.9479539641943734 val loss:0.3495997731567689 acc:0.9441304347826087\n",
      "175.05461883544922: train_loss:0.0005394945310253137 test_acc:0.949616368286445 val loss:0.3665529463592259 acc:0.9454347826086956\n",
      "209.14695191383362: train_loss:0.0004644095913548144 test_acc:0.949616368286445 val loss:0.37794177267730406 acc:0.9445652173913044\n",
      "239.34978795051575: train_loss:0.00043136535143561456 test_acc:0.949616368286445 val loss:0.38469256668612145 acc:0.9456521739130435\n",
      "264.97272658348083: train_loss:0.00041353033575351614 test_acc:0.949616368286445 val loss:0.3892798801297995 acc:0.946304347826087\n",
      "270.01309847831726: train_loss:0.00041110475794382226 test_acc:0.949616368286445 val loss:0.38995759860901863 acc:0.9460869565217391\n",
      "275.0614972114563: train_loss:0.00040877003329894615 test_acc:0.949616368286445 val loss:0.39058686149636085 acc:0.9458695652173913\n",
      "280.1219313144684: train_loss:0.00040676227986469356 test_acc:0.949616368286445 val loss:0.391261842511369 acc:0.9458695652173913\n",
      "285.23840856552124: train_loss:0.00040443485520584376 test_acc:0.949616368286445 val loss:0.3918775966185754 acc:0.9458695652173913\n",
      "297.29147934913635: train_loss:0.0004026294431272822 test_acc:0.949616368286445 val loss:0.39250904084082744 acc:0.9458695652173913\n",
      "302.2838444709778: train_loss:0.00040063937885795824 test_acc:0.949616368286445 val loss:0.39311701083520284 acc:0.9458695652173913\n",
      "0.3094418577033559\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,128,256,128,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.01,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab47c7b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.40791320800781: train_loss:0.42277894174166764 test_acc:0.8480818414322251 val loss:0.5126006176354457 acc:0.8552173913043478\n",
      "87.7118992805481: train_loss:0.21842451859309764 test_acc:0.8879795396419438 val loss:0.3852807350303759 acc:0.8893478260869565\n",
      "127.9761803150177: train_loss:0.11591946399753598 test_acc:0.9135549872122762 val loss:0.3283117312584686 acc:0.9130434782608695\n",
      "168.32944703102112: train_loss:0.07875942694631981 test_acc:0.9254475703324808 val loss:0.2995744550833555 acc:0.9228260869565217\n",
      "208.55870413780212: train_loss:0.0357228781143441 test_acc:0.9315856777493606 val loss:0.2893856147819876 acc:0.935\n",
      "248.77161264419556: train_loss:0.036473020024979375 test_acc:0.9327365728900255 val loss:0.31374912124639853 acc:0.931304347826087\n",
      "270.50874853134155: train_loss:0.019076261476553846 test_acc:0.9361892583120205 val loss:0.2962700136854112 acc:0.936304347826087\n",
      "290.0964834690094: train_loss:0.01716341519958125 test_acc:0.9369565217391305 val loss:0.2889385890612051 acc:0.9402173913043478\n",
      "293.5650942325592: train_loss:0.015279490632910151 test_acc:0.9395140664961636 val loss:0.27995570416729104 acc:0.9419565217391305\n",
      "301.0061240196228: train_loss:0.01685806756940273 test_acc:0.9395140664961636 val loss:0.30036996427524476 acc:0.9373913043478261\n",
      "0.2867636033197009\n"
     ]
    }
   ],
   "source": [
    "a=ANN([1024,512,256,128,64,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.01,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7cf1d1e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.57294821739197: train_loss:0.1796797787483442 test_acc:0.9058823529411765 val loss:0.3298823051760812 acc:0.9082608695652173\n",
      "81.39089274406433: train_loss:0.11414935408156233 test_acc:0.9202046035805627 val loss:0.38292789840970964 acc:0.9119565217391304\n",
      "116.37184143066406: train_loss:0.028298479282018802 test_acc:0.9367007672634271 val loss:0.3100015717671789 acc:0.9321739130434783\n",
      "152.8537871837616: train_loss:0.003323510502790771 test_acc:0.9441176470588235 val loss:0.29066796765553754 acc:0.9458695652173913\n",
      "189.12273335456848: train_loss:0.0005840333661155511 test_acc:0.94769820971867 val loss:0.2997047249594942 acc:0.9458695652173913\n",
      "219.82368803024292: train_loss:0.0004457476740783466 test_acc:0.9483375959079284 val loss:0.30680855420125946 acc:0.945\n",
      "254.90063643455505: train_loss:0.0003639169793008708 test_acc:0.9483375959079284 val loss:0.3130846877794576 acc:0.9460869565217391\n",
      "269.5056140422821: train_loss:0.0003420105473684642 test_acc:0.9483375959079284 val loss:0.31513752795565186 acc:0.9469565217391305\n",
      "277.549604177475: train_loss:0.0003321796093012731 test_acc:0.9483375959079284 val loss:0.3161179888508584 acc:0.9467391304347826\n",
      "285.491592168808: train_loss:0.0003233367337320932 test_acc:0.9483375959079284 val loss:0.3170363703119591 acc:0.9465217391304348\n",
      "288.0005898475647: train_loss:0.0003134602789544787 test_acc:0.948849104859335 val loss:0.3182836794613192 acc:0.9469565217391305\n",
      "291.0775842666626: train_loss:0.0003136980602544263 test_acc:0.9489769820971867 val loss:0.3182817193858599 acc:0.9467391304347826\n",
      "292.6755828857422: train_loss:0.0003135765185899149 test_acc:0.9491048593350384 val loss:0.3182650733819154 acc:0.9469565217391305\n",
      "295.0166997909546: train_loss:0.0003135595288044142 test_acc:0.94923273657289 val loss:0.3182591831765166 acc:0.9469565217391305\n",
      "301.82770109176636: train_loss:0.0003156011669681965 test_acc:0.94923273657289 val loss:0.3179620304131683 acc:0.9469565217391305\n",
      "0.28835153441231043\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,128,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.01,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "480e56d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.99072051048279: train_loss:0.16868984484848681 test_acc:0.9097186700767264 val loss:0.31995765494570316 acc:0.9063043478260869\n",
      "73.42544388771057: train_loss:0.08669732154331952 test_acc:0.9250639386189259 val loss:0.3094399223323513 acc:0.9252173913043479\n",
      "105.76535606384277: train_loss:0.03919317596558535 test_acc:0.9356777493606138 val loss:0.29352202123856674 acc:0.9341304347826087\n",
      "138.20045733451843: train_loss:0.025982386948331805 test_acc:0.9379795396419437 val loss:0.27412895753816147 acc:0.9441304347826087\n",
      "170.50446677207947: train_loss:0.018375166848529235 test_acc:0.9414322250639386 val loss:0.3330124252655081 acc:0.9415217391304348\n",
      "202.84794902801514: train_loss:0.013394854506498159 test_acc:0.9437340153452686 val loss:0.29935172204676 acc:0.9430434782608695\n",
      "235.13612270355225: train_loss:0.006049070970172094 test_acc:0.9460358056265985 val loss:0.3031988643970789 acc:0.9480434782608695\n",
      "267.47882175445557: train_loss:0.0069529734301575505 test_acc:0.9478260869565217 val loss:0.31819417860227556 acc:0.947391304347826\n",
      "276.6196098327637: train_loss:0.007493765376698362 test_acc:0.9478260869565217 val loss:0.33962074939579406 acc:0.9489130434782609\n",
      "285.6685836315155: train_loss:0.0039881629230630045 test_acc:0.9478260869565217 val loss:0.2967476319520776 acc:0.9547826086956521\n",
      "288.01257944107056: train_loss:0.00127235304970289 test_acc:0.9514066496163683 val loss:0.28374729071899324 acc:0.9530434782608695\n",
      "289.73257851600647: train_loss:0.0012566575155537204 test_acc:0.9516624040920716 val loss:0.28343226803261623 acc:0.9530434782608695\n",
      "292.06857466697693: train_loss:0.0012009754474485471 test_acc:0.9517902813299233 val loss:0.2820403645060832 acc:0.9528260869565217\n",
      "294.09741973876953: train_loss:0.0011641425241551344 test_acc:0.951918158567775 val loss:0.28116606459656807 acc:0.9528260869565217\n",
      "302.45386004447937: train_loss:0.0005040902171137958 test_acc:0.9528132992327366 val loss:0.2629606247795215 acc:0.9569565217391305\n",
      "0.29327061398869214\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,128,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.02,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bd4715e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.081953287124634: train_loss:0.16496862947134014 test_acc:0.9093333333333333 val loss:0.32871099466151243 acc:0.9130434782608695\n",
      "71.8319034576416: train_loss:0.07303015477463039 test_acc:0.9276666666666666 val loss:0.318901439689024 acc:0.9271739130434783\n",
      "104.20485544204712: train_loss:0.036603412523440924 test_acc:0.9363333333333334 val loss:0.30283446131944014 acc:0.9393478260869565\n",
      "137.40031790733337: train_loss:0.021100356305079084 test_acc:0.9443333333333334 val loss:0.2872399775875575 acc:0.9404347826086956\n",
      "170.298269033432: train_loss:0.016533412284951064 test_acc:0.9443333333333334 val loss:0.34056767860403003 acc:0.9421739130434783\n",
      "201.7262225151062: train_loss:0.014208477862478862 test_acc:0.9443333333333334 val loss:0.2953918597318869 acc:0.9445652173913044\n",
      "233.9071786403656: train_loss:0.0030428821456885686 test_acc:0.9493333333333334 val loss:0.31919569727331754 acc:0.9491304347826087\n",
      "265.66612911224365: train_loss:0.00014132492437420724 test_acc:0.9513333333333334 val loss:0.2906683867346014 acc:0.9545652173913044\n",
      "275.40011715888977: train_loss:0.00012488938997808462 test_acc:0.952 val loss:0.2923081638953708 acc:0.9543478260869566\n",
      "285.3421013355255: train_loss:0.00011425834709129905 test_acc:0.952 val loss:0.2938509107371141 acc:0.9547826086956521\n",
      "288.0010974407196: train_loss:0.0001121535483587856 test_acc:0.953 val loss:0.294190103815669 acc:0.9545652173913044\n",
      "300.8820803165436: train_loss:0.00010635777005033865 test_acc:0.9533333333333334 val loss:0.29529092932838635 acc:0.9547826086956521\n",
      "0.32590753660438965\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,128,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-3000],y[:-3000],X[-3000:],y[-3000:],.02,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "26b58cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.95992565155029: train_loss:0.12412107190841198 test_acc:0.9186700767263427 val loss:0.31156829886527043 acc:0.9121739130434783\n",
      "78.79885077476501: train_loss:0.051540890734467285 test_acc:0.931457800511509 val loss:0.28756910812543807 acc:0.9304347826086956\n",
      "113.53880167007446: train_loss:0.026691653250763926 test_acc:0.9429667519181586 val loss:0.3140425681035258 acc:0.9389130434782609\n",
      "148.61378574371338: train_loss:0.02795752607744958 test_acc:0.9451406649616368 val loss:0.36482713614487283 acc:0.9371739130434783\n",
      "183.63577914237976: train_loss:0.019284409513587644 test_acc:0.9451406649616368 val loss:0.33162678047980854 acc:0.9441304347826087\n",
      "220.62057757377625: train_loss:0.0063192580817191535 test_acc:0.94769820971867 val loss:0.331605088757638 acc:0.9489130434782609\n",
      "256.33756589889526: train_loss:0.011063150505148132 test_acc:0.94769820971867 val loss:0.37016355108915716 acc:0.946304347826087\n",
      "264.35750365257263: train_loss:0.012924507835683833 test_acc:0.94769820971867 val loss:0.3598193724304136 acc:0.9447826086956522\n",
      "272.390474319458: train_loss:0.02042904519375283 test_acc:0.94769820971867 val loss:0.3933845906403893 acc:0.938695652173913\n",
      "280.32142758369446: train_loss:0.018230104351601543 test_acc:0.94769820971867 val loss:0.38866053707387155 acc:0.9447826086956522\n",
      "288.20138931274414: train_loss:0.01706543397047881 test_acc:0.94769820971867 val loss:0.3330773127154262 acc:0.9428260869565217\n",
      "301.8773684501648: train_loss:0.01587052435503006 test_acc:0.94769820971867 val loss:0.3324792024201493 acc:0.9406521739130435\n",
      "0.33071566484829007\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,128,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.03,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5565a08a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.4821982383728: train_loss:0.1953169856007383 test_acc:0.9058823529411765 val loss:0.3456525543027837 acc:0.9034782608695652\n",
      "74.49162292480469: train_loss:0.07334036958449709 test_acc:0.9285166240409207 val loss:0.29144766359792873 acc:0.9256521739130434\n",
      "107.27178192138672: train_loss:0.020507256421982548 test_acc:0.9420716112531969 val loss:0.2587719333704231 acc:0.9397826086956522\n",
      "140.25158262252808: train_loss:0.003589813808538389 test_acc:0.9510230179028133 val loss:0.2521024248866194 acc:0.9465217391304348\n",
      "173.20758271217346: train_loss:0.0008542498565637495 test_acc:0.9540920716112532 val loss:0.25428812256040106 acc:0.9508695652173913\n",
      "206.17899990081787: train_loss:0.0006454728529170661 test_acc:0.9542199488491049 val loss:0.2605393134547744 acc:0.9515217391304348\n",
      "238.92146372795105: train_loss:0.000550063604174286 test_acc:0.9542199488491049 val loss:0.2650973469355215 acc:0.9517391304347826\n",
      "271.92225098609924: train_loss:0.0004910141034548838 test_acc:0.9542199488491049 val loss:0.2687140893478332 acc:0.951304347826087\n",
      "281.395277261734: train_loss:0.0004797542047120595 test_acc:0.9542199488491049 val loss:0.269505397334243 acc:0.951304347826087\n",
      "288.01565861701965: train_loss:0.00046226485228147396 test_acc:0.9549872122762149 val loss:0.2686356473613991 acc:0.9517391304347826\n",
      "290.3642382621765: train_loss:0.0004621884192716946 test_acc:0.9551150895140665 val loss:0.2685880469212208 acc:0.9517391304347826\n",
      "297.77272605895996: train_loss:0.00046914740261618675 test_acc:0.9551150895140665 val loss:0.27030145475167106 acc:0.9510869565217391\n",
      "307.1137568950653: train_loss:0.00045968531656841866 test_acc:0.9551150895140665 val loss:0.27103433649637826 acc:0.9510869565217391\n",
      "0.24766291352774805\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.02,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1554b00e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.64327359199524: train_loss:0.2332620987634109 test_acc:0.8965473145780051 val loss:0.3628071144208353 acc:0.8932608695652174\n",
      "75.69082045555115: train_loss:0.11916599067660678 test_acc:0.9251918158567775 val loss:0.2955916100084705 acc:0.9132608695652173\n",
      "111.38012528419495: train_loss:0.05563229694561047 test_acc:0.9301790281329924 val loss:0.26450241726910917 acc:0.933695652173913\n",
      "147.5569453239441: train_loss:0.015360137216163658 test_acc:0.9439897698209718 val loss:0.24421590168182805 acc:0.9430434782608695\n",
      "182.98660707473755: train_loss:0.003794724508541884 test_acc:0.950383631713555 val loss:0.2288504531667525 acc:0.951304347826087\n",
      "218.03302311897278: train_loss:0.001638222420652297 test_acc:0.9535805626598466 val loss:0.2325209066461335 acc:0.9545652173913044\n",
      "252.7469732761383: train_loss:0.0010821558923690396 test_acc:0.9535805626598466 val loss:0.24056577092746767 acc:0.9543478260869566\n",
      "265.7082440853119: train_loss:0.0010473493032529878 test_acc:0.9535805626598466 val loss:0.2423692007415571 acc:0.9543478260869566\n",
      "277.2297818660736: train_loss:0.0010218689134795715 test_acc:0.9535805626598466 val loss:0.24398592235290198 acc:0.9543478260869566\n",
      "289.17677068710327: train_loss:0.0010017420593660098 test_acc:0.9535805626598466 val loss:0.24537647466045923 acc:0.9541304347826087\n",
      "304.3827464580536: train_loss:0.0009871476751946303 test_acc:0.9535805626598466 val loss:0.24664387808291183 acc:0.9539130434782609\n",
      "0.22990410547073659\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(200,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.03,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33e73d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.4039409160614: train_loss:0.11436793984406049 test_acc:0.9267391304347826 val loss:0.2799860269975428 acc:0.9232608695652174\n",
      "75.92689061164856: train_loss:0.04034812916379725 test_acc:0.9410869565217391 val loss:0.2624130386392817 acc:0.9410869565217391\n",
      "109.57883882522583: train_loss:0.00475942354466963 test_acc:0.953695652173913 val loss:0.23688297804160405 acc:0.9515217391304348\n",
      "143.54989075660706: train_loss:0.0004123258930839416 test_acc:0.9580434782608696 val loss:0.2371463244625777 acc:0.9578260869565217\n",
      "179.52984189987183: train_loss:0.0002647787548149624 test_acc:0.9580434782608696 val loss:0.24566424987487825 acc:0.9576086956521739\n",
      "210.45980978012085: train_loss:0.0002134846977379771 test_acc:0.9586956521739131 val loss:0.2497513500542939 acc:0.9580434782608696\n",
      "245.50075721740723: train_loss:0.00017440113572679905 test_acc:0.9591304347826087 val loss:0.2535047286708873 acc:0.9584782608695652\n",
      "265.75472831726074: train_loss:0.00015777360948021263 test_acc:0.9591304347826087 val loss:0.2554186605626044 acc:0.9586956521739131\n",
      "273.4907171726227: train_loss:0.0001529854820471906 test_acc:0.9591304347826087 val loss:0.25600848171796214 acc:0.9586956521739131\n",
      "281.15370988845825: train_loss:0.0001485102143023933 test_acc:0.9591304347826087 val loss:0.2566004297578191 acc:0.9586956521739131\n",
      "295.2136881351471: train_loss:0.00014431090181358662 test_acc:0.9591304347826087 val loss:0.25717005554341626 acc:0.9584782608695652\n",
      "302.98968172073364: train_loss:0.00014036573326416845 test_acc:0.9591304347826087 val loss:0.2577417744198698 acc:0.9584782608695652\n",
      "0.24194163786480025\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(200,100,X[:-4600],y[:-4600],X[-4600:],y[-4600:],.03,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1b9d5701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.409884214401245: train_loss:0.12829757955840818 test_acc:0.9293478260869565 val loss:0.26738867291073515 acc:0.9228260869565217\n",
      "71.41286134719849: train_loss:0.06916113035050046 test_acc:0.936304347826087 val loss:0.2754044208840598 acc:0.927608695652174\n",
      "102.57964372634888: train_loss:0.03755930245413452 test_acc:0.9389130434782609 val loss:0.28874733440401545 acc:0.9330434782608695\n",
      "133.9258165359497: train_loss:0.00402313680442555 test_acc:0.9508695652173913 val loss:0.23318355972404364 acc:0.9517391304347826\n",
      "165.23503160476685: train_loss:0.00042005149832913594 test_acc:0.9571739130434782 val loss:0.23372000658881564 acc:0.9556521739130435\n",
      "195.97104024887085: train_loss:0.0002878701687416236 test_acc:0.9576086956521739 val loss:0.24118928137138096 acc:0.9571739130434782\n",
      "227.56770610809326: train_loss:0.0002271951593885984 test_acc:0.9576086956521739 val loss:0.24623369689866176 acc:0.9578260869565217\n",
      "258.68665409088135: train_loss:0.00019031215249189925 test_acc:0.9576086956521739 val loss:0.24999081140317547 acc:0.9576086956521739\n",
      "267.59160327911377: train_loss:0.00018313277971417544 test_acc:0.9578260869565217 val loss:0.25080313740541993 acc:0.9578260869565217\n",
      "276.3794014453888: train_loss:0.00017654641644040045 test_acc:0.9578260869565217 val loss:0.2515637632129445 acc:0.9576086956521739\n",
      "285.537645816803: train_loss:0.00017046244806957233 test_acc:0.9584782608695652 val loss:0.25229096494461445 acc:0.9578260869565217\n",
      "301.17390489578247: train_loss:0.00016483524759582202 test_acc:0.9584782608695652 val loss:0.25298648348660485 acc:0.9578260869565217\n",
      "0.25216470257046963\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(200,100,X[:-4600],y[:-4600],X[-4600:],y[-4600:],.03,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "297db691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.56695079803467: train_loss:0.09554930801234618 test_acc:0.9323333333333333 val loss:0.25019959801270847 acc:0.9282608695652174\n",
      "76.48290014266968: train_loss:0.03781283831516697 test_acc:0.9403333333333334 val loss:0.251778954655288 acc:0.9380434782608695\n",
      "110.31585049629211: train_loss:0.0093439896179738 test_acc:0.948 val loss:0.24439797618052828 acc:0.9454347826086956\n",
      "146.4455258846283: train_loss:0.00039804466274266713 test_acc:0.9533333333333334 val loss:0.22383631567390813 acc:0.9565217391304348\n",
      "179.3161907196045: train_loss:0.0002810947921482433 test_acc:0.9533333333333334 val loss:0.22903411618645064 acc:0.9569565217391305\n",
      "210.7321436405182: train_loss:0.00022427390987310417 test_acc:0.9533333333333334 val loss:0.23318318524628065 acc:0.9569565217391305\n",
      "246.1370975971222: train_loss:0.0001815996507514041 test_acc:0.954 val loss:0.2372024738914938 acc:0.9565217391304348\n",
      "269.48506116867065: train_loss:0.00016369263350073018 test_acc:0.954 val loss:0.2392531959448399 acc:0.9565217391304348\n",
      "278.9550504684448: train_loss:0.00015853727943457023 test_acc:0.954 val loss:0.23987372263863652 acc:0.9565217391304348\n",
      "287.95014452934265: train_loss:0.00015373194016589576 test_acc:0.9543333333333334 val loss:0.24048597766420546 acc:0.9565217391304348\n",
      "291.3481397628784: train_loss:0.0001534440008413179 test_acc:0.9546666666666667 val loss:0.2406662776542511 acc:0.956304347826087\n",
      "301.9111223220825: train_loss:0.00014923778767953608 test_acc:0.9546666666666667 val loss:0.2410988717686516 acc:0.9565217391304348\n",
      "0.29838935558058\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(200,100,X[:-3000],y[:-3000],X[-3000:],y[-3000:],.03,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e8f3e5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.875457763671875: train_loss:0.2379354841598592 test_acc:0.9080562659846547 val loss:0.3378465176933245 acc:0.9043478260869565\n",
      "80.06733798980713: train_loss:0.09936203662660663 test_acc:0.9350383631713555 val loss:0.24445117441031208 acc:0.9308695652173913\n",
      "119.85888504981995: train_loss:0.06488108469035558 test_acc:0.9364450127877237 val loss:0.24668046734821675 acc:0.9302173913043478\n",
      "160.36369061470032: train_loss:0.024026858619412058 test_acc:0.9428388746803069 val loss:0.20999714349337614 acc:0.9423913043478261\n",
      "201.01279067993164: train_loss:0.011735644381758954 test_acc:0.9474424552429668 val loss:0.20586895089746501 acc:0.9484782608695652\n",
      "242.05000591278076: train_loss:0.005909021511908479 test_acc:0.9480818414322251 val loss:0.203259152399204 acc:0.9508695652173913\n",
      "270.1389191150665: train_loss:0.004505887988859828 test_acc:0.94846547314578 val loss:0.2049297373277337 acc:0.952391304347826\n",
      "285.41789722442627: train_loss:0.0040850082748103604 test_acc:0.9491048593350384 val loss:0.2058007202970537 acc:0.9526086956521739\n",
      "288.02289295196533: train_loss:0.004370288751436994 test_acc:0.9493606138107417 val loss:0.20817126904729027 acc:0.951304347826087\n",
      "291.21760153770447: train_loss:0.0044375554412571785 test_acc:0.9494884910485933 val loss:0.20888548827638753 acc:0.9510869565217391\n",
      "293.83979892730713: train_loss:0.004466729564220229 test_acc:0.9501278772378516 val loss:0.20932354665179967 acc:0.9504347826086956\n",
      "308.36661529541016: train_loss:0.0037559035758774704 test_acc:0.9501278772378516 val loss:0.20677308054313645 acc:0.9530434782608695\n",
      "0.210130714568816\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,512,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.02,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b43ae19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.38194966316223: train_loss:0.16128149638774195 test_acc:0.9239130434782609 val loss:0.2784238868741365 acc:0.917608695652174\n",
      "75.81388783454895: train_loss:0.06838508760089507 test_acc:0.9360869565217391 val loss:0.24055884399359273 acc:0.9339130434782609\n",
      "109.38483381271362: train_loss:0.028103206940178524 test_acc:0.9460869565217391 val loss:0.2244332071871174 acc:0.9417391304347826\n",
      "143.23877549171448: train_loss:0.008926009013080211 test_acc:0.9480434782608695 val loss:0.2149175423163724 acc:0.9489130434782609\n",
      "178.23272228240967: train_loss:0.004389468409952323 test_acc:0.9508695652173913 val loss:0.2150540959374948 acc:0.9508695652173913\n",
      "211.24367237091064: train_loss:0.0030148425132350857 test_acc:0.9521739130434783 val loss:0.21644434458692147 acc:0.9519565217391305\n",
      "244.462628364563: train_loss:0.0023737799015236326 test_acc:0.9532608695652174 val loss:0.21870611625968836 acc:0.9521739130434783\n",
      "270.02058959007263: train_loss:0.002078452337899832 test_acc:0.9532608695652174 val loss:0.22064739877725822 acc:0.9521739130434783\n",
      "280.1795747280121: train_loss:0.0019997233425342134 test_acc:0.9532608695652174 val loss:0.22125235252278466 acc:0.9517391304347826\n",
      "296.23255133628845: train_loss:0.0019289575399079424 test_acc:0.9532608695652174 val loss:0.2218422423772622 acc:0.9521739130434783\n",
      "305.38753747940063: train_loss:0.0018635223376345207 test_acc:0.9532608695652174 val loss:0.2224450589228572 acc:0.9521739130434783\n",
      "0.21058203851147003\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,512,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-4600],y[:-4600],X[-4600:],y[-4600:],.02,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f5404536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.36293387413025: train_loss:0.18073683461139037 test_acc:0.9158567774936062 val loss:0.29994761000352543 acc:0.917608695652174\n",
      "80.08662033081055: train_loss:0.07343919031209581 test_acc:0.9319693094629156 val loss:0.24487209205059868 acc:0.9330434782608695\n",
      "115.94376254081726: train_loss:0.030021680969168033 test_acc:0.9383631713554987 val loss:0.23602869616431443 acc:0.9426086956521739\n",
      "151.9185085296631: train_loss:0.009145063295632763 test_acc:0.9464194373401534 val loss:0.2209876589947629 acc:0.9491304347826087\n",
      "187.9098629951477: train_loss:0.004126240144564174 test_acc:0.94693094629156 val loss:0.21699673457490398 acc:0.9530434782608695\n",
      "223.6702573299408: train_loss:0.002921495562653962 test_acc:0.94769820971867 val loss:0.2210010098329331 acc:0.9530434782608695\n",
      "259.717764377594: train_loss:0.0022997021478676685 test_acc:0.94769820971867 val loss:0.22487996078369504 acc:0.953695652173913\n",
      "269.83374857902527: train_loss:0.002181011450072151 test_acc:0.9478260869565217 val loss:0.2257359811221315 acc:0.953695652173913\n",
      "279.95174741744995: train_loss:0.0020725765222446525 test_acc:0.9478260869565217 val loss:0.2265111419025918 acc:0.9539130434782609\n",
      "288.0002772808075: train_loss:0.0019499081025427826 test_acc:0.9485933503836317 val loss:0.22618488226000177 acc:0.9543478260869566\n",
      "290.23266983032227: train_loss:0.001952099905696576 test_acc:0.9487212276214834 val loss:0.22623437269876348 acc:0.9541304347826087\n",
      "297.1652572154999: train_loss:0.0019743352973725634 test_acc:0.9487212276214834 val loss:0.22725197776856623 acc:0.9543478260869566\n",
      "307.2901072502136: train_loss:0.0018845460846510522 test_acc:0.9487212276214834 val loss:0.22796136353756952 acc:0.9545652173913044\n",
      "0.22026696953228603\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,512,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.02,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "298627a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.56820869445801: train_loss:0.46839543025487 test_acc:0.8521739130434782 val loss:0.5321649925856171 acc:0.8586956521739131\n",
      "75.40152406692505: train_loss:0.24763896760263113 test_acc:0.9057544757033248 val loss:0.3472491458647032 acc:0.9010869565217391\n",
      "107.80459690093994: train_loss:0.15808120247284785 test_acc:0.9239130434782609 val loss:0.2806855102580965 acc:0.9147826086956522\n",
      "139.05158138275146: train_loss:0.11348945709924026 test_acc:0.9301790281329924 val loss:0.25549075899830925 acc:0.9230434782608695\n",
      "187.43898558616638: train_loss:0.05976339194172702 test_acc:0.9401534526854219 val loss:0.22430726250199096 acc:0.9373913043478261\n",
      "232.6249144077301: train_loss:0.030762385360820942 test_acc:0.9427109974424552 val loss:0.21847761290936232 acc:0.9410869565217391\n",
      "276.3908483982086: train_loss:0.010790640977519039 test_acc:0.9516624040920716 val loss:0.1951807697899671 acc:0.9521739130434783\n",
      "307.03080201148987: train_loss:0.006996356884959013 test_acc:0.9526854219948849 val loss:0.19340143313921251 acc:0.952391304347826\n",
      "0.1825694636090151\n"
     ]
    }
   ],
   "source": [
    "a=ANN([1024,1024,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.03,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d4f8819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.38517928123474: train_loss:0.27111940133239576 test_acc:0.8936061381074168 val loss:0.3676677291522402 acc:0.8917391304347826\n",
      "75.18897867202759: train_loss:0.1089062633880117 test_acc:0.9274936061381074 val loss:0.26076186067548496 acc:0.9260869565217391\n",
      "108.69157195091248: train_loss:0.05978080037016671 test_acc:0.931457800511509 val loss:0.25997599953813105 acc:0.9328260869565217\n",
      "141.51609706878662: train_loss:0.04069353150692223 test_acc:0.9337595907928389 val loss:0.2787972916490774 acc:0.9347826086956522\n",
      "174.39516353607178: train_loss:0.011477495106889554 test_acc:0.9416879795396419 val loss:0.2571441511393191 acc:0.9432608695652174\n",
      "207.15118718147278: train_loss:0.0034230325472409382 test_acc:0.9456521739130435 val loss:0.25246862800514397 acc:0.9471739130434783\n",
      "239.87031841278076: train_loss:0.002221499662185178 test_acc:0.9464194373401534 val loss:0.2563379630784779 acc:0.9476086956521739\n",
      "264.97727704048157: train_loss:0.0018342210042716002 test_acc:0.94693094629156 val loss:0.2596139060989099 acc:0.9476086956521739\n",
      "274.1946368217468: train_loss:0.0017346291454280128 test_acc:0.9470588235294117 val loss:0.2606349950081342 acc:0.9482608695652174\n",
      "283.5117623806: train_loss:0.0016469154739282446 test_acc:0.9471867007672634 val loss:0.26155543850217294 acc:0.9482608695652174\n",
      "288.00877833366394: train_loss:0.0015831008801243983 test_acc:0.9478260869565217 val loss:0.25851431314104634 acc:0.9476086956521739\n",
      "290.32941722869873: train_loss:0.001576583342247333 test_acc:0.9480818414322251 val loss:0.25822894422004095 acc:0.9482608695652174\n",
      "299.84579706192017: train_loss:0.0015674891504224647 test_acc:0.9480818414322251 val loss:0.26249550918963177 acc:0.9482608695652174\n",
      "0.24561171186147426\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.01,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "80c01726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.629854917526245: train_loss:0.14973734327446533 test_acc:0.917774936061381 val loss:0.2866384447369292 acc:0.9182608695652174\n",
      "77.19422960281372: train_loss:0.06410900827497469 test_acc:0.9309462915601023 val loss:0.26436951588728297 acc:0.9295652173913044\n",
      "112.67437815666199: train_loss:0.02381636184129077 test_acc:0.9346547314578005 val loss:0.263800962846603 acc:0.9408695652173913\n",
      "149.66728401184082: train_loss:0.0038204634161079646 test_acc:0.949616368286445 val loss:0.24482140556015136 acc:0.95\n",
      "185.07041835784912: train_loss:0.0008468743716388611 test_acc:0.9523017902813299 val loss:0.23689611706756003 acc:0.9552173913043478\n",
      "218.83436393737793: train_loss:0.0006521076395288145 test_acc:0.9528132992327366 val loss:0.24406591513150008 acc:0.9530434782608695\n",
      "252.06135845184326: train_loss:0.0005647578563364955 test_acc:0.9535805626598466 val loss:0.24873094664510212 acc:0.9534782608695652\n",
      "269.20358657836914: train_loss:0.0005367949917437183 test_acc:0.9537084398976982 val loss:0.25062268733771725 acc:0.9539130434782609\n",
      "278.45361518859863: train_loss:0.0005249468428233897 test_acc:0.9537084398976982 val loss:0.25150434602406724 acc:0.9539130434782609\n",
      "287.7216010093689: train_loss:0.0005142926026638209 test_acc:0.9537084398976982 val loss:0.2523275989603587 acc:0.9539130434782609\n",
      "303.0403685569763: train_loss:0.0005049606856924889 test_acc:0.9537084398976982 val loss:0.25312757244927525 acc:0.9539130434782609\n",
      "0.24787140068736463\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.02,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5c4391b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.25514054298401: train_loss:0.26547285027025863 test_acc:0.9019181585677749 val loss:0.3676401966293095 acc:0.8995652173913044\n",
      "76.42666268348694: train_loss:0.13583169584825758 test_acc:0.9216112531969309 val loss:0.2870738112762597 acc:0.9217391304347826\n",
      "106.54511022567749: train_loss:0.07839401196628214 test_acc:0.9312020460358056 val loss:0.26385320926774375 acc:0.9297826086956522\n",
      "136.76750683784485: train_loss:0.04172269813032992 test_acc:0.9352941176470588 val loss:0.24596626678208153 acc:0.9360869565217391\n",
      "166.99532628059387: train_loss:0.02335890719801453 test_acc:0.939386189258312 val loss:0.2416835019141257 acc:0.9369565217391305\n",
      "199.2639935016632: train_loss:0.015903610137241335 test_acc:0.9410485933503836 val loss:0.2477999308542595 acc:0.9391304347826087\n",
      "230.70724987983704: train_loss:0.01053396650979548 test_acc:0.9427109974424552 val loss:0.2484263353787227 acc:0.9391304347826087\n",
      "260.8614149093628: train_loss:0.007443752343327421 test_acc:0.9437340153452686 val loss:0.24940487301504707 acc:0.9417391304347826\n",
      "269.27876019477844: train_loss:0.006941291618634362 test_acc:0.9439897698209718 val loss:0.2499056253057668 acc:0.9426086956521739\n",
      "277.8000500202179: train_loss:0.006511275764316546 test_acc:0.9442455242966752 val loss:0.2504130114007961 acc:0.9432608695652174\n",
      "286.21310472488403: train_loss:0.00613908528931101 test_acc:0.9447570332480818 val loss:0.2509614764932563 acc:0.9441304347826087\n",
      "288.2731018066406: train_loss:0.00670227578629414 test_acc:0.9451406649616368 val loss:0.2521248913944765 acc:0.9458695652173913\n",
      "290.03348660469055: train_loss:0.006519311508428847 test_acc:0.9453964194373402 val loss:0.25112732224985207 acc:0.9458695652173913\n",
      "291.7934844493866: train_loss:0.00633539533227832 test_acc:0.9455242966751918 val loss:0.25029584532757165 acc:0.9452173913043478\n",
      "301.79818081855774: train_loss:0.005805639625939126 test_acc:0.9455242966751918 val loss:0.25152622551112896 acc:0.943695652173913\n",
      "0.2285636174027701\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.01,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b91b9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.25674080848694: train_loss:0.11490916211742856 test_acc:0.9226342710997443 val loss:0.2760795054470436 acc:0.9202173913043479\n",
      "76.42368483543396: train_loss:0.04651299090993473 test_acc:0.9332480818414323 val loss:0.26113418242471415 acc:0.933695652173913\n",
      "106.49452376365662: train_loss:0.009411723296352568 test_acc:0.9480818414322251 val loss:0.220510712200291 acc:0.9506521739130435\n",
      "136.65159440040588: train_loss:0.002260232293768041 test_acc:0.9524296675191816 val loss:0.21149507305992787 acc:0.9539130434782609\n",
      "166.75990414619446: train_loss:0.0015522928052144724 test_acc:0.9530690537084399 val loss:0.21565025150355815 acc:0.955\n",
      "196.99534225463867: train_loss:0.0012359357578498394 test_acc:0.9535805626598466 val loss:0.21851838821090122 acc:0.9554347826086956\n",
      "234.11841750144958: train_loss:0.0010096598671228204 test_acc:0.9539641943734015 val loss:0.22129908457477376 acc:0.9552173913043478\n",
      "264.6541676521301: train_loss:0.000892391122512749 test_acc:0.9542199488491049 val loss:0.2232681821314153 acc:0.9545652173913044\n",
      "273.1069414615631: train_loss:0.000868222015435566 test_acc:0.9542199488491049 val loss:0.22372424572124383 acc:0.9545652173913044\n",
      "281.55573534965515: train_loss:0.0008461227644315396 test_acc:0.9542199488491049 val loss:0.22416650205307906 acc:0.9543478260869566\n",
      "296.94103264808655: train_loss:0.0008256065441009477 test_acc:0.9542199488491049 val loss:0.2245931203864599 acc:0.9543478260869566\n",
      "305.47786712646484: train_loss:0.0008063650181013591 test_acc:0.9542199488491049 val loss:0.22499895233157846 acc:0.9543478260869566\n",
      "0.22306396101942116\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.03,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ea095afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.18994998931885: train_loss:0.09048313945513242 test_acc:0.934 val loss:0.2540797840470409 acc:0.9291304347826087\n",
      "78.24106574058533: train_loss:0.024677674065927375 test_acc:0.9433333333333334 val loss:0.24465243997647765 acc:0.9391304347826087\n",
      "109.93901586532593: train_loss:0.00547697772914037 test_acc:0.9463333333333334 val loss:0.2266004035058861 acc:0.9482608695652174\n",
      "140.68196845054626: train_loss:0.0017388076438267417 test_acc:0.952 val loss:0.22978980232542034 acc:0.9510869565217391\n",
      "171.91992330551147: train_loss:0.0012290047436839479 test_acc:0.9526666666666667 val loss:0.23463363819529306 acc:0.9515217391304348\n",
      "206.27187156677246: train_loss:0.000912465192029155 test_acc:0.9526666666666667 val loss:0.23907420479929006 acc:0.952391304347826\n",
      "240.61181926727295: train_loss:0.0007247172287255706 test_acc:0.9526666666666667 val loss:0.24244173023852109 acc:0.9530434782608695\n",
      "268.3977711200714: train_loss:0.0006213314944791805 test_acc:0.9526666666666667 val loss:0.24469004210527898 acc:0.9528260869565217\n",
      "276.8117587566376: train_loss:0.0005996484697107606 test_acc:0.9526666666666667 val loss:0.2452446341965539 acc:0.9526086956521739\n",
      "284.5577483177185: train_loss:0.0005796195747527971 test_acc:0.9526666666666667 val loss:0.24575027236594282 acc:0.9526086956521739\n",
      "298.7207262516022: train_loss:0.0005608146008441829 test_acc:0.9526666666666667 val loss:0.2462471688653411 acc:0.9530434782608695\n",
      "306.5447142124176: train_loss:0.0005430392581995563 test_acc:0.9526666666666667 val loss:0.24673467609189037 acc:0.9530434782608695\n",
      "0.24955205868736516\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-3000],y[:-3000],X[-3000:],y[-3000:],.03,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d510d1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.46494698524475: train_loss:0.0936535790818405 test_acc:0.9310869565217391 val loss:0.24240935069963065 acc:0.9302173913043478\n",
      "79.53789353370667: train_loss:0.031804517378189186 test_acc:0.9410869565217391 val loss:0.24706425107917895 acc:0.9395652173913044\n",
      "114.30884146690369: train_loss:0.00366805510867973 test_acc:0.9532608695652174 val loss:0.21660787235456638 acc:0.9502173913043478\n",
      "150.3997881412506: train_loss:0.0017304294491060823 test_acc:0.9532608695652174 val loss:0.21924960090084714 acc:0.9528260869565217\n",
      "185.64973521232605: train_loss:0.0013308191785239526 test_acc:0.9534782608695652 val loss:0.22268984374903747 acc:0.9530434782608695\n",
      "221.66668057441711: train_loss:0.00110922137339981 test_acc:0.9534782608695652 val loss:0.2253790800430979 acc:0.9541304347826087\n",
      "256.9666426181793: train_loss:0.0009670380205599357 test_acc:0.953695652173913 val loss:0.22761275025360103 acc:0.9543478260869566\n",
      "264.9406313896179: train_loss:0.0009448331965669297 test_acc:0.953695652173913 val loss:0.22801509099820727 acc:0.9541304347826087\n",
      "272.85661911964417: train_loss:0.0009242322369712589 test_acc:0.953695652173913 val loss:0.22842672122853172 acc:0.9543478260869566\n",
      "280.53160667419434: train_loss:0.0009048309290686033 test_acc:0.953695652173913 val loss:0.2288294465768843 acc:0.9541304347826087\n",
      "292.1695899963379: train_loss:0.0008868053583294611 test_acc:0.953695652173913 val loss:0.2292262158692045 acc:0.9541304347826087\n",
      "301.87557578086853: train_loss:0.0008698342127274163 test_acc:0.953695652173913 val loss:0.22962043259835557 acc:0.9543478260869566\n",
      "0.22872226357561046\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(150,100,X[:-4600],y[:-4600],X[-4600:],y[-4600:],.03,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2b66d8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.90794014930725: train_loss:0.13978623000508275 test_acc:0.9176470588235294 val loss:0.28038170627961456 acc:0.9189130434782609\n",
      "83.65839409828186: train_loss:0.06153740115158231 test_acc:0.9272378516624041 val loss:0.27053321571445393 acc:0.9273913043478261\n",
      "122.00581622123718: train_loss:0.014293695332916584 test_acc:0.9436061381074169 val loss:0.23843051103149102 acc:0.9443478260869566\n",
      "157.99660897254944: train_loss:0.0028899494741573503 test_acc:0.9489769820971867 val loss:0.22424910316043442 acc:0.9502173913043478\n",
      "194.18672633171082: train_loss:0.0019944121847373397 test_acc:0.9501278772378516 val loss:0.22818197668602133 acc:0.9515217391304348\n",
      "230.40885376930237: train_loss:0.0015934476623618314 test_acc:0.9515345268542199 val loss:0.23099691466644054 acc:0.951304347826087\n",
      "266.48199367523193: train_loss:0.0013599478811423577 test_acc:0.9516624040920716 val loss:0.23352664060274433 acc:0.9519565217391305\n",
      "276.772500038147: train_loss:0.0013173173477007611 test_acc:0.9516624040920716 val loss:0.2341558202974341 acc:0.9519565217391305\n",
      "287.1904847621918: train_loss:0.0012784881422817646 test_acc:0.9516624040920716 val loss:0.23480447632457951 acc:0.952391304347826\n",
      "303.40350341796875: train_loss:0.0012437995046774943 test_acc:0.9516624040920716 val loss:0.23541059429338637 acc:0.952391304347826\n",
      "0.22472865921113178\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(200,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],.04,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f63df35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.97894597053528: train_loss:0.07881469784647963 test_acc:0.9317391304347826 val loss:0.24895252373275512 acc:0.936304347826087\n",
      "77.25290060043335: train_loss:0.02602879182921264 test_acc:0.94 val loss:0.23231868609024267 acc:0.9421739130434783\n",
      "108.09285426139832: train_loss:0.0022034076930860656 test_acc:0.9532608695652174 val loss:0.22113495823981605 acc:0.9517391304347826\n",
      "138.74881505966187: train_loss:0.001239952464399942 test_acc:0.9534782608695652 val loss:0.22506388120688875 acc:0.952391304347826\n",
      "169.7127673625946: train_loss:0.0009042555249615498 test_acc:0.953695652173913 val loss:0.22912478048074356 acc:0.9515217391304348\n",
      "202.76022505760193: train_loss:0.0007100053947015633 test_acc:0.9539130434782609 val loss:0.232358121322313 acc:0.9517391304347826\n",
      "234.23717713356018: train_loss:0.0005839904652394818 test_acc:0.9539130434782609 val loss:0.23503607439235324 acc:0.951304347826087\n",
      "264.72213196754456: train_loss:0.0004958700878914641 test_acc:0.9539130434782609 val loss:0.2374124410998855 acc:0.951304347826087\n",
      "271.69412112236023: train_loss:0.00048128192991703396 test_acc:0.9539130434782609 val loss:0.23785932449765995 acc:0.9515217391304348\n",
      "278.62911081314087: train_loss:0.00046757480314199963 test_acc:0.9539130434782609 val loss:0.2383011209849482 acc:0.9517391304347826\n",
      "285.661101102829: train_loss:0.00045456361782041733 test_acc:0.9539130434782609 val loss:0.23869631023397372 acc:0.9517391304347826\n",
      "299.0900809764862: train_loss:0.00044235694827416197 test_acc:0.9539130434782609 val loss:0.2391401939296878 acc:0.9517391304347826\n",
      "0.22241557667991627\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(200,100,X[:-4600],y[:-4600],X[-4600:],y[-4600:],.04,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "543ecf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.643953800201416: train_loss:0.09789081658740091 test_acc:0.93 val loss:0.2615154527542008 acc:0.9304347826086956\n",
      "73.53290700912476: train_loss:0.023500941994804743 test_acc:0.9453333333333334 val loss:0.23349992886322637 acc:0.9408695652173913\n",
      "104.28686046600342: train_loss:0.0030725040454500615 test_acc:0.952 val loss:0.22754231605120012 acc:0.9497826086956521\n",
      "137.11081266403198: train_loss:0.0012639650140734537 test_acc:0.956 val loss:0.23152896976108503 acc:0.9530434782608695\n",
      "170.2477638721466: train_loss:0.000895309136175661 test_acc:0.956 val loss:0.23555572157428165 acc:0.9528260869565217\n",
      "204.72471117973328: train_loss:0.0006968105408350091 test_acc:0.9566666666666667 val loss:0.2387884069567739 acc:0.9530434782608695\n",
      "237.69266200065613: train_loss:0.0005702906052649592 test_acc:0.9566666666666667 val loss:0.24164022107513272 acc:0.9532608695652174\n",
      "265.50461983680725: train_loss:0.0004978818664100202 test_acc:0.9566666666666667 val loss:0.24364145113550298 acc:0.9534782608695652\n",
      "272.4666097164154: train_loss:0.0004827115340174977 test_acc:0.9566666666666667 val loss:0.24413628386407535 acc:0.9534782608695652\n",
      "279.4125974178314: train_loss:0.0004682671385923708 test_acc:0.9566666666666667 val loss:0.24458357994903301 acc:0.9534782608695652\n",
      "286.43058705329895: train_loss:0.0004546479029328781 test_acc:0.9566666666666667 val loss:0.245026321245677 acc:0.9534782608695652\n",
      "299.7375671863556: train_loss:0.00044184993982496673 test_acc:0.9566666666666667 val loss:0.2454610980316217 acc:0.9534782608695652\n",
      "0.22127399027618594\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_mom(200,100,X[:-3000],y[:-3000],X[-3000:],y[-3000:],.04,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8cd96923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.175949811935425: train_loss:0.14233548078646738 test_acc:0.9062659846547314 val loss:0.35983846701693517 acc:0.9069565217391304\n",
      "76.70089888572693: train_loss:0.05031158287521853 test_acc:0.9228900255754475 val loss:0.37630741341667023 acc:0.9215217391304348\n",
      "110.11784934997559: train_loss:0.027229892134822874 test_acc:0.9258312020460358 val loss:0.4123399667708028 acc:0.925\n",
      "143.53679943084717: train_loss:0.030734953829462452 test_acc:0.9271099744245525 val loss:0.4857495686806458 acc:0.9252173913043479\n",
      "177.34074759483337: train_loss:0.028594697174064612 test_acc:0.9287723785166241 val loss:0.4723198054002998 acc:0.9315217391304348\n",
      "211.3806962966919: train_loss:0.028956470546354314 test_acc:0.9287723785166241 val loss:0.520832257892302 acc:0.9284782608695652\n",
      "245.4826431274414: train_loss:0.02569672724725539 test_acc:0.9287723785166241 val loss:0.5256079428386186 acc:0.9295652173913044\n",
      "269.1996080875397: train_loss:0.018520051187218618 test_acc:0.9287723785166241 val loss:0.551269604617405 acc:0.9306521739130434\n",
      "275.88759756088257: train_loss:0.022220255457647137 test_acc:0.9287723785166241 val loss:0.5600833728113397 acc:0.9306521739130434\n",
      "283.2415859699249: train_loss:0.01601192638444745 test_acc:0.9290281329923273 val loss:0.5114564957759811 acc:0.9360869565217391\n",
      "288.0475788116455: train_loss:0.0188712442546356 test_acc:0.929156010230179 val loss:0.5486683254963208 acc:0.9354347826086956\n",
      "289.8995769023895: train_loss:0.01720942606448433 test_acc:0.9295396419437341 val loss:0.5328113601314368 acc:0.936304347826087\n",
      "297.14756536483765: train_loss:0.012825323481664586 test_acc:0.9313299232736573 val loss:0.5747505870167873 acc:0.9315217391304348\n",
      "304.2865540981293: train_loss:0.020801703699282668 test_acc:0.9313299232736573 val loss:0.5576031429080595 acc:0.9284782608695652\n",
      "0.5393583386062255\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,64,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_adam(750,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],8e-3,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0269b37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.28795075416565: train_loss:0.5052172422759501 test_acc:0.8204603580562659 val loss:0.6541471669687453 acc:0.8145652173913044\n",
      "77.4858992099762: train_loss:0.13428203408888717 test_acc:0.9076726342710998 val loss:0.37395202043494924 acc:0.9067391304347826\n",
      "107.70585370063782: train_loss:0.06396408015746953 test_acc:0.921227621483376 val loss:0.3493682818516102 acc:0.9241304347826087\n",
      "143.25080394744873: train_loss:0.05940466803692268 test_acc:0.9230179028132992 val loss:0.4003668890340231 acc:0.9208695652173913\n",
      "176.7117531299591: train_loss:0.037368625338639376 test_acc:0.9276214833759591 val loss:0.4254416753691534 acc:0.9191304347826087\n",
      "211.70470142364502: train_loss:0.04016745921203442 test_acc:0.928388746803069 val loss:0.4306455568936109 acc:0.9223913043478261\n",
      "246.09364819526672: train_loss:0.02211348724304685 test_acc:0.9327365728900255 val loss:0.4332278720987436 acc:0.9284782608695652\n",
      "267.38361620903015: train_loss:0.01880379354618827 test_acc:0.9327365728900255 val loss:0.42972465804217896 acc:0.927608695652174\n",
      "275.43660402297974: train_loss:0.022643347956420857 test_acc:0.9327365728900255 val loss:0.4467279277386673 acc:0.9232608695652174\n",
      "283.61659121513367: train_loss:0.027101061317347516 test_acc:0.9327365728900255 val loss:0.47921793455590345 acc:0.9247826086956522\n",
      "298.439569234848: train_loss:0.01980755282142982 test_acc:0.9327365728900255 val loss:0.4359968124720746 acc:0.9258695652173913\n",
      "0.38236406631730824\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,64,46],0,1024,0)\n",
    "t=10\n",
    "loss=a.fit_rmsprop(450,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],8e-3,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49b1e795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.73895454406738: train_loss:0.0871873273039065 test_acc:0.9226342710997443 val loss:0.2910229475363546 acc:0.9208695652173913\n",
      "72.50990581512451: train_loss:0.019679890787943383 test_acc:0.9340153452685422 val loss:0.27231522293632543 acc:0.9391304347826087\n",
      "103.9488570690155: train_loss:0.007694698455458168 test_acc:0.9359335038363171 val loss:0.27132242237580456 acc:0.941304347826087\n",
      "134.9597990512848: train_loss:0.004581719227916861 test_acc:0.9375959079283888 val loss:0.2769035205505894 acc:0.9419565217391305\n",
      "165.06175589561462: train_loss:0.0033308313801123065 test_acc:0.9377237851662404 val loss:0.28275555805666885 acc:0.9404347826086956\n",
      "196.3687093257904: train_loss:0.002516797746965468 test_acc:0.9382352941176471 val loss:0.28826842820254023 acc:0.941304347826087\n",
      "227.49765539169312: train_loss:0.0020188798768587327 test_acc:0.9383631713554987 val loss:0.29289913906878445 acc:0.9410869565217391\n",
      "257.86660957336426: train_loss:0.001717757028334523 test_acc:0.9387468030690537 val loss:0.2963741695115105 acc:0.941304347826087\n",
      "264.58959889411926: train_loss:0.0016634254349857202 test_acc:0.9388746803069054 val loss:0.2970742075221833 acc:0.941304347826087\n",
      "268.2005937099457: train_loss:0.0016377694956989524 test_acc:0.9388746803069054 val loss:0.2974548325117718 acc:0.941304347826087\n",
      "272.0305881500244: train_loss:0.0016132184853620243 test_acc:0.9388746803069054 val loss:0.2978040678642811 acc:0.9415217391304348\n",
      "275.5675826072693: train_loss:0.0015891147036610636 test_acc:0.9391304347826087 val loss:0.2981533165011344 acc:0.9417391304347826\n",
      "279.1085774898529: train_loss:0.0015654209687663682 test_acc:0.9391304347826087 val loss:0.2984834244226574 acc:0.9419565217391305\n",
      "282.9295723438263: train_loss:0.0015432309075595375 test_acc:0.9391304347826087 val loss:0.2987915502598592 acc:0.9419565217391305\n",
      "286.51356649398804: train_loss:0.0015211275512822281 test_acc:0.9391304347826087 val loss:0.2991350024811756 acc:0.9419565217391305\n",
      "296.8035514354706: train_loss:0.0015005087055582293 test_acc:0.9391304347826087 val loss:0.2994889490663067 acc:0.9419565217391305\n",
      "300.4245455265045: train_loss:0.00147993855077281 test_acc:0.9391304347826087 val loss:0.29982438506087145 acc:0.9419565217391305\n",
      "0.28947920470269\n"
     ]
    }
   ],
   "source": [
    "a=ANN([256,46],2,1024,0)\n",
    "t=10\n",
    "loss=a.fit_nag(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],2e-2,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c66a4fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.03195142745972: train_loss:0.7472613574130109 test_acc:0.7631713554987213 val loss:0.8293718830511755 acc:0.7697826086956522\n",
      "78.78189516067505: train_loss:0.21710062208852707 test_acc:0.890153452685422 val loss:0.39558821765781665 acc:0.8913043478260869\n",
      "112.49584436416626: train_loss:0.11209192308764163 test_acc:0.9006393861892583 val loss:0.3508727309950269 acc:0.9060869565217391\n",
      "146.3507936000824: train_loss:0.08211634992038495 test_acc:0.9028132992327366 val loss:0.3562742009247172 acc:0.9102173913043479\n",
      "180.12274289131165: train_loss:0.07296569045168307 test_acc:0.9049872122762148 val loss:0.39074377108223535 acc:0.9082608695652173\n",
      "214.00669121742249: train_loss:0.04646988334280291 test_acc:0.9126598465473146 val loss:0.37387951983782064 acc:0.9156521739130434\n",
      "247.88063979148865: train_loss:0.04010982625979221 test_acc:0.9164961636828645 val loss:0.37997418393328264 acc:0.917608695652174\n",
      "265.5986144542694: train_loss:0.04416628729279405 test_acc:0.9164961636828645 val loss:0.4039757583494758 acc:0.9141304347826087\n",
      "283.40658688545227: train_loss:0.04050890915108762 test_acc:0.9164961636828645 val loss:0.3813590058821801 acc:0.9193478260869565\n",
      "288.0045795440674: train_loss:0.027819467937549393 test_acc:0.9168797953964194 val loss:0.3733765592163195 acc:0.921304347826087\n",
      "290.18257665634155: train_loss:0.02602201909445279 test_acc:0.9180306905370844 val loss:0.37136113654514313 acc:0.9215217391304348\n",
      "308.2575492858887: train_loss:0.06047071142119343 test_acc:0.9180306905370844 val loss:0.4527726898132164 acc:0.9119565217391304\n",
      "0.3957219653198387\n"
     ]
    }
   ],
   "source": [
    "a=ANN([512,256,128,64,46],0,1024,0)\n",
    "t=10\n",
    "loss=a.fit_nadam(150,100,X[:-7820],y[:-7820],X[-7820:],y[-7820:],8e-3,t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b155168f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shubham)",
   "language": "python",
   "name": "shubham"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
